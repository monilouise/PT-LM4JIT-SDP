{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXwsMaLhK0Oo"
   },
   "source": [
    "# Fine-tuning Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dq7W5OJOK_dA",
    "outputId": "a3b476d6-29d1-40eb-ea85-5c3c3f665705"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/monilouise/PEFT4CC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY6b3cGYLC7Z",
    "outputId": "4ac4b25f-7cbe-4ec7-e847-9930457bf75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEwNZzuJOCG0",
    "outputId": "c7557d8a-b1cd-4398-a16e-7409b264b6a1"
   },
   "outputs": [],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kP5dg0pROYyt",
    "outputId": "c0025679-a6c4-4f72-df5a-870dee3c54d1"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/thunlp/OpenDelta.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWTPQxgP0_D0"
   },
   "source": [
    "## JITDefects4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TCMB2zOFLKfM"
   },
   "outputs": [],
   "source": [
    "path = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nis054awwn4G"
   },
   "source": [
    "### Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daoKtyPnwpv9",
    "outputId": "ea555c30-7718-4b20-a440-c6b5e9debb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 16374\n",
      "Valid: 5465\n",
      "Test: 5480\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "features_train = f\"{path}/features_train.pkl\"\n",
    "\n",
    "with open(features_train, 'rb') as f:\n",
    "    features_train = pickle.load(f)\n",
    "\n",
    "features_valid = f\"{path}/features_valid.pkl\"\n",
    "\n",
    "with open(features_valid, 'rb') as f:\n",
    "    features_valid = pickle.load(f)\n",
    "\n",
    "features_test = f\"{path}/features_test.pkl\"\n",
    "\n",
    "with open(features_test, 'rb') as f:\n",
    "    features_test = pickle.load(f)\n",
    "\n",
    "print(f'Train: {len(features_train)}')\n",
    "print(f'Valid: {len(features_valid)}')\n",
    "print(f'Test: {len(features_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mE13J3skSyy"
   },
   "source": [
    "## Raw baseline (without my changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ishuoliu/PEFT4CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpkqEej7kxMw",
    "outputId": "c4161b30-4c0b-43af-d4d8-e6cd8dacf10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:57:17.964301: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 22:57:17.982740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744585038.004974    9368 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744585038.011745    9368 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-13 22:57:18.034146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:43<02:54,  2.35it/s]04/13/2025 23:00:22 - WARNING - __main__ - epoch 0 step 102 loss 0.30161\n",
      "[[0.47029474]\n",
      " [0.10442378]\n",
      " [0.14895575]\n",
      " ...\n",
      " [0.13648011]\n",
      " [0.18749881]\n",
      " [0.13603453]]\n",
      "04/13/2025 23:00:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:00:55 - INFO - __main__ -   auc_score = 0.8024\n",
      "04/13/2025 23:00:55 - INFO - __main__ -   eval_f1 = 0.0169\n",
      "04/13/2025 23:00:55 - INFO - __main__ -   eval_precision = 0.6667\n",
      "04/13/2025 23:00:55 - INFO - __main__ -   eval_recall = 0.0086\n",
      " 40% 203/512 [02:01<02:11,  2.35it/s]04/13/2025 23:01:40 - WARNING - __main__ - epoch 0 step 204 loss 0.24292\n",
      "[[0.6774378 ]\n",
      " [0.06257121]\n",
      " [0.12229461]\n",
      " ...\n",
      " [0.15755749]\n",
      " [0.17736666]\n",
      " [0.1446501 ]]\n",
      "04/13/2025 23:02:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:02:13 - INFO - __main__ -   auc_score = 0.8566\n",
      "04/13/2025 23:02:13 - INFO - __main__ -   eval_f1 = 0.1626\n",
      "04/13/2025 23:02:13 - INFO - __main__ -   eval_precision = 0.6935\n",
      "04/13/2025 23:02:13 - INFO - __main__ -   eval_recall = 0.0921\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/13/2025 23:02:57 - WARNING - __main__ - epoch 0 step 306 loss 0.21018\n",
      "[[0.75695974]\n",
      " [0.08135325]\n",
      " [0.11178543]\n",
      " ...\n",
      " [0.2421766 ]\n",
      " [0.15125611]\n",
      " [0.14966123]]\n",
      "04/13/2025 23:03:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:03:30 - INFO - __main__ -   auc_score = 0.886\n",
      "04/13/2025 23:03:30 - INFO - __main__ -   eval_f1 = 0.2338\n",
      "04/13/2025 23:03:30 - INFO - __main__ -   eval_precision = 0.7303\n",
      "04/13/2025 23:03:30 - INFO - __main__ -   eval_recall = 0.1392\n",
      " 79% 407/512 [04:36<00:44,  2.35it/s]04/13/2025 23:04:15 - WARNING - __main__ - epoch 0 step 408 loss 0.21163\n",
      "[[0.8998394 ]\n",
      " [0.23400387]\n",
      " [0.21853629]\n",
      " ...\n",
      " [0.341541  ]\n",
      " [0.34517547]\n",
      " [0.28996754]]\n",
      "04/13/2025 23:04:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:04:48 - INFO - __main__ -   auc_score = 0.8995\n",
      "04/13/2025 23:04:48 - INFO - __main__ -   eval_f1 = 0.4286\n",
      "04/13/2025 23:04:48 - INFO - __main__ -   eval_precision = 0.6712\n",
      "04/13/2025 23:04:48 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 99% 509/512 [05:53<00:01,  2.35it/s]04/13/2025 23:05:32 - WARNING - __main__ - epoch 0 step 510 loss 0.19239\n",
      "[[0.8800667 ]\n",
      " [0.23800027]\n",
      " [0.1521076 ]\n",
      " ...\n",
      " [0.20352262]\n",
      " [0.21733186]\n",
      " [0.15985155]]\n",
      "04/13/2025 23:06:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:06:05 - INFO - __main__ -   auc_score = 0.903\n",
      "04/13/2025 23:06:05 - INFO - __main__ -   eval_f1 = 0.3866\n",
      "04/13/2025 23:06:05 - INFO - __main__ -   eval_precision = 0.761\n",
      "04/13/2025 23:06:05 - INFO - __main__ -   eval_recall = 0.2591\n",
      "100% 512/512 [06:27<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/13/2025 23:06:49 - WARNING - __main__ - epoch 1 step 102 loss 0.21087\n",
      "[[0.8794166 ]\n",
      " [0.28680828]\n",
      " [0.17927603]\n",
      " ...\n",
      " [0.19784547]\n",
      " [0.18217258]\n",
      " [0.13169433]]\n",
      "04/13/2025 23:07:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:07:22 - INFO - __main__ -   auc_score = 0.9059\n",
      "04/13/2025 23:07:22 - INFO - __main__ -   eval_f1 = 0.3968\n",
      "04/13/2025 23:07:22 - INFO - __main__ -   eval_precision = 0.7669\n",
      "04/13/2025 23:07:22 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:08:06 - WARNING - __main__ - epoch 1 step 204 loss 0.18456\n",
      "[[0.9141264 ]\n",
      " [0.281267  ]\n",
      " [0.12933114]\n",
      " ...\n",
      " [0.20541485]\n",
      " [0.18688984]\n",
      " [0.13976815]]\n",
      "04/13/2025 23:08:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:08:39 - INFO - __main__ -   auc_score = 0.9085\n",
      "04/13/2025 23:08:39 - INFO - __main__ -   eval_f1 = 0.4353\n",
      "04/13/2025 23:08:39 - INFO - __main__ -   eval_precision = 0.7526\n",
      "04/13/2025 23:08:39 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/13/2025 23:09:23 - WARNING - __main__ - epoch 1 step 306 loss 0.177\n",
      "[[0.9483756 ]\n",
      " [0.35153738]\n",
      " [0.18697515]\n",
      " ...\n",
      " [0.20295618]\n",
      " [0.20053786]\n",
      " [0.13593905]]\n",
      "04/13/2025 23:09:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:09:56 - INFO - __main__ -   auc_score = 0.9102\n",
      "04/13/2025 23:09:56 - INFO - __main__ -   eval_f1 = 0.4676\n",
      "04/13/2025 23:09:56 - INFO - __main__ -   eval_precision = 0.7465\n",
      "04/13/2025 23:09:56 - INFO - __main__ -   eval_recall = 0.3405\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/13/2025 23:10:41 - WARNING - __main__ - epoch 1 step 408 loss 0.17486\n",
      "[[0.9199094 ]\n",
      " [0.2626571 ]\n",
      " [0.13208516]\n",
      " ...\n",
      " [0.24612086]\n",
      " [0.26855943]\n",
      " [0.16603872]]\n",
      "04/13/2025 23:11:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:11:14 - INFO - __main__ -   auc_score = 0.9119\n",
      "04/13/2025 23:11:14 - INFO - __main__ -   eval_f1 = 0.4624\n",
      "04/13/2025 23:11:14 - INFO - __main__ -   eval_precision = 0.7406\n",
      "04/13/2025 23:11:14 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 99% 509/512 [05:50<00:01,  2.34it/s]04/13/2025 23:11:57 - WARNING - __main__ - epoch 1 step 510 loss 0.17636\n",
      "[[0.88579744]\n",
      " [0.3088301 ]\n",
      " [0.08949807]\n",
      " ...\n",
      " [0.20449169]\n",
      " [0.13468191]\n",
      " [0.10094674]]\n",
      "04/13/2025 23:12:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:12:30 - INFO - __main__ -   auc_score = 0.9093\n",
      "04/13/2025 23:12:30 - INFO - __main__ -   eval_f1 = 0.4252\n",
      "04/13/2025 23:12:30 - INFO - __main__ -   eval_precision = 0.8036\n",
      "04/13/2025 23:12:30 - INFO - __main__ -   eval_recall = 0.2891\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/13/2025 23:13:14 - WARNING - __main__ - epoch 2 step 102 loss 0.17317\n",
      "[[0.9378508 ]\n",
      " [0.3723017 ]\n",
      " [0.09867793]\n",
      " ...\n",
      " [0.25347483]\n",
      " [0.1756222 ]\n",
      " [0.15181863]]\n",
      "04/13/2025 23:13:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:13:47 - INFO - __main__ -   auc_score = 0.9103\n",
      "04/13/2025 23:13:47 - INFO - __main__ -   eval_f1 = 0.495\n",
      "04/13/2025 23:13:47 - INFO - __main__ -   eval_precision = 0.7457\n",
      "04/13/2025 23:13:47 - INFO - __main__ -   eval_recall = 0.3704\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/13/2025 23:14:31 - WARNING - __main__ - epoch 2 step 204 loss 0.17288\n",
      "[[0.9288383 ]\n",
      " [0.27370405]\n",
      " [0.09322064]\n",
      " ...\n",
      " [0.22561204]\n",
      " [0.17259635]\n",
      " [0.12332728]]\n",
      "04/13/2025 23:15:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:15:04 - INFO - __main__ -   auc_score = 0.9132\n",
      "04/13/2025 23:15:04 - INFO - __main__ -   eval_f1 = 0.4702\n",
      "04/13/2025 23:15:04 - INFO - __main__ -   eval_precision = 0.7707\n",
      "04/13/2025 23:15:04 - INFO - __main__ -   eval_recall = 0.3383\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/13/2025 23:15:48 - WARNING - __main__ - epoch 2 step 306 loss 0.15334\n",
      "[[0.93955183]\n",
      " [0.353028  ]\n",
      " [0.1331902 ]\n",
      " ...\n",
      " [0.2774655 ]\n",
      " [0.2654626 ]\n",
      " [0.15194823]]\n",
      "04/13/2025 23:16:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:16:21 - INFO - __main__ -   auc_score = 0.9148\n",
      "04/13/2025 23:16:21 - INFO - __main__ -   eval_f1 = 0.5129\n",
      "04/13/2025 23:16:21 - INFO - __main__ -   eval_precision = 0.7749\n",
      "04/13/2025 23:16:21 - INFO - __main__ -   eval_recall = 0.3833\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/13/2025 23:17:05 - WARNING - __main__ - epoch 2 step 408 loss 0.18226\n",
      "[[0.9145029 ]\n",
      " [0.36068338]\n",
      " [0.08449152]\n",
      " ...\n",
      " [0.19405805]\n",
      " [0.19180988]\n",
      " [0.09623093]]\n",
      "04/13/2025 23:17:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:17:38 - INFO - __main__ -   auc_score = 0.9119\n",
      "04/13/2025 23:17:38 - INFO - __main__ -   eval_f1 = 0.5124\n",
      "04/13/2025 23:17:38 - INFO - __main__ -   eval_precision = 0.8102\n",
      "04/13/2025 23:17:38 - INFO - __main__ -   eval_recall = 0.3747\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/13/2025 23:18:21 - WARNING - __main__ - epoch 2 step 510 loss 0.17094\n",
      "[[0.96365374]\n",
      " [0.5035222 ]\n",
      " [0.1958833 ]\n",
      " ...\n",
      " [0.22521378]\n",
      " [0.31640163]\n",
      " [0.14917392]]\n",
      "04/13/2025 23:18:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:18:54 - INFO - __main__ -   auc_score = 0.9156\n",
      "04/13/2025 23:18:54 - INFO - __main__ -   eval_f1 = 0.5539\n",
      "04/13/2025 23:18:54 - INFO - __main__ -   eval_precision = 0.7324\n",
      "04/13/2025 23:18:54 - INFO - __main__ -   eval_recall = 0.4454\n",
      "100% 512/512 [06:25<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/13/2025 23:19:40 - WARNING - __main__ - epoch 3 step 102 loss 0.14775\n",
      "[[0.9811792 ]\n",
      " [0.5315911 ]\n",
      " [0.16023073]\n",
      " ...\n",
      " [0.34406966]\n",
      " [0.43004203]\n",
      " [0.26596466]]\n",
      "04/13/2025 23:20:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:20:13 - INFO - __main__ -   auc_score = 0.916\n",
      "04/13/2025 23:20:13 - INFO - __main__ -   eval_f1 = 0.5673\n",
      "04/13/2025 23:20:13 - INFO - __main__ -   eval_precision = 0.6398\n",
      "04/13/2025 23:20:13 - INFO - __main__ -   eval_recall = 0.5096\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/13/2025 23:20:57 - WARNING - __main__ - epoch 3 step 204 loss 0.17038\n",
      "[[0.96041703]\n",
      " [0.5419521 ]\n",
      " [0.15216605]\n",
      " ...\n",
      " [0.22953494]\n",
      " [0.24772656]\n",
      " [0.13566123]]\n",
      "04/13/2025 23:21:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:21:30 - INFO - __main__ -   auc_score = 0.9156\n",
      "04/13/2025 23:21:30 - INFO - __main__ -   eval_f1 = 0.582\n",
      "04/13/2025 23:21:30 - INFO - __main__ -   eval_precision = 0.7612\n",
      "04/13/2025 23:21:30 - INFO - __main__ -   eval_recall = 0.4711\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/13/2025 23:22:15 - WARNING - __main__ - epoch 3 step 306 loss 0.17445\n",
      "[[0.9689626 ]\n",
      " [0.45827878]\n",
      " [0.13098204]\n",
      " ...\n",
      " [0.3027508 ]\n",
      " [0.27962697]\n",
      " [0.18492621]]\n",
      "04/13/2025 23:22:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:22:48 - INFO - __main__ -   auc_score = 0.916\n",
      "04/13/2025 23:22:48 - INFO - __main__ -   eval_f1 = 0.558\n",
      "04/13/2025 23:22:48 - INFO - __main__ -   eval_precision = 0.7527\n",
      "04/13/2025 23:22:48 - INFO - __main__ -   eval_recall = 0.4433\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/13/2025 23:23:31 - WARNING - __main__ - epoch 3 step 408 loss 0.15348\n",
      "[[0.9674221 ]\n",
      " [0.40894517]\n",
      " [0.10759453]\n",
      " ...\n",
      " [0.22402607]\n",
      " [0.22620037]\n",
      " [0.11599231]]\n",
      "04/13/2025 23:24:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:24:04 - INFO - __main__ -   auc_score = 0.9163\n",
      "04/13/2025 23:24:04 - INFO - __main__ -   eval_f1 = 0.5572\n",
      "04/13/2025 23:24:04 - INFO - __main__ -   eval_precision = 0.75\n",
      "04/13/2025 23:24:04 - INFO - __main__ -   eval_recall = 0.4433\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/13/2025 23:24:47 - WARNING - __main__ - epoch 3 step 510 loss 0.1547\n",
      "[[0.9732362 ]\n",
      " [0.54696137]\n",
      " [0.16687037]\n",
      " ...\n",
      " [0.23868355]\n",
      " [0.28155416]\n",
      " [0.12592357]]\n",
      "04/13/2025 23:25:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:25:20 - INFO - __main__ -   auc_score = 0.9182\n",
      "04/13/2025 23:25:20 - INFO - __main__ -   eval_f1 = 0.5869\n",
      "04/13/2025 23:25:20 - INFO - __main__ -   eval_precision = 0.7125\n",
      "04/13/2025 23:25:20 - INFO - __main__ -   eval_recall = 0.4989\n",
      "100% 512/512 [06:25<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/13/2025 23:26:06 - WARNING - __main__ - epoch 4 step 102 loss 0.15672\n",
      "[[0.97679794]\n",
      " [0.39922598]\n",
      " [0.11582715]\n",
      " ...\n",
      " [0.29259777]\n",
      " [0.31805438]\n",
      " [0.14436923]]\n",
      "04/13/2025 23:26:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:26:39 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/13/2025 23:26:39 - INFO - __main__ -   eval_f1 = 0.5793\n",
      "04/13/2025 23:26:39 - INFO - __main__ -   eval_precision = 0.6946\n",
      "04/13/2025 23:26:39 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:27:22 - WARNING - __main__ - epoch 4 step 204 loss 0.14723\n",
      "[[0.978219  ]\n",
      " [0.5081202 ]\n",
      " [0.08593033]\n",
      " ...\n",
      " [0.21024007]\n",
      " [0.08327234]\n",
      " [0.05660181]]\n",
      "04/13/2025 23:27:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:27:55 - INFO - __main__ -   auc_score = 0.913\n",
      "04/13/2025 23:27:55 - INFO - __main__ -   eval_f1 = 0.5718\n",
      "04/13/2025 23:27:55 - INFO - __main__ -   eval_precision = 0.7544\n",
      "04/13/2025 23:27:55 - INFO - __main__ -   eval_recall = 0.4604\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/13/2025 23:28:38 - WARNING - __main__ - epoch 4 step 306 loss 0.14394\n",
      "[[0.96801233]\n",
      " [0.4527022 ]\n",
      " [0.04206291]\n",
      " ...\n",
      " [0.09897399]\n",
      " [0.06917869]\n",
      " [0.04174068]]\n",
      "04/13/2025 23:29:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:29:11 - INFO - __main__ -   auc_score = 0.9122\n",
      "04/13/2025 23:29:11 - INFO - __main__ -   eval_f1 = 0.4793\n",
      "04/13/2025 23:29:11 - INFO - __main__ -   eval_precision = 0.8478\n",
      "04/13/2025 23:29:11 - INFO - __main__ -   eval_recall = 0.334\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/13/2025 23:29:54 - WARNING - __main__ - epoch 4 step 408 loss 0.14821\n",
      "[[0.98622745]\n",
      " [0.5956672 ]\n",
      " [0.09745843]\n",
      " ...\n",
      " [0.2061189 ]\n",
      " [0.27402952]\n",
      " [0.11395695]]\n",
      "04/13/2025 23:30:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:30:27 - INFO - __main__ -   auc_score = 0.917\n",
      "04/13/2025 23:30:27 - INFO - __main__ -   eval_f1 = 0.5985\n",
      "04/13/2025 23:30:27 - INFO - __main__ -   eval_precision = 0.7292\n",
      "04/13/2025 23:30:27 - INFO - __main__ -   eval_recall = 0.5075\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/13/2025 23:31:12 - WARNING - __main__ - epoch 4 step 510 loss 0.14975\n",
      "[[0.9826005 ]\n",
      " [0.53429854]\n",
      " [0.1427014 ]\n",
      " ...\n",
      " [0.2425103 ]\n",
      " [0.3062789 ]\n",
      " [0.11285675]]\n",
      "04/13/2025 23:31:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:31:45 - INFO - __main__ -   auc_score = 0.919\n",
      "04/13/2025 23:31:45 - INFO - __main__ -   eval_f1 = 0.5881\n",
      "04/13/2025 23:31:45 - INFO - __main__ -   eval_precision = 0.7205\n",
      "04/13/2025 23:31:45 - INFO - __main__ -   eval_recall = 0.4968\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/13/2025 23:32:29 - WARNING - __main__ - epoch 5 step 102 loss 0.12544\n",
      "[[0.9908874 ]\n",
      " [0.5803424 ]\n",
      " [0.11811845]\n",
      " ...\n",
      " [0.31582904]\n",
      " [0.36930752]\n",
      " [0.1390091 ]]\n",
      "04/13/2025 23:33:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:33:02 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/13/2025 23:33:02 - INFO - __main__ -   eval_f1 = 0.6069\n",
      "04/13/2025 23:33:02 - INFO - __main__ -   eval_precision = 0.6865\n",
      "04/13/2025 23:33:02 - INFO - __main__ -   eval_recall = 0.5439\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/13/2025 23:33:46 - WARNING - __main__ - epoch 5 step 204 loss 0.14495\n",
      "[[0.98619384]\n",
      " [0.58909464]\n",
      " [0.11215185]\n",
      " ...\n",
      " [0.20845088]\n",
      " [0.27362844]\n",
      " [0.06705216]]\n",
      "04/13/2025 23:34:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:34:19 - INFO - __main__ -   auc_score = 0.9157\n",
      "04/13/2025 23:34:19 - INFO - __main__ -   eval_f1 = 0.6047\n",
      "04/13/2025 23:34:19 - INFO - __main__ -   eval_precision = 0.7057\n",
      "04/13/2025 23:34:19 - INFO - __main__ -   eval_recall = 0.5289\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/13/2025 23:35:03 - WARNING - __main__ - epoch 5 step 306 loss 0.15114\n",
      "[[0.9901917 ]\n",
      " [0.6138677 ]\n",
      " [0.17817451]\n",
      " ...\n",
      " [0.29513088]\n",
      " [0.47898072]\n",
      " [0.12633446]]\n",
      "04/13/2025 23:35:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:35:36 - INFO - __main__ -   auc_score = 0.9188\n",
      "04/13/2025 23:35:36 - INFO - __main__ -   eval_f1 = 0.5959\n",
      "04/13/2025 23:35:36 - INFO - __main__ -   eval_precision = 0.6301\n",
      "04/13/2025 23:35:36 - INFO - __main__ -   eval_recall = 0.5653\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/13/2025 23:36:19 - WARNING - __main__ - epoch 5 step 408 loss 0.15052\n",
      "[[0.99108934]\n",
      " [0.66905844]\n",
      " [0.1767109 ]\n",
      " ...\n",
      " [0.2661826 ]\n",
      " [0.39113423]\n",
      " [0.11134948]]\n",
      "04/13/2025 23:36:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:36:52 - INFO - __main__ -   auc_score = 0.9186\n",
      "04/13/2025 23:36:52 - INFO - __main__ -   eval_f1 = 0.6152\n",
      "04/13/2025 23:36:52 - INFO - __main__ -   eval_precision = 0.6546\n",
      "04/13/2025 23:36:52 - INFO - __main__ -   eval_recall = 0.5803\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/13/2025 23:37:36 - WARNING - __main__ - epoch 5 step 510 loss 0.13514\n",
      "[[0.98953617]\n",
      " [0.6202706 ]\n",
      " [0.14659987]\n",
      " ...\n",
      " [0.28874195]\n",
      " [0.23606288]\n",
      " [0.08383311]]\n",
      "04/13/2025 23:38:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:38:09 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/13/2025 23:38:09 - INFO - __main__ -   eval_f1 = 0.6266\n",
      "04/13/2025 23:38:09 - INFO - __main__ -   eval_precision = 0.6809\n",
      "04/13/2025 23:38:09 - INFO - __main__ -   eval_recall = 0.5803\n",
      "100% 512/512 [06:25<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/13/2025 23:38:55 - WARNING - __main__ - epoch 6 step 102 loss 0.14133\n",
      "[[0.98978627]\n",
      " [0.56401217]\n",
      " [0.15144533]\n",
      " ...\n",
      " [0.3066697 ]\n",
      " [0.43439257]\n",
      " [0.14143996]]\n",
      "04/13/2025 23:39:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:39:28 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/13/2025 23:39:28 - INFO - __main__ -   eval_f1 = 0.6\n",
      "04/13/2025 23:39:28 - INFO - __main__ -   eval_precision = 0.6756\n",
      "04/13/2025 23:39:28 - INFO - __main__ -   eval_recall = 0.5396\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:40:11 - WARNING - __main__ - epoch 6 step 204 loss 0.12946\n",
      "[[0.9867807 ]\n",
      " [0.60139734]\n",
      " [0.10302907]\n",
      " ...\n",
      " [0.14587109]\n",
      " [0.18180768]\n",
      " [0.04397877]]\n",
      "04/13/2025 23:40:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:40:44 - INFO - __main__ -   auc_score = 0.9154\n",
      "04/13/2025 23:40:44 - INFO - __main__ -   eval_f1 = 0.6146\n",
      "04/13/2025 23:40:44 - INFO - __main__ -   eval_precision = 0.7462\n",
      "04/13/2025 23:40:44 - INFO - __main__ -   eval_recall = 0.5225\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/13/2025 23:41:27 - WARNING - __main__ - epoch 6 step 306 loss 0.1342\n",
      "[[0.9864429 ]\n",
      " [0.5994436 ]\n",
      " [0.10352387]\n",
      " ...\n",
      " [0.19096524]\n",
      " [0.29585457]\n",
      " [0.06711732]]\n",
      "04/13/2025 23:42:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:42:00 - INFO - __main__ -   auc_score = 0.9164\n",
      "04/13/2025 23:42:00 - INFO - __main__ -   eval_f1 = 0.6288\n",
      "04/13/2025 23:42:00 - INFO - __main__ -   eval_precision = 0.7222\n",
      "04/13/2025 23:42:00 - INFO - __main__ -   eval_recall = 0.5567\n",
      " 79% 407/512 [04:33<00:44,  2.35it/s]04/13/2025 23:42:45 - WARNING - __main__ - epoch 6 step 408 loss 0.13068\n",
      "[[0.99043477]\n",
      " [0.62463844]\n",
      " [0.13514288]\n",
      " ...\n",
      " [0.22342834]\n",
      " [0.35250577]\n",
      " [0.07906578]]\n",
      "04/13/2025 23:43:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:43:18 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/13/2025 23:43:18 - INFO - __main__ -   eval_f1 = 0.6289\n",
      "04/13/2025 23:43:18 - INFO - __main__ -   eval_precision = 0.6834\n",
      "04/13/2025 23:43:18 - INFO - __main__ -   eval_recall = 0.5824\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/13/2025 23:44:03 - WARNING - __main__ - epoch 6 step 510 loss 0.13319\n",
      "[[0.9904557 ]\n",
      " [0.58456343]\n",
      " [0.1259393 ]\n",
      " ...\n",
      " [0.22863732]\n",
      " [0.2713279 ]\n",
      " [0.05928302]]\n",
      "04/13/2025 23:44:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:44:36 - INFO - __main__ -   auc_score = 0.9162\n",
      "04/13/2025 23:44:36 - INFO - __main__ -   eval_f1 = 0.6209\n",
      "04/13/2025 23:44:36 - INFO - __main__ -   eval_precision = 0.695\n",
      "04/13/2025 23:44:36 - INFO - __main__ -   eval_recall = 0.561\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/13/2025 23:45:20 - WARNING - __main__ - epoch 7 step 102 loss 0.12364\n",
      "[[0.99019426]\n",
      " [0.5756008 ]\n",
      " [0.08424541]\n",
      " ...\n",
      " [0.08929761]\n",
      " [0.1400825 ]\n",
      " [0.02681321]]\n",
      "04/13/2025 23:45:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:45:53 - INFO - __main__ -   auc_score = 0.9136\n",
      "04/13/2025 23:45:53 - INFO - __main__ -   eval_f1 = 0.5867\n",
      "04/13/2025 23:45:53 - INFO - __main__ -   eval_precision = 0.7774\n",
      "04/13/2025 23:45:53 - INFO - __main__ -   eval_recall = 0.4711\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:46:36 - WARNING - __main__ - epoch 7 step 204 loss 0.12116\n",
      "[[0.99369216]\n",
      " [0.5884263 ]\n",
      " [0.09222899]\n",
      " ...\n",
      " [0.15130877]\n",
      " [0.27664125]\n",
      " [0.05274074]]\n",
      "04/13/2025 23:47:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:47:09 - INFO - __main__ -   auc_score = 0.9147\n",
      "04/13/2025 23:47:09 - INFO - __main__ -   eval_f1 = 0.6291\n",
      "04/13/2025 23:47:09 - INFO - __main__ -   eval_precision = 0.6961\n",
      "04/13/2025 23:47:09 - INFO - __main__ -   eval_recall = 0.5739\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/13/2025 23:47:53 - WARNING - __main__ - epoch 7 step 306 loss 0.14018\n",
      "[[0.9908557 ]\n",
      " [0.5812907 ]\n",
      " [0.07994021]\n",
      " ...\n",
      " [0.12404957]\n",
      " [0.2466543 ]\n",
      " [0.0393253 ]]\n",
      "04/13/2025 23:48:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:48:26 - INFO - __main__ -   auc_score = 0.9144\n",
      "04/13/2025 23:48:26 - INFO - __main__ -   eval_f1 = 0.6193\n",
      "04/13/2025 23:48:26 - INFO - __main__ -   eval_precision = 0.708\n",
      "04/13/2025 23:48:26 - INFO - __main__ -   eval_recall = 0.5503\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/13/2025 23:49:10 - WARNING - __main__ - epoch 7 step 408 loss 0.1252\n",
      "[[0.9923265 ]\n",
      " [0.6098041 ]\n",
      " [0.11682798]\n",
      " ...\n",
      " [0.17842206]\n",
      " [0.2957773 ]\n",
      " [0.06209808]]\n",
      "04/13/2025 23:49:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:49:43 - INFO - __main__ -   auc_score = 0.9159\n",
      "04/13/2025 23:49:43 - INFO - __main__ -   eval_f1 = 0.628\n",
      "04/13/2025 23:49:43 - INFO - __main__ -   eval_precision = 0.7029\n",
      "04/13/2025 23:49:43 - INFO - __main__ -   eval_recall = 0.5675\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/13/2025 23:50:26 - WARNING - __main__ - epoch 7 step 510 loss 0.13082\n",
      "[[0.9902352 ]\n",
      " [0.59903574]\n",
      " [0.11172057]\n",
      " ...\n",
      " [0.12609094]\n",
      " [0.20672195]\n",
      " [0.03875589]]\n",
      "04/13/2025 23:50:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:50:59 - INFO - __main__ -   auc_score = 0.9152\n",
      "04/13/2025 23:50:59 - INFO - __main__ -   eval_f1 = 0.6061\n",
      "04/13/2025 23:50:59 - INFO - __main__ -   eval_precision = 0.7524\n",
      "04/13/2025 23:50:59 - INFO - __main__ -   eval_recall = 0.5075\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/13/2025 23:51:43 - WARNING - __main__ - epoch 8 step 102 loss 0.12979\n",
      "[[0.9926213 ]\n",
      " [0.63811195]\n",
      " [0.15381019]\n",
      " ...\n",
      " [0.20509483]\n",
      " [0.34105426]\n",
      " [0.07278867]]\n",
      "04/13/2025 23:52:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:52:16 - INFO - __main__ -   auc_score = 0.916\n",
      "04/13/2025 23:52:16 - INFO - __main__ -   eval_f1 = 0.6165\n",
      "04/13/2025 23:52:16 - INFO - __main__ -   eval_precision = 0.6717\n",
      "04/13/2025 23:52:16 - INFO - __main__ -   eval_recall = 0.5696\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:52:59 - WARNING - __main__ - epoch 8 step 204 loss 0.13331\n",
      "[[0.99327564]\n",
      " [0.6872594 ]\n",
      " [0.17963721]\n",
      " ...\n",
      " [0.17663136]\n",
      " [0.24316807]\n",
      " [0.05840488]]\n",
      "04/13/2025 23:53:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:53:32 - INFO - __main__ -   auc_score = 0.9153\n",
      "04/13/2025 23:53:32 - INFO - __main__ -   eval_f1 = 0.6186\n",
      "04/13/2025 23:53:32 - INFO - __main__ -   eval_precision = 0.665\n",
      "04/13/2025 23:53:32 - INFO - __main__ -   eval_recall = 0.5782\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/13/2025 23:54:15 - WARNING - __main__ - epoch 8 step 306 loss 0.11185\n",
      "[[0.9926944 ]\n",
      " [0.6785405 ]\n",
      " [0.13802603]\n",
      " ...\n",
      " [0.11903521]\n",
      " [0.15905912]\n",
      " [0.03636164]]\n",
      "04/13/2025 23:54:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:54:48 - INFO - __main__ -   auc_score = 0.9135\n",
      "04/13/2025 23:54:48 - INFO - __main__ -   eval_f1 = 0.618\n",
      "04/13/2025 23:54:48 - INFO - __main__ -   eval_precision = 0.7155\n",
      "04/13/2025 23:54:48 - INFO - __main__ -   eval_recall = 0.5439\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/13/2025 23:55:31 - WARNING - __main__ - epoch 8 step 408 loss 0.11698\n",
      "[[0.9931203 ]\n",
      " [0.67322135]\n",
      " [0.13395198]\n",
      " ...\n",
      " [0.15515706]\n",
      " [0.19676904]\n",
      " [0.04323901]]\n",
      "04/13/2025 23:56:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:56:04 - INFO - __main__ -   auc_score = 0.9142\n",
      "04/13/2025 23:56:04 - INFO - __main__ -   eval_f1 = 0.6211\n",
      "04/13/2025 23:56:04 - INFO - __main__ -   eval_precision = 0.7057\n",
      "04/13/2025 23:56:04 - INFO - __main__ -   eval_recall = 0.5546\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/13/2025 23:56:48 - WARNING - __main__ - epoch 8 step 510 loss 0.11385\n",
      "[[0.9952923 ]\n",
      " [0.6501356 ]\n",
      " [0.13813856]\n",
      " ...\n",
      " [0.23122306]\n",
      " [0.3661802 ]\n",
      " [0.09217118]]\n",
      "04/13/2025 23:57:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:57:21 - INFO - __main__ -   auc_score = 0.9156\n",
      "04/13/2025 23:57:21 - INFO - __main__ -   eval_f1 = 0.6205\n",
      "04/13/2025 23:57:21 - INFO - __main__ -   eval_precision = 0.6725\n",
      "04/13/2025 23:57:21 - INFO - __main__ -   eval_recall = 0.576\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/13/2025 23:58:05 - WARNING - __main__ - epoch 9 step 102 loss 0.1193\n",
      "[[0.9954581 ]\n",
      " [0.67166835]\n",
      " [0.14013846]\n",
      " ...\n",
      " [0.18569326]\n",
      " [0.26818964]\n",
      " [0.06296569]]\n",
      "04/13/2025 23:58:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:58:38 - INFO - __main__ -   auc_score = 0.9153\n",
      "04/13/2025 23:58:38 - INFO - __main__ -   eval_f1 = 0.6215\n",
      "04/13/2025 23:58:38 - INFO - __main__ -   eval_precision = 0.6838\n",
      "04/13/2025 23:58:38 - INFO - __main__ -   eval_recall = 0.5696\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/13/2025 23:59:21 - WARNING - __main__ - epoch 9 step 204 loss 0.11152\n",
      "[[0.9960388 ]\n",
      " [0.66371244]\n",
      " [0.14809676]\n",
      " ...\n",
      " [0.22176678]\n",
      " [0.3348888 ]\n",
      " [0.08364195]]\n",
      "04/13/2025 23:59:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 23:59:54 - INFO - __main__ -   auc_score = 0.9157\n",
      "04/13/2025 23:59:54 - INFO - __main__ -   eval_f1 = 0.617\n",
      "04/13/2025 23:59:54 - INFO - __main__ -   eval_precision = 0.6642\n",
      "04/13/2025 23:59:54 - INFO - __main__ -   eval_recall = 0.576\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 00:00:37 - WARNING - __main__ - epoch 9 step 306 loss 0.10983\n",
      "[[0.99558085]\n",
      " [0.64398247]\n",
      " [0.12617101]\n",
      " ...\n",
      " [0.21465875]\n",
      " [0.3043023 ]\n",
      " [0.0742138 ]]\n",
      "04/14/2025 00:01:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:01:10 - INFO - __main__ -   auc_score = 0.9153\n",
      "04/14/2025 00:01:10 - INFO - __main__ -   eval_f1 = 0.6209\n",
      "04/14/2025 00:01:10 - INFO - __main__ -   eval_precision = 0.6794\n",
      "04/14/2025 00:01:10 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 00:01:53 - WARNING - __main__ - epoch 9 step 408 loss 0.11837\n",
      "[[0.9955309 ]\n",
      " [0.6499182 ]\n",
      " [0.12560585]\n",
      " ...\n",
      " [0.19626926]\n",
      " [0.27444324]\n",
      " [0.06537184]]\n",
      "04/14/2025 00:02:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:02:26 - INFO - __main__ -   auc_score = 0.9149\n",
      "04/14/2025 00:02:26 - INFO - __main__ -   eval_f1 = 0.6224\n",
      "04/14/2025 00:02:26 - INFO - __main__ -   eval_precision = 0.6829\n",
      "04/14/2025 00:02:26 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 00:03:10 - WARNING - __main__ - epoch 9 step 510 loss 0.1249\n",
      "[[0.9954555 ]\n",
      " [0.65213907]\n",
      " [0.12704615]\n",
      " ...\n",
      " [0.19408843]\n",
      " [0.26961842]\n",
      " [0.06389291]]\n",
      "04/14/2025 00:03:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:03:43 - INFO - __main__ -   auc_score = 0.9149\n",
      "04/14/2025 00:03:43 - INFO - __main__ -   eval_f1 = 0.6231\n",
      "04/14/2025 00:03:43 - INFO - __main__ -   eval_precision = 0.6846\n",
      "04/14/2025 00:03:43 - INFO - __main__ -   eval_recall = 0.5717\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFKN_DxUnOTZ",
    "outputId": "5aab6026-140c-4b83-b064-b25c34533bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 00:05:18.322063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 00:05:18.340290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744589118.362262   35562 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744589118.369089   35562 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 00:05:18.392125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 00:06:35 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 00:06:35 - INFO - __main__ -   auc_score = 0.9015\n",
      "04/14/2025 00:06:35 - INFO - __main__ -   test_f1 = 0.5123\n",
      "04/14/2025 00:06:35 - INFO - __main__ -   test_precision = 0.5798\n",
      "04/14/2025 00:06:35 - INFO - __main__ -   test_recall = 0.4589\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOIH01_4oIUx"
   },
   "source": [
    "#### Repeating the training with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBXX0eNdoM8e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bH59lv-bokXD"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw_hA9gKoVmC",
    "outputId": "53e29d6b-200f-4bea-d156-68bb723d77c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 00:10:54.502636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 00:10:54.521130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744589454.543373   37716 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744589454.550234   37716 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 00:10:54.572772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:43<02:55,  2.35it/s]04/14/2025 00:13:59 - WARNING - __main__ - epoch 0 step 102 loss 0.29487\n",
      "[[0.2970928 ]\n",
      " [0.05380908]\n",
      " [0.05485589]\n",
      " ...\n",
      " [0.06484897]\n",
      " [0.08790442]\n",
      " [0.07013562]]\n",
      "04/14/2025 00:14:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:14:32 - INFO - __main__ -   auc_score = 0.8089\n",
      "04/14/2025 00:14:32 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "04/14/2025 00:14:32 - INFO - __main__ -   eval_precision = 0.6667\n",
      "04/14/2025 00:14:32 - INFO - __main__ -   eval_recall = 0.0043\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 00:15:17 - WARNING - __main__ - epoch 0 step 204 loss 0.23552\n",
      "[[0.6569195 ]\n",
      " [0.061981  ]\n",
      " [0.06854457]\n",
      " ...\n",
      " [0.172777  ]\n",
      " [0.18738475]\n",
      " [0.18038164]]\n",
      "04/14/2025 00:15:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:15:50 - INFO - __main__ -   auc_score = 0.8734\n",
      "04/14/2025 00:15:50 - INFO - __main__ -   eval_f1 = 0.1901\n",
      "04/14/2025 00:15:50 - INFO - __main__ -   eval_precision = 0.65\n",
      "04/14/2025 00:15:50 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/14/2025 00:16:34 - WARNING - __main__ - epoch 0 step 306 loss 0.21668\n",
      "[[0.817833  ]\n",
      " [0.13237824]\n",
      " [0.09987899]\n",
      " ...\n",
      " [0.18038897]\n",
      " [0.20869793]\n",
      " [0.18064591]]\n",
      "04/14/2025 00:17:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:17:07 - INFO - __main__ -   auc_score = 0.8896\n",
      "04/14/2025 00:17:07 - INFO - __main__ -   eval_f1 = 0.3234\n",
      "04/14/2025 00:17:07 - INFO - __main__ -   eval_precision = 0.705\n",
      "04/14/2025 00:17:07 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 79% 407/512 [04:36<00:44,  2.35it/s]04/14/2025 00:17:52 - WARNING - __main__ - epoch 0 step 408 loss 0.20597\n",
      "[[0.851408  ]\n",
      " [0.1360808 ]\n",
      " [0.05325264]\n",
      " ...\n",
      " [0.16916408]\n",
      " [0.21388537]\n",
      " [0.17644592]]\n",
      "04/14/2025 00:18:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:18:25 - INFO - __main__ -   auc_score = 0.896\n",
      "04/14/2025 00:18:25 - INFO - __main__ -   eval_f1 = 0.3607\n",
      "04/14/2025 00:18:25 - INFO - __main__ -   eval_precision = 0.7273\n",
      "04/14/2025 00:18:25 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 99% 509/512 [05:53<00:01,  2.35it/s]04/14/2025 00:19:10 - WARNING - __main__ - epoch 0 step 510 loss 0.19549\n",
      "[[0.84950435]\n",
      " [0.15098429]\n",
      " [0.06592991]\n",
      " ...\n",
      " [0.25036266]\n",
      " [0.27813968]\n",
      " [0.23269871]]\n",
      "04/14/2025 00:19:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:19:43 - INFO - __main__ -   auc_score = 0.8976\n",
      "04/14/2025 00:19:43 - INFO - __main__ -   eval_f1 = 0.397\n",
      "04/14/2025 00:19:43 - INFO - __main__ -   eval_precision = 0.6788\n",
      "04/14/2025 00:19:43 - INFO - __main__ -   eval_recall = 0.2805\n",
      "100% 512/512 [06:29<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 00:20:28 - WARNING - __main__ - epoch 1 step 102 loss 0.18783\n",
      "[[0.91204107]\n",
      " [0.25617713]\n",
      " [0.10017561]\n",
      " ...\n",
      " [0.2565127 ]\n",
      " [0.30412525]\n",
      " [0.26466718]]\n",
      "04/14/2025 00:21:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:21:01 - INFO - __main__ -   auc_score = 0.9009\n",
      "04/14/2025 00:21:01 - INFO - __main__ -   eval_f1 = 0.4515\n",
      "04/14/2025 00:21:01 - INFO - __main__ -   eval_precision = 0.6964\n",
      "04/14/2025 00:21:01 - INFO - __main__ -   eval_recall = 0.334\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 00:21:45 - WARNING - __main__ - epoch 1 step 204 loss 0.19185\n",
      "[[0.8353995 ]\n",
      " [0.16722794]\n",
      " [0.05440091]\n",
      " ...\n",
      " [0.12775481]\n",
      " [0.12994786]\n",
      " [0.10994653]]\n",
      "04/14/2025 00:22:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:22:18 - INFO - __main__ -   auc_score = 0.9026\n",
      "04/14/2025 00:22:18 - INFO - __main__ -   eval_f1 = 0.3607\n",
      "04/14/2025 00:22:18 - INFO - __main__ -   eval_precision = 0.7692\n",
      "04/14/2025 00:22:18 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 00:23:02 - WARNING - __main__ - epoch 1 step 306 loss 0.18737\n",
      "[[0.9091414 ]\n",
      " [0.27650535]\n",
      " [0.05879512]\n",
      " ...\n",
      " [0.14193818]\n",
      " [0.20757592]\n",
      " [0.15620743]]\n",
      "04/14/2025 00:23:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:23:35 - INFO - __main__ -   auc_score = 0.9053\n",
      "04/14/2025 00:23:35 - INFO - __main__ -   eval_f1 = 0.4123\n",
      "04/14/2025 00:23:35 - INFO - __main__ -   eval_precision = 0.7322\n",
      "04/14/2025 00:23:35 - INFO - __main__ -   eval_recall = 0.2869\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 00:24:18 - WARNING - __main__ - epoch 1 step 408 loss 0.18262\n",
      "[[0.93323535]\n",
      " [0.27686045]\n",
      " [0.07487128]\n",
      " ...\n",
      " [0.24646594]\n",
      " [0.37754422]\n",
      " [0.25397062]]\n",
      "04/14/2025 00:24:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:24:51 - INFO - __main__ -   auc_score = 0.9075\n",
      "04/14/2025 00:24:51 - INFO - __main__ -   eval_f1 = 0.5007\n",
      "04/14/2025 00:24:51 - INFO - __main__ -   eval_precision = 0.6562\n",
      "04/14/2025 00:24:51 - INFO - __main__ -   eval_recall = 0.4047\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 00:25:35 - WARNING - __main__ - epoch 1 step 510 loss 0.17831\n",
      "[[0.90959716]\n",
      " [0.30969444]\n",
      " [0.06870455]\n",
      " ...\n",
      " [0.17768306]\n",
      " [0.19478977]\n",
      " [0.13547081]]\n",
      "04/14/2025 00:26:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:26:08 - INFO - __main__ -   auc_score = 0.9082\n",
      "04/14/2025 00:26:08 - INFO - __main__ -   eval_f1 = 0.4404\n",
      "04/14/2025 00:26:08 - INFO - __main__ -   eval_precision = 0.7449\n",
      "04/14/2025 00:26:08 - INFO - __main__ -   eval_recall = 0.3126\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 00:26:52 - WARNING - __main__ - epoch 2 step 102 loss 0.1708\n",
      "[[0.9487051 ]\n",
      " [0.2783577 ]\n",
      " [0.07134919]\n",
      " ...\n",
      " [0.36268   ]\n",
      " [0.446722  ]\n",
      " [0.3048139 ]]\n",
      "04/14/2025 00:27:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:27:25 - INFO - __main__ -   auc_score = 0.9093\n",
      "04/14/2025 00:27:25 - INFO - __main__ -   eval_f1 = 0.5208\n",
      "04/14/2025 00:27:25 - INFO - __main__ -   eval_precision = 0.6645\n",
      "04/14/2025 00:27:25 - INFO - __main__ -   eval_recall = 0.4283\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 00:28:10 - WARNING - __main__ - epoch 2 step 204 loss 0.18576\n",
      "[[0.95361394]\n",
      " [0.41702947]\n",
      " [0.10641953]\n",
      " ...\n",
      " [0.21362343]\n",
      " [0.2596501 ]\n",
      " [0.18818128]]\n",
      "04/14/2025 00:28:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:28:43 - INFO - __main__ -   auc_score = 0.9115\n",
      "04/14/2025 00:28:43 - INFO - __main__ -   eval_f1 = 0.5269\n",
      "04/14/2025 00:28:43 - INFO - __main__ -   eval_precision = 0.7076\n",
      "04/14/2025 00:28:43 - INFO - __main__ -   eval_recall = 0.4197\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/14/2025 00:29:28 - WARNING - __main__ - epoch 2 step 306 loss 0.1675\n",
      "[[0.9637419 ]\n",
      " [0.48677528]\n",
      " [0.13120177]\n",
      " ...\n",
      " [0.2651684 ]\n",
      " [0.33907515]\n",
      " [0.26607424]]\n",
      "04/14/2025 00:30:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:30:01 - INFO - __main__ -   auc_score = 0.9119\n",
      "04/14/2025 00:30:01 - INFO - __main__ -   eval_f1 = 0.5642\n",
      "04/14/2025 00:30:01 - INFO - __main__ -   eval_precision = 0.649\n",
      "04/14/2025 00:30:01 - INFO - __main__ -   eval_recall = 0.4989\n",
      " 79% 407/512 [04:35<00:44,  2.35it/s]04/14/2025 00:30:45 - WARNING - __main__ - epoch 2 step 408 loss 0.16357\n",
      "[[0.9581279 ]\n",
      " [0.3523693 ]\n",
      " [0.07264548]\n",
      " ...\n",
      " [0.19996037]\n",
      " [0.2755191 ]\n",
      " [0.18025905]]\n",
      "04/14/2025 00:31:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:31:18 - INFO - __main__ -   auc_score = 0.912\n",
      "04/14/2025 00:31:18 - INFO - __main__ -   eval_f1 = 0.527\n",
      "04/14/2025 00:31:18 - INFO - __main__ -   eval_precision = 0.748\n",
      "04/14/2025 00:31:18 - INFO - __main__ -   eval_recall = 0.4069\n",
      " 99% 509/512 [05:51<00:01,  2.35it/s]04/14/2025 00:32:01 - WARNING - __main__ - epoch 2 step 510 loss 0.17362\n",
      "[[0.9467751 ]\n",
      " [0.305822  ]\n",
      " [0.0577805 ]\n",
      " ...\n",
      " [0.16625242]\n",
      " [0.29895437]\n",
      " [0.15741006]]\n",
      "04/14/2025 00:32:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:32:34 - INFO - __main__ -   auc_score = 0.912\n",
      "04/14/2025 00:32:34 - INFO - __main__ -   eval_f1 = 0.4687\n",
      "04/14/2025 00:32:34 - INFO - __main__ -   eval_precision = 0.7734\n",
      "04/14/2025 00:32:34 - INFO - __main__ -   eval_recall = 0.3362\n",
      "100% 512/512 [06:25<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 00:33:18 - WARNING - __main__ - epoch 3 step 102 loss 0.15854\n",
      "[[0.9750098 ]\n",
      " [0.4508196 ]\n",
      " [0.10427314]\n",
      " ...\n",
      " [0.3240699 ]\n",
      " [0.532041  ]\n",
      " [0.3186723 ]]\n",
      "04/14/2025 00:33:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:33:51 - INFO - __main__ -   auc_score = 0.9143\n",
      "04/14/2025 00:33:51 - INFO - __main__ -   eval_f1 = 0.5785\n",
      "04/14/2025 00:33:51 - INFO - __main__ -   eval_precision = 0.6447\n",
      "04/14/2025 00:33:51 - INFO - __main__ -   eval_recall = 0.5246\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 00:34:36 - WARNING - __main__ - epoch 3 step 204 loss 0.16697\n",
      "[[0.96793157]\n",
      " [0.41495594]\n",
      " [0.09549905]\n",
      " ...\n",
      " [0.14130837]\n",
      " [0.23976573]\n",
      " [0.12217028]]\n",
      "04/14/2025 00:35:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:35:09 - INFO - __main__ -   auc_score = 0.912\n",
      "04/14/2025 00:35:09 - INFO - __main__ -   eval_f1 = 0.5643\n",
      "04/14/2025 00:35:09 - INFO - __main__ -   eval_precision = 0.7288\n",
      "04/14/2025 00:35:09 - INFO - __main__ -   eval_recall = 0.4604\n",
      " 60% 305/512 [03:16<01:28,  2.34it/s]04/14/2025 00:35:52 - WARNING - __main__ - epoch 3 step 306 loss 0.15441\n",
      "[[0.97834283]\n",
      " [0.3770211 ]\n",
      " [0.11443935]\n",
      " ...\n",
      " [0.27246317]\n",
      " [0.44938192]\n",
      " [0.2485898 ]]\n",
      "04/14/2025 00:36:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:36:25 - INFO - __main__ -   auc_score = 0.9131\n",
      "04/14/2025 00:36:25 - INFO - __main__ -   eval_f1 = 0.5679\n",
      "04/14/2025 00:36:25 - INFO - __main__ -   eval_precision = 0.6629\n",
      "04/14/2025 00:36:25 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 00:37:08 - WARNING - __main__ - epoch 3 step 408 loss 0.1641\n",
      "[[0.9800624 ]\n",
      " [0.5240299 ]\n",
      " [0.13233079]\n",
      " ...\n",
      " [0.1794454 ]\n",
      " [0.2737591 ]\n",
      " [0.16717973]]\n",
      "04/14/2025 00:37:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:37:41 - INFO - __main__ -   auc_score = 0.915\n",
      "04/14/2025 00:37:41 - INFO - __main__ -   eval_f1 = 0.5531\n",
      "04/14/2025 00:37:41 - INFO - __main__ -   eval_precision = 0.7128\n",
      "04/14/2025 00:37:41 - INFO - __main__ -   eval_recall = 0.4518\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 00:38:25 - WARNING - __main__ - epoch 3 step 510 loss 0.15903\n",
      "[[0.9660324 ]\n",
      " [0.42949027]\n",
      " [0.06302249]\n",
      " ...\n",
      " [0.19405474]\n",
      " [0.20884794]\n",
      " [0.14765245]]\n",
      "04/14/2025 00:38:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:38:58 - INFO - __main__ -   auc_score = 0.9136\n",
      "04/14/2025 00:38:58 - INFO - __main__ -   eval_f1 = 0.5238\n",
      "04/14/2025 00:38:58 - INFO - __main__ -   eval_precision = 0.7571\n",
      "04/14/2025 00:38:58 - INFO - __main__ -   eval_recall = 0.4004\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 00:39:42 - WARNING - __main__ - epoch 4 step 102 loss 0.13589\n",
      "[[0.9788477 ]\n",
      " [0.4602922 ]\n",
      " [0.09001674]\n",
      " ...\n",
      " [0.20228589]\n",
      " [0.26747224]\n",
      " [0.19440086]]\n",
      "04/14/2025 00:40:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:40:15 - INFO - __main__ -   auc_score = 0.9149\n",
      "04/14/2025 00:40:15 - INFO - __main__ -   eval_f1 = 0.5249\n",
      "04/14/2025 00:40:15 - INFO - __main__ -   eval_precision = 0.7393\n",
      "04/14/2025 00:40:15 - INFO - __main__ -   eval_recall = 0.4069\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 00:40:58 - WARNING - __main__ - epoch 4 step 204 loss 0.15258\n",
      "[[0.9863218 ]\n",
      " [0.5251399 ]\n",
      " [0.09078381]\n",
      " ...\n",
      " [0.2309545 ]\n",
      " [0.2420692 ]\n",
      " [0.21547936]]\n",
      "04/14/2025 00:41:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:41:31 - INFO - __main__ -   auc_score = 0.9154\n",
      "04/14/2025 00:41:31 - INFO - __main__ -   eval_f1 = 0.5729\n",
      "04/14/2025 00:41:31 - INFO - __main__ -   eval_precision = 0.7309\n",
      "04/14/2025 00:41:31 - INFO - __main__ -   eval_recall = 0.4711\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 00:42:14 - WARNING - __main__ - epoch 4 step 306 loss 0.168\n",
      "[[0.98314375]\n",
      " [0.553275  ]\n",
      " [0.08931641]\n",
      " ...\n",
      " [0.20216155]\n",
      " [0.23571907]\n",
      " [0.2159893 ]]\n",
      "04/14/2025 00:42:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:42:47 - INFO - __main__ -   auc_score = 0.9155\n",
      "04/14/2025 00:42:47 - INFO - __main__ -   eval_f1 = 0.5888\n",
      "04/14/2025 00:42:47 - INFO - __main__ -   eval_precision = 0.7227\n",
      "04/14/2025 00:42:47 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 00:43:31 - WARNING - __main__ - epoch 4 step 408 loss 0.154\n",
      "[[0.987655  ]\n",
      " [0.54374385]\n",
      " [0.08497895]\n",
      " ...\n",
      " [0.29874104]\n",
      " [0.36723146]\n",
      " [0.2558877 ]]\n",
      "04/14/2025 00:44:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:44:04 - INFO - __main__ -   auc_score = 0.9162\n",
      "04/14/2025 00:44:04 - INFO - __main__ -   eval_f1 = 0.5983\n",
      "04/14/2025 00:44:04 - INFO - __main__ -   eval_precision = 0.696\n",
      "04/14/2025 00:44:04 - INFO - __main__ -   eval_recall = 0.5246\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 00:44:49 - WARNING - __main__ - epoch 4 step 510 loss 0.14867\n",
      "[[0.9881521 ]\n",
      " [0.5664255 ]\n",
      " [0.11493793]\n",
      " ...\n",
      " [0.32870555]\n",
      " [0.557465  ]\n",
      " [0.28321517]]\n",
      "04/14/2025 00:45:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:45:22 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/14/2025 00:45:22 - INFO - __main__ -   eval_f1 = 0.6041\n",
      "04/14/2025 00:45:22 - INFO - __main__ -   eval_precision = 0.6403\n",
      "04/14/2025 00:45:22 - INFO - __main__ -   eval_recall = 0.5717\n",
      "100% 512/512 [06:25<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 00:46:07 - WARNING - __main__ - epoch 5 step 102 loss 0.14102\n",
      "[[0.9863987 ]\n",
      " [0.6330354 ]\n",
      " [0.11410353]\n",
      " ...\n",
      " [0.28822902]\n",
      " [0.57548434]\n",
      " [0.29531208]]\n",
      "04/14/2025 00:46:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:46:41 - INFO - __main__ -   auc_score = 0.9162\n",
      "04/14/2025 00:46:41 - INFO - __main__ -   eval_f1 = 0.5995\n",
      "04/14/2025 00:46:41 - INFO - __main__ -   eval_precision = 0.6355\n",
      "04/14/2025 00:46:41 - INFO - __main__ -   eval_recall = 0.5675\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 00:47:24 - WARNING - __main__ - epoch 5 step 204 loss 0.14691\n",
      "[[0.9837779 ]\n",
      " [0.5679944 ]\n",
      " [0.07375134]\n",
      " ...\n",
      " [0.16843946]\n",
      " [0.27539733]\n",
      " [0.14455631]]\n",
      "04/14/2025 00:47:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:47:57 - INFO - __main__ -   auc_score = 0.9159\n",
      "04/14/2025 00:47:57 - INFO - __main__ -   eval_f1 = 0.5514\n",
      "04/14/2025 00:47:57 - INFO - __main__ -   eval_precision = 0.7672\n",
      "04/14/2025 00:47:57 - INFO - __main__ -   eval_recall = 0.4304\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 00:48:40 - WARNING - __main__ - epoch 5 step 306 loss 0.12515\n",
      "[[0.99114144]\n",
      " [0.64920133]\n",
      " [0.0711559 ]\n",
      " ...\n",
      " [0.15585145]\n",
      " [0.32329807]\n",
      " [0.15651724]]\n",
      "04/14/2025 00:49:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:49:13 - INFO - __main__ -   auc_score = 0.9165\n",
      "04/14/2025 00:49:13 - INFO - __main__ -   eval_f1 = 0.5952\n",
      "04/14/2025 00:49:13 - INFO - __main__ -   eval_precision = 0.7239\n",
      "04/14/2025 00:49:13 - INFO - __main__ -   eval_recall = 0.5054\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 00:49:56 - WARNING - __main__ - epoch 5 step 408 loss 0.15024\n",
      "[[0.9924914 ]\n",
      " [0.6274228 ]\n",
      " [0.104884  ]\n",
      " ...\n",
      " [0.25897172]\n",
      " [0.5231191 ]\n",
      " [0.2814066 ]]\n",
      "04/14/2025 00:50:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:50:29 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/14/2025 00:50:29 - INFO - __main__ -   eval_f1 = 0.6059\n",
      "04/14/2025 00:50:29 - INFO - __main__ -   eval_precision = 0.639\n",
      "04/14/2025 00:50:29 - INFO - __main__ -   eval_recall = 0.576\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 00:51:14 - WARNING - __main__ - epoch 5 step 510 loss 0.15151\n",
      "[[0.99229056]\n",
      " [0.6150014 ]\n",
      " [0.09776721]\n",
      " ...\n",
      " [0.2533521 ]\n",
      " [0.433365  ]\n",
      " [0.23070401]]\n",
      "04/14/2025 00:51:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:51:47 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/14/2025 00:51:47 - INFO - __main__ -   eval_f1 = 0.6136\n",
      "04/14/2025 00:51:47 - INFO - __main__ -   eval_precision = 0.6538\n",
      "04/14/2025 00:51:47 - INFO - __main__ -   eval_recall = 0.5782\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 00:52:32 - WARNING - __main__ - epoch 6 step 102 loss 0.13027\n",
      "[[0.99365485]\n",
      " [0.63636565]\n",
      " [0.10177303]\n",
      " ...\n",
      " [0.37495685]\n",
      " [0.6245817 ]\n",
      " [0.40721107]]\n",
      "04/14/2025 00:53:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:53:05 - INFO - __main__ -   auc_score = 0.9166\n",
      "04/14/2025 00:53:05 - INFO - __main__ -   eval_f1 = 0.6073\n",
      "04/14/2025 00:53:05 - INFO - __main__ -   eval_precision = 0.6319\n",
      "04/14/2025 00:53:05 - INFO - __main__ -   eval_recall = 0.5846\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 00:53:48 - WARNING - __main__ - epoch 6 step 204 loss 0.12802\n",
      "[[0.98991627]\n",
      " [0.6267199 ]\n",
      " [0.05034458]\n",
      " ...\n",
      " [0.16873258]\n",
      " [0.28228673]\n",
      " [0.17109434]]\n",
      "04/14/2025 00:54:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:54:21 - INFO - __main__ -   auc_score = 0.9157\n",
      "04/14/2025 00:54:21 - INFO - __main__ -   eval_f1 = 0.5909\n",
      "04/14/2025 00:54:21 - INFO - __main__ -   eval_precision = 0.72\n",
      "04/14/2025 00:54:21 - INFO - __main__ -   eval_recall = 0.5011\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 00:55:05 - WARNING - __main__ - epoch 6 step 306 loss 0.13799\n",
      "[[0.992819  ]\n",
      " [0.6305788 ]\n",
      " [0.07018764]\n",
      " ...\n",
      " [0.19187827]\n",
      " [0.31337166]\n",
      " [0.17914182]]\n",
      "04/14/2025 00:55:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:55:38 - INFO - __main__ -   auc_score = 0.9166\n",
      "04/14/2025 00:55:38 - INFO - __main__ -   eval_f1 = 0.6036\n",
      "04/14/2025 00:55:38 - INFO - __main__ -   eval_precision = 0.6955\n",
      "04/14/2025 00:55:38 - INFO - __main__ -   eval_recall = 0.5332\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 00:56:21 - WARNING - __main__ - epoch 6 step 408 loss 0.1435\n",
      "[[0.994663  ]\n",
      " [0.6986306 ]\n",
      " [0.10735967]\n",
      " ...\n",
      " [0.21760346]\n",
      " [0.4819138 ]\n",
      " [0.27275148]]\n",
      "04/14/2025 00:56:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:56:54 - INFO - __main__ -   auc_score = 0.918\n",
      "04/14/2025 00:56:54 - INFO - __main__ -   eval_f1 = 0.615\n",
      "04/14/2025 00:56:54 - INFO - __main__ -   eval_precision = 0.6805\n",
      "04/14/2025 00:56:54 - INFO - __main__ -   eval_recall = 0.561\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 00:57:38 - WARNING - __main__ - epoch 6 step 510 loss 0.12763\n",
      "[[0.99376005]\n",
      " [0.6991095 ]\n",
      " [0.08002359]\n",
      " ...\n",
      " [0.13297331]\n",
      " [0.30206442]\n",
      " [0.1825689 ]]\n",
      "04/14/2025 00:58:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:58:11 - INFO - __main__ -   auc_score = 0.9166\n",
      "04/14/2025 00:58:11 - INFO - __main__ -   eval_f1 = 0.6158\n",
      "04/14/2025 00:58:11 - INFO - __main__ -   eval_precision = 0.7095\n",
      "04/14/2025 00:58:11 - INFO - __main__ -   eval_recall = 0.5439\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 00:58:57 - WARNING - __main__ - epoch 7 step 102 loss 0.12793\n",
      "[[0.9948243 ]\n",
      " [0.6573928 ]\n",
      " [0.07380258]\n",
      " ...\n",
      " [0.24400991]\n",
      " [0.48257717]\n",
      " [0.31715664]]\n",
      "04/14/2025 00:59:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 00:59:30 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/14/2025 00:59:30 - INFO - __main__ -   eval_f1 = 0.6121\n",
      "04/14/2025 00:59:30 - INFO - __main__ -   eval_precision = 0.6735\n",
      "04/14/2025 00:59:30 - INFO - __main__ -   eval_recall = 0.561\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 01:00:13 - WARNING - __main__ - epoch 7 step 204 loss 0.12589\n",
      "[[0.99561006]\n",
      " [0.687527  ]\n",
      " [0.07561917]\n",
      " ...\n",
      " [0.22622193]\n",
      " [0.4488    ]\n",
      " [0.3075609 ]]\n",
      "04/14/2025 01:00:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:00:46 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/14/2025 01:00:46 - INFO - __main__ -   eval_f1 = 0.6168\n",
      "04/14/2025 01:00:46 - INFO - __main__ -   eval_precision = 0.6787\n",
      "04/14/2025 01:00:46 - INFO - __main__ -   eval_recall = 0.5653\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 01:01:30 - WARNING - __main__ - epoch 7 step 306 loss 0.12659\n",
      "[[0.9956216 ]\n",
      " [0.6549557 ]\n",
      " [0.0889917 ]\n",
      " ...\n",
      " [0.24673061]\n",
      " [0.5100957 ]\n",
      " [0.3434001 ]]\n",
      "04/14/2025 01:02:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:02:03 - INFO - __main__ -   auc_score = 0.9182\n",
      "04/14/2025 01:02:03 - INFO - __main__ -   eval_f1 = 0.6124\n",
      "04/14/2025 01:02:03 - INFO - __main__ -   eval_precision = 0.6593\n",
      "04/14/2025 01:02:03 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 01:02:47 - WARNING - __main__ - epoch 7 step 408 loss 0.12383\n",
      "[[0.99342257]\n",
      " [0.6592445 ]\n",
      " [0.06476562]\n",
      " ...\n",
      " [0.14356717]\n",
      " [0.3169161 ]\n",
      " [0.2021215 ]]\n",
      "04/14/2025 01:03:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:03:20 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/14/2025 01:03:20 - INFO - __main__ -   eval_f1 = 0.597\n",
      "04/14/2025 01:03:20 - INFO - __main__ -   eval_precision = 0.7122\n",
      "04/14/2025 01:03:20 - INFO - __main__ -   eval_recall = 0.5139\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 01:04:03 - WARNING - __main__ - epoch 7 step 510 loss 0.13349\n",
      "[[0.9944516 ]\n",
      " [0.6182755 ]\n",
      " [0.06775498]\n",
      " ...\n",
      " [0.18737124]\n",
      " [0.48080254]\n",
      " [0.3018988 ]]\n",
      "04/14/2025 01:04:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:04:36 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/14/2025 01:04:36 - INFO - __main__ -   eval_f1 = 0.5969\n",
      "04/14/2025 01:04:36 - INFO - __main__ -   eval_precision = 0.6813\n",
      "04/14/2025 01:04:36 - INFO - __main__ -   eval_recall = 0.531\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 01:05:20 - WARNING - __main__ - epoch 8 step 102 loss 0.12983\n",
      "[[0.9956872 ]\n",
      " [0.68081784]\n",
      " [0.08495048]\n",
      " ...\n",
      " [0.18576701]\n",
      " [0.4592917 ]\n",
      " [0.29960114]]\n",
      "04/14/2025 01:05:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:05:53 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/14/2025 01:05:53 - INFO - __main__ -   eval_f1 = 0.6129\n",
      "04/14/2025 01:05:53 - INFO - __main__ -   eval_precision = 0.6753\n",
      "04/14/2025 01:05:53 - INFO - __main__ -   eval_recall = 0.561\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 01:06:36 - WARNING - __main__ - epoch 8 step 204 loss 0.1255\n",
      "[[0.9960188 ]\n",
      " [0.6989069 ]\n",
      " [0.09640802]\n",
      " ...\n",
      " [0.2018406 ]\n",
      " [0.40893966]\n",
      " [0.2880306 ]]\n",
      "04/14/2025 01:07:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:07:09 - INFO - __main__ -   auc_score = 0.9178\n",
      "04/14/2025 01:07:09 - INFO - __main__ -   eval_f1 = 0.6134\n",
      "04/14/2025 01:07:09 - INFO - __main__ -   eval_precision = 0.6675\n",
      "04/14/2025 01:07:09 - INFO - __main__ -   eval_recall = 0.5675\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 01:07:52 - WARNING - __main__ - epoch 8 step 306 loss 0.12031\n",
      "[[0.99513334]\n",
      " [0.66269135]\n",
      " [0.07699864]\n",
      " ...\n",
      " [0.14467219]\n",
      " [0.31614852]\n",
      " [0.20891856]]\n",
      "04/14/2025 01:08:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:08:25 - INFO - __main__ -   auc_score = 0.9176\n",
      "04/14/2025 01:08:25 - INFO - __main__ -   eval_f1 = 0.5949\n",
      "04/14/2025 01:08:25 - INFO - __main__ -   eval_precision = 0.6943\n",
      "04/14/2025 01:08:25 - INFO - __main__ -   eval_recall = 0.5203\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 01:09:08 - WARNING - __main__ - epoch 8 step 408 loss 0.12756\n",
      "[[0.9958717 ]\n",
      " [0.66757995]\n",
      " [0.08104213]\n",
      " ...\n",
      " [0.19383703]\n",
      " [0.43939152]\n",
      " [0.2769905 ]]\n",
      "04/14/2025 01:09:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:09:41 - INFO - __main__ -   auc_score = 0.9183\n",
      "04/14/2025 01:09:41 - INFO - __main__ -   eval_f1 = 0.6024\n",
      "04/14/2025 01:09:41 - INFO - __main__ -   eval_precision = 0.6783\n",
      "04/14/2025 01:09:41 - INFO - __main__ -   eval_recall = 0.5418\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 01:10:24 - WARNING - __main__ - epoch 8 step 510 loss 0.1155\n",
      "[[0.9957224 ]\n",
      " [0.64863205]\n",
      " [0.0660855 ]\n",
      " ...\n",
      " [0.16343999]\n",
      " [0.4050536 ]\n",
      " [0.25092283]]\n",
      "04/14/2025 01:10:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:10:57 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 01:10:57 - INFO - __main__ -   eval_f1 = 0.5959\n",
      "04/14/2025 01:10:57 - INFO - __main__ -   eval_precision = 0.6823\n",
      "04/14/2025 01:10:57 - INFO - __main__ -   eval_recall = 0.5289\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 01:11:41 - WARNING - __main__ - epoch 9 step 102 loss 0.11564\n",
      "[[0.99675375]\n",
      " [0.6765405 ]\n",
      " [0.08347165]\n",
      " ...\n",
      " [0.2099115 ]\n",
      " [0.47326827]\n",
      " [0.31572095]]\n",
      "04/14/2025 01:12:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:12:14 - INFO - __main__ -   auc_score = 0.9176\n",
      "04/14/2025 01:12:14 - INFO - __main__ -   eval_f1 = 0.6109\n",
      "04/14/2025 01:12:14 - INFO - __main__ -   eval_precision = 0.6675\n",
      "04/14/2025 01:12:14 - INFO - __main__ -   eval_recall = 0.5632\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 01:12:58 - WARNING - __main__ - epoch 9 step 204 loss 0.11335\n",
      "[[0.9965449 ]\n",
      " [0.67927414]\n",
      " [0.07814953]\n",
      " ...\n",
      " [0.1718868 ]\n",
      " [0.4108733 ]\n",
      " [0.26613024]]\n",
      "04/14/2025 01:13:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:13:31 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/14/2025 01:13:31 - INFO - __main__ -   eval_f1 = 0.6085\n",
      "04/14/2025 01:13:31 - INFO - __main__ -   eval_precision = 0.6772\n",
      "04/14/2025 01:13:31 - INFO - __main__ -   eval_recall = 0.5525\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 01:14:14 - WARNING - __main__ - epoch 9 step 306 loss 0.10552\n",
      "[[0.9969715 ]\n",
      " [0.68445206]\n",
      " [0.08334198]\n",
      " ...\n",
      " [0.21034417]\n",
      " [0.49232838]\n",
      " [0.32716638]]\n",
      "04/14/2025 01:14:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:14:47 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 01:14:47 - INFO - __main__ -   eval_f1 = 0.6065\n",
      "04/14/2025 01:14:47 - INFO - __main__ -   eval_precision = 0.6599\n",
      "04/14/2025 01:14:47 - INFO - __main__ -   eval_recall = 0.561\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 01:15:30 - WARNING - __main__ - epoch 9 step 408 loss 0.12737\n",
      "[[0.9971481 ]\n",
      " [0.6897234 ]\n",
      " [0.08826923]\n",
      " ...\n",
      " [0.22680466]\n",
      " [0.505397  ]\n",
      " [0.34673735]]\n",
      "04/14/2025 01:16:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:16:03 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 01:16:03 - INFO - __main__ -   eval_f1 = 0.6135\n",
      "04/14/2025 01:16:03 - INFO - __main__ -   eval_precision = 0.6561\n",
      "04/14/2025 01:16:03 - INFO - __main__ -   eval_recall = 0.576\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 01:16:46 - WARNING - __main__ - epoch 9 step 510 loss 0.12619\n",
      "[[0.9971818 ]\n",
      " [0.6883201 ]\n",
      " [0.08947287]\n",
      " ...\n",
      " [0.23202701]\n",
      " [0.51329327]\n",
      " [0.35340774]]\n",
      "04/14/2025 01:17:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:17:19 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 01:17:19 - INFO - __main__ -   eval_f1 = 0.6135\n",
      "04/14/2025 01:17:19 - INFO - __main__ -   eval_precision = 0.6561\n",
      "04/14/2025 01:17:19 - INFO - __main__ -   eval_recall = 0.576\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uN_wItz5Ebn",
    "outputId": "5a0f2c24-e55c-4e42-e1ff-b8d3315c9d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 01:23:04.999246: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 01:23:05.017443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744593785.039418   65309 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744593785.046188   65309 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 01:23:05.068161: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 01:24:20 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 01:24:20 - INFO - __main__ -   auc_score = 0.9053\n",
      "04/14/2025 01:24:20 - INFO - __main__ -   test_f1 = 0.5303\n",
      "04/14/2025 01:24:20 - INFO - __main__ -   test_precision = 0.6093\n",
      "04/14/2025 01:24:20 - INFO - __main__ -   test_recall = 0.4695\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7xfSJtc56S_"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFFbiFJF6A67",
    "outputId": "f8e3571e-2068-4c9f-d848-10aa3009236a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 01:27:09.505020: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 01:27:09.523051: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744594029.544707   66875 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744594029.551404   66875 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 01:27:09.573484: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:43<02:54,  2.35it/s]04/14/2025 01:30:13 - WARNING - __main__ - epoch 0 step 102 loss 0.31432\n",
      "[[0.3610166 ]\n",
      " [0.12201276]\n",
      " [0.06688413]\n",
      " ...\n",
      " [0.11193477]\n",
      " [0.17602852]\n",
      " [0.15235668]]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "04/14/2025 01:30:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:30:46 - INFO - __main__ -   auc_score = 0.8059\n",
      "04/14/2025 01:30:46 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/14/2025 01:30:46 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/14/2025 01:30:46 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 01:31:29 - WARNING - __main__ - epoch 0 step 204 loss 0.21633\n",
      "[[0.5545576 ]\n",
      " [0.09766895]\n",
      " [0.05871105]\n",
      " ...\n",
      " [0.16425717]\n",
      " [0.20251068]\n",
      " [0.20561661]]\n",
      "04/14/2025 01:32:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:32:02 - INFO - __main__ -   auc_score = 0.8687\n",
      "04/14/2025 01:32:02 - INFO - __main__ -   eval_f1 = 0.1082\n",
      "04/14/2025 01:32:02 - INFO - __main__ -   eval_precision = 0.8438\n",
      "04/14/2025 01:32:02 - INFO - __main__ -   eval_recall = 0.0578\n",
      " 60% 305/512 [03:17<01:28,  2.35it/s]04/14/2025 01:32:46 - WARNING - __main__ - epoch 0 step 306 loss 0.21385\n",
      "[[0.788836  ]\n",
      " [0.20867004]\n",
      " [0.07697517]\n",
      " ...\n",
      " [0.15498252]\n",
      " [0.2418284 ]\n",
      " [0.22046816]]\n",
      "04/14/2025 01:33:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:33:19 - INFO - __main__ -   auc_score = 0.8896\n",
      "04/14/2025 01:33:19 - INFO - __main__ -   eval_f1 = 0.2313\n",
      "04/14/2025 01:33:19 - INFO - __main__ -   eval_precision = 0.6842\n",
      "04/14/2025 01:33:19 - INFO - __main__ -   eval_recall = 0.1392\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/14/2025 01:34:04 - WARNING - __main__ - epoch 0 step 408 loss 0.20775\n",
      "[[0.9012692 ]\n",
      " [0.3318363 ]\n",
      " [0.11555389]\n",
      " ...\n",
      " [0.24810351]\n",
      " [0.33047476]\n",
      " [0.34926334]]\n",
      "04/14/2025 01:34:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:34:37 - INFO - __main__ -   auc_score = 0.8982\n",
      "04/14/2025 01:34:37 - INFO - __main__ -   eval_f1 = 0.384\n",
      "04/14/2025 01:34:37 - INFO - __main__ -   eval_precision = 0.6793\n",
      "04/14/2025 01:34:37 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 99% 509/512 [05:52<00:01,  2.35it/s]04/14/2025 01:35:22 - WARNING - __main__ - epoch 0 step 510 loss 0.19823\n",
      "[[0.88915384]\n",
      " [0.29809168]\n",
      " [0.07974482]\n",
      " ...\n",
      " [0.29057118]\n",
      " [0.39340043]\n",
      " [0.39057976]]\n",
      "04/14/2025 01:35:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:35:55 - INFO - __main__ -   auc_score = 0.9032\n",
      "04/14/2025 01:35:55 - INFO - __main__ -   eval_f1 = 0.4179\n",
      "04/14/2025 01:35:55 - INFO - __main__ -   eval_precision = 0.6897\n",
      "04/14/2025 01:35:55 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 512/512 [06:27<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 01:36:40 - WARNING - __main__ - epoch 1 step 102 loss 0.18584\n",
      "[[0.9032695 ]\n",
      " [0.23686655]\n",
      " [0.04151916]\n",
      " ...\n",
      " [0.24080694]\n",
      " [0.3128625 ]\n",
      " [0.3101177 ]]\n",
      "04/14/2025 01:37:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:37:13 - INFO - __main__ -   auc_score = 0.904\n",
      "04/14/2025 01:37:13 - INFO - __main__ -   eval_f1 = 0.4183\n",
      "04/14/2025 01:37:13 - INFO - __main__ -   eval_precision = 0.7287\n",
      "04/14/2025 01:37:13 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 01:37:58 - WARNING - __main__ - epoch 1 step 204 loss 0.1878\n",
      "[[0.94275695]\n",
      " [0.39785168]\n",
      " [0.15017268]\n",
      " ...\n",
      " [0.33914247]\n",
      " [0.49907592]\n",
      " [0.46582648]]\n",
      "04/14/2025 01:38:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:38:31 - INFO - __main__ -   auc_score = 0.9067\n",
      "04/14/2025 01:38:31 - INFO - __main__ -   eval_f1 = 0.4948\n",
      "04/14/2025 01:38:31 - INFO - __main__ -   eval_precision = 0.6312\n",
      "04/14/2025 01:38:31 - INFO - __main__ -   eval_recall = 0.4069\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/14/2025 01:39:15 - WARNING - __main__ - epoch 1 step 306 loss 0.17967\n",
      "[[0.8944513 ]\n",
      " [0.36906913]\n",
      " [0.0985447 ]\n",
      " ...\n",
      " [0.21337152]\n",
      " [0.35708737]\n",
      " [0.28715643]]\n",
      "04/14/2025 01:39:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:39:48 - INFO - __main__ -   auc_score = 0.9108\n",
      "04/14/2025 01:39:48 - INFO - __main__ -   eval_f1 = 0.4414\n",
      "04/14/2025 01:39:48 - INFO - __main__ -   eval_precision = 0.7387\n",
      "04/14/2025 01:39:48 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/14/2025 01:40:32 - WARNING - __main__ - epoch 1 step 408 loss 0.19057\n",
      "[[0.9083985 ]\n",
      " [0.4113565 ]\n",
      " [0.06509127]\n",
      " ...\n",
      " [0.28703463]\n",
      " [0.26118967]\n",
      " [0.28060812]]\n",
      "04/14/2025 01:41:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:41:05 - INFO - __main__ -   auc_score = 0.9094\n",
      "04/14/2025 01:41:05 - INFO - __main__ -   eval_f1 = 0.5085\n",
      "04/14/2025 01:41:05 - INFO - __main__ -   eval_precision = 0.7469\n",
      "04/14/2025 01:41:05 - INFO - __main__ -   eval_recall = 0.3854\n",
      " 99% 509/512 [05:52<00:01,  2.35it/s]04/14/2025 01:41:49 - WARNING - __main__ - epoch 1 step 510 loss 0.17125\n",
      "[[0.9347342 ]\n",
      " [0.49679145]\n",
      " [0.0946944 ]\n",
      " ...\n",
      " [0.25217107]\n",
      " [0.34493342]\n",
      " [0.31978858]]\n",
      "04/14/2025 01:42:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:42:22 - INFO - __main__ -   auc_score = 0.9129\n",
      "04/14/2025 01:42:22 - INFO - __main__ -   eval_f1 = 0.5105\n",
      "04/14/2025 01:42:22 - INFO - __main__ -   eval_precision = 0.732\n",
      "04/14/2025 01:42:22 - INFO - __main__ -   eval_recall = 0.3919\n",
      "100% 512/512 [06:27<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 01:43:08 - WARNING - __main__ - epoch 2 step 102 loss 0.16969\n",
      "[[0.94276434]\n",
      " [0.52417743]\n",
      " [0.09900463]\n",
      " ...\n",
      " [0.34816784]\n",
      " [0.44086936]\n",
      " [0.4435716 ]]\n",
      "04/14/2025 01:43:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:43:41 - INFO - __main__ -   auc_score = 0.9137\n",
      "04/14/2025 01:43:41 - INFO - __main__ -   eval_f1 = 0.548\n",
      "04/14/2025 01:43:41 - INFO - __main__ -   eval_precision = 0.6677\n",
      "04/14/2025 01:43:41 - INFO - __main__ -   eval_recall = 0.4647\n",
      " 40% 203/512 [02:00<02:12,  2.34it/s]04/14/2025 01:44:26 - WARNING - __main__ - epoch 2 step 204 loss 0.18879\n",
      "[[0.9436908 ]\n",
      " [0.57974076]\n",
      " [0.13885501]\n",
      " ...\n",
      " [0.2832352 ]\n",
      " [0.28862962]\n",
      " [0.30513728]]\n",
      "04/14/2025 01:44:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:44:59 - INFO - __main__ -   auc_score = 0.9154\n",
      "04/14/2025 01:44:59 - INFO - __main__ -   eval_f1 = 0.5711\n",
      "04/14/2025 01:44:59 - INFO - __main__ -   eval_precision = 0.7406\n",
      "04/14/2025 01:44:59 - INFO - __main__ -   eval_recall = 0.4647\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/14/2025 01:45:43 - WARNING - __main__ - epoch 2 step 306 loss 0.16598\n",
      "[[0.96359354]\n",
      " [0.5446075 ]\n",
      " [0.15999417]\n",
      " ...\n",
      " [0.24299575]\n",
      " [0.28945115]\n",
      " [0.3167951 ]]\n",
      "04/14/2025 01:46:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:46:16 - INFO - __main__ -   auc_score = 0.9148\n",
      "04/14/2025 01:46:16 - INFO - __main__ -   eval_f1 = 0.5272\n",
      "04/14/2025 01:46:16 - INFO - __main__ -   eval_precision = 0.756\n",
      "04/14/2025 01:46:16 - INFO - __main__ -   eval_recall = 0.4047\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/14/2025 01:46:59 - WARNING - __main__ - epoch 2 step 408 loss 0.15882\n",
      "[[0.98038346]\n",
      " [0.6190898 ]\n",
      " [0.19413131]\n",
      " ...\n",
      " [0.31404784]\n",
      " [0.54892856]\n",
      " [0.44028437]]\n",
      "04/14/2025 01:47:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:47:32 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 01:47:32 - INFO - __main__ -   eval_f1 = 0.5734\n",
      "04/14/2025 01:47:32 - INFO - __main__ -   eval_precision = 0.6062\n",
      "04/14/2025 01:47:32 - INFO - __main__ -   eval_recall = 0.5439\n",
      " 99% 509/512 [05:52<00:01,  2.35it/s]04/14/2025 01:48:17 - WARNING - __main__ - epoch 2 step 510 loss 0.15541\n",
      "[[0.90301836]\n",
      " [0.3716525 ]\n",
      " [0.058665  ]\n",
      " ...\n",
      " [0.18238088]\n",
      " [0.21249337]\n",
      " [0.16976328]]\n",
      "04/14/2025 01:48:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:48:50 - INFO - __main__ -   auc_score = 0.9139\n",
      "04/14/2025 01:48:50 - INFO - __main__ -   eval_f1 = 0.4829\n",
      "04/14/2025 01:48:50 - INFO - __main__ -   eval_precision = 0.7941\n",
      "04/14/2025 01:48:50 - INFO - __main__ -   eval_recall = 0.3469\n",
      "100% 512/512 [06:26<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 01:49:34 - WARNING - __main__ - epoch 3 step 102 loss 0.1638\n",
      "[[0.9272791 ]\n",
      " [0.51202685]\n",
      " [0.08827107]\n",
      " ...\n",
      " [0.14110407]\n",
      " [0.15554221]\n",
      " [0.14236626]]\n",
      "04/14/2025 01:50:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:50:07 - INFO - __main__ -   auc_score = 0.9153\n",
      "04/14/2025 01:50:07 - INFO - __main__ -   eval_f1 = 0.4596\n",
      "04/14/2025 01:50:07 - INFO - __main__ -   eval_precision = 0.8362\n",
      "04/14/2025 01:50:07 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 01:50:50 - WARNING - __main__ - epoch 3 step 204 loss 0.16995\n",
      "[[0.9711964 ]\n",
      " [0.70040214]\n",
      " [0.16141717]\n",
      " ...\n",
      " [0.28484342]\n",
      " [0.34423435]\n",
      " [0.28227067]]\n",
      "04/14/2025 01:51:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:51:23 - INFO - __main__ -   auc_score = 0.9179\n",
      "04/14/2025 01:51:23 - INFO - __main__ -   eval_f1 = 0.5914\n",
      "04/14/2025 01:51:23 - INFO - __main__ -   eval_precision = 0.648\n",
      "04/14/2025 01:51:23 - INFO - __main__ -   eval_recall = 0.5439\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 01:52:08 - WARNING - __main__ - epoch 3 step 306 loss 0.15168\n",
      "[[0.9467879 ]\n",
      " [0.53851235]\n",
      " [0.0752834 ]\n",
      " ...\n",
      " [0.14675947]\n",
      " [0.21803491]\n",
      " [0.12621689]]\n",
      "04/14/2025 01:52:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:52:41 - INFO - __main__ -   auc_score = 0.9163\n",
      "04/14/2025 01:52:41 - INFO - __main__ -   eval_f1 = 0.5145\n",
      "04/14/2025 01:52:41 - INFO - __main__ -   eval_precision = 0.7911\n",
      "04/14/2025 01:52:41 - INFO - __main__ -   eval_recall = 0.3812\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 01:53:24 - WARNING - __main__ - epoch 3 step 408 loss 0.15982\n",
      "[[0.9703855 ]\n",
      " [0.6092477 ]\n",
      " [0.1322438 ]\n",
      " ...\n",
      " [0.19104305]\n",
      " [0.33919182]\n",
      " [0.20746848]]\n",
      "04/14/2025 01:53:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:53:57 - INFO - __main__ -   auc_score = 0.9192\n",
      "04/14/2025 01:53:57 - INFO - __main__ -   eval_f1 = 0.5619\n",
      "04/14/2025 01:53:57 - INFO - __main__ -   eval_precision = 0.743\n",
      "04/14/2025 01:53:57 - INFO - __main__ -   eval_recall = 0.4518\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 01:54:40 - WARNING - __main__ - epoch 3 step 510 loss 0.16049\n",
      "[[0.98238474]\n",
      " [0.64276963]\n",
      " [0.14473954]\n",
      " ...\n",
      " [0.2256765 ]\n",
      " [0.45181307]\n",
      " [0.2730754 ]]\n",
      "04/14/2025 01:55:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:55:13 - INFO - __main__ -   auc_score = 0.92\n",
      "04/14/2025 01:55:13 - INFO - __main__ -   eval_f1 = 0.5888\n",
      "04/14/2025 01:55:13 - INFO - __main__ -   eval_precision = 0.6817\n",
      "04/14/2025 01:55:13 - INFO - __main__ -   eval_recall = 0.5182\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 01:55:57 - WARNING - __main__ - epoch 4 step 102 loss 0.16251\n",
      "[[0.98028445]\n",
      " [0.74015677]\n",
      " [0.19404444]\n",
      " ...\n",
      " [0.23625511]\n",
      " [0.41485432]\n",
      " [0.24660936]]\n",
      "04/14/2025 01:56:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:56:30 - INFO - __main__ -   auc_score = 0.9208\n",
      "04/14/2025 01:56:30 - INFO - __main__ -   eval_f1 = 0.6159\n",
      "04/14/2025 01:56:30 - INFO - __main__ -   eval_precision = 0.6925\n",
      "04/14/2025 01:56:30 - INFO - __main__ -   eval_recall = 0.5546\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 01:57:15 - WARNING - __main__ - epoch 4 step 204 loss 0.14458\n",
      "[[0.9764396 ]\n",
      " [0.6689365 ]\n",
      " [0.17868532]\n",
      " ...\n",
      " [0.17614865]\n",
      " [0.31020945]\n",
      " [0.20562072]]\n",
      "04/14/2025 01:57:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:57:48 - INFO - __main__ -   auc_score = 0.9211\n",
      "04/14/2025 01:57:48 - INFO - __main__ -   eval_f1 = 0.5896\n",
      "04/14/2025 01:57:48 - INFO - __main__ -   eval_precision = 0.725\n",
      "04/14/2025 01:57:48 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 01:58:31 - WARNING - __main__ - epoch 4 step 306 loss 0.1576\n",
      "[[0.98942786]\n",
      " [0.7249945 ]\n",
      " [0.16425638]\n",
      " ...\n",
      " [0.28635287]\n",
      " [0.58491427]\n",
      " [0.35372993]]\n",
      "04/14/2025 01:59:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 01:59:04 - INFO - __main__ -   auc_score = 0.9189\n",
      "04/14/2025 01:59:04 - INFO - __main__ -   eval_f1 = 0.6055\n",
      "04/14/2025 01:59:04 - INFO - __main__ -   eval_precision = 0.6519\n",
      "04/14/2025 01:59:04 - INFO - __main__ -   eval_recall = 0.5653\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 01:59:47 - WARNING - __main__ - epoch 4 step 408 loss 0.13753\n",
      "[[0.98051363]\n",
      " [0.5854089 ]\n",
      " [0.07568949]\n",
      " ...\n",
      " [0.18201438]\n",
      " [0.37502176]\n",
      " [0.20545074]]\n",
      "04/14/2025 02:00:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:00:20 - INFO - __main__ -   auc_score = 0.9167\n",
      "04/14/2025 02:00:20 - INFO - __main__ -   eval_f1 = 0.5816\n",
      "04/14/2025 02:00:20 - INFO - __main__ -   eval_precision = 0.7192\n",
      "04/14/2025 02:00:20 - INFO - __main__ -   eval_recall = 0.4882\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 02:01:03 - WARNING - __main__ - epoch 4 step 510 loss 0.14997\n",
      "[[0.98395467]\n",
      " [0.60924655]\n",
      " [0.12659557]\n",
      " ...\n",
      " [0.27024767]\n",
      " [0.5314039 ]\n",
      " [0.32486156]]\n",
      "04/14/2025 02:01:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:01:36 - INFO - __main__ -   auc_score = 0.9198\n",
      "04/14/2025 02:01:36 - INFO - __main__ -   eval_f1 = 0.6032\n",
      "04/14/2025 02:01:36 - INFO - __main__ -   eval_precision = 0.7017\n",
      "04/14/2025 02:01:36 - INFO - __main__ -   eval_recall = 0.5289\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 02:02:20 - WARNING - __main__ - epoch 5 step 102 loss 0.14558\n",
      "[[0.9865341 ]\n",
      " [0.6181833 ]\n",
      " [0.13105518]\n",
      " ...\n",
      " [0.32657355]\n",
      " [0.61371577]\n",
      " [0.37006798]]\n",
      "04/14/2025 02:02:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:02:53 - INFO - __main__ -   auc_score = 0.9195\n",
      "04/14/2025 02:02:53 - INFO - __main__ -   eval_f1 = 0.6091\n",
      "04/14/2025 02:02:53 - INFO - __main__ -   eval_precision = 0.6489\n",
      "04/14/2025 02:02:53 - INFO - __main__ -   eval_recall = 0.5739\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:03:37 - WARNING - __main__ - epoch 5 step 204 loss 0.1446\n",
      "[[0.9802729 ]\n",
      " [0.6279269 ]\n",
      " [0.10837045]\n",
      " ...\n",
      " [0.24201171]\n",
      " [0.5348346 ]\n",
      " [0.27851477]]\n",
      "04/14/2025 02:04:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:04:10 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 02:04:10 - INFO - __main__ -   eval_f1 = 0.598\n",
      "04/14/2025 02:04:10 - INFO - __main__ -   eval_precision = 0.7234\n",
      "04/14/2025 02:04:10 - INFO - __main__ -   eval_recall = 0.5096\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 02:04:53 - WARNING - __main__ - epoch 5 step 306 loss 0.12851\n",
      "[[0.9834795 ]\n",
      " [0.68405193]\n",
      " [0.09919516]\n",
      " ...\n",
      " [0.20089799]\n",
      " [0.44002396]\n",
      " [0.21803051]]\n",
      "04/14/2025 02:05:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:05:26 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 02:05:26 - INFO - __main__ -   eval_f1 = 0.6174\n",
      "04/14/2025 02:05:26 - INFO - __main__ -   eval_precision = 0.6962\n",
      "04/14/2025 02:05:26 - INFO - __main__ -   eval_recall = 0.5546\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 02:06:10 - WARNING - __main__ - epoch 5 step 408 loss 0.14264\n",
      "[[0.97862303]\n",
      " [0.64584917]\n",
      " [0.05694765]\n",
      " ...\n",
      " [0.11148325]\n",
      " [0.28329775]\n",
      " [0.12482263]]\n",
      "04/14/2025 02:06:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:06:43 - INFO - __main__ -   auc_score = 0.9154\n",
      "04/14/2025 02:06:43 - INFO - __main__ -   eval_f1 = 0.5955\n",
      "04/14/2025 02:06:43 - INFO - __main__ -   eval_precision = 0.774\n",
      "04/14/2025 02:06:43 - INFO - __main__ -   eval_recall = 0.4839\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 02:07:27 - WARNING - __main__ - epoch 5 step 510 loss 0.14316\n",
      "[[0.98822314]\n",
      " [0.69962305]\n",
      " [0.13714734]\n",
      " ...\n",
      " [0.19454555]\n",
      " [0.46868724]\n",
      " [0.24594256]]\n",
      "04/14/2025 02:08:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:08:00 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 02:08:00 - INFO - __main__ -   eval_f1 = 0.6079\n",
      "04/14/2025 02:08:00 - INFO - __main__ -   eval_precision = 0.7227\n",
      "04/14/2025 02:08:00 - INFO - __main__ -   eval_recall = 0.5246\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 02:08:44 - WARNING - __main__ - epoch 6 step 102 loss 0.13043\n",
      "[[0.99007833]\n",
      " [0.6990763 ]\n",
      " [0.13709575]\n",
      " ...\n",
      " [0.21539137]\n",
      " [0.5398101 ]\n",
      " [0.26741806]]\n",
      "04/14/2025 02:09:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:09:17 - INFO - __main__ -   auc_score = 0.9195\n",
      "04/14/2025 02:09:17 - INFO - __main__ -   eval_f1 = 0.606\n",
      "04/14/2025 02:09:17 - INFO - __main__ -   eval_precision = 0.6875\n",
      "04/14/2025 02:09:17 - INFO - __main__ -   eval_recall = 0.5418\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:10:00 - WARNING - __main__ - epoch 6 step 204 loss 0.12919\n",
      "[[0.9890083 ]\n",
      " [0.7025809 ]\n",
      " [0.16592915]\n",
      " ...\n",
      " [0.27051294]\n",
      " [0.61736214]\n",
      " [0.29889625]]\n",
      "04/14/2025 02:10:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:10:33 - INFO - __main__ -   auc_score = 0.9198\n",
      "04/14/2025 02:10:33 - INFO - __main__ -   eval_f1 = 0.6035\n",
      "04/14/2025 02:10:33 - INFO - __main__ -   eval_precision = 0.6649\n",
      "04/14/2025 02:10:33 - INFO - __main__ -   eval_recall = 0.5525\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 02:11:16 - WARNING - __main__ - epoch 6 step 306 loss 0.14528\n",
      "[[0.9934721 ]\n",
      " [0.7686785 ]\n",
      " [0.23192647]\n",
      " ...\n",
      " [0.29559052]\n",
      " [0.6729041 ]\n",
      " [0.31477115]]\n",
      "04/14/2025 02:11:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:11:49 - INFO - __main__ -   auc_score = 0.9203\n",
      "04/14/2025 02:11:49 - INFO - __main__ -   eval_f1 = 0.6057\n",
      "04/14/2025 02:11:49 - INFO - __main__ -   eval_precision = 0.6164\n",
      "04/14/2025 02:11:49 - INFO - __main__ -   eval_recall = 0.5953\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 02:12:32 - WARNING - __main__ - epoch 6 step 408 loss 0.13196\n",
      "[[0.99017465]\n",
      " [0.73733824]\n",
      " [0.09861312]\n",
      " ...\n",
      " [0.14614615]\n",
      " [0.38591132]\n",
      " [0.13909636]]\n",
      "04/14/2025 02:13:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:13:05 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/14/2025 02:13:05 - INFO - __main__ -   eval_f1 = 0.6139\n",
      "04/14/2025 02:13:05 - INFO - __main__ -   eval_precision = 0.7273\n",
      "04/14/2025 02:13:05 - INFO - __main__ -   eval_recall = 0.531\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 02:13:48 - WARNING - __main__ - epoch 6 step 510 loss 0.12735\n",
      "[[0.9953844 ]\n",
      " [0.7039544 ]\n",
      " [0.11979099]\n",
      " ...\n",
      " [0.27796966]\n",
      " [0.69319135]\n",
      " [0.37352958]]\n",
      "04/14/2025 02:14:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:14:21 - INFO - __main__ -   auc_score = 0.9196\n",
      "04/14/2025 02:14:21 - INFO - __main__ -   eval_f1 = 0.6109\n",
      "04/14/2025 02:14:21 - INFO - __main__ -   eval_precision = 0.6372\n",
      "04/14/2025 02:14:21 - INFO - __main__ -   eval_recall = 0.5867\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 02:15:05 - WARNING - __main__ - epoch 7 step 102 loss 0.13495\n",
      "[[0.995017  ]\n",
      " [0.7239216 ]\n",
      " [0.09332884]\n",
      " ...\n",
      " [0.21628755]\n",
      " [0.6767611 ]\n",
      " [0.34330094]]\n",
      "04/14/2025 02:15:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:15:38 - INFO - __main__ -   auc_score = 0.9181\n",
      "04/14/2025 02:15:38 - INFO - __main__ -   eval_f1 = 0.6112\n",
      "04/14/2025 02:15:38 - INFO - __main__ -   eval_precision = 0.6537\n",
      "04/14/2025 02:15:38 - INFO - __main__ -   eval_recall = 0.5739\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:16:22 - WARNING - __main__ - epoch 7 step 204 loss 0.12536\n",
      "[[0.9941543 ]\n",
      " [0.6969461 ]\n",
      " [0.07551751]\n",
      " ...\n",
      " [0.15259294]\n",
      " [0.53674173]\n",
      " [0.23526455]]\n",
      "04/14/2025 02:16:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:16:55 - INFO - __main__ -   auc_score = 0.9166\n",
      "04/14/2025 02:16:55 - INFO - __main__ -   eval_f1 = 0.6146\n",
      "04/14/2025 02:16:55 - INFO - __main__ -   eval_precision = 0.6995\n",
      "04/14/2025 02:16:55 - INFO - __main__ -   eval_recall = 0.5482\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 02:17:38 - WARNING - __main__ - epoch 7 step 306 loss 0.13501\n",
      "[[0.9929055 ]\n",
      " [0.7047384 ]\n",
      " [0.08755079]\n",
      " ...\n",
      " [0.15256517]\n",
      " [0.55922246]\n",
      " [0.23688293]]\n",
      "04/14/2025 02:18:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:18:11 - INFO - __main__ -   auc_score = 0.9172\n",
      "04/14/2025 02:18:11 - INFO - __main__ -   eval_f1 = 0.5985\n",
      "04/14/2025 02:18:11 - INFO - __main__ -   eval_precision = 0.693\n",
      "04/14/2025 02:18:11 - INFO - __main__ -   eval_recall = 0.5268\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 02:18:54 - WARNING - __main__ - epoch 7 step 408 loss 0.11988\n",
      "[[0.99344903]\n",
      " [0.7025755 ]\n",
      " [0.09757803]\n",
      " ...\n",
      " [0.17500953]\n",
      " [0.5888732 ]\n",
      " [0.24990359]]\n",
      "04/14/2025 02:19:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:19:27 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 02:19:27 - INFO - __main__ -   eval_f1 = 0.6085\n",
      "04/14/2025 02:19:27 - INFO - __main__ -   eval_precision = 0.6772\n",
      "04/14/2025 02:19:27 - INFO - __main__ -   eval_recall = 0.5525\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 02:20:10 - WARNING - __main__ - epoch 7 step 510 loss 0.11537\n",
      "[[0.99407214]\n",
      " [0.71833843]\n",
      " [0.11126497]\n",
      " ...\n",
      " [0.19262135]\n",
      " [0.6176922 ]\n",
      " [0.25705156]]\n",
      "04/14/2025 02:20:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:20:43 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 02:20:43 - INFO - __main__ -   eval_f1 = 0.6056\n",
      "04/14/2025 02:20:43 - INFO - __main__ -   eval_precision = 0.6608\n",
      "04/14/2025 02:20:43 - INFO - __main__ -   eval_recall = 0.5589\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 02:21:27 - WARNING - __main__ - epoch 8 step 102 loss 0.12048\n",
      "[[0.9949576 ]\n",
      " [0.7502949 ]\n",
      " [0.10784113]\n",
      " ...\n",
      " [0.19196233]\n",
      " [0.62250346]\n",
      " [0.2524313 ]]\n",
      "04/14/2025 02:22:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:22:00 - INFO - __main__ -   auc_score = 0.9172\n",
      "04/14/2025 02:22:00 - INFO - __main__ -   eval_f1 = 0.61\n",
      "04/14/2025 02:22:00 - INFO - __main__ -   eval_precision = 0.6684\n",
      "04/14/2025 02:22:00 - INFO - __main__ -   eval_recall = 0.561\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:22:43 - WARNING - __main__ - epoch 8 step 204 loss 0.11804\n",
      "[[0.9956201 ]\n",
      " [0.74736786]\n",
      " [0.13579363]\n",
      " ...\n",
      " [0.23883978]\n",
      " [0.7321131 ]\n",
      " [0.33717066]]\n",
      "04/14/2025 02:23:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:23:16 - INFO - __main__ -   auc_score = 0.9185\n",
      "04/14/2025 02:23:16 - INFO - __main__ -   eval_f1 = 0.6007\n",
      "04/14/2025 02:23:16 - INFO - __main__ -   eval_precision = 0.625\n",
      "04/14/2025 02:23:16 - INFO - __main__ -   eval_recall = 0.5782\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 02:24:00 - WARNING - __main__ - epoch 8 step 306 loss 0.12779\n",
      "[[0.99486154]\n",
      " [0.7435946 ]\n",
      " [0.11423369]\n",
      " ...\n",
      " [0.17628399]\n",
      " [0.59890145]\n",
      " [0.23383972]]\n",
      "04/14/2025 02:24:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:24:33 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/14/2025 02:24:33 - INFO - __main__ -   eval_f1 = 0.6084\n",
      "04/14/2025 02:24:33 - INFO - __main__ -   eval_precision = 0.6675\n",
      "04/14/2025 02:24:33 - INFO - __main__ -   eval_recall = 0.5589\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 02:25:16 - WARNING - __main__ - epoch 8 step 408 loss 0.12271\n",
      "[[0.994935  ]\n",
      " [0.716968  ]\n",
      " [0.10103462]\n",
      " ...\n",
      " [0.18940695]\n",
      " [0.615651  ]\n",
      " [0.24662158]]\n",
      "04/14/2025 02:25:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:25:49 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/14/2025 02:25:49 - INFO - __main__ -   eval_f1 = 0.6044\n",
      "04/14/2025 02:25:49 - INFO - __main__ -   eval_precision = 0.6641\n",
      "04/14/2025 02:25:49 - INFO - __main__ -   eval_recall = 0.5546\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 02:26:32 - WARNING - __main__ - epoch 8 step 510 loss 0.1164\n",
      "[[0.99490696]\n",
      " [0.7228655 ]\n",
      " [0.09630739]\n",
      " ...\n",
      " [0.16559514]\n",
      " [0.5953167 ]\n",
      " [0.23551682]]\n",
      "04/14/2025 02:27:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:27:05 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 02:27:05 - INFO - __main__ -   eval_f1 = 0.6114\n",
      "04/14/2025 02:27:05 - INFO - __main__ -   eval_precision = 0.6844\n",
      "04/14/2025 02:27:05 - INFO - __main__ -   eval_recall = 0.5525\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 02:27:49 - WARNING - __main__ - epoch 9 step 102 loss 0.11111\n",
      "[[0.9952331 ]\n",
      " [0.72229195]\n",
      " [0.09306746]\n",
      " ...\n",
      " [0.15741378]\n",
      " [0.59652716]\n",
      " [0.2322143 ]]\n",
      "04/14/2025 02:28:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:28:22 - INFO - __main__ -   auc_score = 0.9172\n",
      "04/14/2025 02:28:22 - INFO - __main__ -   eval_f1 = 0.606\n",
      "04/14/2025 02:28:22 - INFO - __main__ -   eval_precision = 0.6875\n",
      "04/14/2025 02:28:22 - INFO - __main__ -   eval_recall = 0.5418\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:29:05 - WARNING - __main__ - epoch 9 step 204 loss 0.11698\n",
      "[[0.996084  ]\n",
      " [0.7519256 ]\n",
      " [0.11117539]\n",
      " ...\n",
      " [0.18907997]\n",
      " [0.6575174 ]\n",
      " [0.2716955 ]]\n",
      "04/14/2025 02:29:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:29:38 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 02:29:38 - INFO - __main__ -   eval_f1 = 0.6106\n",
      "04/14/2025 02:29:38 - INFO - __main__ -   eval_precision = 0.6608\n",
      "04/14/2025 02:29:38 - INFO - __main__ -   eval_recall = 0.5675\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 02:30:21 - WARNING - __main__ - epoch 9 step 306 loss 0.12206\n",
      "[[0.99617237]\n",
      " [0.75730175]\n",
      " [0.11339538]\n",
      " ...\n",
      " [0.19526316]\n",
      " [0.66426337]\n",
      " [0.277914  ]]\n",
      "04/14/2025 02:30:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:30:54 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 02:30:54 - INFO - __main__ -   eval_f1 = 0.6039\n",
      "04/14/2025 02:30:54 - INFO - __main__ -   eval_precision = 0.6425\n",
      "04/14/2025 02:30:54 - INFO - __main__ -   eval_recall = 0.5696\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 02:31:38 - WARNING - __main__ - epoch 9 step 408 loss 0.11851\n",
      "[[0.99652207]\n",
      " [0.765406  ]\n",
      " [0.12370984]\n",
      " ...\n",
      " [0.2150109 ]\n",
      " [0.6990233 ]\n",
      " [0.30863157]]\n",
      "04/14/2025 02:32:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:32:11 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 02:32:11 - INFO - __main__ -   eval_f1 = 0.6056\n",
      "04/14/2025 02:32:11 - INFO - __main__ -   eval_precision = 0.6332\n",
      "04/14/2025 02:32:11 - INFO - __main__ -   eval_recall = 0.5803\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 02:32:54 - WARNING - __main__ - epoch 9 step 510 loss 0.11207\n",
      "[[0.99619764]\n",
      " [0.7605005 ]\n",
      " [0.11479126]\n",
      " ...\n",
      " [0.18956512]\n",
      " [0.6457414 ]\n",
      " [0.26772946]]\n",
      "04/14/2025 02:33:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:33:27 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 02:33:27 - INFO - __main__ -   eval_f1 = 0.6064\n",
      "04/14/2025 02:33:27 - INFO - __main__ -   eval_precision = 0.6511\n",
      "04/14/2025 02:33:27 - INFO - __main__ -   eval_recall = 0.5675\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuRuvKD_JWTV",
    "outputId": "5f5d74a5-871f-468a-8baf-4736e7e34c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 02:34:07.710698: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 02:34:07.728872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744598047.750907   92662 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744598047.757624   92662 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 02:34:07.780421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 02:35:23 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 02:35:23 - INFO - __main__ -   auc_score = 0.8999\n",
      "04/14/2025 02:35:23 - INFO - __main__ -   test_f1 = 0.5067\n",
      "04/14/2025 02:35:23 - INFO - __main__ -   test_precision = 0.6053\n",
      "04/14/2025 02:35:23 - INFO - __main__ -   test_recall = 0.4358\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svJo_eFNKy4X"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFFfidN_K22g",
    "outputId": "16d84073-7128-4a08-89b4-0eb69ca7ffb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 02:40:46.568058: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 02:40:46.586439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744598446.608713   95188 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744598446.615555   95188 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 02:40:46.637932: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:43<02:54,  2.35it/s]04/14/2025 02:43:49 - WARNING - __main__ - epoch 0 step 102 loss 0.31952\n",
      "[[0.49123523]\n",
      " [0.08768464]\n",
      " [0.10076721]\n",
      " ...\n",
      " [0.09400464]\n",
      " [0.21690261]\n",
      " [0.1108245 ]]\n",
      "04/14/2025 02:44:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:44:22 - INFO - __main__ -   auc_score = 0.8099\n",
      "04/14/2025 02:44:22 - INFO - __main__ -   eval_f1 = 0.057\n",
      "04/14/2025 02:44:22 - INFO - __main__ -   eval_precision = 0.5833\n",
      "04/14/2025 02:44:22 - INFO - __main__ -   eval_recall = 0.03\n",
      " 40% 203/512 [02:01<02:11,  2.35it/s]04/14/2025 02:45:07 - WARNING - __main__ - epoch 0 step 204 loss 0.22475\n",
      "[[0.79376733]\n",
      " [0.14898273]\n",
      " [0.18441296]\n",
      " ...\n",
      " [0.2724361 ]\n",
      " [0.44062665]\n",
      " [0.27461138]]\n",
      "04/14/2025 02:45:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:45:40 - INFO - __main__ -   auc_score = 0.8763\n",
      "04/14/2025 02:45:40 - INFO - __main__ -   eval_f1 = 0.3438\n",
      "04/14/2025 02:45:40 - INFO - __main__ -   eval_precision = 0.6358\n",
      "04/14/2025 02:45:40 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 60% 305/512 [03:18<01:28,  2.35it/s]04/14/2025 02:46:24 - WARNING - __main__ - epoch 0 step 306 loss 0.21583\n",
      "[[0.782965  ]\n",
      " [0.16977994]\n",
      " [0.13691984]\n",
      " ...\n",
      " [0.2423716 ]\n",
      " [0.43336535]\n",
      " [0.26595756]]\n",
      "04/14/2025 02:46:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:46:57 - INFO - __main__ -   auc_score = 0.8913\n",
      "04/14/2025 02:46:57 - INFO - __main__ -   eval_f1 = 0.359\n",
      "04/14/2025 02:46:57 - INFO - __main__ -   eval_precision = 0.7134\n",
      "04/14/2025 02:46:57 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 79% 407/512 [04:36<00:44,  2.35it/s]04/14/2025 02:47:42 - WARNING - __main__ - epoch 0 step 408 loss 0.21303\n",
      "[[0.85669976]\n",
      " [0.22384779]\n",
      " [0.07066198]\n",
      " ...\n",
      " [0.23204593]\n",
      " [0.39774352]\n",
      " [0.25053227]]\n",
      "04/14/2025 02:48:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:48:15 - INFO - __main__ -   auc_score = 0.8992\n",
      "04/14/2025 02:48:15 - INFO - __main__ -   eval_f1 = 0.4228\n",
      "04/14/2025 02:48:15 - INFO - __main__ -   eval_precision = 0.705\n",
      "04/14/2025 02:48:15 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 99% 509/512 [05:53<00:01,  2.35it/s]04/14/2025 02:48:59 - WARNING - __main__ - epoch 0 step 510 loss 0.18877\n",
      "[[0.93102926]\n",
      " [0.2155633 ]\n",
      " [0.09481125]\n",
      " ...\n",
      " [0.29013383]\n",
      " [0.58173   ]\n",
      " [0.3644011 ]]\n",
      "04/14/2025 02:49:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:49:32 - INFO - __main__ -   auc_score = 0.901\n",
      "04/14/2025 02:49:32 - INFO - __main__ -   eval_f1 = 0.478\n",
      "04/14/2025 02:49:32 - INFO - __main__ -   eval_precision = 0.5793\n",
      "04/14/2025 02:49:32 - INFO - __main__ -   eval_recall = 0.4069\n",
      "100% 512/512 [06:29<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 02:50:18 - WARNING - __main__ - epoch 1 step 102 loss 0.18501\n",
      "[[0.92545795]\n",
      " [0.2720851 ]\n",
      " [0.11005869]\n",
      " ...\n",
      " [0.2845461 ]\n",
      " [0.58262116]\n",
      " [0.33734384]]\n",
      "04/14/2025 02:50:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:50:51 - INFO - __main__ -   auc_score = 0.9062\n",
      "04/14/2025 02:50:51 - INFO - __main__ -   eval_f1 = 0.5\n",
      "04/14/2025 02:50:51 - INFO - __main__ -   eval_precision = 0.6137\n",
      "04/14/2025 02:50:51 - INFO - __main__ -   eval_recall = 0.4218\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 02:51:35 - WARNING - __main__ - epoch 1 step 204 loss 0.17916\n",
      "[[0.8928781 ]\n",
      " [0.27179566]\n",
      " [0.06246257]\n",
      " ...\n",
      " [0.18224797]\n",
      " [0.30604428]\n",
      " [0.21071598]]\n",
      "04/14/2025 02:52:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:52:08 - INFO - __main__ -   auc_score = 0.9085\n",
      "04/14/2025 02:52:08 - INFO - __main__ -   eval_f1 = 0.4414\n",
      "04/14/2025 02:52:08 - INFO - __main__ -   eval_precision = 0.7901\n",
      "04/14/2025 02:52:08 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 02:52:52 - WARNING - __main__ - epoch 1 step 306 loss 0.19268\n",
      "[[0.90689   ]\n",
      " [0.22558914]\n",
      " [0.06850121]\n",
      " ...\n",
      " [0.1805178 ]\n",
      " [0.40246853]\n",
      " [0.22242711]]\n",
      "04/14/2025 02:53:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:53:25 - INFO - __main__ -   auc_score = 0.9083\n",
      "04/14/2025 02:53:25 - INFO - __main__ -   eval_f1 = 0.4658\n",
      "04/14/2025 02:53:25 - INFO - __main__ -   eval_precision = 0.7273\n",
      "04/14/2025 02:53:25 - INFO - __main__ -   eval_recall = 0.3426\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 02:54:08 - WARNING - __main__ - epoch 1 step 408 loss 0.17605\n",
      "[[0.95958054]\n",
      " [0.35251358]\n",
      " [0.08636106]\n",
      " ...\n",
      " [0.24816458]\n",
      " [0.46635842]\n",
      " [0.30521253]]\n",
      "04/14/2025 02:54:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:54:41 - INFO - __main__ -   auc_score = 0.9114\n",
      "04/14/2025 02:54:41 - INFO - __main__ -   eval_f1 = 0.521\n",
      "04/14/2025 02:54:41 - INFO - __main__ -   eval_precision = 0.6406\n",
      "04/14/2025 02:54:41 - INFO - __main__ -   eval_recall = 0.439\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 02:55:25 - WARNING - __main__ - epoch 1 step 510 loss 0.19341\n",
      "[[0.9210189 ]\n",
      " [0.2939646 ]\n",
      " [0.06549755]\n",
      " ...\n",
      " [0.17866798]\n",
      " [0.30492157]\n",
      " [0.19126476]]\n",
      "04/14/2025 02:55:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:55:58 - INFO - __main__ -   auc_score = 0.9122\n",
      "04/14/2025 02:55:58 - INFO - __main__ -   eval_f1 = 0.4949\n",
      "04/14/2025 02:55:58 - INFO - __main__ -   eval_precision = 0.7824\n",
      "04/14/2025 02:55:58 - INFO - __main__ -   eval_recall = 0.3619\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 02:56:42 - WARNING - __main__ - epoch 2 step 102 loss 0.17831\n",
      "[[0.9059376 ]\n",
      " [0.31133243]\n",
      " [0.0599755 ]\n",
      " ...\n",
      " [0.21775764]\n",
      " [0.33618575]\n",
      " [0.205594  ]]\n",
      "04/14/2025 02:57:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:57:15 - INFO - __main__ -   auc_score = 0.9079\n",
      "04/14/2025 02:57:15 - INFO - __main__ -   eval_f1 = 0.489\n",
      "04/14/2025 02:57:15 - INFO - __main__ -   eval_precision = 0.7731\n",
      "04/14/2025 02:57:15 - INFO - __main__ -   eval_recall = 0.3576\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 02:57:59 - WARNING - __main__ - epoch 2 step 204 loss 0.17357\n",
      "[[0.95453674]\n",
      " [0.46469042]\n",
      " [0.08878355]\n",
      " ...\n",
      " [0.20996293]\n",
      " [0.3326592 ]\n",
      " [0.19757222]]\n",
      "04/14/2025 02:58:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:58:32 - INFO - __main__ -   auc_score = 0.9131\n",
      "04/14/2025 02:58:32 - INFO - __main__ -   eval_f1 = 0.5363\n",
      "04/14/2025 02:58:32 - INFO - __main__ -   eval_precision = 0.7424\n",
      "04/14/2025 02:58:32 - INFO - __main__ -   eval_recall = 0.4197\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 02:59:16 - WARNING - __main__ - epoch 2 step 306 loss 0.18444\n",
      "[[0.9588526 ]\n",
      " [0.41395217]\n",
      " [0.13410929]\n",
      " ...\n",
      " [0.2396278 ]\n",
      " [0.37034026]\n",
      " [0.2342918 ]]\n",
      "04/14/2025 02:59:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 02:59:49 - INFO - __main__ -   auc_score = 0.9138\n",
      "04/14/2025 02:59:49 - INFO - __main__ -   eval_f1 = 0.5455\n",
      "04/14/2025 02:59:49 - INFO - __main__ -   eval_precision = 0.7089\n",
      "04/14/2025 02:59:49 - INFO - __main__ -   eval_recall = 0.4433\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/14/2025 03:00:34 - WARNING - __main__ - epoch 2 step 408 loss 0.17577\n",
      "[[0.97047263]\n",
      " [0.45922288]\n",
      " [0.08574823]\n",
      " ...\n",
      " [0.19320652]\n",
      " [0.3820636 ]\n",
      " [0.2375007 ]]\n",
      "04/14/2025 03:01:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:01:07 - INFO - __main__ -   auc_score = 0.9144\n",
      "04/14/2025 03:01:07 - INFO - __main__ -   eval_f1 = 0.517\n",
      "04/14/2025 03:01:07 - INFO - __main__ -   eval_precision = 0.709\n",
      "04/14/2025 03:01:07 - INFO - __main__ -   eval_recall = 0.4069\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 03:01:50 - WARNING - __main__ - epoch 2 step 510 loss 0.15686\n",
      "[[0.97296655]\n",
      " [0.39525607]\n",
      " [0.04830904]\n",
      " ...\n",
      " [0.2558671 ]\n",
      " [0.47177264]\n",
      " [0.27880862]]\n",
      "04/14/2025 03:02:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:02:23 - INFO - __main__ -   auc_score = 0.9149\n",
      "04/14/2025 03:02:23 - INFO - __main__ -   eval_f1 = 0.5381\n",
      "04/14/2025 03:02:23 - INFO - __main__ -   eval_precision = 0.6604\n",
      "04/14/2025 03:02:23 - INFO - __main__ -   eval_recall = 0.454\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 03:03:07 - WARNING - __main__ - epoch 3 step 102 loss 0.15136\n",
      "[[0.975391  ]\n",
      " [0.44123718]\n",
      " [0.1276414 ]\n",
      " ...\n",
      " [0.23314708]\n",
      " [0.35611778]\n",
      " [0.21346058]]\n",
      "04/14/2025 03:03:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:03:40 - INFO - __main__ -   auc_score = 0.9149\n",
      "04/14/2025 03:03:40 - INFO - __main__ -   eval_f1 = 0.5287\n",
      "04/14/2025 03:03:40 - INFO - __main__ -   eval_precision = 0.7021\n",
      "04/14/2025 03:03:40 - INFO - __main__ -   eval_recall = 0.424\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:04:23 - WARNING - __main__ - epoch 3 step 204 loss 0.17421\n",
      "[[0.9753186 ]\n",
      " [0.485314  ]\n",
      " [0.17315276]\n",
      " ...\n",
      " [0.20671849]\n",
      " [0.37530014]\n",
      " [0.21579732]]\n",
      "04/14/2025 03:04:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:04:56 - INFO - __main__ -   auc_score = 0.9183\n",
      "04/14/2025 03:04:56 - INFO - __main__ -   eval_f1 = 0.5447\n",
      "04/14/2025 03:04:56 - INFO - __main__ -   eval_precision = 0.7234\n",
      "04/14/2025 03:04:56 - INFO - __main__ -   eval_recall = 0.4368\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:05:39 - WARNING - __main__ - epoch 3 step 306 loss 0.15162\n",
      "[[0.9793523 ]\n",
      " [0.4113352 ]\n",
      " [0.11227387]\n",
      " ...\n",
      " [0.22171442]\n",
      " [0.47267044]\n",
      " [0.25144938]]\n",
      "04/14/2025 03:06:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:06:12 - INFO - __main__ -   auc_score = 0.9173\n",
      "04/14/2025 03:06:12 - INFO - __main__ -   eval_f1 = 0.5469\n",
      "04/14/2025 03:06:12 - INFO - __main__ -   eval_precision = 0.7138\n",
      "04/14/2025 03:06:12 - INFO - __main__ -   eval_recall = 0.4433\n",
      " 79% 407/512 [04:32<00:44,  2.35it/s]04/14/2025 03:06:57 - WARNING - __main__ - epoch 3 step 408 loss 0.16904\n",
      "[[0.9655933 ]\n",
      " [0.46264634]\n",
      " [0.11210007]\n",
      " ...\n",
      " [0.1666387 ]\n",
      " [0.26689824]\n",
      " [0.13001075]]\n",
      "04/14/2025 03:07:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:07:30 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/14/2025 03:07:30 - INFO - __main__ -   eval_f1 = 0.5404\n",
      "04/14/2025 03:07:30 - INFO - __main__ -   eval_precision = 0.7729\n",
      "04/14/2025 03:07:30 - INFO - __main__ -   eval_recall = 0.4154\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 03:08:13 - WARNING - __main__ - epoch 3 step 510 loss 0.17344\n",
      "[[0.9786982 ]\n",
      " [0.5498136 ]\n",
      " [0.14340994]\n",
      " ...\n",
      " [0.25959054]\n",
      " [0.55989134]\n",
      " [0.24448486]]\n",
      "04/14/2025 03:08:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:08:46 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 03:08:46 - INFO - __main__ -   eval_f1 = 0.6011\n",
      "04/14/2025 03:08:46 - INFO - __main__ -   eval_precision = 0.6364\n",
      "04/14/2025 03:08:46 - INFO - __main__ -   eval_recall = 0.5696\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 03:09:31 - WARNING - __main__ - epoch 4 step 102 loss 0.14824\n",
      "[[0.9638647 ]\n",
      " [0.3994093 ]\n",
      " [0.046505  ]\n",
      " ...\n",
      " [0.10747649]\n",
      " [0.23008406]\n",
      " [0.08369909]]\n",
      "04/14/2025 03:10:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:10:04 - INFO - __main__ -   auc_score = 0.9167\n",
      "04/14/2025 03:10:04 - INFO - __main__ -   eval_f1 = 0.5161\n",
      "04/14/2025 03:10:04 - INFO - __main__ -   eval_precision = 0.8186\n",
      "04/14/2025 03:10:04 - INFO - __main__ -   eval_recall = 0.3769\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:10:47 - WARNING - __main__ - epoch 4 step 204 loss 0.17013\n",
      "[[0.979086  ]\n",
      " [0.5777704 ]\n",
      " [0.13431397]\n",
      " ...\n",
      " [0.16591626]\n",
      " [0.3847944 ]\n",
      " [0.11579396]]\n",
      "04/14/2025 03:11:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:11:20 - INFO - __main__ -   auc_score = 0.9205\n",
      "04/14/2025 03:11:20 - INFO - __main__ -   eval_f1 = 0.5956\n",
      "04/14/2025 03:11:20 - INFO - __main__ -   eval_precision = 0.7436\n",
      "04/14/2025 03:11:20 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:12:04 - WARNING - __main__ - epoch 4 step 306 loss 0.15106\n",
      "[[0.9708006 ]\n",
      " [0.49212608]\n",
      " [0.09598137]\n",
      " ...\n",
      " [0.12915458]\n",
      " [0.3254772 ]\n",
      " [0.09219982]]\n",
      "04/14/2025 03:12:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:12:37 - INFO - __main__ -   auc_score = 0.9197\n",
      "04/14/2025 03:12:37 - INFO - __main__ -   eval_f1 = 0.5378\n",
      "04/14/2025 03:12:37 - INFO - __main__ -   eval_precision = 0.7773\n",
      "04/14/2025 03:12:37 - INFO - __main__ -   eval_recall = 0.4111\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 03:13:20 - WARNING - __main__ - epoch 4 step 408 loss 0.14948\n",
      "[[0.9881196 ]\n",
      " [0.5424978 ]\n",
      " [0.10294364]\n",
      " ...\n",
      " [0.25034496]\n",
      " [0.5182693 ]\n",
      " [0.20048383]]\n",
      "04/14/2025 03:13:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:13:53 - INFO - __main__ -   auc_score = 0.9199\n",
      "04/14/2025 03:13:53 - INFO - __main__ -   eval_f1 = 0.5881\n",
      "04/14/2025 03:13:53 - INFO - __main__ -   eval_precision = 0.6798\n",
      "04/14/2025 03:13:53 - INFO - __main__ -   eval_recall = 0.5182\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 03:14:36 - WARNING - __main__ - epoch 4 step 510 loss 0.14978\n",
      "[[0.9858073 ]\n",
      " [0.5353537 ]\n",
      " [0.07580518]\n",
      " ...\n",
      " [0.21814798]\n",
      " [0.5104626 ]\n",
      " [0.17894508]]\n",
      "04/14/2025 03:15:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:15:09 - INFO - __main__ -   auc_score = 0.9186\n",
      "04/14/2025 03:15:09 - INFO - __main__ -   eval_f1 = 0.5655\n",
      "04/14/2025 03:15:09 - INFO - __main__ -   eval_precision = 0.7171\n",
      "04/14/2025 03:15:09 - INFO - __main__ -   eval_recall = 0.4668\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 03:15:53 - WARNING - __main__ - epoch 5 step 102 loss 0.15136\n",
      "[[0.9826969 ]\n",
      " [0.54929024]\n",
      " [0.12462188]\n",
      " ...\n",
      " [0.17530236]\n",
      " [0.43505082]\n",
      " [0.13134542]]\n",
      "04/14/2025 03:16:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:16:26 - INFO - __main__ -   auc_score = 0.9206\n",
      "04/14/2025 03:16:26 - INFO - __main__ -   eval_f1 = 0.5684\n",
      "04/14/2025 03:16:26 - INFO - __main__ -   eval_precision = 0.7483\n",
      "04/14/2025 03:16:26 - INFO - __main__ -   eval_recall = 0.4582\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:17:09 - WARNING - __main__ - epoch 5 step 204 loss 0.14925\n",
      "[[0.9809583 ]\n",
      " [0.5215775 ]\n",
      " [0.09748133]\n",
      " ...\n",
      " [0.2064356 ]\n",
      " [0.42358372]\n",
      " [0.11783418]]\n",
      "04/14/2025 03:17:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:17:42 - INFO - __main__ -   auc_score = 0.9201\n",
      "04/14/2025 03:17:42 - INFO - __main__ -   eval_f1 = 0.5875\n",
      "04/14/2025 03:17:42 - INFO - __main__ -   eval_precision = 0.7278\n",
      "04/14/2025 03:17:42 - INFO - __main__ -   eval_recall = 0.4925\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:18:25 - WARNING - __main__ - epoch 5 step 306 loss 0.13798\n",
      "[[0.98858833]\n",
      " [0.6155436 ]\n",
      " [0.08247305]\n",
      " ...\n",
      " [0.20002094]\n",
      " [0.28256235]\n",
      " [0.08232908]]\n",
      "04/14/2025 03:18:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:18:58 - INFO - __main__ -   auc_score = 0.9181\n",
      "04/14/2025 03:18:58 - INFO - __main__ -   eval_f1 = 0.617\n",
      "04/14/2025 03:18:58 - INFO - __main__ -   eval_precision = 0.7022\n",
      "04/14/2025 03:18:58 - INFO - __main__ -   eval_recall = 0.5503\n",
      " 79% 407/512 [04:33<00:44,  2.35it/s]04/14/2025 03:19:43 - WARNING - __main__ - epoch 5 step 408 loss 0.14733\n",
      "[[0.99230087]\n",
      " [0.56722724]\n",
      " [0.12741211]\n",
      " ...\n",
      " [0.3001205 ]\n",
      " [0.6862552 ]\n",
      " [0.24019273]]\n",
      "04/14/2025 03:20:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:20:16 - INFO - __main__ -   auc_score = 0.9191\n",
      "04/14/2025 03:20:16 - INFO - __main__ -   eval_f1 = 0.5886\n",
      "04/14/2025 03:20:16 - INFO - __main__ -   eval_precision = 0.6018\n",
      "04/14/2025 03:20:16 - INFO - __main__ -   eval_recall = 0.576\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 03:20:59 - WARNING - __main__ - epoch 5 step 510 loss 0.14416\n",
      "[[0.99041486]\n",
      " [0.6052177 ]\n",
      " [0.1037199 ]\n",
      " ...\n",
      " [0.23882164]\n",
      " [0.62777686]\n",
      " [0.17986968]]\n",
      "04/14/2025 03:21:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:21:32 - INFO - __main__ -   auc_score = 0.9195\n",
      "04/14/2025 03:21:32 - INFO - __main__ -   eval_f1 = 0.6057\n",
      "04/14/2025 03:21:32 - INFO - __main__ -   eval_precision = 0.6495\n",
      "04/14/2025 03:21:32 - INFO - __main__ -   eval_recall = 0.5675\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 03:22:16 - WARNING - __main__ - epoch 6 step 102 loss 0.14287\n",
      "[[0.987043  ]\n",
      " [0.5615296 ]\n",
      " [0.05835185]\n",
      " ...\n",
      " [0.12850021]\n",
      " [0.24777292]\n",
      " [0.06169371]]\n",
      "04/14/2025 03:22:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:22:49 - INFO - __main__ -   auc_score = 0.9185\n",
      "04/14/2025 03:22:49 - INFO - __main__ -   eval_f1 = 0.5741\n",
      "04/14/2025 03:22:49 - INFO - __main__ -   eval_precision = 0.7509\n",
      "04/14/2025 03:22:49 - INFO - __main__ -   eval_recall = 0.4647\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:23:32 - WARNING - __main__ - epoch 6 step 204 loss 0.13764\n",
      "[[0.9930964 ]\n",
      " [0.7078385 ]\n",
      " [0.141816  ]\n",
      " ...\n",
      " [0.22742048]\n",
      " [0.37946972]\n",
      " [0.11020032]]\n",
      "04/14/2025 03:24:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:24:05 - INFO - __main__ -   auc_score = 0.921\n",
      "04/14/2025 03:24:05 - INFO - __main__ -   eval_f1 = 0.6129\n",
      "04/14/2025 03:24:05 - INFO - __main__ -   eval_precision = 0.6633\n",
      "04/14/2025 03:24:05 - INFO - __main__ -   eval_recall = 0.5696\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:24:49 - WARNING - __main__ - epoch 6 step 306 loss 0.11414\n",
      "[[0.99395233]\n",
      " [0.6113063 ]\n",
      " [0.09585726]\n",
      " ...\n",
      " [0.26194996]\n",
      " [0.54361266]\n",
      " [0.14064762]]\n",
      "04/14/2025 03:25:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:25:22 - INFO - __main__ -   auc_score = 0.9191\n",
      "04/14/2025 03:25:22 - INFO - __main__ -   eval_f1 = 0.6103\n",
      "04/14/2025 03:25:22 - INFO - __main__ -   eval_precision = 0.6544\n",
      "04/14/2025 03:25:22 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 03:26:05 - WARNING - __main__ - epoch 6 step 408 loss 0.14189\n",
      "[[0.99337125]\n",
      " [0.59871244]\n",
      " [0.08465535]\n",
      " ...\n",
      " [0.25392815]\n",
      " [0.65408075]\n",
      " [0.15067124]]\n",
      "04/14/2025 03:26:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:26:38 - INFO - __main__ -   auc_score = 0.9186\n",
      "04/14/2025 03:26:38 - INFO - __main__ -   eval_f1 = 0.6027\n",
      "04/14/2025 03:26:38 - INFO - __main__ -   eval_precision = 0.6294\n",
      "04/14/2025 03:26:38 - INFO - __main__ -   eval_recall = 0.5782\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 03:27:21 - WARNING - __main__ - epoch 6 step 510 loss 0.15712\n",
      "[[0.99199826]\n",
      " [0.66836643]\n",
      " [0.10787888]\n",
      " ...\n",
      " [0.17465003]\n",
      " [0.5149232 ]\n",
      " [0.08732406]]\n",
      "04/14/2025 03:27:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:27:54 - INFO - __main__ -   auc_score = 0.9193\n",
      "04/14/2025 03:27:54 - INFO - __main__ -   eval_f1 = 0.6159\n",
      "04/14/2025 03:27:54 - INFO - __main__ -   eval_precision = 0.6925\n",
      "04/14/2025 03:27:54 - INFO - __main__ -   eval_recall = 0.5546\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 03:28:38 - WARNING - __main__ - epoch 7 step 102 loss 0.1226\n",
      "[[0.99351394]\n",
      " [0.6397501 ]\n",
      " [0.10106966]\n",
      " ...\n",
      " [0.16833565]\n",
      " [0.55479556]\n",
      " [0.08935734]]\n",
      "04/14/2025 03:29:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:29:11 - INFO - __main__ -   auc_score = 0.919\n",
      "04/14/2025 03:29:11 - INFO - __main__ -   eval_f1 = 0.6081\n",
      "04/14/2025 03:29:11 - INFO - __main__ -   eval_precision = 0.7074\n",
      "04/14/2025 03:29:11 - INFO - __main__ -   eval_recall = 0.5332\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:29:54 - WARNING - __main__ - epoch 7 step 204 loss 0.12881\n",
      "[[0.9945834 ]\n",
      " [0.68870664]\n",
      " [0.10411835]\n",
      " ...\n",
      " [0.24563102]\n",
      " [0.6846761 ]\n",
      " [0.14796518]]\n",
      "04/14/2025 03:30:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:30:27 - INFO - __main__ -   auc_score = 0.919\n",
      "04/14/2025 03:30:27 - INFO - __main__ -   eval_f1 = 0.6039\n",
      "04/14/2025 03:30:27 - INFO - __main__ -   eval_precision = 0.6599\n",
      "04/14/2025 03:30:27 - INFO - __main__ -   eval_recall = 0.5567\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:31:10 - WARNING - __main__ - epoch 7 step 306 loss 0.14741\n",
      "[[0.9937239 ]\n",
      " [0.66801363]\n",
      " [0.11854151]\n",
      " ...\n",
      " [0.20124799]\n",
      " [0.58857834]\n",
      " [0.12129847]]\n",
      "04/14/2025 03:31:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:31:43 - INFO - __main__ -   auc_score = 0.9196\n",
      "04/14/2025 03:31:43 - INFO - __main__ -   eval_f1 = 0.6139\n",
      "04/14/2025 03:31:43 - INFO - __main__ -   eval_precision = 0.6842\n",
      "04/14/2025 03:31:43 - INFO - __main__ -   eval_recall = 0.5567\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 03:32:27 - WARNING - __main__ - epoch 7 step 408 loss 0.1326\n",
      "[[0.9932749 ]\n",
      " [0.6477978 ]\n",
      " [0.10005847]\n",
      " ...\n",
      " [0.21719484]\n",
      " [0.5853752 ]\n",
      " [0.11252752]]\n",
      "04/14/2025 03:33:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:33:00 - INFO - __main__ -   auc_score = 0.9194\n",
      "04/14/2025 03:33:00 - INFO - __main__ -   eval_f1 = 0.6095\n",
      "04/14/2025 03:33:00 - INFO - __main__ -   eval_precision = 0.6641\n",
      "04/14/2025 03:33:00 - INFO - __main__ -   eval_recall = 0.5632\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 03:33:43 - WARNING - __main__ - epoch 7 step 510 loss 0.12648\n",
      "[[0.9933119 ]\n",
      " [0.68990105]\n",
      " [0.10238192]\n",
      " ...\n",
      " [0.16872318]\n",
      " [0.5121097 ]\n",
      " [0.08049978]]\n",
      "04/14/2025 03:34:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:34:16 - INFO - __main__ -   auc_score = 0.9189\n",
      "04/14/2025 03:34:16 - INFO - __main__ -   eval_f1 = 0.6152\n",
      "04/14/2025 03:34:16 - INFO - __main__ -   eval_precision = 0.6907\n",
      "04/14/2025 03:34:16 - INFO - __main__ -   eval_recall = 0.5546\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 03:35:00 - WARNING - __main__ - epoch 8 step 102 loss 0.12184\n",
      "[[0.99504024]\n",
      " [0.6525097 ]\n",
      " [0.06707075]\n",
      " ...\n",
      " [0.21068332]\n",
      " [0.5746025 ]\n",
      " [0.10052394]]\n",
      "04/14/2025 03:35:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:35:33 - INFO - __main__ -   auc_score = 0.918\n",
      "04/14/2025 03:35:33 - INFO - __main__ -   eval_f1 = 0.6063\n",
      "04/14/2025 03:35:33 - INFO - __main__ -   eval_precision = 0.6719\n",
      "04/14/2025 03:35:33 - INFO - __main__ -   eval_recall = 0.5525\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:36:16 - WARNING - __main__ - epoch 8 step 204 loss 0.12807\n",
      "[[0.99532545]\n",
      " [0.6434926 ]\n",
      " [0.05291767]\n",
      " ...\n",
      " [0.1983752 ]\n",
      " [0.60983294]\n",
      " [0.10745106]]\n",
      "04/14/2025 03:36:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:36:49 - INFO - __main__ -   auc_score = 0.918\n",
      "04/14/2025 03:36:49 - INFO - __main__ -   eval_f1 = 0.6022\n",
      "04/14/2025 03:36:49 - INFO - __main__ -   eval_precision = 0.6811\n",
      "04/14/2025 03:36:49 - INFO - __main__ -   eval_recall = 0.5396\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:37:32 - WARNING - __main__ - epoch 8 step 306 loss 0.13009\n",
      "[[0.9955432 ]\n",
      " [0.6914087 ]\n",
      " [0.09011389]\n",
      " ...\n",
      " [0.19891137]\n",
      " [0.69083405]\n",
      " [0.12162817]]\n",
      "04/14/2025 03:38:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:38:05 - INFO - __main__ -   auc_score = 0.919\n",
      "04/14/2025 03:38:05 - INFO - __main__ -   eval_f1 = 0.6065\n",
      "04/14/2025 03:38:05 - INFO - __main__ -   eval_precision = 0.6599\n",
      "04/14/2025 03:38:05 - INFO - __main__ -   eval_recall = 0.561\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 03:38:48 - WARNING - __main__ - epoch 8 step 408 loss 0.12235\n",
      "[[0.99607277]\n",
      " [0.7076245 ]\n",
      " [0.09925713]\n",
      " ...\n",
      " [0.21716172]\n",
      " [0.7032101 ]\n",
      " [0.13676304]]\n",
      "04/14/2025 03:39:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:39:21 - INFO - __main__ -   auc_score = 0.9192\n",
      "04/14/2025 03:39:21 - INFO - __main__ -   eval_f1 = 0.6054\n",
      "04/14/2025 03:39:21 - INFO - __main__ -   eval_precision = 0.6434\n",
      "04/14/2025 03:39:21 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 03:40:05 - WARNING - __main__ - epoch 8 step 510 loss 0.13148\n",
      "[[0.996027  ]\n",
      " [0.72101396]\n",
      " [0.11992179]\n",
      " ...\n",
      " [0.22908366]\n",
      " [0.6710646 ]\n",
      " [0.11901114]]\n",
      "04/14/2025 03:40:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:40:38 - INFO - __main__ -   auc_score = 0.9193\n",
      "04/14/2025 03:40:38 - INFO - __main__ -   eval_f1 = 0.6118\n",
      "04/14/2025 03:40:38 - INFO - __main__ -   eval_precision = 0.627\n",
      "04/14/2025 03:40:38 - INFO - __main__ -   eval_recall = 0.5974\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 03:41:22 - WARNING - __main__ - epoch 9 step 102 loss 0.11849\n",
      "[[0.99540603]\n",
      " [0.6946928 ]\n",
      " [0.10066081]\n",
      " ...\n",
      " [0.19719559]\n",
      " [0.5397832 ]\n",
      " [0.08267069]]\n",
      "04/14/2025 03:41:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:41:55 - INFO - __main__ -   auc_score = 0.9188\n",
      "04/14/2025 03:41:55 - INFO - __main__ -   eval_f1 = 0.6166\n",
      "04/14/2025 03:41:55 - INFO - __main__ -   eval_precision = 0.6578\n",
      "04/14/2025 03:41:55 - INFO - __main__ -   eval_recall = 0.5803\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 03:42:38 - WARNING - __main__ - epoch 9 step 204 loss 0.11952\n",
      "[[0.9964051 ]\n",
      " [0.6978514 ]\n",
      " [0.11018898]\n",
      " ...\n",
      " [0.25357467]\n",
      " [0.70729387]\n",
      " [0.14216982]]\n",
      "04/14/2025 03:43:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:43:11 - INFO - __main__ -   auc_score = 0.9194\n",
      "04/14/2025 03:43:11 - INFO - __main__ -   eval_f1 = 0.6102\n",
      "04/14/2025 03:43:11 - INFO - __main__ -   eval_precision = 0.6189\n",
      "04/14/2025 03:43:11 - INFO - __main__ -   eval_recall = 0.6017\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 03:43:54 - WARNING - __main__ - epoch 9 step 306 loss 0.12\n",
      "[[0.99604934]\n",
      " [0.685892  ]\n",
      " [0.08871379]\n",
      " ...\n",
      " [0.21222463]\n",
      " [0.6299919 ]\n",
      " [0.10801091]]\n",
      "04/14/2025 03:44:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:44:27 - INFO - __main__ -   auc_score = 0.9188\n",
      "04/14/2025 03:44:27 - INFO - __main__ -   eval_f1 = 0.6147\n",
      "04/14/2025 03:44:27 - INFO - __main__ -   eval_precision = 0.6507\n",
      "04/14/2025 03:44:27 - INFO - __main__ -   eval_recall = 0.5824\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 03:45:10 - WARNING - __main__ - epoch 9 step 408 loss 0.13629\n",
      "[[0.9961718 ]\n",
      " [0.6838959 ]\n",
      " [0.08846397]\n",
      " ...\n",
      " [0.22024646]\n",
      " [0.66810185]\n",
      " [0.11837883]]\n",
      "04/14/2025 03:45:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:45:43 - INFO - __main__ -   auc_score = 0.919\n",
      "04/14/2025 03:45:43 - INFO - __main__ -   eval_f1 = 0.6157\n",
      "04/14/2025 03:45:43 - INFO - __main__ -   eval_precision = 0.6478\n",
      "04/14/2025 03:45:43 - INFO - __main__ -   eval_recall = 0.5867\n",
      " 99% 509/512 [05:47<00:01,  2.35it/s]04/14/2025 03:46:26 - WARNING - __main__ - epoch 9 step 510 loss 0.1167\n",
      "[[0.99600655]\n",
      " [0.6820269 ]\n",
      " [0.08189194]\n",
      " ...\n",
      " [0.20547208]\n",
      " [0.63313365]\n",
      " [0.10568503]]\n",
      "04/14/2025 03:46:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 03:46:59 - INFO - __main__ -   auc_score = 0.9188\n",
      "04/14/2025 03:46:59 - INFO - __main__ -   eval_f1 = 0.614\n",
      "04/14/2025 03:46:59 - INFO - __main__ -   eval_precision = 0.6601\n",
      "04/14/2025 03:46:59 - INFO - __main__ -   eval_recall = 0.5739\n",
      "100% 512/512 [06:21<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Xx15rOmejmz",
    "outputId": "cf6d9273-3822-4e87-cd62-c722e32766a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 04:07:03.710246: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 04:07:03.728735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744603623.750761  128407 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744603623.757628  128407 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 04:07:03.780640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 04:08:19 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 04:08:19 - INFO - __main__ -   auc_score = 0.8987\n",
      "04/14/2025 04:08:19 - INFO - __main__ -   test_f1 = 0.5252\n",
      "04/14/2025 04:08:19 - INFO - __main__ -   test_precision = 0.61\n",
      "04/14/2025 04:08:19 - INFO - __main__ -   test_recall = 0.4611\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUUnaT5rYzeF"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fz5vj-dY-g8",
    "outputId": "572b6ed8-56cd-432d-cc6d-319b9cc5f385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 13:01:43.617870: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 13:01:43.635530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744635703.657486    3513 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744635703.664172    3513 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 13:01:43.687022: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "config.json: 100% 691/691 [00:00<00:00, 5.14MB/s]\n",
      "tokenizer_config.json: 100% 1.11k/1.11k [00:00<00:00, 7.06MB/s]\n",
      "vocab.json: 100% 938k/938k [00:00<00:00, 1.93MB/s]\n",
      "merges.txt: 100% 444k/444k [00:00<00:00, 1.02MB/s]\n",
      "special_tokens_map.json: 100% 772/772 [00:00<00:00, 5.93MB/s]\n",
      "pytorch_model.bin: 100% 504M/504M [00:01<00:00, 374MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "model.safetensors: 100% 504M/504M [00:01<00:00, 331MB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:44<02:55,  2.35it/s]04/14/2025 13:05:04 - WARNING - __main__ - epoch 0 step 102 loss 0.30567\n",
      "[[0.4112656 ]\n",
      " [0.11375376]\n",
      " [0.11847661]\n",
      " ...\n",
      " [0.11048859]\n",
      " [0.22376424]\n",
      " [0.15039824]]\n",
      "04/14/2025 13:05:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:05:37 - INFO - __main__ -   auc_score = 0.8029\n",
      "04/14/2025 13:05:37 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "04/14/2025 13:05:37 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/14/2025 13:05:37 - INFO - __main__ -   eval_recall = 0.0043\n",
      " 40% 203/512 [02:01<02:11,  2.34it/s]04/14/2025 13:06:22 - WARNING - __main__ - epoch 0 step 204 loss 0.24527\n",
      "[[0.6464739 ]\n",
      " [0.10389338]\n",
      " [0.10698155]\n",
      " ...\n",
      " [0.16739206]\n",
      " [0.231202  ]\n",
      " [0.19149667]]\n",
      "04/14/2025 13:06:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:06:55 - INFO - __main__ -   auc_score = 0.8733\n",
      "04/14/2025 13:06:55 - INFO - __main__ -   eval_f1 = 0.1467\n",
      "04/14/2025 13:06:55 - INFO - __main__ -   eval_precision = 0.7451\n",
      "04/14/2025 13:06:55 - INFO - __main__ -   eval_recall = 0.0814\n",
      " 60% 305/512 [03:19<01:28,  2.35it/s]04/14/2025 13:07:39 - WARNING - __main__ - epoch 0 step 306 loss 0.1965\n",
      "[[0.8039345 ]\n",
      " [0.14107671]\n",
      " [0.12896696]\n",
      " ...\n",
      " [0.29245475]\n",
      " [0.4040092 ]\n",
      " [0.33306924]]\n",
      "04/14/2025 13:08:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:08:13 - INFO - __main__ -   auc_score = 0.8932\n",
      "04/14/2025 13:08:13 - INFO - __main__ -   eval_f1 = 0.3725\n",
      "04/14/2025 13:08:13 - INFO - __main__ -   eval_precision = 0.6919\n",
      "04/14/2025 13:08:13 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 79% 407/512 [04:37<00:44,  2.35it/s]04/14/2025 13:08:57 - WARNING - __main__ - epoch 0 step 408 loss 0.19946\n",
      "[[0.81414205]\n",
      " [0.2746728 ]\n",
      " [0.15688285]\n",
      " ...\n",
      " [0.25044546]\n",
      " [0.30651885]\n",
      " [0.23418082]]\n",
      "04/14/2025 13:09:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:09:30 - INFO - __main__ -   auc_score = 0.9012\n",
      "04/14/2025 13:09:30 - INFO - __main__ -   eval_f1 = 0.4056\n",
      "04/14/2025 13:09:30 - INFO - __main__ -   eval_precision = 0.7471\n",
      "04/14/2025 13:09:30 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 99% 509/512 [05:54<00:01,  2.35it/s]04/14/2025 13:10:15 - WARNING - __main__ - epoch 0 step 510 loss 0.1956\n",
      "[[0.8790466 ]\n",
      " [0.2466641 ]\n",
      " [0.11995016]\n",
      " ...\n",
      " [0.21779089]\n",
      " [0.3560273 ]\n",
      " [0.24211861]]\n",
      "04/14/2025 13:10:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:10:48 - INFO - __main__ -   auc_score = 0.9059\n",
      "04/14/2025 13:10:48 - INFO - __main__ -   eval_f1 = 0.4111\n",
      "04/14/2025 13:10:48 - INFO - __main__ -   eval_precision = 0.7389\n",
      "04/14/2025 13:10:48 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [06:30<00:00,  1.31it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:11:33 - WARNING - __main__ - epoch 1 step 102 loss 0.18451\n",
      "[[0.9193118 ]\n",
      " [0.30122083]\n",
      " [0.10487232]\n",
      " ...\n",
      " [0.22802234]\n",
      " [0.43535843]\n",
      " [0.2666822 ]]\n",
      "04/14/2025 13:12:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:12:06 - INFO - __main__ -   auc_score = 0.9071\n",
      "04/14/2025 13:12:06 - INFO - __main__ -   eval_f1 = 0.4709\n",
      "04/14/2025 13:12:06 - INFO - __main__ -   eval_precision = 0.6975\n",
      "04/14/2025 13:12:06 - INFO - __main__ -   eval_recall = 0.3555\n",
      " 40% 203/512 [02:00<02:12,  2.34it/s]04/14/2025 13:12:51 - WARNING - __main__ - epoch 1 step 204 loss 0.18993\n",
      "[[0.86693007]\n",
      " [0.33624512]\n",
      " [0.07160281]\n",
      " ...\n",
      " [0.19175097]\n",
      " [0.2127351 ]\n",
      " [0.17794226]]\n",
      "04/14/2025 13:13:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:13:24 - INFO - __main__ -   auc_score = 0.9051\n",
      "04/14/2025 13:13:24 - INFO - __main__ -   eval_f1 = 0.4063\n",
      "04/14/2025 13:13:24 - INFO - __main__ -   eval_precision = 0.7679\n",
      "04/14/2025 13:13:24 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 13:14:07 - WARNING - __main__ - epoch 1 step 306 loss 0.18368\n",
      "[[0.88485944]\n",
      " [0.34720564]\n",
      " [0.12768832]\n",
      " ...\n",
      " [0.13463095]\n",
      " [0.18295595]\n",
      " [0.14620261]]\n",
      "04/14/2025 13:14:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:14:40 - INFO - __main__ -   auc_score = 0.9095\n",
      "04/14/2025 13:14:40 - INFO - __main__ -   eval_f1 = 0.3994\n",
      "04/14/2025 13:14:40 - INFO - __main__ -   eval_precision = 0.7683\n",
      "04/14/2025 13:14:40 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 79% 407/512 [04:33<00:44,  2.34it/s]04/14/2025 13:15:24 - WARNING - __main__ - epoch 1 step 408 loss 0.19322\n",
      "[[0.9155377 ]\n",
      " [0.35261816]\n",
      " [0.13529868]\n",
      " ...\n",
      " [0.21303236]\n",
      " [0.25420418]\n",
      " [0.22374018]]\n",
      "04/14/2025 13:15:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:15:57 - INFO - __main__ -   auc_score = 0.9122\n",
      "04/14/2025 13:15:57 - INFO - __main__ -   eval_f1 = 0.4831\n",
      "04/14/2025 13:15:57 - INFO - __main__ -   eval_precision = 0.7736\n",
      "04/14/2025 13:15:57 - INFO - __main__ -   eval_recall = 0.3512\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 13:16:41 - WARNING - __main__ - epoch 1 step 510 loss 0.17069\n",
      "[[0.94664365]\n",
      " [0.47096133]\n",
      " [0.17950529]\n",
      " ...\n",
      " [0.28125927]\n",
      " [0.40157235]\n",
      " [0.29790395]]\n",
      "04/14/2025 13:17:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:17:14 - INFO - __main__ -   auc_score = 0.9133\n",
      "04/14/2025 13:17:14 - INFO - __main__ -   eval_f1 = 0.5319\n",
      "04/14/2025 13:17:14 - INFO - __main__ -   eval_precision = 0.7018\n",
      "04/14/2025 13:17:14 - INFO - __main__ -   eval_recall = 0.4283\n",
      "100% 512/512 [06:26<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:18:00 - WARNING - __main__ - epoch 2 step 102 loss 0.17205\n",
      "[[0.96257496]\n",
      " [0.5013186 ]\n",
      " [0.19208416]\n",
      " ...\n",
      " [0.32409048]\n",
      " [0.49010867]\n",
      " [0.33584082]]\n",
      "04/14/2025 13:18:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:18:33 - INFO - __main__ -   auc_score = 0.9138\n",
      "04/14/2025 13:18:33 - INFO - __main__ -   eval_f1 = 0.5355\n",
      "04/14/2025 13:18:33 - INFO - __main__ -   eval_precision = 0.6399\n",
      "04/14/2025 13:18:33 - INFO - __main__ -   eval_recall = 0.4604\n",
      " 40% 203/512 [02:00<02:11,  2.35it/s]04/14/2025 13:19:17 - WARNING - __main__ - epoch 2 step 204 loss 0.17031\n",
      "[[0.9384696 ]\n",
      " [0.3699251 ]\n",
      " [0.1079822 ]\n",
      " ...\n",
      " [0.21892278]\n",
      " [0.27075022]\n",
      " [0.159499  ]]\n",
      "04/14/2025 13:19:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:19:50 - INFO - __main__ -   auc_score = 0.9126\n",
      "04/14/2025 13:19:50 - INFO - __main__ -   eval_f1 = 0.5072\n",
      "04/14/2025 13:19:50 - INFO - __main__ -   eval_precision = 0.7662\n",
      "04/14/2025 13:19:50 - INFO - __main__ -   eval_recall = 0.379\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 13:20:34 - WARNING - __main__ - epoch 2 step 306 loss 0.17135\n",
      "[[0.94051445]\n",
      " [0.4156901 ]\n",
      " [0.10787222]\n",
      " ...\n",
      " [0.17873727]\n",
      " [0.25955504]\n",
      " [0.1525964 ]]\n",
      "04/14/2025 13:21:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:21:07 - INFO - __main__ -   auc_score = 0.914\n",
      "04/14/2025 13:21:07 - INFO - __main__ -   eval_f1 = 0.4956\n",
      "04/14/2025 13:21:07 - INFO - __main__ -   eval_precision = 0.786\n",
      "04/14/2025 13:21:07 - INFO - __main__ -   eval_recall = 0.3619\n",
      " 79% 407/512 [04:33<00:44,  2.34it/s]04/14/2025 13:21:50 - WARNING - __main__ - epoch 2 step 408 loss 0.17949\n",
      "[[0.9456092 ]\n",
      " [0.4668636 ]\n",
      " [0.12893377]\n",
      " ...\n",
      " [0.2002051 ]\n",
      " [0.31817055]\n",
      " [0.18465373]]\n",
      "04/14/2025 13:22:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:22:23 - INFO - __main__ -   auc_score = 0.9152\n",
      "04/14/2025 13:22:23 - INFO - __main__ -   eval_f1 = 0.5275\n",
      "04/14/2025 13:22:23 - INFO - __main__ -   eval_precision = 0.7727\n",
      "04/14/2025 13:22:23 - INFO - __main__ -   eval_recall = 0.4004\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 13:23:06 - WARNING - __main__ - epoch 2 step 510 loss 0.17494\n",
      "[[0.94025403]\n",
      " [0.4205891 ]\n",
      " [0.14270139]\n",
      " ...\n",
      " [0.23158431]\n",
      " [0.14602172]\n",
      " [0.12612   ]]\n",
      "04/14/2025 13:23:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:23:39 - INFO - __main__ -   auc_score = 0.9135\n",
      "04/14/2025 13:23:39 - INFO - __main__ -   eval_f1 = 0.513\n",
      "04/14/2025 13:23:39 - INFO - __main__ -   eval_precision = 0.7841\n",
      "04/14/2025 13:23:39 - INFO - __main__ -   eval_recall = 0.3812\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:24:23 - WARNING - __main__ - epoch 3 step 102 loss 0.1591\n",
      "[[0.95843416]\n",
      " [0.44564262]\n",
      " [0.17426614]\n",
      " ...\n",
      " [0.27225104]\n",
      " [0.3915684 ]\n",
      " [0.24110813]]\n",
      "04/14/2025 13:24:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:24:56 - INFO - __main__ -   auc_score = 0.9167\n",
      "04/14/2025 13:24:56 - INFO - __main__ -   eval_f1 = 0.5306\n",
      "04/14/2025 13:24:56 - INFO - __main__ -   eval_precision = 0.7549\n",
      "04/14/2025 13:24:56 - INFO - __main__ -   eval_recall = 0.409\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 13:25:39 - WARNING - __main__ - epoch 3 step 204 loss 0.16122\n",
      "[[0.9547869 ]\n",
      " [0.51601386]\n",
      " [0.21930572]\n",
      " ...\n",
      " [0.20000783]\n",
      " [0.22033732]\n",
      " [0.1261063 ]]\n",
      "04/14/2025 13:26:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:26:13 - INFO - __main__ -   auc_score = 0.9157\n",
      "04/14/2025 13:26:13 - INFO - __main__ -   eval_f1 = 0.5485\n",
      "04/14/2025 13:26:13 - INFO - __main__ -   eval_precision = 0.7765\n",
      "04/14/2025 13:26:13 - INFO - __main__ -   eval_recall = 0.424\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 13:26:57 - WARNING - __main__ - epoch 3 step 306 loss 0.14792\n",
      "[[0.9685327 ]\n",
      " [0.43485388]\n",
      " [0.09626637]\n",
      " ...\n",
      " [0.1808245 ]\n",
      " [0.31531468]\n",
      " [0.17230609]]\n",
      "04/14/2025 13:27:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:27:30 - INFO - __main__ -   auc_score = 0.9162\n",
      "04/14/2025 13:27:30 - INFO - __main__ -   eval_f1 = 0.5215\n",
      "04/14/2025 13:27:30 - INFO - __main__ -   eval_precision = 0.7879\n",
      "04/14/2025 13:27:30 - INFO - __main__ -   eval_recall = 0.3897\n",
      " 79% 407/512 [04:33<00:44,  2.34it/s]04/14/2025 13:28:13 - WARNING - __main__ - epoch 3 step 408 loss 0.16521\n",
      "[[0.9740269 ]\n",
      " [0.5497548 ]\n",
      " [0.22382876]\n",
      " ...\n",
      " [0.26910034]\n",
      " [0.28770524]\n",
      " [0.15432726]]\n",
      "04/14/2025 13:28:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:28:46 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 13:28:46 - INFO - __main__ -   eval_f1 = 0.6008\n",
      "04/14/2025 13:28:46 - INFO - __main__ -   eval_precision = 0.736\n",
      "04/14/2025 13:28:46 - INFO - __main__ -   eval_recall = 0.5075\n",
      " 99% 509/512 [05:50<00:01,  2.35it/s]04/14/2025 13:29:31 - WARNING - __main__ - epoch 3 step 510 loss 0.17226\n",
      "[[0.9696955 ]\n",
      " [0.5304969 ]\n",
      " [0.15827009]\n",
      " ...\n",
      " [0.26282972]\n",
      " [0.3478107 ]\n",
      " [0.16856037]]\n",
      "04/14/2025 13:30:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:30:04 - INFO - __main__ -   auc_score = 0.918\n",
      "04/14/2025 13:30:04 - INFO - __main__ -   eval_f1 = 0.5987\n",
      "04/14/2025 13:30:04 - INFO - __main__ -   eval_precision = 0.7256\n",
      "04/14/2025 13:30:04 - INFO - __main__ -   eval_recall = 0.5096\n",
      "100% 512/512 [06:24<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:30:48 - WARNING - __main__ - epoch 4 step 102 loss 0.15177\n",
      "[[0.981834  ]\n",
      " [0.5202432 ]\n",
      " [0.19639881]\n",
      " ...\n",
      " [0.3862388 ]\n",
      " [0.39786142]\n",
      " [0.24645075]]\n",
      "04/14/2025 13:31:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:31:21 - INFO - __main__ -   auc_score = 0.9183\n",
      "04/14/2025 13:31:21 - INFO - __main__ -   eval_f1 = 0.6007\n",
      "04/14/2025 13:31:21 - INFO - __main__ -   eval_precision = 0.6327\n",
      "04/14/2025 13:31:21 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 40% 203/512 [01:59<02:11,  2.34it/s]04/14/2025 13:32:04 - WARNING - __main__ - epoch 4 step 204 loss 0.15026\n",
      "[[0.9782534 ]\n",
      " [0.63518935]\n",
      " [0.21766502]\n",
      " ...\n",
      " [0.2352341 ]\n",
      " [0.21245442]\n",
      " [0.12817588]]\n",
      "04/14/2025 13:32:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:32:37 - INFO - __main__ -   auc_score = 0.9153\n",
      "04/14/2025 13:32:37 - INFO - __main__ -   eval_f1 = 0.5788\n",
      "04/14/2025 13:32:37 - INFO - __main__ -   eval_precision = 0.7296\n",
      "04/14/2025 13:32:37 - INFO - __main__ -   eval_recall = 0.4797\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 13:33:21 - WARNING - __main__ - epoch 4 step 306 loss 0.14234\n",
      "[[0.9778311 ]\n",
      " [0.55859405]\n",
      " [0.12879172]\n",
      " ...\n",
      " [0.27088845]\n",
      " [0.5042749 ]\n",
      " [0.22039418]]\n",
      "04/14/2025 13:33:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:33:54 - INFO - __main__ -   auc_score = 0.9187\n",
      "04/14/2025 13:33:54 - INFO - __main__ -   eval_f1 = 0.5813\n",
      "04/14/2025 13:33:54 - INFO - __main__ -   eval_precision = 0.7229\n",
      "04/14/2025 13:33:54 - INFO - __main__ -   eval_recall = 0.4861\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 13:34:37 - WARNING - __main__ - epoch 4 step 408 loss 0.14861\n",
      "[[0.9854998 ]\n",
      " [0.59011006]\n",
      " [0.20816183]\n",
      " ...\n",
      " [0.26090056]\n",
      " [0.4964946 ]\n",
      " [0.21782993]]\n",
      "04/14/2025 13:35:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:35:10 - INFO - __main__ -   auc_score = 0.9199\n",
      "04/14/2025 13:35:10 - INFO - __main__ -   eval_f1 = 0.5978\n",
      "04/14/2025 13:35:10 - INFO - __main__ -   eval_precision = 0.7023\n",
      "04/14/2025 13:35:10 - INFO - __main__ -   eval_recall = 0.5203\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 13:35:53 - WARNING - __main__ - epoch 4 step 510 loss 0.1556\n",
      "[[0.9861309 ]\n",
      " [0.6183106 ]\n",
      " [0.22711848]\n",
      " ...\n",
      " [0.26856685]\n",
      " [0.52130777]\n",
      " [0.2051892 ]]\n",
      "04/14/2025 13:36:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:36:26 - INFO - __main__ -   auc_score = 0.9207\n",
      "04/14/2025 13:36:26 - INFO - __main__ -   eval_f1 = 0.6\n",
      "04/14/2025 13:36:26 - INFO - __main__ -   eval_precision = 0.686\n",
      "04/14/2025 13:36:26 - INFO - __main__ -   eval_recall = 0.5332\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:37:10 - WARNING - __main__ - epoch 5 step 102 loss 0.12693\n",
      "[[0.9833919 ]\n",
      " [0.6374541 ]\n",
      " [0.23135285]\n",
      " ...\n",
      " [0.19053216]\n",
      " [0.30982238]\n",
      " [0.09337737]]\n",
      "04/14/2025 13:37:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:37:43 - INFO - __main__ -   auc_score = 0.92\n",
      "04/14/2025 13:37:43 - INFO - __main__ -   eval_f1 = 0.6063\n",
      "04/14/2025 13:37:43 - INFO - __main__ -   eval_precision = 0.7348\n",
      "04/14/2025 13:37:43 - INFO - __main__ -   eval_recall = 0.5161\n",
      " 40% 203/512 [02:00<02:11,  2.34it/s]04/14/2025 13:38:28 - WARNING - __main__ - epoch 5 step 204 loss 0.13474\n",
      "[[0.99194616]\n",
      " [0.57142115]\n",
      " [0.16244334]\n",
      " ...\n",
      " [0.30503467]\n",
      " [0.44126546]\n",
      " [0.16300009]]\n",
      "04/14/2025 13:39:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:39:01 - INFO - __main__ -   auc_score = 0.9191\n",
      "04/14/2025 13:39:01 - INFO - __main__ -   eval_f1 = 0.5995\n",
      "04/14/2025 13:39:01 - INFO - __main__ -   eval_precision = 0.6919\n",
      "04/14/2025 13:39:01 - INFO - __main__ -   eval_recall = 0.5289\n",
      " 60% 305/512 [03:16<01:28,  2.35it/s]04/14/2025 13:39:44 - WARNING - __main__ - epoch 5 step 306 loss 0.15972\n",
      "[[0.989263  ]\n",
      " [0.65213805]\n",
      " [0.2117565 ]\n",
      " ...\n",
      " [0.34740797]\n",
      " [0.50716096]\n",
      " [0.20021278]]\n",
      "04/14/2025 13:40:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:40:17 - INFO - __main__ -   auc_score = 0.9198\n",
      "04/14/2025 13:40:17 - INFO - __main__ -   eval_f1 = 0.5972\n",
      "04/14/2025 13:40:17 - INFO - __main__ -   eval_precision = 0.6589\n",
      "04/14/2025 13:40:17 - INFO - __main__ -   eval_recall = 0.546\n",
      " 79% 407/512 [04:33<00:44,  2.35it/s]04/14/2025 13:41:01 - WARNING - __main__ - epoch 5 step 408 loss 0.14698\n",
      "[[0.9856522 ]\n",
      " [0.57507837]\n",
      " [0.16604882]\n",
      " ...\n",
      " [0.26164725]\n",
      " [0.43601045]\n",
      " [0.16412775]]\n",
      "04/14/2025 13:41:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:41:34 - INFO - __main__ -   auc_score = 0.9195\n",
      "04/14/2025 13:41:34 - INFO - __main__ -   eval_f1 = 0.5935\n",
      "04/14/2025 13:41:34 - INFO - __main__ -   eval_precision = 0.7468\n",
      "04/14/2025 13:41:34 - INFO - __main__ -   eval_recall = 0.4925\n",
      " 99% 509/512 [05:49<00:01,  2.34it/s]04/14/2025 13:42:17 - WARNING - __main__ - epoch 5 step 510 loss 0.14423\n",
      "[[0.9922627 ]\n",
      " [0.6212014 ]\n",
      " [0.2528252 ]\n",
      " ...\n",
      " [0.4179877 ]\n",
      " [0.60703933]\n",
      " [0.28064486]]\n",
      "04/14/2025 13:42:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:42:50 - INFO - __main__ -   auc_score = 0.9196\n",
      "04/14/2025 13:42:50 - INFO - __main__ -   eval_f1 = 0.593\n",
      "04/14/2025 13:42:50 - INFO - __main__ -   eval_precision = 0.6262\n",
      "04/14/2025 13:42:50 - INFO - __main__ -   eval_recall = 0.5632\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:43:34 - WARNING - __main__ - epoch 6 step 102 loss 0.14503\n",
      "[[0.992309  ]\n",
      " [0.58690286]\n",
      " [0.1907802 ]\n",
      " ...\n",
      " [0.35288984]\n",
      " [0.6112925 ]\n",
      " [0.26027745]]\n",
      "04/14/2025 13:44:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:44:07 - INFO - __main__ -   auc_score = 0.9178\n",
      "04/14/2025 13:44:07 - INFO - __main__ -   eval_f1 = 0.592\n",
      "04/14/2025 13:44:07 - INFO - __main__ -   eval_precision = 0.6588\n",
      "04/14/2025 13:44:07 - INFO - __main__ -   eval_recall = 0.5375\n",
      " 40% 203/512 [01:59<02:11,  2.34it/s]04/14/2025 13:44:50 - WARNING - __main__ - epoch 6 step 204 loss 0.12953\n",
      "[[0.98256266]\n",
      " [0.5498153 ]\n",
      " [0.12631096]\n",
      " ...\n",
      " [0.19845201]\n",
      " [0.21914738]\n",
      " [0.08572746]]\n",
      "04/14/2025 13:45:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:45:23 - INFO - __main__ -   auc_score = 0.9165\n",
      "04/14/2025 13:45:23 - INFO - __main__ -   eval_f1 = 0.5619\n",
      "04/14/2025 13:45:23 - INFO - __main__ -   eval_precision = 0.8016\n",
      "04/14/2025 13:45:23 - INFO - __main__ -   eval_recall = 0.4325\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 13:46:07 - WARNING - __main__ - epoch 6 step 306 loss 0.11885\n",
      "[[0.9920293 ]\n",
      " [0.632327  ]\n",
      " [0.20436609]\n",
      " ...\n",
      " [0.3338262 ]\n",
      " [0.5589931 ]\n",
      " [0.19842039]]\n",
      "04/14/2025 13:46:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:46:40 - INFO - __main__ -   auc_score = 0.92\n",
      "04/14/2025 13:46:40 - INFO - __main__ -   eval_f1 = 0.5995\n",
      "04/14/2025 13:46:40 - INFO - __main__ -   eval_precision = 0.6437\n",
      "04/14/2025 13:46:40 - INFO - __main__ -   eval_recall = 0.561\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 13:47:23 - WARNING - __main__ - epoch 6 step 408 loss 0.14308\n",
      "[[0.99334794]\n",
      " [0.69096935]\n",
      " [0.197004  ]\n",
      " ...\n",
      " [0.3635296 ]\n",
      " [0.54515624]\n",
      " [0.19365634]]\n",
      "04/14/2025 13:47:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:47:56 - INFO - __main__ -   auc_score = 0.9185\n",
      "04/14/2025 13:47:56 - INFO - __main__ -   eval_f1 = 0.6075\n",
      "04/14/2025 13:47:56 - INFO - __main__ -   eval_precision = 0.6299\n",
      "04/14/2025 13:47:56 - INFO - __main__ -   eval_recall = 0.5867\n",
      " 99% 509/512 [05:49<00:01,  2.34it/s]04/14/2025 13:48:41 - WARNING - __main__ - epoch 6 step 510 loss 0.13995\n",
      "[[0.99353516]\n",
      " [0.6511687 ]\n",
      " [0.21773046]\n",
      " ...\n",
      " [0.36931342]\n",
      " [0.5970212 ]\n",
      " [0.24400307]]\n",
      "04/14/2025 13:49:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:49:14 - INFO - __main__ -   auc_score = 0.919\n",
      "04/14/2025 13:49:14 - INFO - __main__ -   eval_f1 = 0.6032\n",
      "04/14/2025 13:49:14 - INFO - __main__ -   eval_precision = 0.641\n",
      "04/14/2025 13:49:14 - INFO - __main__ -   eval_recall = 0.5696\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:49:58 - WARNING - __main__ - epoch 7 step 102 loss 0.13124\n",
      "[[0.9959824 ]\n",
      " [0.6433091 ]\n",
      " [0.23721588]\n",
      " ...\n",
      " [0.44870678]\n",
      " [0.6809147 ]\n",
      " [0.30929393]]\n",
      "04/14/2025 13:50:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:50:31 - INFO - __main__ -   auc_score = 0.9185\n",
      "04/14/2025 13:50:31 - INFO - __main__ -   eval_f1 = 0.5959\n",
      "04/14/2025 13:50:31 - INFO - __main__ -   eval_precision = 0.6031\n",
      "04/14/2025 13:50:31 - INFO - __main__ -   eval_recall = 0.5889\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 13:51:14 - WARNING - __main__ - epoch 7 step 204 loss 0.12732\n",
      "[[0.99494016]\n",
      " [0.67701954]\n",
      " [0.26430428]\n",
      " ...\n",
      " [0.37013474]\n",
      " [0.4768823 ]\n",
      " [0.19733278]]\n",
      "04/14/2025 13:51:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:51:47 - INFO - __main__ -   auc_score = 0.9194\n",
      "04/14/2025 13:51:47 - INFO - __main__ -   eval_f1 = 0.6041\n",
      "04/14/2025 13:51:47 - INFO - __main__ -   eval_precision = 0.6403\n",
      "04/14/2025 13:51:47 - INFO - __main__ -   eval_recall = 0.5717\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 13:52:30 - WARNING - __main__ - epoch 7 step 306 loss 0.11979\n",
      "[[0.9936838 ]\n",
      " [0.57164526]\n",
      " [0.12314662]\n",
      " ...\n",
      " [0.28446993]\n",
      " [0.47520524]\n",
      " [0.17071195]]\n",
      "04/14/2025 13:53:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:53:03 - INFO - __main__ -   auc_score = 0.9164\n",
      "04/14/2025 13:53:03 - INFO - __main__ -   eval_f1 = 0.5888\n",
      "04/14/2025 13:53:03 - INFO - __main__ -   eval_precision = 0.7227\n",
      "04/14/2025 13:53:03 - INFO - __main__ -   eval_recall = 0.4968\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 13:53:46 - WARNING - __main__ - epoch 7 step 408 loss 0.12749\n",
      "[[0.99150896]\n",
      " [0.6392401 ]\n",
      " [0.17857412]\n",
      " ...\n",
      " [0.27838266]\n",
      " [0.44916216]\n",
      " [0.14266923]]\n",
      "04/14/2025 13:54:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:54:20 - INFO - __main__ -   auc_score = 0.9178\n",
      "04/14/2025 13:54:20 - INFO - __main__ -   eval_f1 = 0.6048\n",
      "04/14/2025 13:54:20 - INFO - __main__ -   eval_precision = 0.6915\n",
      "04/14/2025 13:54:20 - INFO - __main__ -   eval_recall = 0.5375\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 13:55:03 - WARNING - __main__ - epoch 7 step 510 loss 0.13101\n",
      "[[0.9929097 ]\n",
      " [0.6560152 ]\n",
      " [0.17318481]\n",
      " ...\n",
      " [0.2666201 ]\n",
      " [0.43930444]\n",
      " [0.14389369]]\n",
      "04/14/2025 13:55:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:55:36 - INFO - __main__ -   auc_score = 0.918\n",
      "04/14/2025 13:55:36 - INFO - __main__ -   eval_f1 = 0.6044\n",
      "04/14/2025 13:55:36 - INFO - __main__ -   eval_precision = 0.6975\n",
      "04/14/2025 13:55:36 - INFO - __main__ -   eval_recall = 0.5332\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 13:56:20 - WARNING - __main__ - epoch 8 step 102 loss 0.11367\n",
      "[[0.99467444]\n",
      " [0.6735153 ]\n",
      " [0.21756178]\n",
      " ...\n",
      " [0.40971112]\n",
      " [0.5273736 ]\n",
      " [0.20570159]]\n",
      "04/14/2025 13:56:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:56:53 - INFO - __main__ -   auc_score = 0.9165\n",
      "04/14/2025 13:56:53 - INFO - __main__ -   eval_f1 = 0.5993\n",
      "04/14/2025 13:56:53 - INFO - __main__ -   eval_precision = 0.6377\n",
      "04/14/2025 13:56:53 - INFO - __main__ -   eval_recall = 0.5653\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 13:57:36 - WARNING - __main__ - epoch 8 step 204 loss 0.13026\n",
      "[[0.9941989 ]\n",
      " [0.6338649 ]\n",
      " [0.20769034]\n",
      " ...\n",
      " [0.35611868]\n",
      " [0.56920946]\n",
      " [0.20786282]]\n",
      "04/14/2025 13:58:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:58:09 - INFO - __main__ -   auc_score = 0.9177\n",
      "04/14/2025 13:58:09 - INFO - __main__ -   eval_f1 = 0.6028\n",
      "04/14/2025 13:58:09 - INFO - __main__ -   eval_precision = 0.6541\n",
      "04/14/2025 13:58:09 - INFO - __main__ -   eval_recall = 0.5589\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 13:58:52 - WARNING - __main__ - epoch 8 step 306 loss 0.11545\n",
      "[[0.9930161 ]\n",
      " [0.6014855 ]\n",
      " [0.15818104]\n",
      " ...\n",
      " [0.28466293]\n",
      " [0.5025961 ]\n",
      " [0.16469882]]\n",
      "04/14/2025 13:59:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 13:59:25 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/14/2025 13:59:25 - INFO - __main__ -   eval_f1 = 0.608\n",
      "04/14/2025 13:59:25 - INFO - __main__ -   eval_precision = 0.6961\n",
      "04/14/2025 13:59:25 - INFO - __main__ -   eval_recall = 0.5396\n",
      " 79% 407/512 [04:33<00:44,  2.35it/s]04/14/2025 14:00:10 - WARNING - __main__ - epoch 8 step 408 loss 0.11069\n",
      "[[0.99408937]\n",
      " [0.62974125]\n",
      " [0.16322662]\n",
      " ...\n",
      " [0.29580963]\n",
      " [0.5182927 ]\n",
      " [0.1764694 ]]\n",
      "04/14/2025 14:00:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:00:43 - INFO - __main__ -   auc_score = 0.9164\n",
      "04/14/2025 14:00:43 - INFO - __main__ -   eval_f1 = 0.6043\n",
      "04/14/2025 14:00:43 - INFO - __main__ -   eval_precision = 0.6764\n",
      "04/14/2025 14:00:43 - INFO - __main__ -   eval_recall = 0.546\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 14:01:26 - WARNING - __main__ - epoch 8 step 510 loss 0.13584\n",
      "[[0.99467885]\n",
      " [0.64492214]\n",
      " [0.1799403 ]\n",
      " ...\n",
      " [0.3198922 ]\n",
      " [0.52130526]\n",
      " [0.17343302]]\n",
      "04/14/2025 14:01:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:01:59 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/14/2025 14:01:59 - INFO - __main__ -   eval_f1 = 0.6028\n",
      "04/14/2025 14:01:59 - INFO - __main__ -   eval_precision = 0.6632\n",
      "04/14/2025 14:01:59 - INFO - __main__ -   eval_recall = 0.5525\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:02:43 - WARNING - __main__ - epoch 9 step 102 loss 0.12142\n",
      "[[0.9957131 ]\n",
      " [0.6932604 ]\n",
      " [0.23160906]\n",
      " ...\n",
      " [0.35264146]\n",
      " [0.59256446]\n",
      " [0.19395095]]\n",
      "04/14/2025 14:03:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:03:17 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 14:03:17 - INFO - __main__ -   eval_f1 = 0.602\n",
      "04/14/2025 14:03:17 - INFO - __main__ -   eval_precision = 0.6279\n",
      "04/14/2025 14:03:17 - INFO - __main__ -   eval_recall = 0.5782\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:04:00 - WARNING - __main__ - epoch 9 step 204 loss 0.11973\n",
      "[[0.99505913]\n",
      " [0.64618105]\n",
      " [0.18980312]\n",
      " ...\n",
      " [0.30873895]\n",
      " [0.5346768 ]\n",
      " [0.16764522]]\n",
      "04/14/2025 14:04:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:04:33 - INFO - __main__ -   auc_score = 0.9174\n",
      "04/14/2025 14:04:33 - INFO - __main__ -   eval_f1 = 0.6058\n",
      "04/14/2025 14:04:33 - INFO - __main__ -   eval_precision = 0.6675\n",
      "04/14/2025 14:04:33 - INFO - __main__ -   eval_recall = 0.5546\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:05:16 - WARNING - __main__ - epoch 9 step 306 loss 0.1192\n",
      "[[0.99434966]\n",
      " [0.62881094]\n",
      " [0.16853555]\n",
      " ...\n",
      " [0.26884422]\n",
      " [0.41347057]\n",
      " [0.12897691]]\n",
      "04/14/2025 14:05:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:05:49 - INFO - __main__ -   auc_score = 0.9168\n",
      "04/14/2025 14:05:49 - INFO - __main__ -   eval_f1 = 0.6036\n",
      "04/14/2025 14:05:49 - INFO - __main__ -   eval_precision = 0.6848\n",
      "04/14/2025 14:05:49 - INFO - __main__ -   eval_recall = 0.5396\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:06:32 - WARNING - __main__ - epoch 9 step 408 loss 0.1076\n",
      "[[0.99514186]\n",
      " [0.6436121 ]\n",
      " [0.1858379 ]\n",
      " ...\n",
      " [0.30337858]\n",
      " [0.47958186]\n",
      " [0.15294832]]\n",
      "04/14/2025 14:07:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:07:05 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/14/2025 14:07:05 - INFO - __main__ -   eval_f1 = 0.6091\n",
      "04/14/2025 14:07:05 - INFO - __main__ -   eval_precision = 0.6692\n",
      "04/14/2025 14:07:05 - INFO - __main__ -   eval_recall = 0.5589\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 14:07:50 - WARNING - __main__ - epoch 9 step 510 loss 0.12336\n",
      "[[0.9950486 ]\n",
      " [0.6437779 ]\n",
      " [0.18557179]\n",
      " ...\n",
      " [0.30057642]\n",
      " [0.47432107]\n",
      " [0.15055878]]\n",
      "04/14/2025 14:08:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:08:23 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/14/2025 14:08:23 - INFO - __main__ -   eval_f1 = 0.6066\n",
      "04/14/2025 14:08:23 - INFO - __main__ -   eval_precision = 0.6693\n",
      "04/14/2025 14:08:23 - INFO - __main__ -   eval_recall = 0.5546\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJOF0IIQofK6",
    "outputId": "dbfea15f-a21f-46b0-f882-1eb0e85a47eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:09:24.181391: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 14:09:24.200342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744639764.223428   29688 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744639764.230462   29688 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 14:09:24.253844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 14:10:44 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 14:10:44 - INFO - __main__ -   auc_score = 0.9013\n",
      "04/14/2025 14:10:44 - INFO - __main__ -   test_f1 = 0.5203\n",
      "04/14/2025 14:10:44 - INFO - __main__ -   test_precision = 0.5803\n",
      "04/14/2025 14:10:44 - INFO - __main__ -   test_recall = 0.4716\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/concat/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7y1reehqIw0"
   },
   "source": [
    "### Raw baseline without expert features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCNW_OHdqXs8",
    "outputId": "cd256386-5ecf-47be-e13f-fbd72ec6b826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/drive/MyDrive/UFPE/Tese/PEFT4CC/results/jitfine_lora/unixcoder-base/single/checkpoints': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/single/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCiB64YDqdcK",
    "outputId": "bbc769d1-1f4b-457a-8fec-393dd95fc8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:18:13.071615: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 14:18:13.090139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744640293.112420   32991 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744640293.119137   32991 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 14:18:13.142011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      " 20% 101/512 [00:43<02:54,  2.35it/s]04/14/2025 14:21:19 - WARNING - __main__ - epoch 0 step 102 loss 0.33388\n",
      "[[0.23953402]\n",
      " [0.04059779]\n",
      " [0.05706038]\n",
      " ...\n",
      " [0.19853966]\n",
      " [0.08295073]\n",
      " [0.1538412 ]]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "04/14/2025 14:21:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:21:52 - INFO - __main__ -   auc_score = 0.7299\n",
      "04/14/2025 14:21:52 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/14/2025 14:21:52 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/14/2025 14:21:52 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:22:36 - WARNING - __main__ - epoch 0 step 204 loss 0.25662\n",
      "[[0.49057844]\n",
      " [0.03790125]\n",
      " [0.05989184]\n",
      " ...\n",
      " [0.36453322]\n",
      " [0.1386465 ]\n",
      " [0.27239946]]\n",
      "04/14/2025 14:23:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:23:09 - INFO - __main__ -   auc_score = 0.8168\n",
      "04/14/2025 14:23:09 - INFO - __main__ -   eval_f1 = 0.0043\n",
      "04/14/2025 14:23:09 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/14/2025 14:23:09 - INFO - __main__ -   eval_recall = 0.0021\n",
      " 60% 305/512 [03:17<01:28,  2.35it/s]04/14/2025 14:23:53 - WARNING - __main__ - epoch 0 step 306 loss 0.23721\n",
      "[[0.46984383]\n",
      " [0.04509946]\n",
      " [0.02681133]\n",
      " ...\n",
      " [0.3538599 ]\n",
      " [0.08624461]\n",
      " [0.22167157]]\n",
      "04/14/2025 14:24:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:24:26 - INFO - __main__ -   auc_score = 0.8444\n",
      "04/14/2025 14:24:26 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "04/14/2025 14:24:26 - INFO - __main__ -   eval_precision = 1.0\n",
      "04/14/2025 14:24:26 - INFO - __main__ -   eval_recall = 0.0043\n",
      " 79% 407/512 [04:34<00:44,  2.35it/s]04/14/2025 14:25:11 - WARNING - __main__ - epoch 0 step 408 loss 0.22595\n",
      "[[0.54264164]\n",
      " [0.06528105]\n",
      " [0.03927552]\n",
      " ...\n",
      " [0.4343945 ]\n",
      " [0.1343986 ]\n",
      " [0.31901875]]\n",
      "04/14/2025 14:25:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:25:44 - INFO - __main__ -   auc_score = 0.853\n",
      "04/14/2025 14:25:44 - INFO - __main__ -   eval_f1 = 0.0211\n",
      "04/14/2025 14:25:44 - INFO - __main__ -   eval_precision = 0.7143\n",
      "04/14/2025 14:25:44 - INFO - __main__ -   eval_recall = 0.0107\n",
      " 99% 509/512 [05:52<00:01,  2.35it/s]04/14/2025 14:26:29 - WARNING - __main__ - epoch 0 step 510 loss 0.22579\n",
      "[[0.72719383]\n",
      " [0.1465219 ]\n",
      " [0.06932428]\n",
      " ...\n",
      " [0.548662  ]\n",
      " [0.2121551 ]\n",
      " [0.44185624]]\n",
      "04/14/2025 14:27:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:27:02 - INFO - __main__ -   auc_score = 0.8596\n",
      "04/14/2025 14:27:02 - INFO - __main__ -   eval_f1 = 0.1903\n",
      "04/14/2025 14:27:02 - INFO - __main__ -   eval_precision = 0.4955\n",
      "04/14/2025 14:27:02 - INFO - __main__ -   eval_recall = 0.1178\n",
      "100% 512/512 [06:28<00:00,  1.32it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:27:47 - WARNING - __main__ - epoch 1 step 102 loss 0.21211\n",
      "[[0.6270386 ]\n",
      " [0.12411837]\n",
      " [0.04202727]\n",
      " ...\n",
      " [0.32794067]\n",
      " [0.10792675]\n",
      " [0.2390395 ]]\n",
      "04/14/2025 14:28:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:28:20 - INFO - __main__ -   auc_score = 0.8554\n",
      "04/14/2025 14:28:20 - INFO - __main__ -   eval_f1 = 0.0373\n",
      "04/14/2025 14:28:20 - INFO - __main__ -   eval_precision = 0.5625\n",
      "04/14/2025 14:28:20 - INFO - __main__ -   eval_recall = 0.0193\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:29:03 - WARNING - __main__ - epoch 1 step 204 loss 0.21449\n",
      "[[0.6149895 ]\n",
      " [0.09155551]\n",
      " [0.04974156]\n",
      " ...\n",
      " [0.36041874]\n",
      " [0.13309342]\n",
      " [0.26980785]]\n",
      "04/14/2025 14:29:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:29:36 - INFO - __main__ -   auc_score = 0.8611\n",
      "04/14/2025 14:29:36 - INFO - __main__ -   eval_f1 = 0.0574\n",
      "04/14/2025 14:29:36 - INFO - __main__ -   eval_precision = 0.6667\n",
      "04/14/2025 14:29:36 - INFO - __main__ -   eval_recall = 0.03\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:30:19 - WARNING - __main__ - epoch 1 step 306 loss 0.21489\n",
      "[[0.5860463 ]\n",
      " [0.08516144]\n",
      " [0.04566429]\n",
      " ...\n",
      " [0.33560896]\n",
      " [0.11089698]\n",
      " [0.21316485]]\n",
      "04/14/2025 14:30:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:30:52 - INFO - __main__ -   auc_score = 0.8629\n",
      "04/14/2025 14:30:52 - INFO - __main__ -   eval_f1 = 0.0293\n",
      "04/14/2025 14:30:52 - INFO - __main__ -   eval_precision = 0.6364\n",
      "04/14/2025 14:30:52 - INFO - __main__ -   eval_recall = 0.015\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:31:36 - WARNING - __main__ - epoch 1 step 408 loss 0.20988\n",
      "[[0.8115658 ]\n",
      " [0.1617707 ]\n",
      " [0.08125763]\n",
      " ...\n",
      " [0.5988956 ]\n",
      " [0.19038899]\n",
      " [0.39348966]]\n",
      "04/14/2025 14:32:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:32:09 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/14/2025 14:32:09 - INFO - __main__ -   eval_f1 = 0.2874\n",
      "04/14/2025 14:32:09 - INFO - __main__ -   eval_precision = 0.4897\n",
      "04/14/2025 14:32:09 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 14:32:53 - WARNING - __main__ - epoch 1 step 510 loss 0.22306\n",
      "[[0.58854926]\n",
      " [0.10900029]\n",
      " [0.03328849]\n",
      " ...\n",
      " [0.38790432]\n",
      " [0.12407199]\n",
      " [0.23519063]]\n",
      "04/14/2025 14:33:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:33:26 - INFO - __main__ -   auc_score = 0.8645\n",
      "04/14/2025 14:33:26 - INFO - __main__ -   eval_f1 = 0.0575\n",
      "04/14/2025 14:33:26 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/14/2025 14:33:26 - INFO - __main__ -   eval_recall = 0.03\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:34:10 - WARNING - __main__ - epoch 2 step 102 loss 0.19521\n",
      "[[0.775428  ]\n",
      " [0.17323884]\n",
      " [0.05717562]\n",
      " ...\n",
      " [0.6390254 ]\n",
      " [0.24429496]\n",
      " [0.43599308]]\n",
      "04/14/2025 14:34:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:34:43 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/14/2025 14:34:43 - INFO - __main__ -   eval_f1 = 0.2777\n",
      "04/14/2025 14:34:43 - INFO - __main__ -   eval_precision = 0.5115\n",
      "04/14/2025 14:34:43 - INFO - __main__ -   eval_recall = 0.1906\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:35:27 - WARNING - __main__ - epoch 2 step 204 loss 0.18848\n",
      "[[0.71796596]\n",
      " [0.18240415]\n",
      " [0.03029952]\n",
      " ...\n",
      " [0.46469498]\n",
      " [0.16281798]\n",
      " [0.30690002]]\n",
      "04/14/2025 14:36:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:36:00 - INFO - __main__ -   auc_score = 0.8633\n",
      "04/14/2025 14:36:00 - INFO - __main__ -   eval_f1 = 0.1741\n",
      "04/14/2025 14:36:00 - INFO - __main__ -   eval_precision = 0.6438\n",
      "04/14/2025 14:36:00 - INFO - __main__ -   eval_recall = 0.1006\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:36:43 - WARNING - __main__ - epoch 2 step 306 loss 0.20285\n",
      "[[0.73820937]\n",
      " [0.18113461]\n",
      " [0.05080953]\n",
      " ...\n",
      " [0.538893  ]\n",
      " [0.19930431]\n",
      " [0.33361158]]\n",
      "04/14/2025 14:37:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:37:16 - INFO - __main__ -   auc_score = 0.8681\n",
      "04/14/2025 14:37:16 - INFO - __main__ -   eval_f1 = 0.2349\n",
      "04/14/2025 14:37:16 - INFO - __main__ -   eval_precision = 0.5426\n",
      "04/14/2025 14:37:16 - INFO - __main__ -   eval_recall = 0.1499\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:37:59 - WARNING - __main__ - epoch 2 step 408 loss 0.20909\n",
      "[[0.70206064]\n",
      " [0.17476141]\n",
      " [0.04421551]\n",
      " ...\n",
      " [0.44491476]\n",
      " [0.13676974]\n",
      " [0.22694245]]\n",
      "04/14/2025 14:38:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:38:32 - INFO - __main__ -   auc_score = 0.8691\n",
      "04/14/2025 14:38:32 - INFO - __main__ -   eval_f1 = 0.1305\n",
      "04/14/2025 14:38:32 - INFO - __main__ -   eval_precision = 0.6296\n",
      "04/14/2025 14:38:32 - INFO - __main__ -   eval_recall = 0.0728\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 14:39:15 - WARNING - __main__ - epoch 2 step 510 loss 0.22532\n",
      "[[0.7136804 ]\n",
      " [0.19602855]\n",
      " [0.09446874]\n",
      " ...\n",
      " [0.54311985]\n",
      " [0.21420214]\n",
      " [0.31722835]]\n",
      "04/14/2025 14:39:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:39:49 - INFO - __main__ -   auc_score = 0.8714\n",
      "04/14/2025 14:39:49 - INFO - __main__ -   eval_f1 = 0.1831\n",
      "04/14/2025 14:39:49 - INFO - __main__ -   eval_precision = 0.5667\n",
      "04/14/2025 14:39:49 - INFO - __main__ -   eval_recall = 0.1092\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:54,  2.35it/s]04/14/2025 14:40:33 - WARNING - __main__ - epoch 3 step 102 loss 0.20396\n",
      "[[0.71582216]\n",
      " [0.19257115]\n",
      " [0.05728472]\n",
      " ...\n",
      " [0.60977095]\n",
      " [0.20915416]\n",
      " [0.3057478 ]]\n",
      "04/14/2025 14:41:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:41:06 - INFO - __main__ -   auc_score = 0.8696\n",
      "04/14/2025 14:41:06 - INFO - __main__ -   eval_f1 = 0.2508\n",
      "04/14/2025 14:41:06 - INFO - __main__ -   eval_precision = 0.5468\n",
      "04/14/2025 14:41:06 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:41:49 - WARNING - __main__ - epoch 3 step 204 loss 0.18521\n",
      "[[0.70268697]\n",
      " [0.14530507]\n",
      " [0.03754251]\n",
      " ...\n",
      " [0.50791794]\n",
      " [0.17547402]\n",
      " [0.23457976]]\n",
      "04/14/2025 14:42:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:42:22 - INFO - __main__ -   auc_score = 0.8692\n",
      "04/14/2025 14:42:22 - INFO - __main__ -   eval_f1 = 0.2169\n",
      "04/14/2025 14:42:22 - INFO - __main__ -   eval_precision = 0.5526\n",
      "04/14/2025 14:42:22 - INFO - __main__ -   eval_recall = 0.1349\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:43:05 - WARNING - __main__ - epoch 3 step 306 loss 0.1994\n",
      "[[0.69941497]\n",
      " [0.17698559]\n",
      " [0.04220774]\n",
      " ...\n",
      " [0.45178586]\n",
      " [0.14750001]\n",
      " [0.21184017]]\n",
      "04/14/2025 14:43:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:43:38 - INFO - __main__ -   auc_score = 0.8687\n",
      "04/14/2025 14:43:38 - INFO - __main__ -   eval_f1 = 0.1798\n",
      "04/14/2025 14:43:38 - INFO - __main__ -   eval_precision = 0.6282\n",
      "04/14/2025 14:43:38 - INFO - __main__ -   eval_recall = 0.1049\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:44:21 - WARNING - __main__ - epoch 3 step 408 loss 0.20087\n",
      "[[0.7451994 ]\n",
      " [0.2511852 ]\n",
      " [0.06092641]\n",
      " ...\n",
      " [0.44373554]\n",
      " [0.16114277]\n",
      " [0.21414492]]\n",
      "04/14/2025 14:44:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:44:54 - INFO - __main__ -   auc_score = 0.8664\n",
      "04/14/2025 14:44:54 - INFO - __main__ -   eval_f1 = 0.1607\n",
      "04/14/2025 14:44:54 - INFO - __main__ -   eval_precision = 0.6324\n",
      "04/14/2025 14:44:54 - INFO - __main__ -   eval_recall = 0.0921\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 14:45:38 - WARNING - __main__ - epoch 3 step 510 loss 0.19151\n",
      "[[0.8384265 ]\n",
      " [0.23133077]\n",
      " [0.08536928]\n",
      " ...\n",
      " [0.70214033]\n",
      " [0.37537122]\n",
      " [0.462034  ]]\n",
      "04/14/2025 14:46:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:46:11 - INFO - __main__ -   auc_score = 0.8714\n",
      "04/14/2025 14:46:11 - INFO - __main__ -   eval_f1 = 0.3634\n",
      "04/14/2025 14:46:11 - INFO - __main__ -   eval_precision = 0.5019\n",
      "04/14/2025 14:46:11 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [06:23<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:46:56 - WARNING - __main__ - epoch 4 step 102 loss 0.18859\n",
      "[[0.79844815]\n",
      " [0.22493841]\n",
      " [0.04988784]\n",
      " ...\n",
      " [0.6075833 ]\n",
      " [0.22128782]\n",
      " [0.279277  ]]\n",
      "04/14/2025 14:47:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:47:29 - INFO - __main__ -   auc_score = 0.8692\n",
      "04/14/2025 14:47:29 - INFO - __main__ -   eval_f1 = 0.2764\n",
      "04/14/2025 14:47:29 - INFO - __main__ -   eval_precision = 0.5743\n",
      "04/14/2025 14:47:29 - INFO - __main__ -   eval_recall = 0.182\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:48:12 - WARNING - __main__ - epoch 4 step 204 loss 0.1923\n",
      "[[0.74210596]\n",
      " [0.28185743]\n",
      " [0.04801694]\n",
      " ...\n",
      " [0.5747883 ]\n",
      " [0.20537992]\n",
      " [0.241661  ]]\n",
      "04/14/2025 14:48:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:48:45 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/14/2025 14:48:45 - INFO - __main__ -   eval_f1 = 0.2889\n",
      "04/14/2025 14:48:45 - INFO - __main__ -   eval_precision = 0.5769\n",
      "04/14/2025 14:48:45 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:49:29 - WARNING - __main__ - epoch 4 step 306 loss 0.18457\n",
      "[[0.76921463]\n",
      " [0.22572307]\n",
      " [0.0353939 ]\n",
      " ...\n",
      " [0.5804495 ]\n",
      " [0.25127968]\n",
      " [0.26557022]]\n",
      "04/14/2025 14:50:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:50:02 - INFO - __main__ -   auc_score = 0.8695\n",
      "04/14/2025 14:50:02 - INFO - __main__ -   eval_f1 = 0.3021\n",
      "04/14/2025 14:50:02 - INFO - __main__ -   eval_precision = 0.5864\n",
      "04/14/2025 14:50:02 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:50:45 - WARNING - __main__ - epoch 4 step 408 loss 0.19138\n",
      "[[0.7294184 ]\n",
      " [0.17932524]\n",
      " [0.03675574]\n",
      " ...\n",
      " [0.5603973 ]\n",
      " [0.23482956]\n",
      " [0.24989574]]\n",
      "04/14/2025 14:51:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:51:18 - INFO - __main__ -   auc_score = 0.8715\n",
      "04/14/2025 14:51:18 - INFO - __main__ -   eval_f1 = 0.2853\n",
      "04/14/2025 14:51:18 - INFO - __main__ -   eval_precision = 0.5867\n",
      "04/14/2025 14:51:18 - INFO - __main__ -   eval_recall = 0.1884\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 14:52:01 - WARNING - __main__ - epoch 4 step 510 loss 0.18951\n",
      "[[0.7352243 ]\n",
      " [0.24277307]\n",
      " [0.05887409]\n",
      " ...\n",
      " [0.59777474]\n",
      " [0.26132044]\n",
      " [0.26928782]]\n",
      "04/14/2025 14:52:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:52:34 - INFO - __main__ -   auc_score = 0.8713\n",
      "04/14/2025 14:52:34 - INFO - __main__ -   eval_f1 = 0.3077\n",
      "04/14/2025 14:52:34 - INFO - __main__ -   eval_precision = 0.5765\n",
      "04/14/2025 14:52:34 - INFO - __main__ -   eval_recall = 0.2099\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:53:18 - WARNING - __main__ - epoch 5 step 102 loss 0.18259\n",
      "[[0.64657634]\n",
      " [0.17080458]\n",
      " [0.04356616]\n",
      " ...\n",
      " [0.5643221 ]\n",
      " [0.19278844]\n",
      " [0.18486246]]\n",
      "04/14/2025 14:53:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:53:51 - INFO - __main__ -   auc_score = 0.8699\n",
      "04/14/2025 14:53:51 - INFO - __main__ -   eval_f1 = 0.2568\n",
      "04/14/2025 14:53:51 - INFO - __main__ -   eval_precision = 0.608\n",
      "04/14/2025 14:53:51 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 14:54:35 - WARNING - __main__ - epoch 5 step 204 loss 0.17866\n",
      "[[0.6404735 ]\n",
      " [0.153317  ]\n",
      " [0.03174603]\n",
      " ...\n",
      " [0.46637812]\n",
      " [0.1389587 ]\n",
      " [0.11445252]]\n",
      "04/14/2025 14:55:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:55:08 - INFO - __main__ -   auc_score = 0.869\n",
      "04/14/2025 14:55:08 - INFO - __main__ -   eval_f1 = 0.1919\n",
      "04/14/2025 14:55:08 - INFO - __main__ -   eval_precision = 0.6933\n",
      "04/14/2025 14:55:08 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 14:55:51 - WARNING - __main__ - epoch 5 step 306 loss 0.17564\n",
      "[[0.7070034 ]\n",
      " [0.19921225]\n",
      " [0.0485733 ]\n",
      " ...\n",
      " [0.56568694]\n",
      " [0.24018593]\n",
      " [0.18306234]]\n",
      "04/14/2025 14:56:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:56:24 - INFO - __main__ -   auc_score = 0.8704\n",
      "04/14/2025 14:56:24 - INFO - __main__ -   eval_f1 = 0.3313\n",
      "04/14/2025 14:56:24 - INFO - __main__ -   eval_precision = 0.5584\n",
      "04/14/2025 14:56:24 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 14:57:07 - WARNING - __main__ - epoch 5 step 408 loss 0.18008\n",
      "[[0.76071095]\n",
      " [0.28066576]\n",
      " [0.05299563]\n",
      " ...\n",
      " [0.58658355]\n",
      " [0.34945124]\n",
      " [0.22961959]]\n",
      "04/14/2025 14:57:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:57:40 - INFO - __main__ -   auc_score = 0.8713\n",
      "04/14/2025 14:57:40 - INFO - __main__ -   eval_f1 = 0.3668\n",
      "04/14/2025 14:57:40 - INFO - __main__ -   eval_precision = 0.5541\n",
      "04/14/2025 14:57:40 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 14:58:25 - WARNING - __main__ - epoch 5 step 510 loss 0.1832\n",
      "[[0.7290414 ]\n",
      " [0.23107754]\n",
      " [0.04198466]\n",
      " ...\n",
      " [0.57280314]\n",
      " [0.33979848]\n",
      " [0.24321347]]\n",
      "04/14/2025 14:58:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 14:58:58 - INFO - __main__ -   auc_score = 0.8708\n",
      "04/14/2025 14:58:58 - INFO - __main__ -   eval_f1 = 0.3398\n",
      "04/14/2025 14:58:58 - INFO - __main__ -   eval_precision = 0.5588\n",
      "04/14/2025 14:58:58 - INFO - __main__ -   eval_recall = 0.2441\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 14:59:42 - WARNING - __main__ - epoch 6 step 102 loss 0.17362\n",
      "[[0.69436187]\n",
      " [0.30638918]\n",
      " [0.04464951]\n",
      " ...\n",
      " [0.50701773]\n",
      " [0.2778281 ]\n",
      " [0.16295421]]\n",
      "04/14/2025 15:00:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:00:15 - INFO - __main__ -   auc_score = 0.8683\n",
      "04/14/2025 15:00:15 - INFO - __main__ -   eval_f1 = 0.3195\n",
      "04/14/2025 15:00:15 - INFO - __main__ -   eval_precision = 0.5652\n",
      "04/14/2025 15:00:15 - INFO - __main__ -   eval_recall = 0.2227\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 15:00:58 - WARNING - __main__ - epoch 6 step 204 loss 0.18362\n",
      "[[0.60685486]\n",
      " [0.20882018]\n",
      " [0.03085988]\n",
      " ...\n",
      " [0.45578876]\n",
      " [0.23910989]\n",
      " [0.13563631]]\n",
      "04/14/2025 15:01:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:01:31 - INFO - __main__ -   auc_score = 0.8665\n",
      "04/14/2025 15:01:31 - INFO - __main__ -   eval_f1 = 0.2167\n",
      "04/14/2025 15:01:31 - INFO - __main__ -   eval_precision = 0.6354\n",
      "04/14/2025 15:01:31 - INFO - __main__ -   eval_recall = 0.1306\n",
      " 60% 305/512 [03:15<01:28,  2.34it/s]04/14/2025 15:02:14 - WARNING - __main__ - epoch 6 step 306 loss 0.17114\n",
      "[[0.69052684]\n",
      " [0.20241149]\n",
      " [0.04847852]\n",
      " ...\n",
      " [0.6169241 ]\n",
      " [0.36026636]\n",
      " [0.2270911 ]]\n",
      "04/14/2025 15:02:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:02:47 - INFO - __main__ -   auc_score = 0.8706\n",
      "04/14/2025 15:02:47 - INFO - __main__ -   eval_f1 = 0.3429\n",
      "04/14/2025 15:02:47 - INFO - __main__ -   eval_precision = 0.5758\n",
      "04/14/2025 15:02:47 - INFO - __main__ -   eval_recall = 0.2441\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 15:03:31 - WARNING - __main__ - epoch 6 step 408 loss 0.17702\n",
      "[[0.6916177 ]\n",
      " [0.27477628]\n",
      " [0.05700138]\n",
      " ...\n",
      " [0.66764647]\n",
      " [0.3532695 ]\n",
      " [0.24962132]]\n",
      "04/14/2025 15:04:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:04:04 - INFO - __main__ -   auc_score = 0.8694\n",
      "04/14/2025 15:04:04 - INFO - __main__ -   eval_f1 = 0.3464\n",
      "04/14/2025 15:04:04 - INFO - __main__ -   eval_precision = 0.5409\n",
      "04/14/2025 15:04:04 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 99% 509/512 [05:48<00:01,  2.34it/s]04/14/2025 15:04:47 - WARNING - __main__ - epoch 6 step 510 loss 0.16051\n",
      "[[0.6541004 ]\n",
      " [0.29665563]\n",
      " [0.04269068]\n",
      " ...\n",
      " [0.61847115]\n",
      " [0.28409448]\n",
      " [0.18709143]]\n",
      "04/14/2025 15:05:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:05:20 - INFO - __main__ -   auc_score = 0.8678\n",
      "04/14/2025 15:05:20 - INFO - __main__ -   eval_f1 = 0.3452\n",
      "04/14/2025 15:05:20 - INFO - __main__ -   eval_precision = 0.5659\n",
      "04/14/2025 15:05:20 - INFO - __main__ -   eval_recall = 0.2484\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 15:06:04 - WARNING - __main__ - epoch 7 step 102 loss 0.19321\n",
      "[[0.70333964]\n",
      " [0.22262855]\n",
      " [0.05033893]\n",
      " ...\n",
      " [0.6670842 ]\n",
      " [0.38351765]\n",
      " [0.24374764]]\n",
      "04/14/2025 15:06:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:06:37 - INFO - __main__ -   auc_score = 0.8708\n",
      "04/14/2025 15:06:37 - INFO - __main__ -   eval_f1 = 0.3528\n",
      "04/14/2025 15:06:37 - INFO - __main__ -   eval_precision = 0.5254\n",
      "04/14/2025 15:06:37 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 40% 203/512 [01:59<02:11,  2.34it/s]04/14/2025 15:07:20 - WARNING - __main__ - epoch 7 step 204 loss 0.1449\n",
      "[[0.67222196]\n",
      " [0.29402152]\n",
      " [0.04481297]\n",
      " ...\n",
      " [0.5564838 ]\n",
      " [0.2654921 ]\n",
      " [0.14426707]]\n",
      "04/14/2025 15:07:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:07:53 - INFO - __main__ -   auc_score = 0.8674\n",
      "04/14/2025 15:07:53 - INFO - __main__ -   eval_f1 = 0.3189\n",
      "04/14/2025 15:07:53 - INFO - __main__ -   eval_precision = 0.5754\n",
      "04/14/2025 15:07:53 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 15:08:37 - WARNING - __main__ - epoch 7 step 306 loss 0.17733\n",
      "[[0.8049985 ]\n",
      " [0.43428674]\n",
      " [0.08001161]\n",
      " ...\n",
      " [0.7114216 ]\n",
      " [0.45690244]\n",
      " [0.27983102]]\n",
      "04/14/2025 15:09:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:09:10 - INFO - __main__ -   auc_score = 0.8698\n",
      "04/14/2025 15:09:10 - INFO - __main__ -   eval_f1 = 0.4261\n",
      "04/14/2025 15:09:10 - INFO - __main__ -   eval_precision = 0.5014\n",
      "04/14/2025 15:09:10 - INFO - __main__ -   eval_recall = 0.3704\n",
      " 79% 407/512 [04:33<00:44,  2.35it/s]04/14/2025 15:09:54 - WARNING - __main__ - epoch 7 step 408 loss 0.17358\n",
      "[[0.679386  ]\n",
      " [0.35295555]\n",
      " [0.05418492]\n",
      " ...\n",
      " [0.5457694 ]\n",
      " [0.32811913]\n",
      " [0.17865281]]\n",
      "04/14/2025 15:10:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:10:27 - INFO - __main__ -   auc_score = 0.8667\n",
      "04/14/2025 15:10:27 - INFO - __main__ -   eval_f1 = 0.3373\n",
      "04/14/2025 15:10:27 - INFO - __main__ -   eval_precision = 0.5685\n",
      "04/14/2025 15:10:27 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 99% 509/512 [05:49<00:01,  2.35it/s]04/14/2025 15:11:10 - WARNING - __main__ - epoch 7 step 510 loss 0.14667\n",
      "[[0.6996799 ]\n",
      " [0.34698275]\n",
      " [0.06149802]\n",
      " ...\n",
      " [0.6596365 ]\n",
      " [0.4190263 ]\n",
      " [0.23401655]]\n",
      "04/14/2025 15:11:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:11:44 - INFO - __main__ -   auc_score = 0.8694\n",
      "04/14/2025 15:11:44 - INFO - __main__ -   eval_f1 = 0.3748\n",
      "04/14/2025 15:11:44 - INFO - __main__ -   eval_precision = 0.5189\n",
      "04/14/2025 15:11:44 - INFO - __main__ -   eval_recall = 0.2934\n",
      "100% 512/512 [06:23<00:00,  1.33it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.34it/s]04/14/2025 15:12:28 - WARNING - __main__ - epoch 8 step 102 loss 0.15633\n",
      "[[0.72153926]\n",
      " [0.37289357]\n",
      " [0.06975999]\n",
      " ...\n",
      " [0.6792044 ]\n",
      " [0.43421975]\n",
      " [0.240635  ]]\n",
      "04/14/2025 15:13:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:13:01 - INFO - __main__ -   auc_score = 0.8693\n",
      "04/14/2025 15:13:01 - INFO - __main__ -   eval_f1 = 0.391\n",
      "04/14/2025 15:13:01 - INFO - __main__ -   eval_precision = 0.5103\n",
      "04/14/2025 15:13:01 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 15:13:44 - WARNING - __main__ - epoch 8 step 204 loss 0.16614\n",
      "[[0.56655246]\n",
      " [0.28348288]\n",
      " [0.0486193 ]\n",
      " ...\n",
      " [0.57855165]\n",
      " [0.34887728]\n",
      " [0.15818906]]\n",
      "04/14/2025 15:14:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:14:17 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/14/2025 15:14:17 - INFO - __main__ -   eval_f1 = 0.3298\n",
      "04/14/2025 15:14:17 - INFO - __main__ -   eval_precision = 0.5745\n",
      "04/14/2025 15:14:17 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 15:15:00 - WARNING - __main__ - epoch 8 step 306 loss 0.17221\n",
      "[[0.6028948 ]\n",
      " [0.33473304]\n",
      " [0.05677215]\n",
      " ...\n",
      " [0.6097129 ]\n",
      " [0.39869   ]\n",
      " [0.16747773]]\n",
      "04/14/2025 15:15:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:15:33 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/14/2025 15:15:33 - INFO - __main__ -   eval_f1 = 0.357\n",
      "04/14/2025 15:15:33 - INFO - __main__ -   eval_precision = 0.5541\n",
      "04/14/2025 15:15:33 - INFO - __main__ -   eval_recall = 0.2634\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 15:16:16 - WARNING - __main__ - epoch 8 step 408 loss 0.15141\n",
      "[[0.66691315]\n",
      " [0.3643267 ]\n",
      " [0.06672069]\n",
      " ...\n",
      " [0.66197705]\n",
      " [0.47236016]\n",
      " [0.21031487]]\n",
      "04/14/2025 15:16:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:16:49 - INFO - __main__ -   auc_score = 0.8678\n",
      "04/14/2025 15:16:49 - INFO - __main__ -   eval_f1 = 0.3821\n",
      "04/14/2025 15:16:49 - INFO - __main__ -   eval_precision = 0.5203\n",
      "04/14/2025 15:16:49 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 15:17:33 - WARNING - __main__ - epoch 8 step 510 loss 0.15736\n",
      "[[0.59541845]\n",
      " [0.30390075]\n",
      " [0.05214123]\n",
      " ...\n",
      " [0.5998813 ]\n",
      " [0.3956077 ]\n",
      " [0.16651182]]\n",
      "04/14/2025 15:18:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:18:06 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/14/2025 15:18:06 - INFO - __main__ -   eval_f1 = 0.3504\n",
      "04/14/2025 15:18:06 - INFO - __main__ -   eval_precision = 0.5505\n",
      "04/14/2025 15:18:06 - INFO - __main__ -   eval_recall = 0.257\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n",
      " 20% 101/512 [00:42<02:55,  2.35it/s]04/14/2025 15:18:50 - WARNING - __main__ - epoch 9 step 102 loss 0.15325\n",
      "[[0.59766835]\n",
      " [0.30694523]\n",
      " [0.05377943]\n",
      " ...\n",
      " [0.6067543 ]\n",
      " [0.39418194]\n",
      " [0.16151206]]\n",
      "04/14/2025 15:19:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:19:23 - INFO - __main__ -   auc_score = 0.867\n",
      "04/14/2025 15:19:23 - INFO - __main__ -   eval_f1 = 0.3497\n",
      "04/14/2025 15:19:23 - INFO - __main__ -   eval_precision = 0.5378\n",
      "04/14/2025 15:19:23 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 40% 203/512 [01:59<02:11,  2.35it/s]04/14/2025 15:20:06 - WARNING - __main__ - epoch 9 step 204 loss 0.13646\n",
      "[[0.67332244]\n",
      " [0.30949944]\n",
      " [0.05713973]\n",
      " ...\n",
      " [0.6726739 ]\n",
      " [0.46688443]\n",
      " [0.21561149]]\n",
      "04/14/2025 15:20:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:20:39 - INFO - __main__ -   auc_score = 0.8685\n",
      "04/14/2025 15:20:39 - INFO - __main__ -   eval_f1 = 0.3723\n",
      "04/14/2025 15:20:39 - INFO - __main__ -   eval_precision = 0.5093\n",
      "04/14/2025 15:20:39 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 60% 305/512 [03:15<01:28,  2.35it/s]04/14/2025 15:21:22 - WARNING - __main__ - epoch 9 step 306 loss 0.16496\n",
      "[[0.5876699 ]\n",
      " [0.3124948 ]\n",
      " [0.0516735 ]\n",
      " ...\n",
      " [0.5755399 ]\n",
      " [0.37629992]\n",
      " [0.15284051]]\n",
      "04/14/2025 15:21:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:21:55 - INFO - __main__ -   auc_score = 0.8655\n",
      "04/14/2025 15:21:55 - INFO - __main__ -   eval_f1 = 0.3422\n",
      "04/14/2025 15:21:55 - INFO - __main__ -   eval_precision = 0.5498\n",
      "04/14/2025 15:21:55 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 79% 407/512 [04:31<00:44,  2.35it/s]04/14/2025 15:22:39 - WARNING - __main__ - epoch 9 step 408 loss 0.1533\n",
      "[[0.66158414]\n",
      " [0.3421662 ]\n",
      " [0.06149052]\n",
      " ...\n",
      " [0.657329  ]\n",
      " [0.46012333]\n",
      " [0.20845708]]\n",
      "04/14/2025 15:23:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:23:12 - INFO - __main__ -   auc_score = 0.8673\n",
      "04/14/2025 15:23:12 - INFO - __main__ -   eval_f1 = 0.3711\n",
      "04/14/2025 15:23:12 - INFO - __main__ -   eval_precision = 0.5113\n",
      "04/14/2025 15:23:12 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 99% 509/512 [05:48<00:01,  2.35it/s]04/14/2025 15:23:55 - WARNING - __main__ - epoch 9 step 510 loss 0.17186\n",
      "[[0.6537193 ]\n",
      " [0.3409965 ]\n",
      " [0.06123566]\n",
      " ...\n",
      " [0.646674  ]\n",
      " [0.44895753]\n",
      " [0.19994888]]\n",
      "04/14/2025 15:24:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 15:24:28 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/14/2025 15:24:28 - INFO - __main__ -   eval_f1 = 0.3604\n",
      "04/14/2025 15:24:28 - INFO - __main__ -   eval_precision = 0.5038\n",
      "04/14/2025 15:24:28 - INFO - __main__ -   eval_recall = 0.2805\n",
      "100% 512/512 [06:22<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/single/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdO1icBP8O3N",
    "outputId": "00f399b1-8431-44ab-a21a-45028117a0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:35:43.037503: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 15:35:43.056075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744644943.078012   62773 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744644943.085004   62773 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 15:35:43.108654: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 15:36:59 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 15:36:59 - INFO - __main__ -   auc_score = 0.8692\n",
      "04/14/2025 15:36:59 - INFO - __main__ -   test_f1 = 0.3815\n",
      "04/14/2025 15:36:59 - INFO - __main__ -   test_precision = 0.4511\n",
      "04/14/2025 15:36:59 - INFO - __main__ -   test_recall = 0.3305\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/unixcoder-base/single/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9DisG1fcRRn"
   },
   "source": [
    "### CodeT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msJhwt1bKOLp"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7t6ie9MXcufR",
    "outputId": "12ef1bcb-c303-4ca0-e80c-2531a6bbf1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100% 1.57k/1.57k [00:00<00:00, 9.19MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 9.69MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 9.37MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 66.3MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 10.4kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 52.0MB/s]\n",
      "pytorch_model.bin: 100% 892M/892M [00:04<00:00, 201MB/s]\n",
      "trainable params: 7,077,888 || all params: 229,961,472 || trainable%: 3.0778581900884685\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:56<03:44,  1.83it/s]04/24/2024 00:24:20 - WARNING - __main__ - epoch 0 step 102 loss 0.48432\n",
      "[[0.08265162]\n",
      " [0.095338  ]\n",
      " [0.08237641]\n",
      " ...\n",
      " [0.08929519]\n",
      " [0.07931488]\n",
      " [0.08374754]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:25:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:25:00 - INFO - __main__ -   auc_score = 0.454\n",
      "04/24/2024 00:25:00 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:25:00 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:25:00 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [02:32<02:48,  1.83it/s]04/24/2024 00:25:55 - WARNING - __main__ - epoch 0 step 204 loss 0.29909\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.12170325]\n",
      " [0.06902031]\n",
      " [0.09461856]\n",
      " ...\n",
      " [0.13272749]\n",
      " [0.10373981]\n",
      " [0.12258095]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:26:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:26:36 - INFO - __main__ -   auc_score = 0.6297\n",
      "04/24/2024 00:26:36 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:26:36 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:26:36 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [04:07<01:53,  1.83it/s]04/24/2024 00:27:31 - WARNING - __main__ - epoch 0 step 306 loss 0.27122\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.11565514]\n",
      " [0.03819288]\n",
      " [0.06392171]\n",
      " ...\n",
      " [0.1409164 ]\n",
      " [0.08593968]\n",
      " [0.12023605]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:28:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:28:11 - INFO - __main__ -   auc_score = 0.6652\n",
      "04/24/2024 00:28:11 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:28:11 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:28:11 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [05:43<00:57,  1.83it/s]04/24/2024 00:29:07 - WARNING - __main__ - epoch 0 step 408 loss 0.27354\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.15723413]\n",
      " [0.04104778]\n",
      " [0.0698951 ]\n",
      " ...\n",
      " [0.19419552]\n",
      " [0.10761444]\n",
      " [0.16920714]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:29:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:29:47 - INFO - __main__ -   auc_score = 0.7243\n",
      "04/24/2024 00:29:47 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:29:47 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:29:47 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [07:19<00:01,  1.83it/s]04/24/2024 00:30:42 - WARNING - __main__ - epoch 0 step 510 loss 0.25286\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.1305115 ]\n",
      " [0.02830672]\n",
      " [0.03841376]\n",
      " ...\n",
      " [0.19000407]\n",
      " [0.09078465]\n",
      " [0.15142445]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:31:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:31:22 - INFO - __main__ -   auc_score = 0.813\n",
      "04/24/2024 00:31:22 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:31:22 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:31:22 - INFO - __main__ -   eval_recall = 0.0\n",
      "100% 512/512 [08:00<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 00:32:19 - WARNING - __main__ - epoch 1 step 102 loss 0.25154\n",
      "[[0.2971457 ]\n",
      " [0.068385  ]\n",
      " [0.07613765]\n",
      " ...\n",
      " [0.3550246 ]\n",
      " [0.22305225]\n",
      " [0.29596645]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:32:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:32:59 - INFO - __main__ -   auc_score = 0.8389\n",
      "04/24/2024 00:32:59 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:32:59 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:32:59 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [02:30<02:49,  1.83it/s]04/24/2024 00:33:54 - WARNING - __main__ - epoch 1 step 204 loss 0.23933\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5348027 ]\n",
      " [0.22490536]\n",
      " [0.1982849 ]\n",
      " ...\n",
      " [0.5774063 ]\n",
      " [0.4544595 ]\n",
      " [0.5237705 ]]\n",
      "04/24/2024 00:34:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:34:34 - INFO - __main__ -   auc_score = 0.8503\n",
      "04/24/2024 00:34:34 - INFO - __main__ -   eval_f1 = 0.3166\n",
      "04/24/2024 00:34:34 - INFO - __main__ -   eval_precision = 0.4124\n",
      "04/24/2024 00:34:34 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 305/512 [04:07<01:53,  1.83it/s]04/24/2024 00:35:31 - WARNING - __main__ - epoch 1 step 306 loss 0.21203\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.35772985]\n",
      " [0.07363002]\n",
      " [0.07056162]\n",
      " ...\n",
      " [0.34238064]\n",
      " [0.24171218]\n",
      " [0.3331398 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:36:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:36:11 - INFO - __main__ -   auc_score = 0.8531\n",
      "04/24/2024 00:36:11 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:36:11 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:36:11 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [05:43<00:57,  1.83it/s]04/24/2024 00:37:07 - WARNING - __main__ - epoch 1 step 408 loss 0.22674\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.3895373 ]\n",
      " [0.11681083]\n",
      " [0.06632816]\n",
      " ...\n",
      " [0.3709509 ]\n",
      " [0.24171077]\n",
      " [0.34566838]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 00:37:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:37:47 - INFO - __main__ -   auc_score = 0.8585\n",
      "04/24/2024 00:37:47 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 00:37:47 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 00:37:47 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [07:18<00:01,  1.83it/s]04/24/2024 00:38:42 - WARNING - __main__ - epoch 1 step 510 loss 0.21215\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.42147616]\n",
      " [0.13456161]\n",
      " [0.06457082]\n",
      " ...\n",
      " [0.38552558]\n",
      " [0.21853988]\n",
      " [0.33635417]]\n",
      "04/24/2024 00:39:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:39:22 - INFO - __main__ -   auc_score = 0.8622\n",
      "04/24/2024 00:39:22 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "04/24/2024 00:39:22 - INFO - __main__ -   eval_precision = 0.6667\n",
      "04/24/2024 00:39:22 - INFO - __main__ -   eval_recall = 0.0043\n",
      "100% 512/512 [08:00<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 00:40:19 - WARNING - __main__ - epoch 2 step 102 loss 0.21448\n",
      "[[0.45048195]\n",
      " [0.11698366]\n",
      " [0.05207967]\n",
      " ...\n",
      " [0.3906646 ]\n",
      " [0.21791331]\n",
      " [0.34580916]]\n",
      "04/24/2024 00:40:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:40:59 - INFO - __main__ -   auc_score = 0.8622\n",
      "04/24/2024 00:40:59 - INFO - __main__ -   eval_f1 = 0.029\n",
      "04/24/2024 00:40:59 - INFO - __main__ -   eval_precision = 0.4667\n",
      "04/24/2024 00:40:59 - INFO - __main__ -   eval_recall = 0.015\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 00:41:54 - WARNING - __main__ - epoch 2 step 204 loss 0.21924\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.46458295]\n",
      " [0.1935362 ]\n",
      " [0.08961644]\n",
      " ...\n",
      " [0.40406477]\n",
      " [0.27440533]\n",
      " [0.37840497]]\n",
      "04/24/2024 00:42:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:42:34 - INFO - __main__ -   auc_score = 0.8632\n",
      "04/24/2024 00:42:34 - INFO - __main__ -   eval_f1 = 0.0168\n",
      "04/24/2024 00:42:34 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/24/2024 00:42:34 - INFO - __main__ -   eval_recall = 0.0086\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 00:43:30 - WARNING - __main__ - epoch 2 step 306 loss 0.22043\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.49060994]\n",
      " [0.17888798]\n",
      " [0.05689828]\n",
      " ...\n",
      " [0.38937864]\n",
      " [0.24009423]\n",
      " [0.3720233 ]]\n",
      "04/24/2024 00:44:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:44:10 - INFO - __main__ -   auc_score = 0.8624\n",
      "04/24/2024 00:44:10 - INFO - __main__ -   eval_f1 = 0.0717\n",
      "04/24/2024 00:44:10 - INFO - __main__ -   eval_precision = 0.5143\n",
      "04/24/2024 00:44:10 - INFO - __main__ -   eval_recall = 0.0385\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 00:45:05 - WARNING - __main__ - epoch 2 step 408 loss 0.20252\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.482205  ]\n",
      " [0.14659016]\n",
      " [0.05736712]\n",
      " ...\n",
      " [0.41788056]\n",
      " [0.2417403 ]\n",
      " [0.37455398]]\n",
      "04/24/2024 00:45:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:45:46 - INFO - __main__ -   auc_score = 0.8642\n",
      "04/24/2024 00:45:46 - INFO - __main__ -   eval_f1 = 0.0861\n",
      "04/24/2024 00:45:46 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/24/2024 00:45:46 - INFO - __main__ -   eval_recall = 0.0471\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 00:46:41 - WARNING - __main__ - epoch 2 step 510 loss 0.20981\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.4889903 ]\n",
      " [0.13263857]\n",
      " [0.05539373]\n",
      " ...\n",
      " [0.36603242]\n",
      " [0.1979846 ]\n",
      " [0.32206857]]\n",
      "04/24/2024 00:47:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:47:21 - INFO - __main__ -   auc_score = 0.8667\n",
      "04/24/2024 00:47:21 - INFO - __main__ -   eval_f1 = 0.0533\n",
      "04/24/2024 00:47:21 - INFO - __main__ -   eval_precision = 0.619\n",
      "04/24/2024 00:47:21 - INFO - __main__ -   eval_recall = 0.0278\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 00:48:18 - WARNING - __main__ - epoch 3 step 102 loss 0.20477\n",
      "[[0.52283955]\n",
      " [0.20887178]\n",
      " [0.07742251]\n",
      " ...\n",
      " [0.4186673 ]\n",
      " [0.25378615]\n",
      " [0.36245352]]\n",
      "04/24/2024 00:48:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:48:58 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/24/2024 00:48:58 - INFO - __main__ -   eval_f1 = 0.1257\n",
      "04/24/2024 00:48:58 - INFO - __main__ -   eval_precision = 0.569\n",
      "04/24/2024 00:48:58 - INFO - __main__ -   eval_recall = 0.0707\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 00:49:53 - WARNING - __main__ - epoch 3 step 204 loss 0.21534\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6285725 ]\n",
      " [0.2969994 ]\n",
      " [0.08831986]\n",
      " ...\n",
      " [0.5507897 ]\n",
      " [0.33320847]\n",
      " [0.45374212]]\n",
      "04/24/2024 00:50:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:50:33 - INFO - __main__ -   auc_score = 0.8687\n",
      "04/24/2024 00:50:33 - INFO - __main__ -   eval_f1 = 0.3529\n",
      "04/24/2024 00:50:33 - INFO - __main__ -   eval_precision = 0.5634\n",
      "04/24/2024 00:50:33 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 305/512 [04:08<01:53,  1.83it/s]04/24/2024 00:51:31 - WARNING - __main__ - epoch 3 step 306 loss 0.21443\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.48522586]\n",
      " [0.14927016]\n",
      " [0.04910217]\n",
      " ...\n",
      " [0.349506  ]\n",
      " [0.18686849]\n",
      " [0.26669368]]\n",
      "04/24/2024 00:52:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:52:11 - INFO - __main__ -   auc_score = 0.8677\n",
      "04/24/2024 00:52:11 - INFO - __main__ -   eval_f1 = 0.0803\n",
      "04/24/2024 00:52:11 - INFO - __main__ -   eval_precision = 0.6452\n",
      "04/24/2024 00:52:11 - INFO - __main__ -   eval_recall = 0.0428\n",
      " 79% 407/512 [05:43<00:57,  1.83it/s]04/24/2024 00:53:06 - WARNING - __main__ - epoch 3 step 408 loss 0.19634\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.57228506]\n",
      " [0.16813302]\n",
      " [0.05646047]\n",
      " ...\n",
      " [0.4032203 ]\n",
      " [0.21215995]\n",
      " [0.30593032]]\n",
      "04/24/2024 00:53:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:53:46 - INFO - __main__ -   auc_score = 0.8712\n",
      "04/24/2024 00:53:46 - INFO - __main__ -   eval_f1 = 0.1758\n",
      "04/24/2024 00:53:46 - INFO - __main__ -   eval_precision = 0.6076\n",
      "04/24/2024 00:53:46 - INFO - __main__ -   eval_recall = 0.1028\n",
      " 99% 509/512 [07:19<00:01,  1.83it/s]04/24/2024 00:54:42 - WARNING - __main__ - epoch 3 step 510 loss 0.19101\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5817221 ]\n",
      " [0.2021018 ]\n",
      " [0.0680333 ]\n",
      " ...\n",
      " [0.38031322]\n",
      " [0.22635244]\n",
      " [0.31015715]]\n",
      "04/24/2024 00:55:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:55:22 - INFO - __main__ -   auc_score = 0.8702\n",
      "04/24/2024 00:55:22 - INFO - __main__ -   eval_f1 = 0.1657\n",
      "04/24/2024 00:55:22 - INFO - __main__ -   eval_precision = 0.5921\n",
      "04/24/2024 00:55:22 - INFO - __main__ -   eval_recall = 0.0964\n",
      "100% 512/512 [08:00<00:00,  1.06it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 00:56:18 - WARNING - __main__ - epoch 4 step 102 loss 0.19254\n",
      "[[0.65431416]\n",
      " [0.22452442]\n",
      " [0.07810465]\n",
      " ...\n",
      " [0.45706096]\n",
      " [0.2737566 ]\n",
      " [0.364278  ]]\n",
      "04/24/2024 00:56:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:56:59 - INFO - __main__ -   auc_score = 0.8709\n",
      "04/24/2024 00:56:59 - INFO - __main__ -   eval_f1 = 0.3096\n",
      "04/24/2024 00:56:59 - INFO - __main__ -   eval_precision = 0.5904\n",
      "04/24/2024 00:56:59 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 00:57:54 - WARNING - __main__ - epoch 4 step 204 loss 0.20702\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6021352 ]\n",
      " [0.23199625]\n",
      " [0.06762097]\n",
      " ...\n",
      " [0.39832318]\n",
      " [0.21541779]\n",
      " [0.28161418]]\n",
      "04/24/2024 00:58:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 00:58:34 - INFO - __main__ -   auc_score = 0.871\n",
      "04/24/2024 00:58:34 - INFO - __main__ -   eval_f1 = 0.2418\n",
      "04/24/2024 00:58:34 - INFO - __main__ -   eval_precision = 0.625\n",
      "04/24/2024 00:58:34 - INFO - __main__ -   eval_recall = 0.1499\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 00:59:30 - WARNING - __main__ - epoch 4 step 306 loss 0.21039\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.63865703]\n",
      " [0.31725335]\n",
      " [0.08692415]\n",
      " ...\n",
      " [0.48612455]\n",
      " [0.28792086]\n",
      " [0.36144862]]\n",
      "04/24/2024 01:00:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:00:10 - INFO - __main__ -   auc_score = 0.8712\n",
      "04/24/2024 01:00:10 - INFO - __main__ -   eval_f1 = 0.3499\n",
      "04/24/2024 01:00:10 - INFO - __main__ -   eval_precision = 0.5918\n",
      "04/24/2024 01:00:10 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 01:01:05 - WARNING - __main__ - epoch 4 step 408 loss 0.18344\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.663489  ]\n",
      " [0.29670742]\n",
      " [0.08261254]\n",
      " ...\n",
      " [0.44570875]\n",
      " [0.25360993]\n",
      " [0.32185993]]\n",
      "04/24/2024 01:01:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:01:45 - INFO - __main__ -   auc_score = 0.8708\n",
      "04/24/2024 01:01:45 - INFO - __main__ -   eval_f1 = 0.3469\n",
      "04/24/2024 01:01:45 - INFO - __main__ -   eval_precision = 0.5867\n",
      "04/24/2024 01:01:45 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 01:02:41 - WARNING - __main__ - epoch 4 step 510 loss 0.19216\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6812007 ]\n",
      " [0.29709476]\n",
      " [0.08743932]\n",
      " ...\n",
      " [0.43144077]\n",
      " [0.2583262 ]\n",
      " [0.3238204 ]]\n",
      "04/24/2024 01:03:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:03:21 - INFO - __main__ -   auc_score = 0.8708\n",
      "04/24/2024 01:03:21 - INFO - __main__ -   eval_f1 = 0.3369\n",
      "04/24/2024 01:03:21 - INFO - __main__ -   eval_precision = 0.6056\n",
      "04/24/2024 01:03:21 - INFO - __main__ -   eval_recall = 0.2334\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 01:04:17 - WARNING - __main__ - epoch 5 step 102 loss 0.17506\n",
      "[[0.7119639 ]\n",
      " [0.22900407]\n",
      " [0.06580034]\n",
      " ...\n",
      " [0.40265504]\n",
      " [0.20234592]\n",
      " [0.28707802]]\n",
      "04/24/2024 01:04:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:04:57 - INFO - __main__ -   auc_score = 0.8684\n",
      "04/24/2024 01:04:57 - INFO - __main__ -   eval_f1 = 0.3206\n",
      "04/24/2024 01:04:57 - INFO - __main__ -   eval_precision = 0.6196\n",
      "04/24/2024 01:04:57 - INFO - __main__ -   eval_recall = 0.2163\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 01:05:53 - WARNING - __main__ - epoch 5 step 204 loss 0.1917\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6784787 ]\n",
      " [0.24879998]\n",
      " [0.06433436]\n",
      " ...\n",
      " [0.32271665]\n",
      " [0.17726968]\n",
      " [0.2577817 ]]\n",
      "04/24/2024 01:06:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:06:33 - INFO - __main__ -   auc_score = 0.8671\n",
      "04/24/2024 01:06:33 - INFO - __main__ -   eval_f1 = 0.2487\n",
      "04/24/2024 01:06:33 - INFO - __main__ -   eval_precision = 0.6083\n",
      "04/24/2024 01:06:33 - INFO - __main__ -   eval_recall = 0.1563\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 01:07:28 - WARNING - __main__ - epoch 5 step 306 loss 0.19893\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.74988085]\n",
      " [0.30329347]\n",
      " [0.09790825]\n",
      " ...\n",
      " [0.50130534]\n",
      " [0.2918957 ]\n",
      " [0.3785979 ]]\n",
      "04/24/2024 01:08:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:08:08 - INFO - __main__ -   auc_score = 0.8695\n",
      "04/24/2024 01:08:08 - INFO - __main__ -   eval_f1 = 0.409\n",
      "04/24/2024 01:08:08 - INFO - __main__ -   eval_precision = 0.5326\n",
      "04/24/2024 01:08:08 - INFO - __main__ -   eval_recall = 0.3319\n",
      " 79% 407/512 [05:43<00:57,  1.83it/s]04/24/2024 01:09:06 - WARNING - __main__ - epoch 5 step 408 loss 0.19819\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.63909405]\n",
      " [0.2349328 ]\n",
      " [0.06894943]\n",
      " ...\n",
      " [0.34094873]\n",
      " [0.17703894]\n",
      " [0.2373794 ]]\n",
      "04/24/2024 01:09:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:09:46 - INFO - __main__ -   auc_score = 0.8678\n",
      "04/24/2024 01:09:46 - INFO - __main__ -   eval_f1 = 0.2676\n",
      "04/24/2024 01:09:46 - INFO - __main__ -   eval_precision = 0.6107\n",
      "04/24/2024 01:09:46 - INFO - __main__ -   eval_recall = 0.1713\n",
      " 99% 509/512 [07:19<00:01,  1.83it/s]04/24/2024 01:10:42 - WARNING - __main__ - epoch 5 step 510 loss 0.18729\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.68336517]\n",
      " [0.30899793]\n",
      " [0.09504609]\n",
      " ...\n",
      " [0.38699716]\n",
      " [0.22487767]\n",
      " [0.28145155]]\n",
      "04/24/2024 01:11:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:11:22 - INFO - __main__ -   auc_score = 0.8712\n",
      "04/24/2024 01:11:22 - INFO - __main__ -   eval_f1 = 0.3282\n",
      "04/24/2024 01:11:22 - INFO - __main__ -   eval_precision = 0.5784\n",
      "04/24/2024 01:11:22 - INFO - __main__ -   eval_recall = 0.2291\n",
      "100% 512/512 [08:00<00:00,  1.06it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 01:12:18 - WARNING - __main__ - epoch 6 step 102 loss 0.19319\n",
      "[[0.6992646 ]\n",
      " [0.30159807]\n",
      " [0.0900349 ]\n",
      " ...\n",
      " [0.3812747 ]\n",
      " [0.2373024 ]\n",
      " [0.28166917]]\n",
      "04/24/2024 01:12:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:12:58 - INFO - __main__ -   auc_score = 0.8717\n",
      "04/24/2024 01:12:58 - INFO - __main__ -   eval_f1 = 0.316\n",
      "04/24/2024 01:12:58 - INFO - __main__ -   eval_precision = 0.5568\n",
      "04/24/2024 01:12:58 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 01:13:54 - WARNING - __main__ - epoch 6 step 204 loss 0.18171\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.74761176]\n",
      " [0.3434572 ]\n",
      " [0.1031813 ]\n",
      " ...\n",
      " [0.4208415 ]\n",
      " [0.26198897]\n",
      " [0.29991147]]\n",
      "04/24/2024 01:14:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:14:34 - INFO - __main__ -   auc_score = 0.8723\n",
      "04/24/2024 01:14:34 - INFO - __main__ -   eval_f1 = 0.389\n",
      "04/24/2024 01:14:34 - INFO - __main__ -   eval_precision = 0.5399\n",
      "04/24/2024 01:14:34 - INFO - __main__ -   eval_recall = 0.3041\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 01:15:29 - WARNING - __main__ - epoch 6 step 306 loss 0.18761\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6468897 ]\n",
      " [0.2600409 ]\n",
      " [0.0836377 ]\n",
      " ...\n",
      " [0.30690354]\n",
      " [0.20737395]\n",
      " [0.20529327]]\n",
      "04/24/2024 01:16:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:16:09 - INFO - __main__ -   auc_score = 0.8692\n",
      "04/24/2024 01:16:09 - INFO - __main__ -   eval_f1 = 0.2913\n",
      "04/24/2024 01:16:09 - INFO - __main__ -   eval_precision = 0.6181\n",
      "04/24/2024 01:16:09 - INFO - __main__ -   eval_recall = 0.1906\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 01:17:05 - WARNING - __main__ - epoch 6 step 408 loss 0.17127\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6717054 ]\n",
      " [0.22064863]\n",
      " [0.076951  ]\n",
      " ...\n",
      " [0.31967887]\n",
      " [0.18214919]\n",
      " [0.19311298]]\n",
      "04/24/2024 01:17:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:17:45 - INFO - __main__ -   auc_score = 0.8704\n",
      "04/24/2024 01:17:45 - INFO - __main__ -   eval_f1 = 0.2968\n",
      "04/24/2024 01:17:45 - INFO - __main__ -   eval_precision = 0.6013\n",
      "04/24/2024 01:17:45 - INFO - __main__ -   eval_recall = 0.197\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 01:18:40 - WARNING - __main__ - epoch 6 step 510 loss 0.18824\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7614959 ]\n",
      " [0.2576699 ]\n",
      " [0.09509347]\n",
      " ...\n",
      " [0.4426573 ]\n",
      " [0.24867041]\n",
      " [0.2733862 ]]\n",
      "04/24/2024 01:19:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:19:20 - INFO - __main__ -   auc_score = 0.8709\n",
      "04/24/2024 01:19:20 - INFO - __main__ -   eval_f1 = 0.4058\n",
      "04/24/2024 01:19:20 - INFO - __main__ -   eval_precision = 0.5219\n",
      "04/24/2024 01:19:20 - INFO - __main__ -   eval_recall = 0.3319\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 01:20:17 - WARNING - __main__ - epoch 7 step 102 loss 0.18177\n",
      "[[0.5992446 ]\n",
      " [0.17545326]\n",
      " [0.06496277]\n",
      " ...\n",
      " [0.24970786]\n",
      " [0.16627581]\n",
      " [0.13700107]]\n",
      "04/24/2024 01:20:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:20:57 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/24/2024 01:20:57 - INFO - __main__ -   eval_f1 = 0.2572\n",
      "04/24/2024 01:20:57 - INFO - __main__ -   eval_precision = 0.6129\n",
      "04/24/2024 01:20:57 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 01:21:52 - WARNING - __main__ - epoch 7 step 204 loss 0.18653\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.73683006]\n",
      " [0.26466876]\n",
      " [0.09664395]\n",
      " ...\n",
      " [0.3959298 ]\n",
      " [0.26183623]\n",
      " [0.22233653]]\n",
      "04/24/2024 01:22:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:22:32 - INFO - __main__ -   auc_score = 0.8689\n",
      "04/24/2024 01:22:32 - INFO - __main__ -   eval_f1 = 0.3973\n",
      "04/24/2024 01:22:32 - INFO - __main__ -   eval_precision = 0.5324\n",
      "04/24/2024 01:22:32 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 01:23:28 - WARNING - __main__ - epoch 7 step 306 loss 0.16611\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.69705087]\n",
      " [0.18743904]\n",
      " [0.07340761]\n",
      " ...\n",
      " [0.27997044]\n",
      " [0.17545559]\n",
      " [0.15404378]]\n",
      "04/24/2024 01:24:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:24:08 - INFO - __main__ -   auc_score = 0.868\n",
      "04/24/2024 01:24:08 - INFO - __main__ -   eval_f1 = 0.2885\n",
      "04/24/2024 01:24:08 - INFO - __main__ -   eval_precision = 0.5732\n",
      "04/24/2024 01:24:08 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 01:25:03 - WARNING - __main__ - epoch 7 step 408 loss 0.18409\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7219612 ]\n",
      " [0.25116163]\n",
      " [0.09601463]\n",
      " ...\n",
      " [0.3438154 ]\n",
      " [0.22426362]\n",
      " [0.20344743]]\n",
      "04/24/2024 01:25:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:25:43 - INFO - __main__ -   auc_score = 0.8683\n",
      "04/24/2024 01:25:43 - INFO - __main__ -   eval_f1 = 0.3782\n",
      "04/24/2024 01:25:43 - INFO - __main__ -   eval_precision = 0.5714\n",
      "04/24/2024 01:25:43 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 01:26:39 - WARNING - __main__ - epoch 7 step 510 loss 0.17063\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.74826735]\n",
      " [0.2388138 ]\n",
      " [0.09955862]\n",
      " ...\n",
      " [0.36548433]\n",
      " [0.2269152 ]\n",
      " [0.23005663]]\n",
      "04/24/2024 01:27:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:27:19 - INFO - __main__ -   auc_score = 0.869\n",
      "04/24/2024 01:27:19 - INFO - __main__ -   eval_f1 = 0.3934\n",
      "04/24/2024 01:27:19 - INFO - __main__ -   eval_precision = 0.5569\n",
      "04/24/2024 01:27:19 - INFO - __main__ -   eval_recall = 0.3041\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 01:28:15 - WARNING - __main__ - epoch 8 step 102 loss 0.17117\n",
      "[[0.78200525]\n",
      " [0.2449075 ]\n",
      " [0.10303133]\n",
      " ...\n",
      " [0.37694794]\n",
      " [0.24069995]\n",
      " [0.24382475]]\n",
      "04/24/2024 01:28:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:28:56 - INFO - __main__ -   auc_score = 0.8699\n",
      "04/24/2024 01:28:56 - INFO - __main__ -   eval_f1 = 0.3989\n",
      "04/24/2024 01:28:56 - INFO - __main__ -   eval_precision = 0.5263\n",
      "04/24/2024 01:28:56 - INFO - __main__ -   eval_recall = 0.3212\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 01:29:51 - WARNING - __main__ - epoch 8 step 204 loss 0.17776\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7357146 ]\n",
      " [0.20580915]\n",
      " [0.09320152]\n",
      " ...\n",
      " [0.30916867]\n",
      " [0.19637926]\n",
      " [0.18417543]]\n",
      "04/24/2024 01:30:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:30:31 - INFO - __main__ -   auc_score = 0.8686\n",
      "04/24/2024 01:30:31 - INFO - __main__ -   eval_f1 = 0.3596\n",
      "04/24/2024 01:30:31 - INFO - __main__ -   eval_precision = 0.5668\n",
      "04/24/2024 01:30:31 - INFO - __main__ -   eval_recall = 0.2634\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 01:31:26 - WARNING - __main__ - epoch 8 step 306 loss 0.15639\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.77241325]\n",
      " [0.23426773]\n",
      " [0.09228665]\n",
      " ...\n",
      " [0.3295092 ]\n",
      " [0.18787248]\n",
      " [0.18955827]]\n",
      "04/24/2024 01:32:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:32:07 - INFO - __main__ -   auc_score = 0.8686\n",
      "04/24/2024 01:32:07 - INFO - __main__ -   eval_f1 = 0.386\n",
      "04/24/2024 01:32:07 - INFO - __main__ -   eval_precision = 0.5565\n",
      "04/24/2024 01:32:07 - INFO - __main__ -   eval_recall = 0.2955\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 01:33:02 - WARNING - __main__ - epoch 8 step 408 loss 0.17655\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.722514  ]\n",
      " [0.1990898 ]\n",
      " [0.08098313]\n",
      " ...\n",
      " [0.27180734]\n",
      " [0.14907938]\n",
      " [0.14224781]]\n",
      "04/24/2024 01:33:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:33:42 - INFO - __main__ -   auc_score = 0.8659\n",
      "04/24/2024 01:33:42 - INFO - __main__ -   eval_f1 = 0.3472\n",
      "04/24/2024 01:33:42 - INFO - __main__ -   eval_precision = 0.5652\n",
      "04/24/2024 01:33:42 - INFO - __main__ -   eval_recall = 0.2505\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 01:34:38 - WARNING - __main__ - epoch 8 step 510 loss 0.19052\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7933804 ]\n",
      " [0.2573889 ]\n",
      " [0.11107934]\n",
      " ...\n",
      " [0.3815267 ]\n",
      " [0.2344031 ]\n",
      " [0.23429358]]\n",
      "04/24/2024 01:35:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:35:18 - INFO - __main__ -   auc_score = 0.868\n",
      "04/24/2024 01:35:18 - INFO - __main__ -   eval_f1 = 0.4046\n",
      "04/24/2024 01:35:18 - INFO - __main__ -   eval_precision = 0.4984\n",
      "04/24/2024 01:35:18 - INFO - __main__ -   eval_recall = 0.3405\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/24/2024 01:36:14 - WARNING - __main__ - epoch 9 step 102 loss 0.164\n",
      "[[0.7836994 ]\n",
      " [0.23552418]\n",
      " [0.09829839]\n",
      " ...\n",
      " [0.33553314]\n",
      " [0.19762874]\n",
      " [0.20004037]]\n",
      "04/24/2024 01:36:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:36:54 - INFO - __main__ -   auc_score = 0.867\n",
      "04/24/2024 01:36:54 - INFO - __main__ -   eval_f1 = 0.3929\n",
      "04/24/2024 01:36:54 - INFO - __main__ -   eval_precision = 0.5414\n",
      "04/24/2024 01:36:54 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/24/2024 01:37:50 - WARNING - __main__ - epoch 9 step 204 loss 0.18226\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7893583 ]\n",
      " [0.24445322]\n",
      " [0.10415798]\n",
      " ...\n",
      " [0.35841215]\n",
      " [0.21229969]\n",
      " [0.21108091]]\n",
      "04/24/2024 01:38:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:38:30 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/24/2024 01:38:30 - INFO - __main__ -   eval_f1 = 0.3984\n",
      "04/24/2024 01:38:30 - INFO - __main__ -   eval_precision = 0.5135\n",
      "04/24/2024 01:38:30 - INFO - __main__ -   eval_recall = 0.3255\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/24/2024 01:39:25 - WARNING - __main__ - epoch 9 step 306 loss 0.15901\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.79274565]\n",
      " [0.23161663]\n",
      " [0.09869846]\n",
      " ...\n",
      " [0.3483299 ]\n",
      " [0.20160991]\n",
      " [0.20316117]]\n",
      "04/24/2024 01:40:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:40:05 - INFO - __main__ -   auc_score = 0.8671\n",
      "04/24/2024 01:40:05 - INFO - __main__ -   eval_f1 = 0.3941\n",
      "04/24/2024 01:40:05 - INFO - __main__ -   eval_precision = 0.5211\n",
      "04/24/2024 01:40:05 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/24/2024 01:41:01 - WARNING - __main__ - epoch 9 step 408 loss 0.1726\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.79645246]\n",
      " [0.24424462]\n",
      " [0.10472548]\n",
      " ...\n",
      " [0.3631944 ]\n",
      " [0.21575913]\n",
      " [0.21452619]]\n",
      "04/24/2024 01:41:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:41:41 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/24/2024 01:41:41 - INFO - __main__ -   eval_f1 = 0.3969\n",
      "04/24/2024 01:41:41 - INFO - __main__ -   eval_precision = 0.5033\n",
      "04/24/2024 01:41:41 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/24/2024 01:42:36 - WARNING - __main__ - epoch 9 step 510 loss 0.17874\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7900839 ]\n",
      " [0.23781939]\n",
      " [0.10182308]\n",
      " ...\n",
      " [0.34984428]\n",
      " [0.20658447]\n",
      " [0.20504381]]\n",
      "04/24/2024 01:43:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 01:43:17 - INFO - __main__ -   auc_score = 0.8671\n",
      "04/24/2024 01:43:17 - INFO - __main__ -   eval_f1 = 0.3937\n",
      "04/24/2024 01:43:17 - INFO - __main__ -   eval_precision = 0.5138\n",
      "04/24/2024 01:43:17 - INFO - __main__ -   eval_recall = 0.3191\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir ../results/jitfine_lora/codet5/single/checkpoints \\\n",
    "   --pretrained_model codet5 \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkidPd2GxzRP",
    "outputId": "b73a57b6-52f9-4a57-bc20-57db399673d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,077,888 || all params: 229,961,472 || trainable%: 3.0778581900884685\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 01:46:47 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 01:46:47 - INFO - __main__ -   auc_score = 0.8625\n",
      "04/24/2024 01:46:47 - INFO - __main__ -   test_f1 = 0.3508\n",
      "04/24/2024 01:46:47 - INFO - __main__ -   test_precision = 0.4637\n",
      "04/24/2024 01:46:47 - INFO - __main__ -   test_recall = 0.2821\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir ../results/jitfine_lora/codet5/single/checkpoints \\\n",
    "   --pretrained_model codet5 \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sXz45ErKSnb"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_EHHPZ-KU-N",
    "outputId": "f3b338b8-6c35-4bc2-ed53-82122a69c4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "config.json: 100% 1.57k/1.57k [00:00<00:00, 5.65MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 10.5MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 22.7MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 39.8MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 16.1kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 52.6MB/s]\n",
      "pytorch_model.bin: 100% 892M/892M [00:05<00:00, 157MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:17,  1.50s/it]04/24/2024 22:23:36 - WARNING - __main__ - epoch 0 step 102 loss 0.38754\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:25:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:25:26 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:25:26 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:25:26 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:27:16 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:27:16 - INFO - __main__ -   auc_score = 0.5858\n",
      "04/24/2024 22:27:16 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:27:16 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:27:16 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [08:44<07:44,  1.50s/it]04/24/2024 22:29:48 - WARNING - __main__ - epoch 0 step 204 loss 0.29048\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:31:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:31:38 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:31:38 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:31:38 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:33:28 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:33:28 - INFO - __main__ -   auc_score = 0.622\n",
      "04/24/2024 22:33:28 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:33:28 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:33:28 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [14:57<05:12,  1.51s/it]04/24/2024 22:36:01 - WARNING - __main__ - epoch 0 step 306 loss 0.28553\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:37:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:37:51 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:37:51 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:37:51 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:39:38 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:39:38 - INFO - __main__ -   auc_score = 0.6524\n",
      "04/24/2024 22:39:38 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:39:38 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:39:38 - INFO - __main__ -   test_recall = 0.0\n",
      " 79% 407/512 [21:07<02:37,  1.50s/it]04/24/2024 22:42:11 - WARNING - __main__ - epoch 0 step 408 loss 0.27965\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:44:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:44:00 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:44:00 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:44:00 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:45:50 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:45:50 - INFO - __main__ -   auc_score = 0.6736\n",
      "04/24/2024 22:45:50 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:45:50 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:45:50 - INFO - __main__ -   test_recall = 0.0\n",
      " 99% 509/512 [27:19<00:04,  1.50s/it]04/24/2024 22:48:23 - WARNING - __main__ - epoch 0 step 510 loss 0.26021\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:50:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:50:13 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:50:13 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:50:13 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:52:03 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:52:03 - INFO - __main__ -   auc_score = 0.7313\n",
      "04/24/2024 22:52:03 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:52:03 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:52:03 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 512/512 [31:02<00:00,  3.64s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:18,  1.50s/it]04/24/2024 22:54:38 - WARNING - __main__ - epoch 1 step 102 loss 0.25358\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:56:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 22:56:28 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 22:56:28 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 22:56:28 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 22:58:18 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 22:58:18 - INFO - __main__ -   auc_score = 0.8106\n",
      "04/24/2024 22:58:18 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 22:58:18 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 22:58:18 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [08:44<07:46,  1.51s/it]04/24/2024 23:00:51 - WARNING - __main__ - epoch 1 step 204 loss 0.24769\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:02:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:02:41 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:02:41 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:02:41 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:04:30 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:04:30 - INFO - __main__ -   auc_score = 0.8408\n",
      "04/24/2024 23:04:30 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 23:04:30 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 23:04:30 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [14:57<05:11,  1.51s/it]04/24/2024 23:07:03 - WARNING - __main__ - epoch 1 step 306 loss 0.22907\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:08:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:08:53 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:08:53 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:08:53 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:10:43 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:10:43 - INFO - __main__ -   auc_score = 0.8474\n",
      "04/24/2024 23:10:43 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 23:10:43 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 23:10:43 - INFO - __main__ -   test_recall = 0.0\n",
      " 79% 407/512 [21:09<02:38,  1.51s/it]04/24/2024 23:13:16 - WARNING - __main__ - epoch 1 step 408 loss 0.21933\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:15:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:15:05 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:15:05 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:15:05 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:16:55 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:16:55 - INFO - __main__ -   auc_score = 0.8496\n",
      "04/24/2024 23:16:55 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 23:16:55 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 23:16:55 - INFO - __main__ -   test_recall = 0.0\n",
      " 99% 509/512 [27:22<00:04,  1.51s/it]04/24/2024 23:19:28 - WARNING - __main__ - epoch 1 step 510 loss 0.22633\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:21:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:21:18 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:21:18 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:21:18 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:23:08 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:23:08 - INFO - __main__ -   auc_score = 0.8553\n",
      "04/24/2024 23:23:08 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 23:23:08 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 23:23:08 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 512/512 [31:05<00:00,  3.64s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:19,  1.51s/it]04/24/2024 23:25:43 - WARNING - __main__ - epoch 2 step 102 loss 0.22304\n",
      "04/24/2024 23:27:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:27:33 - INFO - __main__ -   eval_f1 = 0.0084\n",
      "04/24/2024 23:27:33 - INFO - __main__ -   eval_precision = 0.2857\n",
      "04/24/2024 23:27:33 - INFO - __main__ -   eval_recall = 0.0043\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:29:25 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:29:25 - INFO - __main__ -   auc_score = 0.8562\n",
      "04/24/2024 23:29:25 - INFO - __main__ -   test_f1 = 0.0289\n",
      "04/24/2024 23:29:25 - INFO - __main__ -   test_precision = 0.7778\n",
      "04/24/2024 23:29:25 - INFO - __main__ -   test_recall = 0.0147\n",
      " 40% 203/512 [08:46<07:45,  1.51s/it]04/24/2024 23:31:57 - WARNING - __main__ - epoch 2 step 204 loss 0.22233\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:33:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:33:47 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:33:47 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:33:47 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:35:37 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:35:37 - INFO - __main__ -   auc_score = 0.8574\n",
      "04/24/2024 23:35:37 - INFO - __main__ -   test_f1 = 0.0084\n",
      "04/24/2024 23:35:37 - INFO - __main__ -   test_precision = 1.0\n",
      "04/24/2024 23:35:37 - INFO - __main__ -   test_recall = 0.0042\n",
      " 60% 305/512 [14:58<05:11,  1.50s/it]04/24/2024 23:38:10 - WARNING - __main__ - epoch 2 step 306 loss 0.22668\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:40:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:40:00 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/24/2024 23:40:00 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/24/2024 23:40:00 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/24/2024 23:41:49 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:41:49 - INFO - __main__ -   auc_score = 0.8583\n",
      "04/24/2024 23:41:49 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/24/2024 23:41:49 - INFO - __main__ -   test_precision = 0.0\n",
      "04/24/2024 23:41:49 - INFO - __main__ -   test_recall = 0.0\n",
      " 79% 407/512 [21:10<02:37,  1.50s/it]04/24/2024 23:44:22 - WARNING - __main__ - epoch 2 step 408 loss 0.21262\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:46:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:46:12 - INFO - __main__ -   eval_f1 = 0.1366\n",
      "04/24/2024 23:46:12 - INFO - __main__ -   eval_precision = 0.6\n",
      "04/24/2024 23:46:12 - INFO - __main__ -   eval_recall = 0.0771\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:48:04 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:48:04 - INFO - __main__ -   auc_score = 0.8604\n",
      "04/24/2024 23:48:04 - INFO - __main__ -   test_f1 = 0.1245\n",
      "04/24/2024 23:48:04 - INFO - __main__ -   test_precision = 0.6\n",
      "04/24/2024 23:48:04 - INFO - __main__ -   test_recall = 0.0695\n",
      " 99% 509/512 [27:24<00:04,  1.50s/it]04/24/2024 23:50:36 - WARNING - __main__ - epoch 2 step 510 loss 0.21371\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:52:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:52:26 - INFO - __main__ -   eval_f1 = 0.0528\n",
      "04/24/2024 23:52:26 - INFO - __main__ -   eval_precision = 0.52\n",
      "04/24/2024 23:52:26 - INFO - __main__ -   eval_recall = 0.0278\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/24/2024 23:54:16 - INFO - __main__ - ***** Test results *****\n",
      "04/24/2024 23:54:16 - INFO - __main__ -   auc_score = 0.8622\n",
      "04/24/2024 23:54:16 - INFO - __main__ -   test_f1 = 0.0528\n",
      "04/24/2024 23:54:16 - INFO - __main__ -   test_precision = 0.7647\n",
      "04/24/2024 23:54:16 - INFO - __main__ -   test_recall = 0.0274\n",
      "100% 512/512 [31:07<00:00,  3.65s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:20,  1.51s/it]04/24/2024 23:56:51 - WARNING - __main__ - epoch 3 step 102 loss 0.21667\n",
      "04/24/2024 23:58:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/24/2024 23:58:41 - INFO - __main__ -   eval_f1 = 0.0607\n",
      "04/24/2024 23:58:41 - INFO - __main__ -   eval_precision = 0.5556\n",
      "04/24/2024 23:58:41 - INFO - __main__ -   eval_recall = 0.0321\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:00:31 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:00:31 - INFO - __main__ -   auc_score = 0.8614\n",
      "04/25/2024 00:00:31 - INFO - __main__ -   test_f1 = 0.045\n",
      "04/25/2024 00:00:31 - INFO - __main__ -   test_precision = 0.7857\n",
      "04/25/2024 00:00:31 - INFO - __main__ -   test_recall = 0.0232\n",
      " 40% 203/512 [08:44<07:45,  1.51s/it]04/25/2024 00:03:04 - WARNING - __main__ - epoch 3 step 204 loss 0.21233\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:04:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:04:54 - INFO - __main__ -   eval_f1 = 0.1512\n",
      "04/25/2024 00:04:54 - INFO - __main__ -   eval_precision = 0.6452\n",
      "04/25/2024 00:04:54 - INFO - __main__ -   eval_recall = 0.0857\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:06:45 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:06:45 - INFO - __main__ -   auc_score = 0.8625\n",
      "04/25/2024 00:06:45 - INFO - __main__ -   test_f1 = 0.1147\n",
      "04/25/2024 00:06:45 - INFO - __main__ -   test_precision = 0.625\n",
      "04/25/2024 00:06:45 - INFO - __main__ -   test_recall = 0.0632\n",
      " 60% 305/512 [14:58<05:10,  1.50s/it]04/25/2024 00:09:18 - WARNING - __main__ - epoch 3 step 306 loss 0.20252\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:11:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:11:08 - INFO - __main__ -   eval_f1 = 0.1024\n",
      "04/25/2024 00:11:08 - INFO - __main__ -   eval_precision = 0.6341\n",
      "04/25/2024 00:11:08 - INFO - __main__ -   eval_recall = 0.0557\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:12:58 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:12:58 - INFO - __main__ -   auc_score = 0.8646\n",
      "04/25/2024 00:12:58 - INFO - __main__ -   test_f1 = 0.0792\n",
      "04/25/2024 00:12:58 - INFO - __main__ -   test_precision = 0.6667\n",
      "04/25/2024 00:12:58 - INFO - __main__ -   test_recall = 0.0421\n",
      " 79% 407/512 [21:11<02:38,  1.50s/it]04/25/2024 00:15:31 - WARNING - __main__ - epoch 3 step 408 loss 0.19904\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:17:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:17:21 - INFO - __main__ -   eval_f1 = 0.2245\n",
      "04/25/2024 00:17:21 - INFO - __main__ -   eval_precision = 0.5804\n",
      "04/25/2024 00:17:21 - INFO - __main__ -   eval_recall = 0.1392\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:19:12 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:19:12 - INFO - __main__ -   auc_score = 0.866\n",
      "04/25/2024 00:19:12 - INFO - __main__ -   test_f1 = 0.2192\n",
      "04/25/2024 00:19:12 - INFO - __main__ -   test_precision = 0.5872\n",
      "04/25/2024 00:19:12 - INFO - __main__ -   test_recall = 0.1347\n",
      " 99% 509/512 [27:25<00:04,  1.50s/it]04/25/2024 00:21:45 - WARNING - __main__ - epoch 3 step 510 loss 0.21895\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:23:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:23:35 - INFO - __main__ -   eval_f1 = 0.2572\n",
      "04/25/2024 00:23:35 - INFO - __main__ -   eval_precision = 0.6129\n",
      "04/25/2024 00:23:35 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:25:28 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:25:28 - INFO - __main__ -   auc_score = 0.8662\n",
      "04/25/2024 00:25:28 - INFO - __main__ -   test_f1 = 0.2355\n",
      "04/25/2024 00:25:28 - INFO - __main__ -   test_precision = 0.5547\n",
      "04/25/2024 00:25:28 - INFO - __main__ -   test_recall = 0.1495\n",
      "100% 512/512 [31:11<00:00,  3.66s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:31<10:18,  1.50s/it]04/25/2024 00:28:03 - WARNING - __main__ - epoch 4 step 102 loss 0.19457\n",
      "04/25/2024 00:29:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:29:53 - INFO - __main__ -   eval_f1 = 0.0453\n",
      "04/25/2024 00:29:53 - INFO - __main__ -   eval_precision = 0.5789\n",
      "04/25/2024 00:29:53 - INFO - __main__ -   eval_recall = 0.0236\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:31:43 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:31:43 - INFO - __main__ -   auc_score = 0.8655\n",
      "04/25/2024 00:31:43 - INFO - __main__ -   test_f1 = 0.0531\n",
      "04/25/2024 00:31:43 - INFO - __main__ -   test_precision = 0.8667\n",
      "04/25/2024 00:31:43 - INFO - __main__ -   test_recall = 0.0274\n",
      " 40% 203/512 [08:44<07:47,  1.51s/it]04/25/2024 00:34:16 - WARNING - __main__ - epoch 4 step 204 loss 0.20146\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:36:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:36:05 - INFO - __main__ -   eval_f1 = 0.2487\n",
      "04/25/2024 00:36:05 - INFO - __main__ -   eval_precision = 0.6083\n",
      "04/25/2024 00:36:05 - INFO - __main__ -   eval_recall = 0.1563\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:37:55 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:37:55 - INFO - __main__ -   auc_score = 0.865\n",
      "04/25/2024 00:37:55 - INFO - __main__ -   test_f1 = 0.2093\n",
      "04/25/2024 00:37:55 - INFO - __main__ -   test_precision = 0.5648\n",
      "04/25/2024 00:37:55 - INFO - __main__ -   test_recall = 0.1284\n",
      " 60% 305/512 [14:57<05:10,  1.50s/it]04/25/2024 00:40:28 - WARNING - __main__ - epoch 4 step 306 loss 0.20775\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:42:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:42:18 - INFO - __main__ -   eval_f1 = 0.225\n",
      "04/25/2024 00:42:18 - INFO - __main__ -   eval_precision = 0.6275\n",
      "04/25/2024 00:42:18 - INFO - __main__ -   eval_recall = 0.137\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:44:08 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:44:08 - INFO - __main__ -   auc_score = 0.865\n",
      "04/25/2024 00:44:08 - INFO - __main__ -   test_f1 = 0.2\n",
      "04/25/2024 00:44:08 - INFO - __main__ -   test_precision = 0.6\n",
      "04/25/2024 00:44:08 - INFO - __main__ -   test_recall = 0.12\n",
      " 79% 407/512 [21:09<02:38,  1.51s/it]04/25/2024 00:46:41 - WARNING - __main__ - epoch 4 step 408 loss 0.21142\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:48:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:48:31 - INFO - __main__ -   eval_f1 = 0.3091\n",
      "04/25/2024 00:48:31 - INFO - __main__ -   eval_precision = 0.5556\n",
      "04/25/2024 00:48:31 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:50:22 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:50:22 - INFO - __main__ -   auc_score = 0.8654\n",
      "04/25/2024 00:50:22 - INFO - __main__ -   test_f1 = 0.2799\n",
      "04/25/2024 00:50:22 - INFO - __main__ -   test_precision = 0.5357\n",
      "04/25/2024 00:50:22 - INFO - __main__ -   test_recall = 0.1895\n",
      " 99% 509/512 [27:24<00:04,  1.50s/it]04/25/2024 00:52:55 - WARNING - __main__ - epoch 4 step 510 loss 0.20354\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:54:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 00:54:45 - INFO - __main__ -   eval_f1 = 0.3338\n",
      "04/25/2024 00:54:45 - INFO - __main__ -   eval_precision = 0.5381\n",
      "04/25/2024 00:54:45 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 00:56:36 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 00:56:36 - INFO - __main__ -   auc_score = 0.8658\n",
      "04/25/2024 00:56:36 - INFO - __main__ -   test_f1 = 0.3113\n",
      "04/25/2024 00:56:36 - INFO - __main__ -   test_precision = 0.5146\n",
      "04/25/2024 00:56:36 - INFO - __main__ -   test_recall = 0.2232\n",
      "100% 512/512 [31:08<00:00,  3.65s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:31<10:19,  1.51s/it]04/25/2024 00:59:12 - WARNING - __main__ - epoch 5 step 102 loss 0.21947\n",
      "04/25/2024 01:01:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:01:01 - INFO - __main__ -   eval_f1 = 0.2676\n",
      "04/25/2024 01:01:01 - INFO - __main__ -   eval_precision = 0.6107\n",
      "04/25/2024 01:01:01 - INFO - __main__ -   eval_recall = 0.1713\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:02:51 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:02:51 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/25/2024 01:02:51 - INFO - __main__ -   test_f1 = 0.2393\n",
      "04/25/2024 01:02:51 - INFO - __main__ -   test_precision = 0.5407\n",
      "04/25/2024 01:02:51 - INFO - __main__ -   test_recall = 0.1537\n",
      " 40% 203/512 [08:44<07:45,  1.51s/it]04/25/2024 01:05:24 - WARNING - __main__ - epoch 5 step 204 loss 0.20673\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:07:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:07:14 - INFO - __main__ -   eval_f1 = 0.2083\n",
      "04/25/2024 01:07:14 - INFO - __main__ -   eval_precision = 0.6444\n",
      "04/25/2024 01:07:14 - INFO - __main__ -   eval_recall = 0.1242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:09:04 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:09:04 - INFO - __main__ -   auc_score = 0.8671\n",
      "04/25/2024 01:09:04 - INFO - __main__ -   test_f1 = 0.1891\n",
      "04/25/2024 01:09:04 - INFO - __main__ -   test_precision = 0.6933\n",
      "04/25/2024 01:09:04 - INFO - __main__ -   test_recall = 0.1095\n",
      " 60% 305/512 [14:56<05:11,  1.50s/it]04/25/2024 01:11:36 - WARNING - __main__ - epoch 5 step 306 loss 0.20224\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:13:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:13:26 - INFO - __main__ -   eval_f1 = 0.3065\n",
      "04/25/2024 01:13:26 - INFO - __main__ -   eval_precision = 0.6209\n",
      "04/25/2024 01:13:26 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:15:16 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:15:16 - INFO - __main__ -   auc_score = 0.8662\n",
      "04/25/2024 01:15:16 - INFO - __main__ -   test_f1 = 0.2613\n",
      "04/25/2024 01:15:16 - INFO - __main__ -   test_precision = 0.5586\n",
      "04/25/2024 01:15:16 - INFO - __main__ -   test_recall = 0.1705\n",
      " 79% 407/512 [21:09<02:38,  1.51s/it]04/25/2024 01:17:49 - WARNING - __main__ - epoch 5 step 408 loss 0.17896\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:19:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:19:39 - INFO - __main__ -   eval_f1 = 0.1974\n",
      "04/25/2024 01:19:39 - INFO - __main__ -   eval_precision = 0.675\n",
      "04/25/2024 01:19:39 - INFO - __main__ -   eval_recall = 0.1156\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:21:28 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:21:28 - INFO - __main__ -   auc_score = 0.8663\n",
      "04/25/2024 01:21:28 - INFO - __main__ -   test_f1 = 0.1567\n",
      "04/25/2024 01:21:28 - INFO - __main__ -   test_precision = 0.6885\n",
      "04/25/2024 01:21:28 - INFO - __main__ -   test_recall = 0.0884\n",
      " 99% 509/512 [27:21<00:04,  1.50s/it]04/25/2024 01:24:01 - WARNING - __main__ - epoch 5 step 510 loss 0.19294\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:25:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:25:51 - INFO - __main__ -   eval_f1 = 0.2246\n",
      "04/25/2024 01:25:51 - INFO - __main__ -   eval_precision = 0.6702\n",
      "04/25/2024 01:25:51 - INFO - __main__ -   eval_recall = 0.1349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:27:41 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:27:41 - INFO - __main__ -   auc_score = 0.8665\n",
      "04/25/2024 01:27:41 - INFO - __main__ -   test_f1 = 0.1942\n",
      "04/25/2024 01:27:41 - INFO - __main__ -   test_precision = 0.6667\n",
      "04/25/2024 01:27:41 - INFO - __main__ -   test_recall = 0.1137\n",
      "100% 512/512 [31:04<00:00,  3.64s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:19,  1.51s/it]04/25/2024 01:30:16 - WARNING - __main__ - epoch 6 step 102 loss 0.19675\n",
      "04/25/2024 01:32:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:32:06 - INFO - __main__ -   eval_f1 = 0.2301\n",
      "04/25/2024 01:32:06 - INFO - __main__ -   eval_precision = 0.6633\n",
      "04/25/2024 01:32:06 - INFO - __main__ -   eval_recall = 0.1392\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:33:56 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:33:56 - INFO - __main__ -   auc_score = 0.8665\n",
      "04/25/2024 01:33:56 - INFO - __main__ -   test_f1 = 0.1947\n",
      "04/25/2024 01:33:56 - INFO - __main__ -   test_precision = 0.6111\n",
      "04/25/2024 01:33:56 - INFO - __main__ -   test_recall = 0.1158\n",
      " 40% 203/512 [08:44<07:44,  1.50s/it]04/25/2024 01:36:29 - WARNING - __main__ - epoch 6 step 204 loss 0.19334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:38:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:38:18 - INFO - __main__ -   eval_f1 = 0.3368\n",
      "04/25/2024 01:38:18 - INFO - __main__ -   eval_precision = 0.5657\n",
      "04/25/2024 01:38:18 - INFO - __main__ -   eval_recall = 0.2398\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:40:10 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:40:10 - INFO - __main__ -   auc_score = 0.8673\n",
      "04/25/2024 01:40:10 - INFO - __main__ -   test_f1 = 0.3024\n",
      "04/25/2024 01:40:10 - INFO - __main__ -   test_precision = 0.5233\n",
      "04/25/2024 01:40:10 - INFO - __main__ -   test_recall = 0.2126\n",
      " 60% 305/512 [14:58<05:12,  1.51s/it]04/25/2024 01:42:43 - WARNING - __main__ - epoch 6 step 306 loss 0.19454\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:44:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:44:32 - INFO - __main__ -   eval_f1 = 0.3175\n",
      "04/25/2024 01:44:32 - INFO - __main__ -   eval_precision = 0.6135\n",
      "04/25/2024 01:44:32 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:46:22 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:46:22 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/25/2024 01:46:22 - INFO - __main__ -   test_f1 = 0.2875\n",
      "04/25/2024 01:46:22 - INFO - __main__ -   test_precision = 0.5759\n",
      "04/25/2024 01:46:22 - INFO - __main__ -   test_recall = 0.1916\n",
      " 79% 407/512 [21:10<02:38,  1.51s/it]04/25/2024 01:48:55 - WARNING - __main__ - epoch 6 step 408 loss 0.19916\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:50:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:50:45 - INFO - __main__ -   eval_f1 = 0.2959\n",
      "04/25/2024 01:50:45 - INFO - __main__ -   eval_precision = 0.6149\n",
      "04/25/2024 01:50:45 - INFO - __main__ -   eval_recall = 0.1949\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:52:34 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:52:34 - INFO - __main__ -   auc_score = 0.8677\n",
      "04/25/2024 01:52:34 - INFO - __main__ -   test_f1 = 0.2621\n",
      "04/25/2024 01:52:34 - INFO - __main__ -   test_precision = 0.5664\n",
      "04/25/2024 01:52:34 - INFO - __main__ -   test_recall = 0.1705\n",
      " 99% 509/512 [27:22<00:04,  1.51s/it]04/25/2024 01:55:07 - WARNING - __main__ - epoch 6 step 510 loss 0.19453\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:56:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 01:56:57 - INFO - __main__ -   eval_f1 = 0.2434\n",
      "04/25/2024 01:56:57 - INFO - __main__ -   eval_precision = 0.69\n",
      "04/25/2024 01:56:57 - INFO - __main__ -   eval_recall = 0.1478\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 01:58:47 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 01:58:47 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/25/2024 01:58:47 - INFO - __main__ -   test_f1 = 0.1947\n",
      "04/25/2024 01:58:47 - INFO - __main__ -   test_precision = 0.6111\n",
      "04/25/2024 01:58:47 - INFO - __main__ -   test_recall = 0.1158\n",
      "100% 512/512 [31:05<00:00,  3.64s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:31<10:17,  1.50s/it]04/25/2024 02:01:22 - WARNING - __main__ - epoch 7 step 102 loss 0.1974\n",
      "04/25/2024 02:03:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:03:12 - INFO - __main__ -   eval_f1 = 0.2862\n",
      "04/25/2024 02:03:12 - INFO - __main__ -   eval_precision = 0.617\n",
      "04/25/2024 02:03:12 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:05:02 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:05:02 - INFO - __main__ -   auc_score = 0.8673\n",
      "04/25/2024 02:05:02 - INFO - __main__ -   test_f1 = 0.2621\n",
      "04/25/2024 02:05:02 - INFO - __main__ -   test_precision = 0.5664\n",
      "04/25/2024 02:05:02 - INFO - __main__ -   test_recall = 0.1705\n",
      " 40% 203/512 [08:44<07:44,  1.50s/it]04/25/2024 02:07:34 - WARNING - __main__ - epoch 7 step 204 loss 0.19487\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:09:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:09:24 - INFO - __main__ -   eval_f1 = 0.2785\n",
      "04/25/2024 02:09:24 - INFO - __main__ -   eval_precision = 0.6434\n",
      "04/25/2024 02:09:24 - INFO - __main__ -   eval_recall = 0.1777\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:11:14 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:11:14 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/25/2024 02:11:14 - INFO - __main__ -   test_f1 = 0.2454\n",
      "04/25/2024 02:11:14 - INFO - __main__ -   test_precision = 0.5781\n",
      "04/25/2024 02:11:14 - INFO - __main__ -   test_recall = 0.1558\n",
      " 60% 305/512 [14:56<05:12,  1.51s/it]04/25/2024 02:13:47 - WARNING - __main__ - epoch 7 step 306 loss 0.18842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:15:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:15:37 - INFO - __main__ -   eval_f1 = 0.2421\n",
      "04/25/2024 02:15:37 - INFO - __main__ -   eval_precision = 0.6699\n",
      "04/25/2024 02:15:37 - INFO - __main__ -   eval_recall = 0.1478\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:17:24 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:17:24 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/25/2024 02:17:24 - INFO - __main__ -   test_f1 = 0.207\n",
      "04/25/2024 02:17:24 - INFO - __main__ -   test_precision = 0.6211\n",
      "04/25/2024 02:17:24 - INFO - __main__ -   test_recall = 0.1242\n",
      " 79% 407/512 [21:06<02:37,  1.50s/it]04/25/2024 02:19:57 - WARNING - __main__ - epoch 7 step 408 loss 0.19704\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:21:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:21:47 - INFO - __main__ -   eval_f1 = 0.3852\n",
      "04/25/2024 02:21:47 - INFO - __main__ -   eval_precision = 0.5321\n",
      "04/25/2024 02:21:47 - INFO - __main__ -   eval_recall = 0.3019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:23:38 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:23:38 - INFO - __main__ -   auc_score = 0.8678\n",
      "04/25/2024 02:23:38 - INFO - __main__ -   test_f1 = 0.3361\n",
      "04/25/2024 02:23:38 - INFO - __main__ -   test_precision = 0.5021\n",
      "04/25/2024 02:23:38 - INFO - __main__ -   test_recall = 0.2526\n",
      " 99% 509/512 [27:20<00:04,  1.50s/it]04/25/2024 02:26:11 - WARNING - __main__ - epoch 7 step 510 loss 0.18485\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:28:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:28:00 - INFO - __main__ -   eval_f1 = 0.3206\n",
      "04/25/2024 02:28:00 - INFO - __main__ -   eval_precision = 0.6196\n",
      "04/25/2024 02:28:00 - INFO - __main__ -   eval_recall = 0.2163\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:29:50 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:29:50 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 02:29:50 - INFO - __main__ -   test_f1 = 0.2799\n",
      "04/25/2024 02:29:50 - INFO - __main__ -   test_precision = 0.5528\n",
      "04/25/2024 02:29:50 - INFO - __main__ -   test_recall = 0.1874\n",
      "100% 512/512 [31:03<00:00,  3.64s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:19,  1.51s/it]04/25/2024 02:32:26 - WARNING - __main__ - epoch 8 step 102 loss 0.19034\n",
      "04/25/2024 02:34:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:34:15 - INFO - __main__ -   eval_f1 = 0.3779\n",
      "04/25/2024 02:34:15 - INFO - __main__ -   eval_precision = 0.531\n",
      "04/25/2024 02:34:15 - INFO - __main__ -   eval_recall = 0.2934\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:36:07 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:36:07 - INFO - __main__ -   auc_score = 0.8681\n",
      "04/25/2024 02:36:07 - INFO - __main__ -   test_f1 = 0.3385\n",
      "04/25/2024 02:36:07 - INFO - __main__ -   test_precision = 0.5042\n",
      "04/25/2024 02:36:07 - INFO - __main__ -   test_recall = 0.2547\n",
      " 40% 203/512 [08:45<07:46,  1.51s/it]04/25/2024 02:38:39 - WARNING - __main__ - epoch 8 step 204 loss 0.19564\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:40:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:40:29 - INFO - __main__ -   eval_f1 = 0.3887\n",
      "04/25/2024 02:40:29 - INFO - __main__ -   eval_precision = 0.5255\n",
      "04/25/2024 02:40:29 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:42:22 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:42:22 - INFO - __main__ -   auc_score = 0.868\n",
      "04/25/2024 02:42:22 - INFO - __main__ -   test_f1 = 0.3481\n",
      "04/25/2024 02:42:22 - INFO - __main__ -   test_precision = 0.506\n",
      "04/25/2024 02:42:22 - INFO - __main__ -   test_recall = 0.2653\n",
      " 60% 305/512 [15:01<05:11,  1.51s/it]04/25/2024 02:44:55 - WARNING - __main__ - epoch 8 step 306 loss 0.18613\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:46:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:46:45 - INFO - __main__ -   eval_f1 = 0.3444\n",
      "04/25/2024 02:46:45 - INFO - __main__ -   eval_precision = 0.5846\n",
      "04/25/2024 02:46:45 - INFO - __main__ -   eval_recall = 0.2441\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:48:36 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:48:36 - INFO - __main__ -   auc_score = 0.8677\n",
      "04/25/2024 02:48:36 - INFO - __main__ -   test_f1 = 0.3024\n",
      "04/25/2024 02:48:36 - INFO - __main__ -   test_precision = 0.5233\n",
      "04/25/2024 02:48:36 - INFO - __main__ -   test_recall = 0.2126\n",
      " 79% 407/512 [21:15<02:38,  1.51s/it]04/25/2024 02:51:09 - WARNING - __main__ - epoch 8 step 408 loss 0.1811\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:52:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:52:59 - INFO - __main__ -   eval_f1 = 0.2871\n",
      "04/25/2024 02:52:59 - INFO - __main__ -   eval_precision = 0.6259\n",
      "04/25/2024 02:52:59 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:54:50 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 02:54:50 - INFO - __main__ -   auc_score = 0.8674\n",
      "04/25/2024 02:54:50 - INFO - __main__ -   test_f1 = 0.2553\n",
      "04/25/2024 02:54:50 - INFO - __main__ -   test_precision = 0.5735\n",
      "04/25/2024 02:54:50 - INFO - __main__ -   test_recall = 0.1642\n",
      " 99% 509/512 [27:29<00:04,  1.51s/it]04/25/2024 02:57:23 - WARNING - __main__ - epoch 8 step 510 loss 0.19492\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 02:59:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 02:59:13 - INFO - __main__ -   eval_f1 = 0.3175\n",
      "04/25/2024 02:59:13 - INFO - __main__ -   eval_precision = 0.6135\n",
      "04/25/2024 02:59:13 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:01:04 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:01:04 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 03:01:04 - INFO - __main__ -   test_f1 = 0.2826\n",
      "04/25/2024 03:01:04 - INFO - __main__ -   test_precision = 0.5556\n",
      "04/25/2024 03:01:04 - INFO - __main__ -   test_recall = 0.1895\n",
      "100% 512/512 [31:14<00:00,  3.66s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [02:32<10:22,  1.51s/it]04/25/2024 03:03:40 - WARNING - __main__ - epoch 9 step 102 loss 0.19841\n",
      "04/25/2024 03:05:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 03:05:30 - INFO - __main__ -   eval_f1 = 0.3323\n",
      "04/25/2024 03:05:30 - INFO - __main__ -   eval_precision = 0.5902\n",
      "04/25/2024 03:05:30 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:07:21 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:07:21 - INFO - __main__ -   auc_score = 0.8677\n",
      "04/25/2024 03:07:21 - INFO - __main__ -   test_f1 = 0.3072\n",
      "04/25/2024 03:07:21 - INFO - __main__ -   test_precision = 0.5397\n",
      "04/25/2024 03:07:21 - INFO - __main__ -   test_recall = 0.2147\n",
      " 40% 203/512 [08:46<07:44,  1.50s/it]04/25/2024 03:09:54 - WARNING - __main__ - epoch 9 step 204 loss 0.18558\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:11:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 03:11:43 - INFO - __main__ -   eval_f1 = 0.3185\n",
      "04/25/2024 03:11:43 - INFO - __main__ -   eval_precision = 0.6211\n",
      "04/25/2024 03:11:43 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:13:35 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:13:35 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 03:13:35 - INFO - __main__ -   test_f1 = 0.2785\n",
      "04/25/2024 03:13:35 - INFO - __main__ -   test_precision = 0.5605\n",
      "04/25/2024 03:13:35 - INFO - __main__ -   test_recall = 0.1853\n",
      " 60% 305/512 [15:00<05:10,  1.50s/it]04/25/2024 03:16:08 - WARNING - __main__ - epoch 9 step 306 loss 0.18924\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:17:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 03:17:57 - INFO - __main__ -   eval_f1 = 0.3302\n",
      "04/25/2024 03:17:57 - INFO - __main__ -   eval_precision = 0.6057\n",
      "04/25/2024 03:17:57 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:19:49 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:19:49 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 03:19:49 - INFO - __main__ -   test_f1 = 0.3018\n",
      "04/25/2024 03:19:49 - INFO - __main__ -   test_precision = 0.547\n",
      "04/25/2024 03:19:49 - INFO - __main__ -   test_recall = 0.2084\n",
      " 79% 407/512 [21:13<02:37,  1.50s/it]04/25/2024 03:22:21 - WARNING - __main__ - epoch 9 step 408 loss 0.18746\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:24:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 03:24:11 - INFO - __main__ -   eval_f1 = 0.318\n",
      "04/25/2024 03:24:11 - INFO - __main__ -   eval_precision = 0.6173\n",
      "04/25/2024 03:24:11 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:26:00 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:26:00 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 03:26:00 - INFO - __main__ -   test_f1 = 0.2772\n",
      "04/25/2024 03:26:00 - INFO - __main__ -   test_precision = 0.55\n",
      "04/25/2024 03:26:00 - INFO - __main__ -   test_recall = 0.1853\n",
      " 99% 509/512 [27:25<00:04,  1.50s/it]04/25/2024 03:28:33 - WARNING - __main__ - epoch 9 step 510 loss 0.18205\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:30:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/25/2024 03:30:23 - INFO - __main__ -   eval_f1 = 0.3185\n",
      "04/25/2024 03:30:23 - INFO - __main__ -   eval_precision = 0.6211\n",
      "04/25/2024 03:30:23 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:32:14 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:32:14 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/25/2024 03:32:14 - INFO - __main__ -   test_f1 = 0.2749\n",
      "04/25/2024 03:32:14 - INFO - __main__ -   test_precision = 0.5506\n",
      "04/25/2024 03:32:14 - INFO - __main__ -   test_recall = 0.1832\n",
      "100% 512/512 [31:09<00:00,  3.65s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/unixcoder/single/checkpoints --pretrained_model codet5 --learning_rate 2e-5 --epochs 10 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DCqKwQbUbSJ",
    "outputId": "e2bb9b03-46ef-4a21-9071-382a2756d5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/25/2024 03:35:44 - INFO - __main__ - Successfully load epoch 8's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/25/2024 03:37:35 - INFO - __main__ - ***** Test results *****\n",
      "04/25/2024 03:37:35 - INFO - __main__ -   auc_score = 0.8687\n",
      "04/25/2024 03:37:35 - INFO - __main__ -   test_f1 = 0.3686\n",
      "04/25/2024 03:37:35 - INFO - __main__ -   test_precision = 0.5171\n",
      "04/25/2024 03:37:35 - INFO - __main__ -   test_recall = 0.2863\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/unixcoder/single/checkpoints --pretrained_model codet5 --learning_rate 2e-5 --epochs 10 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvidhyExP8cm"
   },
   "source": [
    "### codet5p-220m-bimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leR4hSYoLh_r"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1y4x9Riuk51",
    "outputId": "96aa5a25-58be-40f5-bad3-cbaf4c3235ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "config.json: 100% 1.07k/1.07k [00:00<00:00, 4.83MB/s]\n",
      "You are using a model of type codet5p_bimodal to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "tokenizer_config.json: 100% 1.34k/1.34k [00:00<00:00, 8.19MB/s]\n",
      "vocab.json: 100% 511k/511k [00:00<00:00, 2.07MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 92.8MB/s]\n",
      "added_tokens.json: 100% 59.0/59.0 [00:00<00:00, 375kB/s]\n",
      "special_tokens_map.json: 100% 1.03k/1.03k [00:00<00:00, 6.50MB/s]\n",
      "tokenizer.json: 100% 1.37M/1.37M [00:00<00:00, 1.90MB/s]\n",
      "pytorch_model.bin: 100% 892M/892M [00:57<00:00, 15.6MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:12<04:48,  1.42it/s]04/26/2024 00:49:50 - WARNING - __main__ - epoch 0 step 102 loss 0.28796\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:50:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 00:50:28 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 00:50:28 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 00:50:28 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:51:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 00:51:06 - INFO - __main__ -   auc_score = 0.8395\n",
      "04/26/2024 00:51:06 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 00:51:06 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 00:51:06 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [03:40<03:36,  1.43it/s]04/26/2024 00:52:17 - WARNING - __main__ - epoch 0 step 204 loss 0.25055\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:52:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 00:52:56 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 00:52:56 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 00:52:56 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:53:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 00:53:34 - INFO - __main__ -   auc_score = 0.8532\n",
      "04/26/2024 00:53:34 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 00:53:34 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 00:53:34 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [06:08<02:25,  1.42it/s]04/26/2024 00:54:45 - WARNING - __main__ - epoch 0 step 306 loss 0.21819\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:55:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 00:55:24 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 00:55:24 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 00:55:24 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 00:56:02 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 00:56:02 - INFO - __main__ -   auc_score = 0.8676\n",
      "04/26/2024 00:56:02 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 00:56:02 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 00:56:02 - INFO - __main__ -   test_recall = 0.0\n",
      " 79% 407/512 [08:36<01:13,  1.43it/s]04/26/2024 00:57:13 - WARNING - __main__ - epoch 0 step 408 loss 0.21498\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 00:57:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 00:57:52 - INFO - __main__ -   eval_f1 = 0.1731\n",
      "04/26/2024 00:57:52 - INFO - __main__ -   eval_precision = 0.6184\n",
      "04/26/2024 00:57:52 - INFO - __main__ -   eval_recall = 0.1006\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 00:58:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 00:58:34 - INFO - __main__ -   auc_score = 0.8686\n",
      "04/26/2024 00:58:34 - INFO - __main__ -   test_f1 = 0.1103\n",
      "04/26/2024 00:58:34 - INFO - __main__ -   test_precision = 0.5686\n",
      "04/26/2024 00:58:34 - INFO - __main__ -   test_recall = 0.0611\n",
      " 99% 509/512 [11:07<00:02,  1.43it/s]04/26/2024 00:59:45 - WARNING - __main__ - epoch 0 step 510 loss 0.21535\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:00:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:00:23 - INFO - __main__ -   eval_f1 = 0.1676\n",
      "04/26/2024 01:00:23 - INFO - __main__ -   eval_precision = 0.6429\n",
      "04/26/2024 01:00:23 - INFO - __main__ -   eval_recall = 0.0964\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:01:02 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:01:02 - INFO - __main__ -   auc_score = 0.8729\n",
      "04/26/2024 01:01:02 - INFO - __main__ -   test_f1 = 0.1351\n",
      "04/26/2024 01:01:02 - INFO - __main__ -   test_precision = 0.6207\n",
      "04/26/2024 01:01:02 - INFO - __main__ -   test_recall = 0.0758\n",
      "100% 512/512 [12:26<00:00,  1.46s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.42it/s]04/26/2024 01:02:14 - WARNING - __main__ - epoch 1 step 102 loss 0.18041\n",
      "04/26/2024 01:02:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:02:52 - INFO - __main__ -   eval_f1 = 0.2975\n",
      "04/26/2024 01:02:52 - INFO - __main__ -   eval_precision = 0.5697\n",
      "04/26/2024 01:02:52 - INFO - __main__ -   eval_recall = 0.2013\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:03:37 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:03:37 - INFO - __main__ -   auc_score = 0.8735\n",
      "04/26/2024 01:03:37 - INFO - __main__ -   test_f1 = 0.2839\n",
      "04/26/2024 01:03:37 - INFO - __main__ -   test_precision = 0.566\n",
      "04/26/2024 01:03:37 - INFO - __main__ -   test_recall = 0.1895\n",
      " 40% 203/512 [03:44<03:36,  1.42it/s]04/26/2024 01:04:48 - WARNING - __main__ - epoch 1 step 204 loss 0.19965\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:05:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:05:26 - INFO - __main__ -   eval_f1 = 0.3476\n",
      "04/26/2024 01:05:26 - INFO - __main__ -   eval_precision = 0.4884\n",
      "04/26/2024 01:05:26 - INFO - __main__ -   eval_recall = 0.2698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:06:07 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:06:07 - INFO - __main__ -   auc_score = 0.8647\n",
      "04/26/2024 01:06:07 - INFO - __main__ -   test_f1 = 0.3319\n",
      "04/26/2024 01:06:07 - INFO - __main__ -   test_precision = 0.5\n",
      "04/26/2024 01:06:07 - INFO - __main__ -   test_recall = 0.2484\n",
      " 60% 305/512 [06:15<02:25,  1.42it/s]04/26/2024 01:07:19 - WARNING - __main__ - epoch 1 step 306 loss 0.18272\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:07:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:07:57 - INFO - __main__ -   eval_f1 = 0.2389\n",
      "04/26/2024 01:07:57 - INFO - __main__ -   eval_precision = 0.5882\n",
      "04/26/2024 01:07:57 - INFO - __main__ -   eval_recall = 0.1499\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:08:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:08:35 - INFO - __main__ -   auc_score = 0.8705\n",
      "04/26/2024 01:08:35 - INFO - __main__ -   test_f1 = 0.2329\n",
      "04/26/2024 01:08:35 - INFO - __main__ -   test_precision = 0.6239\n",
      "04/26/2024 01:08:35 - INFO - __main__ -   test_recall = 0.1432\n",
      " 79% 407/512 [08:43<01:13,  1.42it/s]04/26/2024 01:09:46 - WARNING - __main__ - epoch 1 step 408 loss 0.18326\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:10:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:10:25 - INFO - __main__ -   eval_f1 = 0.2262\n",
      "04/26/2024 01:10:25 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/26/2024 01:10:25 - INFO - __main__ -   eval_recall = 0.1349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:11:03 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:11:03 - INFO - __main__ -   auc_score = 0.8693\n",
      "04/26/2024 01:11:03 - INFO - __main__ -   test_f1 = 0.1809\n",
      "04/26/2024 01:11:03 - INFO - __main__ -   test_precision = 0.573\n",
      "04/26/2024 01:11:03 - INFO - __main__ -   test_recall = 0.1074\n",
      " 99% 509/512 [11:11<00:02,  1.43it/s]04/26/2024 01:12:14 - WARNING - __main__ - epoch 1 step 510 loss 0.18714\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:12:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:12:53 - INFO - __main__ -   eval_f1 = 0.371\n",
      "04/26/2024 01:12:53 - INFO - __main__ -   eval_precision = 0.4982\n",
      "04/26/2024 01:12:53 - INFO - __main__ -   eval_recall = 0.2955\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:13:37 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:13:37 - INFO - __main__ -   auc_score = 0.8674\n",
      "04/26/2024 01:13:37 - INFO - __main__ -   test_f1 = 0.3553\n",
      "04/26/2024 01:13:37 - INFO - __main__ -   test_precision = 0.4737\n",
      "04/26/2024 01:13:37 - INFO - __main__ -   test_recall = 0.2842\n",
      "100% 512/512 [12:35<00:00,  1.48s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.42it/s]04/26/2024 01:14:50 - WARNING - __main__ - epoch 2 step 102 loss 0.13239\n",
      "04/26/2024 01:15:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:15:28 - INFO - __main__ -   eval_f1 = 0.3439\n",
      "04/26/2024 01:15:28 - INFO - __main__ -   eval_precision = 0.4808\n",
      "04/26/2024 01:15:28 - INFO - __main__ -   eval_recall = 0.2677\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:16:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:16:06 - INFO - __main__ -   auc_score = 0.8654\n",
      "04/26/2024 01:16:06 - INFO - __main__ -   test_f1 = 0.3081\n",
      "04/26/2024 01:16:06 - INFO - __main__ -   test_precision = 0.4302\n",
      "04/26/2024 01:16:06 - INFO - __main__ -   test_recall = 0.24\n",
      " 40% 203/512 [03:38<03:36,  1.42it/s]04/26/2024 01:17:17 - WARNING - __main__ - epoch 2 step 204 loss 0.12261\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:17:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:17:56 - INFO - __main__ -   eval_f1 = 0.4054\n",
      "04/26/2024 01:17:56 - INFO - __main__ -   eval_precision = 0.4716\n",
      "04/26/2024 01:17:56 - INFO - __main__ -   eval_recall = 0.3555\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:18:37 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:18:37 - INFO - __main__ -   auc_score = 0.8615\n",
      "04/26/2024 01:18:37 - INFO - __main__ -   test_f1 = 0.3492\n",
      "04/26/2024 01:18:37 - INFO - __main__ -   test_precision = 0.4157\n",
      "04/26/2024 01:18:37 - INFO - __main__ -   test_recall = 0.3011\n",
      " 60% 305/512 [06:09<02:25,  1.43it/s]04/26/2024 01:19:48 - WARNING - __main__ - epoch 2 step 306 loss 0.13539\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:20:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:20:27 - INFO - __main__ -   eval_f1 = 0.357\n",
      "04/26/2024 01:20:27 - INFO - __main__ -   eval_precision = 0.4784\n",
      "04/26/2024 01:20:27 - INFO - __main__ -   eval_recall = 0.2848\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:21:05 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:21:05 - INFO - __main__ -   auc_score = 0.8595\n",
      "04/26/2024 01:21:05 - INFO - __main__ -   test_f1 = 0.3151\n",
      "04/26/2024 01:21:05 - INFO - __main__ -   test_precision = 0.413\n",
      "04/26/2024 01:21:05 - INFO - __main__ -   test_recall = 0.2547\n",
      " 79% 407/512 [08:37<01:13,  1.43it/s]04/26/2024 01:22:16 - WARNING - __main__ - epoch 2 step 408 loss 0.13633\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:22:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:22:55 - INFO - __main__ -   eval_f1 = 0.3435\n",
      "04/26/2024 01:22:55 - INFO - __main__ -   eval_precision = 0.4863\n",
      "04/26/2024 01:22:55 - INFO - __main__ -   eval_recall = 0.2655\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:23:33 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:23:33 - INFO - __main__ -   auc_score = 0.8601\n",
      "04/26/2024 01:23:33 - INFO - __main__ -   test_f1 = 0.3003\n",
      "04/26/2024 01:23:33 - INFO - __main__ -   test_precision = 0.4589\n",
      "04/26/2024 01:23:33 - INFO - __main__ -   test_recall = 0.2232\n",
      " 99% 509/512 [11:05<00:02,  1.42it/s]04/26/2024 01:24:44 - WARNING - __main__ - epoch 2 step 510 loss 0.14326\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:25:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:25:23 - INFO - __main__ -   eval_f1 = 0.3047\n",
      "04/26/2024 01:25:23 - INFO - __main__ -   eval_precision = 0.4928\n",
      "04/26/2024 01:25:23 - INFO - __main__ -   eval_recall = 0.2206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:26:01 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:26:01 - INFO - __main__ -   auc_score = 0.8492\n",
      "04/26/2024 01:26:01 - INFO - __main__ -   test_f1 = 0.2584\n",
      "04/26/2024 01:26:01 - INFO - __main__ -   test_precision = 0.4272\n",
      "04/26/2024 01:26:01 - INFO - __main__ -   test_recall = 0.1853\n",
      "100% 512/512 [12:23<00:00,  1.45s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.42it/s]04/26/2024 01:27:13 - WARNING - __main__ - epoch 3 step 102 loss 0.07904\n",
      "04/26/2024 01:27:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:27:52 - INFO - __main__ -   eval_f1 = 0.2942\n",
      "04/26/2024 01:27:52 - INFO - __main__ -   eval_precision = 0.4806\n",
      "04/26/2024 01:27:52 - INFO - __main__ -   eval_recall = 0.212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:28:30 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:28:30 - INFO - __main__ -   auc_score = 0.8499\n",
      "04/26/2024 01:28:30 - INFO - __main__ -   test_f1 = 0.2558\n",
      "04/26/2024 01:28:30 - INFO - __main__ -   test_precision = 0.4131\n",
      "04/26/2024 01:28:30 - INFO - __main__ -   test_recall = 0.1853\n",
      " 40% 203/512 [03:38<03:36,  1.43it/s]04/26/2024 01:29:41 - WARNING - __main__ - epoch 3 step 204 loss 0.07938\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:30:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:30:20 - INFO - __main__ -   eval_f1 = 0.3627\n",
      "04/26/2024 01:30:20 - INFO - __main__ -   eval_precision = 0.4404\n",
      "04/26/2024 01:30:20 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:30:58 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:30:58 - INFO - __main__ -   auc_score = 0.8532\n",
      "04/26/2024 01:30:58 - INFO - __main__ -   test_f1 = 0.3379\n",
      "04/26/2024 01:30:58 - INFO - __main__ -   test_precision = 0.4121\n",
      "04/26/2024 01:30:58 - INFO - __main__ -   test_recall = 0.2863\n",
      " 60% 305/512 [06:06<02:25,  1.43it/s]04/26/2024 01:32:09 - WARNING - __main__ - epoch 3 step 306 loss 0.0757\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:32:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:32:47 - INFO - __main__ -   eval_f1 = 0.382\n",
      "04/26/2024 01:32:47 - INFO - __main__ -   eval_precision = 0.4423\n",
      "04/26/2024 01:32:47 - INFO - __main__ -   eval_recall = 0.3362\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:33:26 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:33:26 - INFO - __main__ -   auc_score = 0.8551\n",
      "04/26/2024 01:33:26 - INFO - __main__ -   test_f1 = 0.3554\n",
      "04/26/2024 01:33:26 - INFO - __main__ -   test_precision = 0.4383\n",
      "04/26/2024 01:33:26 - INFO - __main__ -   test_recall = 0.2989\n",
      " 79% 407/512 [08:34<01:13,  1.42it/s]04/26/2024 01:34:37 - WARNING - __main__ - epoch 3 step 408 loss 0.08839\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:35:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:35:15 - INFO - __main__ -   eval_f1 = 0.3131\n",
      "04/26/2024 01:35:15 - INFO - __main__ -   eval_precision = 0.5048\n",
      "04/26/2024 01:35:15 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:35:54 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:35:54 - INFO - __main__ -   auc_score = 0.8507\n",
      "04/26/2024 01:35:54 - INFO - __main__ -   test_f1 = 0.2629\n",
      "04/26/2024 01:35:54 - INFO - __main__ -   test_precision = 0.4406\n",
      "04/26/2024 01:35:54 - INFO - __main__ -   test_recall = 0.1874\n",
      " 99% 509/512 [11:02<00:02,  1.42it/s]04/26/2024 01:37:05 - WARNING - __main__ - epoch 3 step 510 loss 0.07612\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:37:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:37:43 - INFO - __main__ -   eval_f1 = 0.3644\n",
      "04/26/2024 01:37:43 - INFO - __main__ -   eval_precision = 0.4807\n",
      "04/26/2024 01:37:43 - INFO - __main__ -   eval_recall = 0.2934\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:38:22 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:38:22 - INFO - __main__ -   auc_score = 0.8453\n",
      "04/26/2024 01:38:22 - INFO - __main__ -   test_f1 = 0.3193\n",
      "04/26/2024 01:38:22 - INFO - __main__ -   test_precision = 0.4276\n",
      "04/26/2024 01:38:22 - INFO - __main__ -   test_recall = 0.2547\n",
      "100% 512/512 [12:20<00:00,  1.45s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.42it/s]04/26/2024 01:39:34 - WARNING - __main__ - epoch 4 step 102 loss 0.04001\n",
      "04/26/2024 01:40:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:40:12 - INFO - __main__ -   eval_f1 = 0.3234\n",
      "04/26/2024 01:40:12 - INFO - __main__ -   eval_precision = 0.4424\n",
      "04/26/2024 01:40:12 - INFO - __main__ -   eval_recall = 0.2548\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:40:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:40:51 - INFO - __main__ -   auc_score = 0.84\n",
      "04/26/2024 01:40:51 - INFO - __main__ -   test_f1 = 0.2807\n",
      "04/26/2024 01:40:51 - INFO - __main__ -   test_precision = 0.391\n",
      "04/26/2024 01:40:51 - INFO - __main__ -   test_recall = 0.2189\n",
      " 40% 203/512 [03:38<03:36,  1.43it/s]04/26/2024 01:42:02 - WARNING - __main__ - epoch 4 step 204 loss 0.05456\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:42:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:42:40 - INFO - __main__ -   eval_f1 = 0.264\n",
      "04/26/2024 01:42:40 - INFO - __main__ -   eval_precision = 0.4802\n",
      "04/26/2024 01:42:40 - INFO - __main__ -   eval_recall = 0.182\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:43:19 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:43:19 - INFO - __main__ -   auc_score = 0.83\n",
      "04/26/2024 01:43:19 - INFO - __main__ -   test_f1 = 0.2261\n",
      "04/26/2024 01:43:19 - INFO - __main__ -   test_precision = 0.4444\n",
      "04/26/2024 01:43:19 - INFO - __main__ -   test_recall = 0.1516\n",
      " 60% 305/512 [06:06<02:25,  1.42it/s]04/26/2024 01:44:30 - WARNING - __main__ - epoch 4 step 306 loss 0.043\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:45:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:45:08 - INFO - __main__ -   eval_f1 = 0.3172\n",
      "04/26/2024 01:45:08 - INFO - __main__ -   eval_precision = 0.4457\n",
      "04/26/2024 01:45:08 - INFO - __main__ -   eval_recall = 0.2463\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:45:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:45:46 - INFO - __main__ -   auc_score = 0.8419\n",
      "04/26/2024 01:45:46 - INFO - __main__ -   test_f1 = 0.2926\n",
      "04/26/2024 01:45:46 - INFO - __main__ -   test_precision = 0.4037\n",
      "04/26/2024 01:45:46 - INFO - __main__ -   test_recall = 0.2295\n",
      " 79% 407/512 [08:34<01:13,  1.42it/s]04/26/2024 01:46:58 - WARNING - __main__ - epoch 4 step 408 loss 0.04296\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:47:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:47:36 - INFO - __main__ -   eval_f1 = 0.279\n",
      "04/26/2024 01:47:36 - INFO - __main__ -   eval_precision = 0.4439\n",
      "04/26/2024 01:47:36 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:48:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:48:14 - INFO - __main__ -   auc_score = 0.8253\n",
      "04/26/2024 01:48:14 - INFO - __main__ -   test_f1 = 0.2518\n",
      "04/26/2024 01:48:14 - INFO - __main__ -   test_precision = 0.4028\n",
      "04/26/2024 01:48:14 - INFO - __main__ -   test_recall = 0.1832\n",
      " 99% 509/512 [11:02<00:02,  1.42it/s]04/26/2024 01:49:26 - WARNING - __main__ - epoch 4 step 510 loss 0.04535\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:50:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:50:04 - INFO - __main__ -   eval_f1 = 0.3029\n",
      "04/26/2024 01:50:04 - INFO - __main__ -   eval_precision = 0.4549\n",
      "04/26/2024 01:50:04 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:50:42 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:50:42 - INFO - __main__ -   auc_score = 0.8279\n",
      "04/26/2024 01:50:42 - INFO - __main__ -   test_f1 = 0.2723\n",
      "04/26/2024 01:50:42 - INFO - __main__ -   test_precision = 0.4174\n",
      "04/26/2024 01:50:42 - INFO - __main__ -   test_recall = 0.2021\n",
      "100% 512/512 [12:20<00:00,  1.45s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.43it/s]04/26/2024 01:51:55 - WARNING - __main__ - epoch 5 step 102 loss 0.02372\n",
      "04/26/2024 01:52:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:52:33 - INFO - __main__ -   eval_f1 = 0.2366\n",
      "04/26/2024 01:52:33 - INFO - __main__ -   eval_precision = 0.4867\n",
      "04/26/2024 01:52:33 - INFO - __main__ -   eval_recall = 0.1563\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:53:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:53:11 - INFO - __main__ -   auc_score = 0.8138\n",
      "04/26/2024 01:53:11 - INFO - __main__ -   test_f1 = 0.237\n",
      "04/26/2024 01:53:11 - INFO - __main__ -   test_precision = 0.4747\n",
      "04/26/2024 01:53:11 - INFO - __main__ -   test_recall = 0.1579\n",
      " 40% 203/512 [03:38<03:36,  1.43it/s]04/26/2024 01:54:23 - WARNING - __main__ - epoch 5 step 204 loss 0.02201\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:55:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:55:01 - INFO - __main__ -   eval_f1 = 0.2441\n",
      "04/26/2024 01:55:01 - INFO - __main__ -   eval_precision = 0.4695\n",
      "04/26/2024 01:55:01 - INFO - __main__ -   eval_recall = 0.1649\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:55:39 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:55:39 - INFO - __main__ -   auc_score = 0.8163\n",
      "04/26/2024 01:55:39 - INFO - __main__ -   test_f1 = 0.2496\n",
      "04/26/2024 01:55:39 - INFO - __main__ -   test_precision = 0.4505\n",
      "04/26/2024 01:55:39 - INFO - __main__ -   test_recall = 0.1726\n",
      " 60% 305/512 [06:06<02:25,  1.42it/s]04/26/2024 01:56:50 - WARNING - __main__ - epoch 5 step 306 loss 0.03491\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:57:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:57:29 - INFO - __main__ -   eval_f1 = 0.2613\n",
      "04/26/2024 01:57:29 - INFO - __main__ -   eval_precision = 0.4773\n",
      "04/26/2024 01:57:29 - INFO - __main__ -   eval_recall = 0.1799\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:58:07 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 01:58:07 - INFO - __main__ -   auc_score = 0.8133\n",
      "04/26/2024 01:58:07 - INFO - __main__ -   test_f1 = 0.2421\n",
      "04/26/2024 01:58:07 - INFO - __main__ -   test_precision = 0.4301\n",
      "04/26/2024 01:58:07 - INFO - __main__ -   test_recall = 0.1684\n",
      " 79% 407/512 [08:34<01:13,  1.42it/s]04/26/2024 01:59:18 - WARNING - __main__ - epoch 5 step 408 loss 0.02203\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 01:59:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 01:59:57 - INFO - __main__ -   eval_f1 = 0.3174\n",
      "04/26/2024 01:59:57 - INFO - __main__ -   eval_precision = 0.4612\n",
      "04/26/2024 01:59:57 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:00:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:00:35 - INFO - __main__ -   auc_score = 0.8242\n",
      "04/26/2024 02:00:35 - INFO - __main__ -   test_f1 = 0.2806\n",
      "04/26/2024 02:00:35 - INFO - __main__ -   test_precision = 0.4048\n",
      "04/26/2024 02:00:35 - INFO - __main__ -   test_recall = 0.2147\n",
      " 99% 509/512 [11:02<00:02,  1.42it/s]04/26/2024 02:01:46 - WARNING - __main__ - epoch 5 step 510 loss 0.02654\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:02:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:02:25 - INFO - __main__ -   eval_f1 = 0.3491\n",
      "04/26/2024 02:02:25 - INFO - __main__ -   eval_precision = 0.4179\n",
      "04/26/2024 02:02:25 - INFO - __main__ -   eval_recall = 0.2998\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:03:03 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:03:03 - INFO - __main__ -   auc_score = 0.8186\n",
      "04/26/2024 02:03:03 - INFO - __main__ -   test_f1 = 0.3398\n",
      "04/26/2024 02:03:03 - INFO - __main__ -   test_precision = 0.3972\n",
      "04/26/2024 02:03:03 - INFO - __main__ -   test_recall = 0.2968\n",
      "100% 512/512 [12:20<00:00,  1.45s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.43it/s]04/26/2024 02:04:15 - WARNING - __main__ - epoch 6 step 102 loss 0.01406\n",
      "04/26/2024 02:04:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:04:54 - INFO - __main__ -   eval_f1 = 0.3284\n",
      "04/26/2024 02:04:54 - INFO - __main__ -   eval_precision = 0.4362\n",
      "04/26/2024 02:04:54 - INFO - __main__ -   eval_recall = 0.2634\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:05:32 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:05:32 - INFO - __main__ -   auc_score = 0.8152\n",
      "04/26/2024 02:05:32 - INFO - __main__ -   test_f1 = 0.3177\n",
      "04/26/2024 02:05:32 - INFO - __main__ -   test_precision = 0.4006\n",
      "04/26/2024 02:05:32 - INFO - __main__ -   test_recall = 0.2632\n",
      " 40% 203/512 [03:38<03:36,  1.43it/s]04/26/2024 02:06:43 - WARNING - __main__ - epoch 6 step 204 loss 0.01218\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:07:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:07:22 - INFO - __main__ -   eval_f1 = 0.2135\n",
      "04/26/2024 02:07:22 - INFO - __main__ -   eval_precision = 0.4577\n",
      "04/26/2024 02:07:22 - INFO - __main__ -   eval_recall = 0.1392\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:08:00 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:08:00 - INFO - __main__ -   auc_score = 0.805\n",
      "04/26/2024 02:08:00 - INFO - __main__ -   test_f1 = 0.2212\n",
      "04/26/2024 02:08:00 - INFO - __main__ -   test_precision = 0.443\n",
      "04/26/2024 02:08:00 - INFO - __main__ -   test_recall = 0.1474\n",
      " 60% 305/512 [06:06<02:25,  1.42it/s]04/26/2024 02:09:11 - WARNING - __main__ - epoch 6 step 306 loss 0.01801\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:09:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:09:50 - INFO - __main__ -   eval_f1 = 0.2305\n",
      "04/26/2024 02:09:50 - INFO - __main__ -   eval_precision = 0.4229\n",
      "04/26/2024 02:09:50 - INFO - __main__ -   eval_recall = 0.1585\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:10:28 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:10:28 - INFO - __main__ -   auc_score = 0.7906\n",
      "04/26/2024 02:10:28 - INFO - __main__ -   test_f1 = 0.2385\n",
      "04/26/2024 02:10:28 - INFO - __main__ -   test_precision = 0.4358\n",
      "04/26/2024 02:10:28 - INFO - __main__ -   test_recall = 0.1642\n",
      " 79% 407/512 [08:34<01:13,  1.43it/s]04/26/2024 02:11:39 - WARNING - __main__ - epoch 6 step 408 loss 0.02331\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:12:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:12:17 - INFO - __main__ -   eval_f1 = 0.3071\n",
      "04/26/2024 02:12:17 - INFO - __main__ -   eval_precision = 0.4336\n",
      "04/26/2024 02:12:17 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:12:56 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:12:56 - INFO - __main__ -   auc_score = 0.7888\n",
      "04/26/2024 02:12:56 - INFO - __main__ -   test_f1 = 0.2819\n",
      "04/26/2024 02:12:56 - INFO - __main__ -   test_precision = 0.3827\n",
      "04/26/2024 02:12:56 - INFO - __main__ -   test_recall = 0.2232\n",
      " 99% 509/512 [11:02<00:02,  1.42it/s]04/26/2024 02:14:07 - WARNING - __main__ - epoch 6 step 510 loss 0.0159\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:14:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:14:45 - INFO - __main__ -   eval_f1 = 0.3355\n",
      "04/26/2024 02:14:45 - INFO - __main__ -   eval_precision = 0.4272\n",
      "04/26/2024 02:14:45 - INFO - __main__ -   eval_recall = 0.2762\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:15:24 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:15:24 - INFO - __main__ -   auc_score = 0.8133\n",
      "04/26/2024 02:15:24 - INFO - __main__ -   test_f1 = 0.314\n",
      "04/26/2024 02:15:24 - INFO - __main__ -   test_precision = 0.404\n",
      "04/26/2024 02:15:24 - INFO - __main__ -   test_recall = 0.2568\n",
      "100% 512/512 [12:20<00:00,  1.45s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [01:10<04:48,  1.43it/s]04/26/2024 02:16:36 - WARNING - __main__ - epoch 7 step 102 loss 0.00795\n",
      "04/26/2024 02:17:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:17:15 - INFO - __main__ -   eval_f1 = 0.2928\n",
      "04/26/2024 02:17:15 - INFO - __main__ -   eval_precision = 0.463\n",
      "04/26/2024 02:17:15 - INFO - __main__ -   eval_recall = 0.2141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:17:53 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:17:53 - INFO - __main__ -   auc_score = 0.8081\n",
      "04/26/2024 02:17:53 - INFO - __main__ -   test_f1 = 0.2647\n",
      "04/26/2024 02:17:53 - INFO - __main__ -   test_precision = 0.4182\n",
      "04/26/2024 02:17:53 - INFO - __main__ -   test_recall = 0.1937\n",
      " 40% 203/512 [03:38<03:36,  1.42it/s]04/26/2024 02:19:04 - WARNING - __main__ - epoch 7 step 204 loss 0.01481\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:19:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:19:42 - INFO - __main__ -   eval_f1 = 0.303\n",
      "04/26/2024 02:19:42 - INFO - __main__ -   eval_precision = 0.4646\n",
      "04/26/2024 02:19:42 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:20:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:20:21 - INFO - __main__ -   auc_score = 0.8139\n",
      "04/26/2024 02:20:21 - INFO - __main__ -   test_f1 = 0.2646\n",
      "04/26/2024 02:20:21 - INFO - __main__ -   test_precision = 0.4079\n",
      "04/26/2024 02:20:21 - INFO - __main__ -   test_recall = 0.1958\n",
      " 60% 305/512 [06:06<02:25,  1.42it/s]04/26/2024 02:21:32 - WARNING - __main__ - epoch 7 step 306 loss 0.00851\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:22:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 02:22:10 - INFO - __main__ -   eval_f1 = 0.2457\n",
      "04/26/2024 02:22:10 - INFO - __main__ -   eval_precision = 0.4643\n",
      "04/26/2024 02:22:10 - INFO - __main__ -   eval_recall = 0.167\n",
      "04/26/2024 02:22:10 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 60% 305/512 [06:45<04:35,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p/single/checkpoints --pretrained_model codet5p --learning_rate 2e-5 --epochs 10 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y78sFmKf3BkW",
    "outputId": "1168cece-ff1b-4cb0-8cf0-9f00baa43870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p_bimodal to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/26/2024 02:31:08 - INFO - __main__ - Successfully load epoch 2's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 02:31:47 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 02:31:47 - INFO - __main__ -   auc_score = 0.8605\n",
      "04/26/2024 02:31:47 - INFO - __main__ -   test_f1 = 0.3595\n",
      "04/26/2024 02:31:47 - INFO - __main__ -   test_precision = 0.4137\n",
      "04/26/2024 02:31:47 - INFO - __main__ -   test_recall = 0.3179\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p/single/checkpoints --pretrained_model codet5p --learning_rate 2e-5 --epochs 10 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwjTahocLnlw"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2D9t4pyzL1xf",
    "outputId": "a5e98cdc-2ee9-49ba-bb7a-41a5c453d94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using a model of type codet5p_bimodal to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "trainable params: 7,077,888 || all params: 229,963,776 || trainable%: 3.077827353121911\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:56<03:44,  1.83it/s]04/29/2024 23:34:35 - WARNING - __main__ - epoch 0 step 102 loss 0.38326\n",
      "[[0.09269339]\n",
      " [0.10696883]\n",
      " [0.07359513]\n",
      " ...\n",
      " [0.0731163 ]\n",
      " [0.07669707]\n",
      " [0.07587609]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 23:35:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:35:15 - INFO - __main__ -   auc_score = 0.5219\n",
      "04/29/2024 23:35:15 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 23:35:15 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 23:35:15 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [02:31<02:48,  1.83it/s]04/29/2024 23:36:11 - WARNING - __main__ - epoch 0 step 204 loss 0.29559\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.15215705]\n",
      " [0.10798123]\n",
      " [0.08134073]\n",
      " ...\n",
      " [0.10316709]\n",
      " [0.10312553]\n",
      " [0.11501598]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 23:36:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:36:51 - INFO - __main__ -   auc_score = 0.7161\n",
      "04/29/2024 23:36:51 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 23:36:51 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 23:36:51 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [04:07<01:53,  1.83it/s]04/29/2024 23:37:46 - WARNING - __main__ - epoch 0 step 306 loss 0.28027\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.30063275]\n",
      " [0.11835433]\n",
      " [0.0838135 ]\n",
      " ...\n",
      " [0.1811519 ]\n",
      " [0.14697108]\n",
      " [0.2081215 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 23:38:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:38:26 - INFO - __main__ -   auc_score = 0.8242\n",
      "04/29/2024 23:38:26 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 23:38:26 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 23:38:26 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [05:42<00:57,  1.83it/s]04/29/2024 23:39:22 - WARNING - __main__ - epoch 0 step 408 loss 0.22831\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6570032 ]\n",
      " [0.12589884]\n",
      " [0.07748486]\n",
      " ...\n",
      " [0.44907618]\n",
      " [0.32652658]\n",
      " [0.50951463]]\n",
      "04/29/2024 23:40:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:40:02 - INFO - __main__ -   auc_score = 0.8428\n",
      "04/29/2024 23:40:02 - INFO - __main__ -   eval_f1 = 0.0484\n",
      "04/29/2024 23:40:02 - INFO - __main__ -   eval_precision = 0.4138\n",
      "04/29/2024 23:40:02 - INFO - __main__ -   eval_recall = 0.0257\n",
      " 99% 509/512 [07:20<00:01,  1.83it/s]04/29/2024 23:41:00 - WARNING - __main__ - epoch 0 step 510 loss 0.22874\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.72986305]\n",
      " [0.20288707]\n",
      " [0.08801208]\n",
      " ...\n",
      " [0.5672446 ]\n",
      " [0.38164517]\n",
      " [0.59858614]]\n",
      "04/29/2024 23:41:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:41:40 - INFO - __main__ -   auc_score = 0.8542\n",
      "04/29/2024 23:41:40 - INFO - __main__ -   eval_f1 = 0.2119\n",
      "04/29/2024 23:41:40 - INFO - __main__ -   eval_precision = 0.4672\n",
      "04/29/2024 23:41:40 - INFO - __main__ -   eval_recall = 0.137\n",
      "100% 512/512 [08:04<00:00,  1.06it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/29/2024 23:42:39 - WARNING - __main__ - epoch 1 step 102 loss 0.22777\n",
      "[[0.5986253 ]\n",
      " [0.16423479]\n",
      " [0.04111316]\n",
      " ...\n",
      " [0.27657598]\n",
      " [0.17975397]\n",
      " [0.36292374]]\n",
      "04/29/2024 23:43:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:43:19 - INFO - __main__ -   auc_score = 0.8552\n",
      "04/29/2024 23:43:19 - INFO - __main__ -   eval_f1 = 0.0127\n",
      "04/29/2024 23:43:19 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/29/2024 23:43:19 - INFO - __main__ -   eval_recall = 0.0064\n",
      " 40% 203/512 [02:30<02:49,  1.83it/s]04/29/2024 23:44:14 - WARNING - __main__ - epoch 1 step 204 loss 0.21978\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7414612 ]\n",
      " [0.29822204]\n",
      " [0.08408083]\n",
      " ...\n",
      " [0.4504413 ]\n",
      " [0.3591326 ]\n",
      " [0.55603653]]\n",
      "04/29/2024 23:44:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:44:55 - INFO - __main__ -   auc_score = 0.8629\n",
      "04/29/2024 23:44:55 - INFO - __main__ -   eval_f1 = 0.1727\n",
      "04/29/2024 23:44:55 - INFO - __main__ -   eval_precision = 0.5393\n",
      "04/29/2024 23:44:55 - INFO - __main__ -   eval_recall = 0.1028\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/29/2024 23:45:50 - WARNING - __main__ - epoch 1 step 306 loss 0.20615\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8003728 ]\n",
      " [0.30409026]\n",
      " [0.05433619]\n",
      " ...\n",
      " [0.4749577 ]\n",
      " [0.37035072]\n",
      " [0.5995948 ]]\n",
      "04/29/2024 23:46:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:46:30 - INFO - __main__ -   auc_score = 0.866\n",
      "04/29/2024 23:46:30 - INFO - __main__ -   eval_f1 = 0.1857\n",
      "04/29/2024 23:46:30 - INFO - __main__ -   eval_precision = 0.5591\n",
      "04/29/2024 23:46:30 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 79% 407/512 [05:42<00:57,  1.83it/s]04/29/2024 23:47:26 - WARNING - __main__ - epoch 1 step 408 loss 0.21717\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7264901 ]\n",
      " [0.25928867]\n",
      " [0.04373982]\n",
      " ...\n",
      " [0.34613088]\n",
      " [0.18535571]\n",
      " [0.45627478]]\n",
      "04/29/2024 23:48:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:48:06 - INFO - __main__ -   auc_score = 0.864\n",
      "04/29/2024 23:48:06 - INFO - __main__ -   eval_f1 = 0.1163\n",
      "04/29/2024 23:48:06 - INFO - __main__ -   eval_precision = 0.6122\n",
      "04/29/2024 23:48:06 - INFO - __main__ -   eval_recall = 0.0642\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/29/2024 23:49:01 - WARNING - __main__ - epoch 1 step 510 loss 0.20138\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.85064495]\n",
      " [0.3414838 ]\n",
      " [0.06091101]\n",
      " ...\n",
      " [0.5838363 ]\n",
      " [0.41610515]\n",
      " [0.6947642 ]]\n",
      "04/29/2024 23:49:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:49:41 - INFO - __main__ -   auc_score = 0.868\n",
      "04/29/2024 23:49:41 - INFO - __main__ -   eval_f1 = 0.3415\n",
      "04/29/2024 23:49:41 - INFO - __main__ -   eval_precision = 0.5174\n",
      "04/29/2024 23:49:41 - INFO - __main__ -   eval_recall = 0.2548\n",
      "100% 512/512 [08:01<00:00,  1.06it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/29/2024 23:50:40 - WARNING - __main__ - epoch 2 step 102 loss 0.20643\n",
      "[[0.804035  ]\n",
      " [0.44278228]\n",
      " [0.07002816]\n",
      " ...\n",
      " [0.4054885 ]\n",
      " [0.24931693]\n",
      " [0.5655591 ]]\n",
      "04/29/2024 23:51:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:51:21 - INFO - __main__ -   auc_score = 0.8672\n",
      "04/29/2024 23:51:21 - INFO - __main__ -   eval_f1 = 0.2077\n",
      "04/29/2024 23:51:21 - INFO - __main__ -   eval_precision = 0.5842\n",
      "04/29/2024 23:51:21 - INFO - __main__ -   eval_recall = 0.1263\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/29/2024 23:52:16 - WARNING - __main__ - epoch 2 step 204 loss 0.20131\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8091092 ]\n",
      " [0.4448367 ]\n",
      " [0.06048757]\n",
      " ...\n",
      " [0.44733718]\n",
      " [0.26334512]\n",
      " [0.62134236]]\n",
      "04/29/2024 23:52:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:52:56 - INFO - __main__ -   auc_score = 0.8707\n",
      "04/29/2024 23:52:56 - INFO - __main__ -   eval_f1 = 0.3021\n",
      "04/29/2024 23:52:56 - INFO - __main__ -   eval_precision = 0.5864\n",
      "04/29/2024 23:52:56 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/29/2024 23:53:52 - WARNING - __main__ - epoch 2 step 306 loss 0.19619\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8447106 ]\n",
      " [0.40611306]\n",
      " [0.04637149]\n",
      " ...\n",
      " [0.52626795]\n",
      " [0.3754245 ]\n",
      " [0.6636174 ]]\n",
      "04/29/2024 23:54:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:54:32 - INFO - __main__ -   auc_score = 0.8701\n",
      "04/29/2024 23:54:32 - INFO - __main__ -   eval_f1 = 0.3294\n",
      "04/29/2024 23:54:32 - INFO - __main__ -   eval_precision = 0.5258\n",
      "04/29/2024 23:54:32 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 79% 407/512 [05:42<00:57,  1.83it/s]04/29/2024 23:55:27 - WARNING - __main__ - epoch 2 step 408 loss 0.2005\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.87773526]\n",
      " [0.53889877]\n",
      " [0.07381146]\n",
      " ...\n",
      " [0.57886404]\n",
      " [0.48329404]\n",
      " [0.72863793]]\n",
      "04/29/2024 23:56:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:56:08 - INFO - __main__ -   auc_score = 0.8719\n",
      "04/29/2024 23:56:08 - INFO - __main__ -   eval_f1 = 0.3812\n",
      "04/29/2024 23:56:08 - INFO - __main__ -   eval_precision = 0.4688\n",
      "04/29/2024 23:56:08 - INFO - __main__ -   eval_recall = 0.3212\n",
      " 99% 509/512 [07:20<00:01,  1.83it/s]04/29/2024 23:57:05 - WARNING - __main__ - epoch 2 step 510 loss 0.2077\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8026719 ]\n",
      " [0.38434705]\n",
      " [0.03625705]\n",
      " ...\n",
      " [0.3678625 ]\n",
      " [0.25260195]\n",
      " [0.57165974]]\n",
      "04/29/2024 23:57:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:57:46 - INFO - __main__ -   auc_score = 0.871\n",
      "04/29/2024 23:57:46 - INFO - __main__ -   eval_f1 = 0.2483\n",
      "04/29/2024 23:57:46 - INFO - __main__ -   eval_precision = 0.6033\n",
      "04/29/2024 23:57:46 - INFO - __main__ -   eval_recall = 0.1563\n",
      "100% 512/512 [08:01<00:00,  1.06it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/29/2024 23:58:42 - WARNING - __main__ - epoch 3 step 102 loss 0.17931\n",
      "[[0.8406054 ]\n",
      " [0.40618488]\n",
      " [0.0311624 ]\n",
      " ...\n",
      " [0.47023392]\n",
      " [0.28361714]\n",
      " [0.67074037]]\n",
      "04/29/2024 23:59:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:59:22 - INFO - __main__ -   auc_score = 0.8712\n",
      "04/29/2024 23:59:22 - INFO - __main__ -   eval_f1 = 0.3096\n",
      "04/29/2024 23:59:22 - INFO - __main__ -   eval_precision = 0.5587\n",
      "04/29/2024 23:59:22 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 40% 203/512 [02:30<02:49,  1.83it/s]04/30/2024 00:00:18 - WARNING - __main__ - epoch 3 step 204 loss 0.19021\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8801612 ]\n",
      " [0.6553178 ]\n",
      " [0.06627595]\n",
      " ...\n",
      " [0.51871437]\n",
      " [0.3446767 ]\n",
      " [0.7375297 ]]\n",
      "04/30/2024 00:00:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:00:58 - INFO - __main__ -   auc_score = 0.8699\n",
      "04/30/2024 00:00:58 - INFO - __main__ -   eval_f1 = 0.3726\n",
      "04/30/2024 00:00:58 - INFO - __main__ -   eval_precision = 0.4565\n",
      "04/30/2024 00:00:58 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/30/2024 00:01:53 - WARNING - __main__ - epoch 3 step 306 loss 0.19729\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.82798576]\n",
      " [0.4820012 ]\n",
      " [0.04319257]\n",
      " ...\n",
      " [0.4303887 ]\n",
      " [0.34053224]\n",
      " [0.672228  ]]\n",
      "04/30/2024 00:02:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:02:34 - INFO - __main__ -   auc_score = 0.8702\n",
      "04/30/2024 00:02:34 - INFO - __main__ -   eval_f1 = 0.3304\n",
      "04/30/2024 00:02:34 - INFO - __main__ -   eval_precision = 0.5207\n",
      "04/30/2024 00:02:34 - INFO - __main__ -   eval_recall = 0.242\n",
      " 79% 407/512 [05:42<00:57,  1.83it/s]04/30/2024 00:03:29 - WARNING - __main__ - epoch 3 step 408 loss 0.19569\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7532605 ]\n",
      " [0.4299303 ]\n",
      " [0.0348957 ]\n",
      " ...\n",
      " [0.2832474 ]\n",
      " [0.19257304]\n",
      " [0.5200209 ]]\n",
      "04/30/2024 00:04:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:04:09 - INFO - __main__ -   auc_score = 0.8667\n",
      "04/30/2024 00:04:09 - INFO - __main__ -   eval_f1 = 0.2427\n",
      "04/30/2024 00:04:09 - INFO - __main__ -   eval_precision = 0.6017\n",
      "04/30/2024 00:04:09 - INFO - __main__ -   eval_recall = 0.152\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/30/2024 00:05:05 - WARNING - __main__ - epoch 3 step 510 loss 0.18923\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8647261 ]\n",
      " [0.5387125 ]\n",
      " [0.03935926]\n",
      " ...\n",
      " [0.35817966]\n",
      " [0.28935567]\n",
      " [0.6409754 ]]\n",
      "04/30/2024 00:05:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:05:45 - INFO - __main__ -   auc_score = 0.8703\n",
      "04/30/2024 00:05:45 - INFO - __main__ -   eval_f1 = 0.3434\n",
      "04/30/2024 00:05:45 - INFO - __main__ -   eval_precision = 0.5265\n",
      "04/30/2024 00:05:45 - INFO - __main__ -   eval_recall = 0.2548\n",
      "100% 512/512 [07:59<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/30/2024 00:06:41 - WARNING - __main__ - epoch 4 step 102 loss 0.18259\n",
      "[[0.83402324]\n",
      " [0.4803514 ]\n",
      " [0.03595082]\n",
      " ...\n",
      " [0.23747243]\n",
      " [0.2301466 ]\n",
      " [0.5884591 ]]\n",
      "04/30/2024 00:07:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:07:22 - INFO - __main__ -   auc_score = 0.8697\n",
      "04/30/2024 00:07:22 - INFO - __main__ -   eval_f1 = 0.2797\n",
      "04/30/2024 00:07:22 - INFO - __main__ -   eval_precision = 0.5811\n",
      "04/30/2024 00:07:22 - INFO - __main__ -   eval_recall = 0.1842\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/30/2024 00:08:17 - WARNING - __main__ - epoch 4 step 204 loss 0.18739\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.87682045]\n",
      " [0.580645  ]\n",
      " [0.05064118]\n",
      " ...\n",
      " [0.21246897]\n",
      " [0.30257368]\n",
      " [0.6504259 ]]\n",
      "04/30/2024 00:08:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:08:57 - INFO - __main__ -   auc_score = 0.8699\n",
      "04/30/2024 00:08:57 - INFO - __main__ -   eval_f1 = 0.3501\n",
      "04/30/2024 00:08:57 - INFO - __main__ -   eval_precision = 0.4778\n",
      "04/30/2024 00:08:57 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/30/2024 00:09:53 - WARNING - __main__ - epoch 4 step 306 loss 0.17536\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.84330314]\n",
      " [0.539141  ]\n",
      " [0.0341216 ]\n",
      " ...\n",
      " [0.1465737 ]\n",
      " [0.21158998]\n",
      " [0.56978154]]\n",
      "04/30/2024 00:10:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:10:33 - INFO - __main__ -   auc_score = 0.8691\n",
      "04/30/2024 00:10:33 - INFO - __main__ -   eval_f1 = 0.3218\n",
      "04/30/2024 00:10:33 - INFO - __main__ -   eval_precision = 0.5404\n",
      "04/30/2024 00:10:33 - INFO - __main__ -   eval_recall = 0.2291\n",
      " 79% 407/512 [05:42<00:57,  1.83it/s]04/30/2024 00:11:28 - WARNING - __main__ - epoch 4 step 408 loss 0.1798\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.855877  ]\n",
      " [0.5484247 ]\n",
      " [0.03236081]\n",
      " ...\n",
      " [0.21640423]\n",
      " [0.25757545]\n",
      " [0.6347374 ]]\n",
      "04/30/2024 00:12:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:12:08 - INFO - __main__ -   auc_score = 0.869\n",
      "04/30/2024 00:12:08 - INFO - __main__ -   eval_f1 = 0.3163\n",
      "04/30/2024 00:12:08 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/30/2024 00:12:08 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/30/2024 00:13:04 - WARNING - __main__ - epoch 4 step 510 loss 0.17605\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7972087 ]\n",
      " [0.50825423]\n",
      " [0.02624498]\n",
      " ...\n",
      " [0.17071237]\n",
      " [0.21519709]\n",
      " [0.5680883 ]]\n",
      "04/30/2024 00:13:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:13:44 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/30/2024 00:13:44 - INFO - __main__ -   eval_f1 = 0.2978\n",
      "04/30/2024 00:13:44 - INFO - __main__ -   eval_precision = 0.5556\n",
      "04/30/2024 00:13:44 - INFO - __main__ -   eval_recall = 0.2034\n",
      "100% 512/512 [07:59<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/30/2024 00:14:40 - WARNING - __main__ - epoch 5 step 102 loss 0.15833\n",
      "[[0.8083484 ]\n",
      " [0.5159961 ]\n",
      " [0.02490795]\n",
      " ...\n",
      " [0.18771812]\n",
      " [0.15724784]\n",
      " [0.59566826]]\n",
      "04/30/2024 00:15:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:15:21 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/30/2024 00:15:21 - INFO - __main__ -   eval_f1 = 0.3043\n",
      "04/30/2024 00:15:21 - INFO - __main__ -   eval_precision = 0.5537\n",
      "04/30/2024 00:15:21 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/30/2024 00:16:16 - WARNING - __main__ - epoch 5 step 204 loss 0.18429\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.85599387]\n",
      " [0.6261144 ]\n",
      " [0.0502248 ]\n",
      " ...\n",
      " [0.28214815]\n",
      " [0.3792    ]\n",
      " [0.77049   ]]\n",
      "04/30/2024 00:16:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:16:56 - INFO - __main__ -   auc_score = 0.8681\n",
      "04/30/2024 00:16:56 - INFO - __main__ -   eval_f1 = 0.3739\n",
      "04/30/2024 00:16:56 - INFO - __main__ -   eval_precision = 0.4282\n",
      "04/30/2024 00:16:56 - INFO - __main__ -   eval_recall = 0.3319\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/30/2024 00:17:52 - WARNING - __main__ - epoch 5 step 306 loss 0.16901\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.76193327]\n",
      " [0.4765506 ]\n",
      " [0.02146161]\n",
      " ...\n",
      " [0.08801516]\n",
      " [0.16027208]\n",
      " [0.5440753 ]]\n",
      "04/30/2024 00:18:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:18:32 - INFO - __main__ -   auc_score = 0.8628\n",
      "04/30/2024 00:18:32 - INFO - __main__ -   eval_f1 = 0.2306\n",
      "04/30/2024 00:18:32 - INFO - __main__ -   eval_precision = 0.5877\n",
      "04/30/2024 00:18:32 - INFO - __main__ -   eval_recall = 0.1435\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/30/2024 00:19:27 - WARNING - __main__ - epoch 5 step 408 loss 0.17606\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.83141714]\n",
      " [0.5586209 ]\n",
      " [0.02720876]\n",
      " ...\n",
      " [0.09610133]\n",
      " [0.25370657]\n",
      " [0.6079188 ]]\n",
      "04/30/2024 00:20:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:20:07 - INFO - __main__ -   auc_score = 0.8659\n",
      "04/30/2024 00:20:07 - INFO - __main__ -   eval_f1 = 0.2897\n",
      "04/30/2024 00:20:07 - INFO - __main__ -   eval_precision = 0.5165\n",
      "04/30/2024 00:20:07 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/30/2024 00:21:03 - WARNING - __main__ - epoch 5 step 510 loss 0.17253\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.823544  ]\n",
      " [0.55078274]\n",
      " [0.02137665]\n",
      " ...\n",
      " [0.09450544]\n",
      " [0.17772558]\n",
      " [0.58593124]]\n",
      "04/30/2024 00:21:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:21:43 - INFO - __main__ -   auc_score = 0.8646\n",
      "04/30/2024 00:21:43 - INFO - __main__ -   eval_f1 = 0.2916\n",
      "04/30/2024 00:21:43 - INFO - __main__ -   eval_precision = 0.561\n",
      "04/30/2024 00:21:43 - INFO - __main__ -   eval_recall = 0.197\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/30/2024 00:22:39 - WARNING - __main__ - epoch 6 step 102 loss 0.17564\n",
      "[[0.8403113 ]\n",
      " [0.6066577 ]\n",
      " [0.03026945]\n",
      " ...\n",
      " [0.08332074]\n",
      " [0.20842569]\n",
      " [0.5885383 ]]\n",
      "04/30/2024 00:23:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:23:19 - INFO - __main__ -   auc_score = 0.8631\n",
      "04/30/2024 00:23:19 - INFO - __main__ -   eval_f1 = 0.2911\n",
      "04/30/2024 00:23:19 - INFO - __main__ -   eval_precision = 0.5407\n",
      "04/30/2024 00:23:19 - INFO - __main__ -   eval_recall = 0.1991\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/30/2024 00:24:15 - WARNING - __main__ - epoch 6 step 204 loss 0.16894\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.90195847]\n",
      " [0.7072076 ]\n",
      " [0.05055428]\n",
      " ...\n",
      " [0.09252526]\n",
      " [0.35582414]\n",
      " [0.7250544 ]]\n",
      "04/30/2024 00:24:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:24:55 - INFO - __main__ -   auc_score = 0.866\n",
      "04/30/2024 00:24:55 - INFO - __main__ -   eval_f1 = 0.3513\n",
      "04/30/2024 00:24:55 - INFO - __main__ -   eval_precision = 0.4377\n",
      "04/30/2024 00:24:55 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/30/2024 00:25:50 - WARNING - __main__ - epoch 6 step 306 loss 0.14923\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8431154 ]\n",
      " [0.6319392 ]\n",
      " [0.03324828]\n",
      " ...\n",
      " [0.03605453]\n",
      " [0.23078784]\n",
      " [0.6636303 ]]\n",
      "04/30/2024 00:26:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:26:31 - INFO - __main__ -   auc_score = 0.8631\n",
      "04/30/2024 00:26:31 - INFO - __main__ -   eval_f1 = 0.3137\n",
      "04/30/2024 00:26:31 - INFO - __main__ -   eval_precision = 0.4781\n",
      "04/30/2024 00:26:31 - INFO - __main__ -   eval_recall = 0.2334\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/30/2024 00:27:26 - WARNING - __main__ - epoch 6 step 408 loss 0.16523\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.85429066]\n",
      " [0.63089526]\n",
      " [0.02270589]\n",
      " ...\n",
      " [0.05442658]\n",
      " [0.23145795]\n",
      " [0.6926127 ]]\n",
      "04/30/2024 00:28:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:28:06 - INFO - __main__ -   auc_score = 0.8625\n",
      "04/30/2024 00:28:06 - INFO - __main__ -   eval_f1 = 0.3007\n",
      "04/30/2024 00:28:06 - INFO - __main__ -   eval_precision = 0.4725\n",
      "04/30/2024 00:28:06 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/30/2024 00:29:02 - WARNING - __main__ - epoch 6 step 510 loss 0.16193\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.854136  ]\n",
      " [0.6076013 ]\n",
      " [0.02304074]\n",
      " ...\n",
      " [0.08268033]\n",
      " [0.28283966]\n",
      " [0.72393334]]\n",
      "04/30/2024 00:29:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:29:42 - INFO - __main__ -   auc_score = 0.8635\n",
      "04/30/2024 00:29:42 - INFO - __main__ -   eval_f1 = 0.3175\n",
      "04/30/2024 00:29:42 - INFO - __main__ -   eval_precision = 0.4542\n",
      "04/30/2024 00:29:42 - INFO - __main__ -   eval_recall = 0.2441\n",
      "100% 512/512 [07:58<00:00,  1.07it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:55<03:44,  1.83it/s]04/30/2024 00:30:38 - WARNING - __main__ - epoch 7 step 102 loss 0.1556\n",
      "[[0.8698075 ]\n",
      " [0.6656063 ]\n",
      " [0.02775258]\n",
      " ...\n",
      " [0.07258676]\n",
      " [0.34230053]\n",
      " [0.78109723]]\n",
      "04/30/2024 00:31:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:31:18 - INFO - __main__ -   auc_score = 0.8623\n",
      "04/30/2024 00:31:18 - INFO - __main__ -   eval_f1 = 0.3492\n",
      "04/30/2024 00:31:18 - INFO - __main__ -   eval_precision = 0.4359\n",
      "04/30/2024 00:31:18 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 40% 203/512 [02:30<02:48,  1.83it/s]04/30/2024 00:32:14 - WARNING - __main__ - epoch 7 step 204 loss 0.13688\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.88537335]\n",
      " [0.692491  ]\n",
      " [0.02489308]\n",
      " ...\n",
      " [0.09279069]\n",
      " [0.34506702]\n",
      " [0.8103469 ]]\n",
      "04/30/2024 00:32:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:32:54 - INFO - __main__ -   auc_score = 0.8627\n",
      "04/30/2024 00:32:54 - INFO - __main__ -   eval_f1 = 0.3485\n",
      "04/30/2024 00:32:54 - INFO - __main__ -   eval_precision = 0.4246\n",
      "04/30/2024 00:32:54 - INFO - __main__ -   eval_recall = 0.2955\n",
      " 60% 305/512 [04:06<01:53,  1.83it/s]04/30/2024 00:33:49 - WARNING - __main__ - epoch 7 step 306 loss 0.1562\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8899131 ]\n",
      " [0.7570074 ]\n",
      " [0.03376082]\n",
      " ...\n",
      " [0.14060074]\n",
      " [0.33355063]\n",
      " [0.83934486]]\n",
      "04/30/2024 00:34:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:34:29 - INFO - __main__ -   auc_score = 0.8614\n",
      "04/30/2024 00:34:29 - INFO - __main__ -   eval_f1 = 0.3521\n",
      "04/30/2024 00:34:29 - INFO - __main__ -   eval_precision = 0.4103\n",
      "04/30/2024 00:34:29 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 79% 407/512 [05:41<00:57,  1.83it/s]04/30/2024 00:35:25 - WARNING - __main__ - epoch 7 step 408 loss 0.16935\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.85496587]\n",
      " [0.6853213 ]\n",
      " [0.02421904]\n",
      " ...\n",
      " [0.09276155]\n",
      " [0.25564185]\n",
      " [0.78832674]]\n",
      "04/30/2024 00:36:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:36:05 - INFO - __main__ -   auc_score = 0.8599\n",
      "04/30/2024 00:36:05 - INFO - __main__ -   eval_f1 = 0.2949\n",
      "04/30/2024 00:36:05 - INFO - __main__ -   eval_precision = 0.4286\n",
      "04/30/2024 00:36:05 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 99% 509/512 [07:17<00:01,  1.83it/s]04/30/2024 00:37:00 - WARNING - __main__ - epoch 7 step 510 loss 0.15838\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.88933927]\n",
      " [0.69769025]\n",
      " [0.02895171]\n",
      " ...\n",
      " [0.10323851]\n",
      " [0.27610275]\n",
      " [0.7998611 ]]\n",
      "04/30/2024 00:37:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:37:40 - INFO - __main__ -   auc_score = 0.8612\n",
      "04/30/2024 00:37:40 - INFO - __main__ -   eval_f1 = 0.3117\n",
      "04/30/2024 00:37:40 - INFO - __main__ -   eval_precision = 0.4244\n",
      "04/30/2024 00:37:40 - INFO - __main__ -   eval_recall = 0.2463\n",
      "04/30/2024 00:37:40 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 99% 509/512 [07:57<00:02,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p/single/checkpoints \\\n",
    "   --pretrained_model codet5p \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrQsd0rLcc04",
    "outputId": "cd0cde70-3487-4946-b8c2-804f87f3e536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using a model of type codet5p_bimodal to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "trainable params: 7,077,888 || all params: 229,963,776 || trainable%: 3.077827353121911\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/30/2024 00:41:50 - INFO - __main__ - ***** Test results *****\n",
      "04/30/2024 00:41:50 - INFO - __main__ -   auc_score = 0.8622\n",
      "04/30/2024 00:41:50 - INFO - __main__ -   test_f1 = 0.3363\n",
      "04/30/2024 00:41:50 - INFO - __main__ -   test_precision = 0.4209\n",
      "04/30/2024 00:41:50 - INFO - __main__ -   test_recall = 0.28\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p/single/checkpoints \\\n",
    "   --pretrained_model codet5p \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaYnBvTcQ1ZW"
   },
   "source": [
    "### codet5p-770m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTZbnb2iNEzt"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7PtTfrvPUQq",
    "outputId": "5ea8d36d-2448-4823-97e4-1bc10333a6a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:33,  1.14s/it]04/26/2024 15:18:48 - WARNING - __main__ - epoch 0 step 204 loss 0.28573\n",
      "04/26/2024 15:20:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 15:20:53 - INFO - __main__ -   eval_f1 = 0.0958\n",
      "04/26/2024 15:20:53 - INFO - __main__ -   eval_precision = 0.7059\n",
      "04/26/2024 15:20:53 - INFO - __main__ -   eval_recall = 0.0514\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:23:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 15:23:11 - INFO - __main__ -   auc_score = 0.8521\n",
      "04/26/2024 15:23:11 - INFO - __main__ -   test_f1 = 0.0752\n",
      "04/26/2024 15:23:11 - INFO - __main__ -   test_precision = 0.6333\n",
      "04/26/2024 15:23:11 - INFO - __main__ -   test_recall = 0.04\n",
      " 40% 407/1024 [12:07<11:41,  1.14s/it]04/26/2024 15:27:03 - WARNING - __main__ - epoch 0 step 408 loss 0.23472\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:29:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 15:29:08 - INFO - __main__ -   eval_f1 = 0.2118\n",
      "04/26/2024 15:29:08 - INFO - __main__ -   eval_precision = 0.6556\n",
      "04/26/2024 15:29:08 - INFO - __main__ -   eval_recall = 0.1263\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:31:29 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 15:31:29 - INFO - __main__ -   auc_score = 0.8604\n",
      "04/26/2024 15:31:29 - INFO - __main__ -   test_f1 = 0.2047\n",
      "04/26/2024 15:31:29 - INFO - __main__ -   test_precision = 0.6951\n",
      "04/26/2024 15:31:29 - INFO - __main__ -   test_recall = 0.12\n",
      " 60% 611/1024 [20:25<07:49,  1.14s/it]04/26/2024 15:35:20 - WARNING - __main__ - epoch 0 step 612 loss 0.21469\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:37:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 15:37:26 - INFO - __main__ -   eval_f1 = 0.3149\n",
      "04/26/2024 15:37:26 - INFO - __main__ -   eval_precision = 0.651\n",
      "04/26/2024 15:37:26 - INFO - __main__ -   eval_recall = 0.2077\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:39:49 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 15:39:49 - INFO - __main__ -   auc_score = 0.8641\n",
      "04/26/2024 15:39:49 - INFO - __main__ -   test_f1 = 0.2496\n",
      "04/26/2024 15:39:49 - INFO - __main__ -   test_precision = 0.5672\n",
      "04/26/2024 15:39:49 - INFO - __main__ -   test_recall = 0.16\n",
      " 80% 815/1024 [28:44<03:57,  1.14s/it]04/26/2024 15:43:40 - WARNING - __main__ - epoch 0 step 816 loss 0.20927\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:45:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 15:45:46 - INFO - __main__ -   eval_f1 = 0.429\n",
      "04/26/2024 15:45:46 - INFO - __main__ -   eval_precision = 0.5925\n",
      "04/26/2024 15:45:46 - INFO - __main__ -   eval_recall = 0.3362\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:48:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 15:48:06 - INFO - __main__ -   auc_score = 0.8703\n",
      "04/26/2024 15:48:06 - INFO - __main__ -   test_f1 = 0.3675\n",
      "04/26/2024 15:48:06 - INFO - __main__ -   test_precision = 0.5\n",
      "04/26/2024 15:48:06 - INFO - __main__ -   test_recall = 0.2905\n",
      "100% 1019/1024 [37:01<00:05,  1.14s/it]04/26/2024 15:51:57 - WARNING - __main__ - epoch 0 step 1020 loss 0.21898\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:54:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 15:54:03 - INFO - __main__ -   eval_f1 = 0.3724\n",
      "04/26/2024 15:54:03 - INFO - __main__ -   eval_precision = 0.6231\n",
      "04/26/2024 15:54:03 - INFO - __main__ -   eval_recall = 0.2655\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 15:56:08 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 15:56:08 - INFO - __main__ -   auc_score = 0.8711\n",
      "04/26/2024 15:56:08 - INFO - __main__ -   test_f1 = 0.3155\n",
      "04/26/2024 15:56:08 - INFO - __main__ -   test_precision = 0.5787\n",
      "04/26/2024 15:56:08 - INFO - __main__ -   test_recall = 0.2168\n",
      "100% 1024/1024 [41:17<00:00,  2.42s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:50<15:33,  1.14s/it]04/26/2024 16:00:03 - WARNING - __main__ - epoch 1 step 204 loss 0.16905\n",
      "04/26/2024 16:02:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:02:09 - INFO - __main__ -   eval_f1 = 0.4233\n",
      "04/26/2024 16:02:09 - INFO - __main__ -   eval_precision = 0.6287\n",
      "04/26/2024 16:02:09 - INFO - __main__ -   eval_recall = 0.3191\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:04:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:04:14 - INFO - __main__ -   auc_score = 0.8678\n",
      "04/26/2024 16:04:14 - INFO - __main__ -   test_f1 = 0.3669\n",
      "04/26/2024 16:04:14 - INFO - __main__ -   test_precision = 0.5481\n",
      "04/26/2024 16:04:14 - INFO - __main__ -   test_recall = 0.2758\n",
      " 40% 407/1024 [11:53<11:41,  1.14s/it]04/26/2024 16:08:05 - WARNING - __main__ - epoch 1 step 408 loss 0.17025\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:10:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:10:11 - INFO - __main__ -   eval_f1 = 0.3514\n",
      "04/26/2024 16:10:11 - INFO - __main__ -   eval_precision = 0.5879\n",
      "04/26/2024 16:10:11 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:12:16 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:12:16 - INFO - __main__ -   auc_score = 0.8635\n",
      "04/26/2024 16:12:16 - INFO - __main__ -   test_f1 = 0.3097\n",
      "04/26/2024 16:12:16 - INFO - __main__ -   test_precision = 0.4954\n",
      "04/26/2024 16:12:16 - INFO - __main__ -   test_recall = 0.2253\n",
      " 60% 611/1024 [19:55<07:49,  1.14s/it]04/26/2024 16:16:08 - WARNING - __main__ - epoch 1 step 612 loss 0.16124\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:18:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:18:13 - INFO - __main__ -   eval_f1 = 0.3917\n",
      "04/26/2024 16:18:13 - INFO - __main__ -   eval_precision = 0.5573\n",
      "04/26/2024 16:18:13 - INFO - __main__ -   eval_recall = 0.3019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:20:19 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:20:19 - INFO - __main__ -   auc_score = 0.8666\n",
      "04/26/2024 16:20:19 - INFO - __main__ -   test_f1 = 0.3396\n",
      "04/26/2024 16:20:19 - INFO - __main__ -   test_precision = 0.4652\n",
      "04/26/2024 16:20:19 - INFO - __main__ -   test_recall = 0.2674\n",
      " 80% 815/1024 [27:57<03:57,  1.14s/it]04/26/2024 16:24:10 - WARNING - __main__ - epoch 1 step 816 loss 0.1757\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:26:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:26:16 - INFO - __main__ -   eval_f1 = 0.3909\n",
      "04/26/2024 16:26:16 - INFO - __main__ -   eval_precision = 0.5774\n",
      "04/26/2024 16:26:16 - INFO - __main__ -   eval_recall = 0.2955\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:28:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:28:21 - INFO - __main__ -   auc_score = 0.8752\n",
      "04/26/2024 16:28:21 - INFO - __main__ -   test_f1 = 0.3636\n",
      "04/26/2024 16:28:21 - INFO - __main__ -   test_precision = 0.559\n",
      "04/26/2024 16:28:21 - INFO - __main__ -   test_recall = 0.2695\n",
      "100% 1019/1024 [35:59<00:05,  1.14s/it]04/26/2024 16:32:12 - WARNING - __main__ - epoch 1 step 1020 loss 0.15326\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:34:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:34:18 - INFO - __main__ -   eval_f1 = 0.4225\n",
      "04/26/2024 16:34:18 - INFO - __main__ -   eval_precision = 0.4915\n",
      "04/26/2024 16:34:18 - INFO - __main__ -   eval_recall = 0.3704\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:36:23 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:36:23 - INFO - __main__ -   auc_score = 0.8647\n",
      "04/26/2024 16:36:23 - INFO - __main__ -   test_f1 = 0.4062\n",
      "04/26/2024 16:36:23 - INFO - __main__ -   test_precision = 0.4696\n",
      "04/26/2024 16:36:23 - INFO - __main__ -   test_recall = 0.3579\n",
      "100% 1024/1024 [40:15<00:00,  2.36s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:50<15:33,  1.14s/it]04/26/2024 16:40:18 - WARNING - __main__ - epoch 2 step 204 loss 0.0917\n",
      "04/26/2024 16:42:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:42:24 - INFO - __main__ -   eval_f1 = 0.3324\n",
      "04/26/2024 16:42:24 - INFO - __main__ -   eval_precision = 0.4386\n",
      "04/26/2024 16:42:24 - INFO - __main__ -   eval_recall = 0.2677\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:44:29 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:44:29 - INFO - __main__ -   auc_score = 0.858\n",
      "04/26/2024 16:44:29 - INFO - __main__ -   test_f1 = 0.3674\n",
      "04/26/2024 16:44:29 - INFO - __main__ -   test_precision = 0.4765\n",
      "04/26/2024 16:44:29 - INFO - __main__ -   test_recall = 0.2989\n",
      " 40% 407/1024 [11:53<11:41,  1.14s/it]04/26/2024 16:48:21 - WARNING - __main__ - epoch 2 step 408 loss 0.08033\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:50:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:50:26 - INFO - __main__ -   eval_f1 = 0.3541\n",
      "04/26/2024 16:50:26 - INFO - __main__ -   eval_precision = 0.4799\n",
      "04/26/2024 16:50:26 - INFO - __main__ -   eval_recall = 0.2805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:52:32 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 16:52:32 - INFO - __main__ -   auc_score = 0.8518\n",
      "04/26/2024 16:52:32 - INFO - __main__ -   test_f1 = 0.324\n",
      "04/26/2024 16:52:32 - INFO - __main__ -   test_precision = 0.4388\n",
      "04/26/2024 16:52:32 - INFO - __main__ -   test_recall = 0.2568\n",
      " 60% 611/1024 [19:55<07:49,  1.14s/it]04/26/2024 16:56:23 - WARNING - __main__ - epoch 2 step 612 loss 0.09778\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 16:58:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 16:58:29 - INFO - __main__ -   eval_f1 = 0.3329\n",
      "04/26/2024 16:58:29 - INFO - __main__ -   eval_precision = 0.414\n",
      "04/26/2024 16:58:29 - INFO - __main__ -   eval_recall = 0.2784\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:00:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:00:34 - INFO - __main__ -   auc_score = 0.8463\n",
      "04/26/2024 17:00:34 - INFO - __main__ -   test_f1 = 0.3272\n",
      "04/26/2024 17:00:34 - INFO - __main__ -   test_precision = 0.4382\n",
      "04/26/2024 17:00:34 - INFO - __main__ -   test_recall = 0.2611\n",
      " 80% 815/1024 [27:57<03:57,  1.14s/it]04/26/2024 17:04:25 - WARNING - __main__ - epoch 2 step 816 loss 0.0947\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:06:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:06:31 - INFO - __main__ -   eval_f1 = 0.3241\n",
      "04/26/2024 17:06:31 - INFO - __main__ -   eval_precision = 0.5092\n",
      "04/26/2024 17:06:31 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:08:36 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:08:36 - INFO - __main__ -   auc_score = 0.8534\n",
      "04/26/2024 17:08:36 - INFO - __main__ -   test_f1 = 0.3003\n",
      "04/26/2024 17:08:36 - INFO - __main__ -   test_precision = 0.4882\n",
      "04/26/2024 17:08:36 - INFO - __main__ -   test_recall = 0.2168\n",
      "100% 1019/1024 [36:00<00:05,  1.14s/it]04/26/2024 17:12:27 - WARNING - __main__ - epoch 2 step 1020 loss 0.08136\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:14:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:14:33 - INFO - __main__ -   eval_f1 = 0.3499\n",
      "04/26/2024 17:14:33 - INFO - __main__ -   eval_precision = 0.4903\n",
      "04/26/2024 17:14:33 - INFO - __main__ -   eval_recall = 0.2719\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:16:38 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:16:38 - INFO - __main__ -   auc_score = 0.8547\n",
      "04/26/2024 17:16:38 - INFO - __main__ -   test_f1 = 0.3243\n",
      "04/26/2024 17:16:38 - INFO - __main__ -   test_precision = 0.4528\n",
      "04/26/2024 17:16:38 - INFO - __main__ -   test_recall = 0.2526\n",
      "100% 1024/1024 [40:15<00:00,  2.36s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:50<15:33,  1.14s/it]04/26/2024 17:20:34 - WARNING - __main__ - epoch 3 step 204 loss 0.03105\n",
      "04/26/2024 17:22:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:22:39 - INFO - __main__ -   eval_f1 = 0.3801\n",
      "04/26/2024 17:22:39 - INFO - __main__ -   eval_precision = 0.47\n",
      "04/26/2024 17:22:39 - INFO - __main__ -   eval_recall = 0.3191\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:24:45 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:24:45 - INFO - __main__ -   auc_score = 0.8561\n",
      "04/26/2024 17:24:45 - INFO - __main__ -   test_f1 = 0.363\n",
      "04/26/2024 17:24:45 - INFO - __main__ -   test_precision = 0.4475\n",
      "04/26/2024 17:24:45 - INFO - __main__ -   test_recall = 0.3053\n",
      " 40% 407/1024 [11:53<11:41,  1.14s/it]04/26/2024 17:28:36 - WARNING - __main__ - epoch 3 step 408 loss 0.03519\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:30:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:30:41 - INFO - __main__ -   eval_f1 = 0.3877\n",
      "04/26/2024 17:30:41 - INFO - __main__ -   eval_precision = 0.454\n",
      "04/26/2024 17:30:41 - INFO - __main__ -   eval_recall = 0.3383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:32:47 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:32:47 - INFO - __main__ -   auc_score = 0.8563\n",
      "04/26/2024 17:32:47 - INFO - __main__ -   test_f1 = 0.3718\n",
      "04/26/2024 17:32:47 - INFO - __main__ -   test_precision = 0.4397\n",
      "04/26/2024 17:32:47 - INFO - __main__ -   test_recall = 0.3221\n",
      " 60% 611/1024 [19:55<07:49,  1.14s/it]04/26/2024 17:36:38 - WARNING - __main__ - epoch 3 step 612 loss 0.03748\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:38:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:38:44 - INFO - __main__ -   eval_f1 = 0.374\n",
      "04/26/2024 17:38:44 - INFO - __main__ -   eval_precision = 0.4752\n",
      "04/26/2024 17:38:44 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:40:49 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:40:49 - INFO - __main__ -   auc_score = 0.8579\n",
      "04/26/2024 17:40:49 - INFO - __main__ -   test_f1 = 0.3596\n",
      "04/26/2024 17:40:49 - INFO - __main__ -   test_precision = 0.4664\n",
      "04/26/2024 17:40:49 - INFO - __main__ -   test_recall = 0.2926\n",
      " 80% 815/1024 [27:57<03:57,  1.14s/it]04/26/2024 17:44:40 - WARNING - __main__ - epoch 3 step 816 loss 0.0468\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:46:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:46:46 - INFO - __main__ -   eval_f1 = 0.3126\n",
      "04/26/2024 17:46:46 - INFO - __main__ -   eval_precision = 0.4821\n",
      "04/26/2024 17:46:46 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:48:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:48:51 - INFO - __main__ -   auc_score = 0.8557\n",
      "04/26/2024 17:48:51 - INFO - __main__ -   test_f1 = 0.2665\n",
      "04/26/2024 17:48:51 - INFO - __main__ -   test_precision = 0.4611\n",
      "04/26/2024 17:48:51 - INFO - __main__ -   test_recall = 0.1874\n",
      "100% 1019/1024 [35:59<00:05,  1.14s/it]04/26/2024 17:52:42 - WARNING - __main__ - epoch 3 step 1020 loss 0.04882\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:54:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 17:54:48 - INFO - __main__ -   eval_f1 = 0.3592\n",
      "04/26/2024 17:54:48 - INFO - __main__ -   eval_precision = 0.4434\n",
      "04/26/2024 17:54:48 - INFO - __main__ -   eval_recall = 0.3019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 17:56:53 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 17:56:53 - INFO - __main__ -   auc_score = 0.8573\n",
      "04/26/2024 17:56:53 - INFO - __main__ -   test_f1 = 0.3124\n",
      "04/26/2024 17:56:53 - INFO - __main__ -   test_precision = 0.3987\n",
      "04/26/2024 17:56:53 - INFO - __main__ -   test_recall = 0.2568\n",
      "100% 1024/1024 [40:14<00:00,  2.36s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:50<15:33,  1.14s/it]04/26/2024 18:00:49 - WARNING - __main__ - epoch 4 step 204 loss 0.01727\n",
      "04/26/2024 18:02:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:02:54 - INFO - __main__ -   eval_f1 = 0.3507\n",
      "04/26/2024 18:02:54 - INFO - __main__ -   eval_precision = 0.4679\n",
      "04/26/2024 18:02:54 - INFO - __main__ -   eval_recall = 0.2805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:05:00 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:05:00 - INFO - __main__ -   auc_score = 0.8592\n",
      "04/26/2024 18:05:00 - INFO - __main__ -   test_f1 = 0.319\n",
      "04/26/2024 18:05:00 - INFO - __main__ -   test_precision = 0.4675\n",
      "04/26/2024 18:05:00 - INFO - __main__ -   test_recall = 0.2421\n",
      " 40% 407/1024 [11:53<11:41,  1.14s/it]04/26/2024 18:08:51 - WARNING - __main__ - epoch 4 step 408 loss 0.02383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:10:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:10:57 - INFO - __main__ -   eval_f1 = 0.3144\n",
      "04/26/2024 18:10:57 - INFO - __main__ -   eval_precision = 0.4909\n",
      "04/26/2024 18:10:57 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:13:02 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:13:02 - INFO - __main__ -   auc_score = 0.858\n",
      "04/26/2024 18:13:02 - INFO - __main__ -   test_f1 = 0.2997\n",
      "04/26/2024 18:13:02 - INFO - __main__ -   test_precision = 0.4749\n",
      "04/26/2024 18:13:02 - INFO - __main__ -   test_recall = 0.2189\n",
      " 60% 611/1024 [19:55<07:49,  1.14s/it]04/26/2024 18:16:53 - WARNING - __main__ - epoch 4 step 612 loss 0.02174\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:18:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:18:59 - INFO - __main__ -   eval_f1 = 0.3343\n",
      "04/26/2024 18:18:59 - INFO - __main__ -   eval_precision = 0.511\n",
      "04/26/2024 18:18:59 - INFO - __main__ -   eval_recall = 0.2484\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:21:04 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:21:04 - INFO - __main__ -   auc_score = 0.8489\n",
      "04/26/2024 18:21:04 - INFO - __main__ -   test_f1 = 0.305\n",
      "04/26/2024 18:21:04 - INFO - __main__ -   test_precision = 0.5024\n",
      "04/26/2024 18:21:04 - INFO - __main__ -   test_recall = 0.2189\n",
      " 80% 815/1024 [27:57<03:57,  1.14s/it]04/26/2024 18:24:55 - WARNING - __main__ - epoch 4 step 816 loss 0.01368\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:27:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:27:01 - INFO - __main__ -   eval_f1 = 0.3126\n",
      "04/26/2024 18:27:01 - INFO - __main__ -   eval_precision = 0.5365\n",
      "04/26/2024 18:27:01 - INFO - __main__ -   eval_recall = 0.2206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:29:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:29:06 - INFO - __main__ -   auc_score = 0.8543\n",
      "04/26/2024 18:29:06 - INFO - __main__ -   test_f1 = 0.2816\n",
      "04/26/2024 18:29:06 - INFO - __main__ -   test_precision = 0.5669\n",
      "04/26/2024 18:29:06 - INFO - __main__ -   test_recall = 0.1874\n",
      "100% 1019/1024 [35:59<00:05,  1.14s/it]04/26/2024 18:32:57 - WARNING - __main__ - epoch 4 step 1020 loss 0.0194\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:35:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:35:03 - INFO - __main__ -   eval_f1 = 0.3667\n",
      "04/26/2024 18:35:03 - INFO - __main__ -   eval_precision = 0.4274\n",
      "04/26/2024 18:35:03 - INFO - __main__ -   eval_recall = 0.3212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:37:08 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:37:08 - INFO - __main__ -   auc_score = 0.8505\n",
      "04/26/2024 18:37:08 - INFO - __main__ -   test_f1 = 0.3664\n",
      "04/26/2024 18:37:08 - INFO - __main__ -   test_precision = 0.463\n",
      "04/26/2024 18:37:08 - INFO - __main__ -   test_recall = 0.3032\n",
      "100% 1024/1024 [40:15<00:00,  2.36s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:50<15:33,  1.14s/it]04/26/2024 18:41:04 - WARNING - __main__ - epoch 5 step 204 loss 0.00483\n",
      "04/26/2024 18:43:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:43:09 - INFO - __main__ -   eval_f1 = 0.3908\n",
      "04/26/2024 18:43:09 - INFO - __main__ -   eval_precision = 0.451\n",
      "04/26/2024 18:43:09 - INFO - __main__ -   eval_recall = 0.3448\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:45:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:45:15 - INFO - __main__ -   auc_score = 0.8588\n",
      "04/26/2024 18:45:15 - INFO - __main__ -   test_f1 = 0.3807\n",
      "04/26/2024 18:45:15 - INFO - __main__ -   test_precision = 0.4611\n",
      "04/26/2024 18:45:15 - INFO - __main__ -   test_recall = 0.3242\n",
      " 40% 407/1024 [11:52<11:41,  1.14s/it]04/26/2024 18:49:06 - WARNING - __main__ - epoch 5 step 408 loss 0.00878\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:51:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:51:11 - INFO - __main__ -   eval_f1 = 0.32\n",
      "04/26/2024 18:51:11 - INFO - __main__ -   eval_precision = 0.5192\n",
      "04/26/2024 18:51:11 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:53:17 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 18:53:17 - INFO - __main__ -   auc_score = 0.8445\n",
      "04/26/2024 18:53:17 - INFO - __main__ -   test_f1 = 0.2942\n",
      "04/26/2024 18:53:17 - INFO - __main__ -   test_precision = 0.5\n",
      "04/26/2024 18:53:17 - INFO - __main__ -   test_recall = 0.2084\n",
      " 60% 611/1024 [19:55<07:49,  1.14s/it]04/26/2024 18:57:08 - WARNING - __main__ - epoch 5 step 612 loss 0.01123\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 18:59:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 18:59:14 - INFO - __main__ -   eval_f1 = 0.3656\n",
      "04/26/2024 18:59:14 - INFO - __main__ -   eval_precision = 0.491\n",
      "04/26/2024 18:59:14 - INFO - __main__ -   eval_recall = 0.2912\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 19:01:19 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 19:01:19 - INFO - __main__ -   auc_score = 0.8544\n",
      "04/26/2024 19:01:19 - INFO - __main__ -   test_f1 = 0.357\n",
      "04/26/2024 19:01:19 - INFO - __main__ -   test_precision = 0.4739\n",
      "04/26/2024 19:01:19 - INFO - __main__ -   test_recall = 0.2863\n",
      " 80% 815/1024 [27:57<03:57,  1.14s/it]04/26/2024 19:05:10 - WARNING - __main__ - epoch 5 step 816 loss 0.01221\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 19:07:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 19:07:16 - INFO - __main__ -   eval_f1 = 0.3634\n",
      "04/26/2024 19:07:16 - INFO - __main__ -   eval_precision = 0.4891\n",
      "04/26/2024 19:07:16 - INFO - __main__ -   eval_recall = 0.2891\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 19:09:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 19:09:21 - INFO - __main__ -   auc_score = 0.849\n",
      "04/26/2024 19:09:21 - INFO - __main__ -   test_f1 = 0.3266\n",
      "04/26/2024 19:09:21 - INFO - __main__ -   test_precision = 0.4549\n",
      "04/26/2024 19:09:21 - INFO - __main__ -   test_recall = 0.2547\n",
      "100% 1019/1024 [35:59<00:05,  1.14s/it]04/26/2024 19:13:13 - WARNING - __main__ - epoch 5 step 1020 loss 0.01457\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 19:15:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 19:15:18 - INFO - __main__ -   eval_f1 = 0.3421\n",
      "04/26/2024 19:15:18 - INFO - __main__ -   eval_precision = 0.5392\n",
      "04/26/2024 19:15:18 - INFO - __main__ -   eval_recall = 0.2505\n",
      "04/26/2024 19:15:18 - INFO - __main__ - patience greater than 5, early stop!\n",
      "100% 1019/1024 [38:06<00:11,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 2e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8UKpNYGqmDG",
    "outputId": "47aa8ac7-1890-4295-81ba-f02af04cdf69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/26/2024 19:23:40 - INFO - __main__ - Successfully load epoch 0's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 19:25:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 19:25:46 - INFO - __main__ -   auc_score = 0.8662\n",
      "04/26/2024 19:25:46 - INFO - __main__ -   test_f1 = 0.3678\n",
      "04/26/2024 19:25:46 - INFO - __main__ -   test_precision = 0.5074\n",
      "04/26/2024 19:25:46 - INFO - __main__ -   test_recall = 0.2884\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 2e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpWyaGcsMSD1"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uI2JAFqEMVGD",
    "outputId": "1ee1af73-7ffa-4d97-f31d-9f7b5a3035e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100% 770/770 [00:00<00:00, 3.72MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 8.22MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 774kB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 1.22MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 10.5kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 47.8MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [01:31<00:00, 16.1MB/s]\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949071786785058\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:59<11:58,  1.14it/s]04/29/2024 19:30:44 - WARNING - __main__ - epoch 0 step 204 loss 0.56175\n",
      "[[0.10615852]\n",
      " [0.09684186]\n",
      " [0.09295222]\n",
      " ...\n",
      " [0.10715334]\n",
      " [0.10720866]\n",
      " [0.10150161]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 19:32:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:32:54 - INFO - __main__ -   auc_score = 0.6219\n",
      "04/29/2024 19:32:54 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 19:32:54 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 19:32:54 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 407/1024 [08:08<08:59,  1.14it/s]04/29/2024 19:35:52 - WARNING - __main__ - epoch 0 step 408 loss 0.29361\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.17724061]\n",
      " [0.06708268]\n",
      " [0.07490098]\n",
      " ...\n",
      " [0.13955516]\n",
      " [0.16018276]\n",
      " [0.14648618]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 19:38:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:38:03 - INFO - __main__ -   auc_score = 0.6986\n",
      "04/29/2024 19:38:03 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 19:38:03 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 19:38:03 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 611/1024 [13:16<06:01,  1.14it/s]04/29/2024 19:41:01 - WARNING - __main__ - epoch 0 step 612 loss 0.25027\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.2673752 ]\n",
      " [0.04809113]\n",
      " [0.04627695]\n",
      " ...\n",
      " [0.1488348 ]\n",
      " [0.15243314]\n",
      " [0.17417586]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/29/2024 19:43:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:43:11 - INFO - __main__ -   auc_score = 0.8365\n",
      "04/29/2024 19:43:11 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/29/2024 19:43:11 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/29/2024 19:43:11 - INFO - __main__ -   eval_recall = 0.0\n",
      " 80% 815/1024 [18:25<03:02,  1.14it/s]04/29/2024 19:46:09 - WARNING - __main__ - epoch 0 step 816 loss 0.23243\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6070236 ]\n",
      " [0.21280988]\n",
      " [0.06357685]\n",
      " ...\n",
      " [0.35373408]\n",
      " [0.2997633 ]\n",
      " [0.36250633]]\n",
      "04/29/2024 19:48:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:48:20 - INFO - __main__ -   auc_score = 0.8702\n",
      "04/29/2024 19:48:20 - INFO - __main__ -   eval_f1 = 0.3319\n",
      "04/29/2024 19:48:20 - INFO - __main__ -   eval_precision = 0.528\n",
      "04/29/2024 19:48:20 - INFO - __main__ -   eval_recall = 0.242\n",
      "100% 1019/1024 [23:43<00:04,  1.14it/s]04/29/2024 19:51:28 - WARNING - __main__ - epoch 0 step 1020 loss 0.22673\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5535749 ]\n",
      " [0.16168468]\n",
      " [0.0812576 ]\n",
      " ...\n",
      " [0.26029462]\n",
      " [0.2386756 ]\n",
      " [0.22709201]]\n",
      "04/29/2024 19:53:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:53:38 - INFO - __main__ -   auc_score = 0.874\n",
      "04/29/2024 19:53:38 - INFO - __main__ -   eval_f1 = 0.085\n",
      "04/29/2024 19:53:38 - INFO - __main__ -   eval_precision = 0.7778\n",
      "04/29/2024 19:53:38 - INFO - __main__ -   eval_recall = 0.045\n",
      "100% 1024/1024 [25:57<00:00,  1.52s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 19:56:39 - WARNING - __main__ - epoch 1 step 204 loss 0.21445\n",
      "[[0.6148371 ]\n",
      " [0.10935525]\n",
      " [0.05068139]\n",
      " ...\n",
      " [0.3009018 ]\n",
      " [0.20214964]\n",
      " [0.24149002]]\n",
      "04/29/2024 19:58:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 19:58:50 - INFO - __main__ -   auc_score = 0.8761\n",
      "04/29/2024 19:58:50 - INFO - __main__ -   eval_f1 = 0.1453\n",
      "04/29/2024 19:58:50 - INFO - __main__ -   eval_precision = 0.6786\n",
      "04/29/2024 19:58:50 - INFO - __main__ -   eval_recall = 0.0814\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 20:01:48 - WARNING - __main__ - epoch 1 step 408 loss 0.20201\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6255928 ]\n",
      " [0.15286842]\n",
      " [0.07880022]\n",
      " ...\n",
      " [0.29783753]\n",
      " [0.21241263]\n",
      " [0.19568282]]\n",
      "04/29/2024 20:03:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:03:58 - INFO - __main__ -   auc_score = 0.8765\n",
      "04/29/2024 20:03:58 - INFO - __main__ -   eval_f1 = 0.1274\n",
      "04/29/2024 20:03:58 - INFO - __main__ -   eval_precision = 0.6471\n",
      "04/29/2024 20:03:58 - INFO - __main__ -   eval_recall = 0.0707\n",
      " 60% 611/1024 [13:14<06:01,  1.14it/s]04/29/2024 20:06:56 - WARNING - __main__ - epoch 1 step 612 loss 0.20973\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7047996 ]\n",
      " [0.30788106]\n",
      " [0.1607801 ]\n",
      " ...\n",
      " [0.38001996]\n",
      " [0.23743303]\n",
      " [0.22297537]]\n",
      "04/29/2024 20:09:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:09:07 - INFO - __main__ -   auc_score = 0.874\n",
      "04/29/2024 20:09:07 - INFO - __main__ -   eval_f1 = 0.2975\n",
      "04/29/2024 20:09:07 - INFO - __main__ -   eval_precision = 0.5697\n",
      "04/29/2024 20:09:07 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 80% 815/1024 [18:22<03:02,  1.14it/s]04/29/2024 20:12:05 - WARNING - __main__ - epoch 1 step 816 loss 0.20102\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6995742 ]\n",
      " [0.3216146 ]\n",
      " [0.13472533]\n",
      " ...\n",
      " [0.2907972 ]\n",
      " [0.19690901]\n",
      " [0.13725658]]\n",
      "04/29/2024 20:14:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:14:15 - INFO - __main__ -   auc_score = 0.8754\n",
      "04/29/2024 20:14:15 - INFO - __main__ -   eval_f1 = 0.2526\n",
      "04/29/2024 20:14:15 - INFO - __main__ -   eval_precision = 0.6218\n",
      "04/29/2024 20:14:15 - INFO - __main__ -   eval_recall = 0.1585\n",
      "100% 1019/1024 [23:31<00:04,  1.14it/s]04/29/2024 20:17:13 - WARNING - __main__ - epoch 1 step 1020 loss 0.20878\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.67295194]\n",
      " [0.24501443]\n",
      " [0.17327711]\n",
      " ...\n",
      " [0.3517309 ]\n",
      " [0.24452993]\n",
      " [0.190273  ]]\n",
      "04/29/2024 20:19:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:19:24 - INFO - __main__ -   auc_score = 0.8751\n",
      "04/29/2024 20:19:24 - INFO - __main__ -   eval_f1 = 0.1901\n",
      "04/29/2024 20:19:24 - INFO - __main__ -   eval_precision = 0.65\n",
      "04/29/2024 20:19:24 - INFO - __main__ -   eval_recall = 0.1113\n",
      "100% 1024/1024 [25:45<00:00,  1.51s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 20:22:25 - WARNING - __main__ - epoch 2 step 204 loss 0.18048\n",
      "[[0.7601094 ]\n",
      " [0.20890927]\n",
      " [0.13415119]\n",
      " ...\n",
      " [0.2944168 ]\n",
      " [0.17010969]\n",
      " [0.11885578]]\n",
      "04/29/2024 20:24:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:24:35 - INFO - __main__ -   auc_score = 0.8761\n",
      "04/29/2024 20:24:35 - INFO - __main__ -   eval_f1 = 0.2612\n",
      "04/29/2024 20:24:35 - INFO - __main__ -   eval_precision = 0.6609\n",
      "04/29/2024 20:24:35 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 20:27:33 - WARNING - __main__ - epoch 2 step 408 loss 0.19995\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7253155 ]\n",
      " [0.13501856]\n",
      " [0.17146516]\n",
      " ...\n",
      " [0.37483647]\n",
      " [0.29407933]\n",
      " [0.14981377]]\n",
      "04/29/2024 20:29:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:29:44 - INFO - __main__ -   auc_score = 0.8764\n",
      "04/29/2024 20:29:44 - INFO - __main__ -   eval_f1 = 0.2965\n",
      "04/29/2024 20:29:44 - INFO - __main__ -   eval_precision = 0.6429\n",
      "04/29/2024 20:29:44 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 60% 611/1024 [13:14<06:01,  1.14it/s]04/29/2024 20:32:42 - WARNING - __main__ - epoch 2 step 612 loss 0.19648\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.77469355]\n",
      " [0.15638106]\n",
      " [0.12438394]\n",
      " ...\n",
      " [0.32644185]\n",
      " [0.23008105]\n",
      " [0.10229368]]\n",
      "04/29/2024 20:34:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:34:52 - INFO - __main__ -   auc_score = 0.8759\n",
      "04/29/2024 20:34:52 - INFO - __main__ -   eval_f1 = 0.3172\n",
      "04/29/2024 20:34:52 - INFO - __main__ -   eval_precision = 0.649\n",
      "04/29/2024 20:34:52 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 80% 815/1024 [18:23<03:02,  1.14it/s]04/29/2024 20:37:50 - WARNING - __main__ - epoch 2 step 816 loss 0.18978\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7660275 ]\n",
      " [0.15088047]\n",
      " [0.13136733]\n",
      " ...\n",
      " [0.22379057]\n",
      " [0.192248  ]\n",
      " [0.0605276 ]]\n",
      "04/29/2024 20:40:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:40:01 - INFO - __main__ -   auc_score = 0.8744\n",
      "04/29/2024 20:40:01 - INFO - __main__ -   eval_f1 = 0.2282\n",
      "04/29/2024 20:40:01 - INFO - __main__ -   eval_precision = 0.6809\n",
      "04/29/2024 20:40:01 - INFO - __main__ -   eval_recall = 0.137\n",
      "100% 1019/1024 [23:32<00:04,  1.14it/s]04/29/2024 20:42:59 - WARNING - __main__ - epoch 2 step 1020 loss 0.18461\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8415811 ]\n",
      " [0.24993552]\n",
      " [0.20364404]\n",
      " ...\n",
      " [0.30784887]\n",
      " [0.17326425]\n",
      " [0.12291206]]\n",
      "04/29/2024 20:45:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:45:10 - INFO - __main__ -   auc_score = 0.8782\n",
      "04/29/2024 20:45:10 - INFO - __main__ -   eval_f1 = 0.3919\n",
      "04/29/2024 20:45:10 - INFO - __main__ -   eval_precision = 0.5991\n",
      "04/29/2024 20:45:10 - INFO - __main__ -   eval_recall = 0.2912\n",
      "100% 1024/1024 [25:55<00:00,  1.52s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 20:48:21 - WARNING - __main__ - epoch 3 step 204 loss 0.16899\n",
      "[[0.84645426]\n",
      " [0.26730523]\n",
      " [0.13674682]\n",
      " ...\n",
      " [0.18480729]\n",
      " [0.05658848]\n",
      " [0.06169963]]\n",
      "04/29/2024 20:50:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:50:31 - INFO - __main__ -   auc_score = 0.8748\n",
      "04/29/2024 20:50:31 - INFO - __main__ -   eval_f1 = 0.3077\n",
      "04/29/2024 20:50:31 - INFO - __main__ -   eval_precision = 0.6528\n",
      "04/29/2024 20:50:31 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 20:53:29 - WARNING - __main__ - epoch 3 step 408 loss 0.17371\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9075266 ]\n",
      " [0.18243456]\n",
      " [0.12064409]\n",
      " ...\n",
      " [0.35863107]\n",
      " [0.23481807]\n",
      " [0.14737956]]\n",
      "04/29/2024 20:55:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 20:55:40 - INFO - __main__ -   auc_score = 0.8777\n",
      "04/29/2024 20:55:40 - INFO - __main__ -   eval_f1 = 0.4189\n",
      "04/29/2024 20:55:40 - INFO - __main__ -   eval_precision = 0.5945\n",
      "04/29/2024 20:55:40 - INFO - __main__ -   eval_recall = 0.3233\n",
      " 60% 611/1024 [13:24<06:01,  1.14it/s]04/29/2024 20:58:48 - WARNING - __main__ - epoch 3 step 612 loss 0.17519\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9371266 ]\n",
      " [0.39584875]\n",
      " [0.38883933]\n",
      " ...\n",
      " [0.5421739 ]\n",
      " [0.29504344]\n",
      " [0.17327648]]\n",
      "04/29/2024 21:00:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:00:58 - INFO - __main__ -   auc_score = 0.8788\n",
      "04/29/2024 21:00:58 - INFO - __main__ -   eval_f1 = 0.475\n",
      "04/29/2024 21:00:58 - INFO - __main__ -   eval_precision = 0.4931\n",
      "04/29/2024 21:00:58 - INFO - __main__ -   eval_recall = 0.4582\n",
      " 80% 815/1024 [18:43<03:02,  1.14it/s]04/29/2024 21:04:06 - WARNING - __main__ - epoch 3 step 816 loss 0.17573\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.91719675]\n",
      " [0.24091572]\n",
      " [0.29001665]\n",
      " ...\n",
      " [0.23535097]\n",
      " [0.10419349]\n",
      " [0.05271075]]\n",
      "04/29/2024 21:06:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:06:16 - INFO - __main__ -   auc_score = 0.8725\n",
      "04/29/2024 21:06:16 - INFO - __main__ -   eval_f1 = 0.3875\n",
      "04/29/2024 21:06:16 - INFO - __main__ -   eval_precision = 0.6373\n",
      "04/29/2024 21:06:16 - INFO - __main__ -   eval_recall = 0.2784\n",
      "100% 1019/1024 [23:51<00:04,  1.14it/s]04/29/2024 21:09:15 - WARNING - __main__ - epoch 3 step 1020 loss 0.17526\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.89972126]\n",
      " [0.17387697]\n",
      " [0.22838007]\n",
      " ...\n",
      " [0.19610661]\n",
      " [0.10503864]\n",
      " [0.05093447]]\n",
      "04/29/2024 21:11:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:11:25 - INFO - __main__ -   auc_score = 0.8744\n",
      "04/29/2024 21:11:25 - INFO - __main__ -   eval_f1 = 0.3082\n",
      "04/29/2024 21:11:25 - INFO - __main__ -   eval_precision = 0.7077\n",
      "04/29/2024 21:11:25 - INFO - __main__ -   eval_recall = 0.197\n",
      "100% 1024/1024 [26:05<00:00,  1.53s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 21:14:26 - WARNING - __main__ - epoch 4 step 204 loss 0.16334\n",
      "[[0.9509881 ]\n",
      " [0.37383494]\n",
      " [0.25900945]\n",
      " ...\n",
      " [0.16757104]\n",
      " [0.12532698]\n",
      " [0.05203465]]\n",
      "04/29/2024 21:16:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:16:37 - INFO - __main__ -   auc_score = 0.8753\n",
      "04/29/2024 21:16:37 - INFO - __main__ -   eval_f1 = 0.4297\n",
      "04/29/2024 21:16:37 - INFO - __main__ -   eval_precision = 0.5333\n",
      "04/29/2024 21:16:37 - INFO - __main__ -   eval_recall = 0.3597\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 21:19:35 - WARNING - __main__ - epoch 4 step 408 loss 0.16105\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9335915 ]\n",
      " [0.21136908]\n",
      " [0.23754643]\n",
      " ...\n",
      " [0.21335383]\n",
      " [0.13137424]\n",
      " [0.07983346]]\n",
      "04/29/2024 21:21:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:21:45 - INFO - __main__ -   auc_score = 0.8767\n",
      "04/29/2024 21:21:45 - INFO - __main__ -   eval_f1 = 0.3765\n",
      "04/29/2024 21:21:45 - INFO - __main__ -   eval_precision = 0.6345\n",
      "04/29/2024 21:21:45 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 60% 611/1024 [13:15<06:01,  1.14it/s]04/29/2024 21:24:44 - WARNING - __main__ - epoch 4 step 612 loss 0.14365\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9502533 ]\n",
      " [0.22540501]\n",
      " [0.2536234 ]\n",
      " ...\n",
      " [0.18858345]\n",
      " [0.14238636]\n",
      " [0.07460488]]\n",
      "04/29/2024 21:26:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:26:54 - INFO - __main__ -   auc_score = 0.8718\n",
      "04/29/2024 21:26:54 - INFO - __main__ -   eval_f1 = 0.3886\n",
      "04/29/2024 21:26:54 - INFO - __main__ -   eval_precision = 0.5837\n",
      "04/29/2024 21:26:54 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 80% 815/1024 [18:23<03:02,  1.14it/s]04/29/2024 21:29:52 - WARNING - __main__ - epoch 4 step 816 loss 0.15844\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.96620774]\n",
      " [0.2769179 ]\n",
      " [0.17737204]\n",
      " ...\n",
      " [0.26102406]\n",
      " [0.25893366]\n",
      " [0.10519548]]\n",
      "04/29/2024 21:32:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:32:03 - INFO - __main__ -   auc_score = 0.8718\n",
      "04/29/2024 21:32:03 - INFO - __main__ -   eval_f1 = 0.4215\n",
      "04/29/2024 21:32:03 - INFO - __main__ -   eval_precision = 0.5222\n",
      "04/29/2024 21:32:03 - INFO - __main__ -   eval_recall = 0.3533\n",
      "100% 1019/1024 [23:32<00:04,  1.14it/s]04/29/2024 21:35:01 - WARNING - __main__ - epoch 4 step 1020 loss 0.1683\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9435567 ]\n",
      " [0.19757573]\n",
      " [0.16626161]\n",
      " ...\n",
      " [0.23184499]\n",
      " [0.11295669]\n",
      " [0.09732942]]\n",
      "04/29/2024 21:37:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:37:12 - INFO - __main__ -   auc_score = 0.8735\n",
      "04/29/2024 21:37:12 - INFO - __main__ -   eval_f1 = 0.3828\n",
      "04/29/2024 21:37:12 - INFO - __main__ -   eval_precision = 0.6232\n",
      "04/29/2024 21:37:12 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 1024/1024 [25:46<00:00,  1.51s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 21:40:13 - WARNING - __main__ - epoch 5 step 204 loss 0.14336\n",
      "[[0.9625111 ]\n",
      " [0.3422473 ]\n",
      " [0.37539104]\n",
      " ...\n",
      " [0.25541472]\n",
      " [0.08031662]\n",
      " [0.0916876 ]]\n",
      "04/29/2024 21:42:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:42:23 - INFO - __main__ -   auc_score = 0.866\n",
      "04/29/2024 21:42:23 - INFO - __main__ -   eval_f1 = 0.3918\n",
      "04/29/2024 21:42:23 - INFO - __main__ -   eval_precision = 0.4919\n",
      "04/29/2024 21:42:23 - INFO - __main__ -   eval_recall = 0.3255\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 21:45:21 - WARNING - __main__ - epoch 5 step 408 loss 0.13614\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9518442 ]\n",
      " [0.20014817]\n",
      " [0.22273357]\n",
      " ...\n",
      " [0.21975027]\n",
      " [0.09542906]\n",
      " [0.08360361]]\n",
      "04/29/2024 21:47:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:47:32 - INFO - __main__ -   auc_score = 0.8691\n",
      "04/29/2024 21:47:32 - INFO - __main__ -   eval_f1 = 0.4132\n",
      "04/29/2024 21:47:32 - INFO - __main__ -   eval_precision = 0.5062\n",
      "04/29/2024 21:47:32 - INFO - __main__ -   eval_recall = 0.349\n",
      " 60% 611/1024 [13:15<06:01,  1.14it/s]04/29/2024 21:50:30 - WARNING - __main__ - epoch 5 step 612 loss 0.13647\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.97420484]\n",
      " [0.29393494]\n",
      " [0.29907885]\n",
      " ...\n",
      " [0.31842068]\n",
      " [0.06893276]\n",
      " [0.12801023]]\n",
      "04/29/2024 21:52:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:52:41 - INFO - __main__ -   auc_score = 0.8716\n",
      "04/29/2024 21:52:41 - INFO - __main__ -   eval_f1 = 0.4299\n",
      "04/29/2024 21:52:41 - INFO - __main__ -   eval_precision = 0.464\n",
      "04/29/2024 21:52:41 - INFO - __main__ -   eval_recall = 0.4004\n",
      " 80% 815/1024 [18:23<03:03,  1.14it/s]04/29/2024 21:55:39 - WARNING - __main__ - epoch 5 step 816 loss 0.13206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9780898 ]\n",
      " [0.42108205]\n",
      " [0.33369273]\n",
      " ...\n",
      " [0.30512398]\n",
      " [0.06745298]\n",
      " [0.06026986]]\n",
      "04/29/2024 21:57:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 21:57:49 - INFO - __main__ -   auc_score = 0.87\n",
      "04/29/2024 21:57:49 - INFO - __main__ -   eval_f1 = 0.3839\n",
      "04/29/2024 21:57:49 - INFO - __main__ -   eval_precision = 0.4868\n",
      "04/29/2024 21:57:49 - INFO - __main__ -   eval_recall = 0.3169\n",
      "100% 1019/1024 [23:32<00:04,  1.14it/s]04/29/2024 22:00:47 - WARNING - __main__ - epoch 5 step 1020 loss 0.16102\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9779668 ]\n",
      " [0.3748845 ]\n",
      " [0.3862407 ]\n",
      " ...\n",
      " [0.3152228 ]\n",
      " [0.17618474]\n",
      " [0.16639264]]\n",
      "04/29/2024 22:02:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:02:58 - INFO - __main__ -   auc_score = 0.8733\n",
      "04/29/2024 22:02:58 - INFO - __main__ -   eval_f1 = 0.4335\n",
      "04/29/2024 22:02:58 - INFO - __main__ -   eval_precision = 0.4817\n",
      "04/29/2024 22:02:58 - INFO - __main__ -   eval_recall = 0.394\n",
      "100% 1024/1024 [25:46<00:00,  1.51s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 22:05:59 - WARNING - __main__ - epoch 6 step 204 loss 0.12266\n",
      "[[0.98379666]\n",
      " [0.39296883]\n",
      " [0.23926263]\n",
      " ...\n",
      " [0.30935904]\n",
      " [0.04741959]\n",
      " [0.15947297]]\n",
      "04/29/2024 22:08:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:08:10 - INFO - __main__ -   auc_score = 0.8702\n",
      "04/29/2024 22:08:10 - INFO - __main__ -   eval_f1 = 0.44\n",
      "04/29/2024 22:08:10 - INFO - __main__ -   eval_precision = 0.4623\n",
      "04/29/2024 22:08:10 - INFO - __main__ -   eval_recall = 0.4197\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 22:11:08 - WARNING - __main__ - epoch 6 step 408 loss 0.13705\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.98325807]\n",
      " [0.5490883 ]\n",
      " [0.51626503]\n",
      " ...\n",
      " [0.4858608 ]\n",
      " [0.14795297]\n",
      " [0.45031068]]\n",
      "04/29/2024 22:13:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:13:18 - INFO - __main__ -   auc_score = 0.8709\n",
      "04/29/2024 22:13:18 - INFO - __main__ -   eval_f1 = 0.4447\n",
      "04/29/2024 22:13:18 - INFO - __main__ -   eval_precision = 0.3983\n",
      "04/29/2024 22:13:18 - INFO - __main__ -   eval_recall = 0.5032\n",
      " 60% 611/1024 [13:14<06:01,  1.14it/s]04/29/2024 22:16:16 - WARNING - __main__ - epoch 6 step 612 loss 0.13203\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.97401154]\n",
      " [0.11526294]\n",
      " [0.21129306]\n",
      " ...\n",
      " [0.10365833]\n",
      " [0.03051382]\n",
      " [0.05375297]]\n",
      "04/29/2024 22:18:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:18:27 - INFO - __main__ -   auc_score = 0.8651\n",
      "04/29/2024 22:18:27 - INFO - __main__ -   eval_f1 = 0.3543\n",
      "04/29/2024 22:18:27 - INFO - __main__ -   eval_precision = 0.5322\n",
      "04/29/2024 22:18:27 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 80% 815/1024 [18:23<03:02,  1.14it/s]04/29/2024 22:21:25 - WARNING - __main__ - epoch 6 step 816 loss 0.10888\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9868057 ]\n",
      " [0.34773007]\n",
      " [0.53680944]\n",
      " ...\n",
      " [0.10154084]\n",
      " [0.03717032]\n",
      " [0.0718806 ]]\n",
      "04/29/2024 22:23:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:23:35 - INFO - __main__ -   auc_score = 0.8666\n",
      "04/29/2024 22:23:35 - INFO - __main__ -   eval_f1 = 0.3971\n",
      "04/29/2024 22:23:35 - INFO - __main__ -   eval_precision = 0.4568\n",
      "04/29/2024 22:23:35 - INFO - __main__ -   eval_recall = 0.3512\n",
      "100% 1019/1024 [23:31<00:04,  1.14it/s]04/29/2024 22:26:33 - WARNING - __main__ - epoch 6 step 1020 loss 0.12633\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.981498  ]\n",
      " [0.18734801]\n",
      " [0.33523858]\n",
      " ...\n",
      " [0.10364051]\n",
      " [0.02200656]\n",
      " [0.03916666]]\n",
      "04/29/2024 22:28:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:28:43 - INFO - __main__ -   auc_score = 0.8669\n",
      "04/29/2024 22:28:43 - INFO - __main__ -   eval_f1 = 0.3578\n",
      "04/29/2024 22:28:43 - INFO - __main__ -   eval_precision = 0.5079\n",
      "04/29/2024 22:28:43 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 1024/1024 [25:45<00:00,  1.51s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 22:31:44 - WARNING - __main__ - epoch 7 step 204 loss 0.09667\n",
      "[[0.9858358 ]\n",
      " [0.1832976 ]\n",
      " [0.29687452]\n",
      " ...\n",
      " [0.03665707]\n",
      " [0.01022108]\n",
      " [0.02010537]]\n",
      "04/29/2024 22:33:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:33:55 - INFO - __main__ -   auc_score = 0.8664\n",
      "04/29/2024 22:33:55 - INFO - __main__ -   eval_f1 = 0.3788\n",
      "04/29/2024 22:33:55 - INFO - __main__ -   eval_precision = 0.4965\n",
      "04/29/2024 22:33:55 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 40% 407/1024 [08:05<09:00,  1.14it/s]04/29/2024 22:36:53 - WARNING - __main__ - epoch 7 step 408 loss 0.11331\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.98875016]\n",
      " [0.39611262]\n",
      " [0.30509093]\n",
      " ...\n",
      " [0.06228683]\n",
      " [0.01451252]\n",
      " [0.02969896]]\n",
      "04/29/2024 22:39:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:39:03 - INFO - __main__ -   auc_score = 0.86\n",
      "04/29/2024 22:39:03 - INFO - __main__ -   eval_f1 = 0.3744\n",
      "04/29/2024 22:39:03 - INFO - __main__ -   eval_precision = 0.4665\n",
      "04/29/2024 22:39:03 - INFO - __main__ -   eval_recall = 0.3126\n",
      " 60% 611/1024 [13:14<06:01,  1.14it/s]04/29/2024 22:42:01 - WARNING - __main__ - epoch 7 step 612 loss 0.11833\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9895891 ]\n",
      " [0.21762285]\n",
      " [0.28667095]\n",
      " ...\n",
      " [0.09925365]\n",
      " [0.02876835]\n",
      " [0.04333262]]\n",
      "04/29/2024 22:44:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:44:12 - INFO - __main__ -   auc_score = 0.8648\n",
      "04/29/2024 22:44:12 - INFO - __main__ -   eval_f1 = 0.393\n",
      "04/29/2024 22:44:12 - INFO - __main__ -   eval_precision = 0.4688\n",
      "04/29/2024 22:44:12 - INFO - __main__ -   eval_recall = 0.3383\n",
      " 80% 815/1024 [18:23<03:02,  1.14it/s]04/29/2024 22:47:10 - WARNING - __main__ - epoch 7 step 816 loss 0.11238\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.99053323]\n",
      " [0.12138966]\n",
      " [0.24707033]\n",
      " ...\n",
      " [0.08735234]\n",
      " [0.02913207]\n",
      " [0.03943008]]\n",
      "04/29/2024 22:49:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:49:20 - INFO - __main__ -   auc_score = 0.8658\n",
      "04/29/2024 22:49:20 - INFO - __main__ -   eval_f1 = 0.3894\n",
      "04/29/2024 22:49:20 - INFO - __main__ -   eval_precision = 0.4711\n",
      "04/29/2024 22:49:20 - INFO - __main__ -   eval_recall = 0.3319\n",
      "100% 1019/1024 [23:31<00:04,  1.14it/s]04/29/2024 22:52:19 - WARNING - __main__ - epoch 7 step 1020 loss 0.1324\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9882748 ]\n",
      " [0.21222436]\n",
      " [0.37159178]\n",
      " ...\n",
      " [0.05010784]\n",
      " [0.01532896]\n",
      " [0.01934512]]\n",
      "04/29/2024 22:54:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:54:29 - INFO - __main__ -   auc_score = 0.8556\n",
      "04/29/2024 22:54:29 - INFO - __main__ -   eval_f1 = 0.3511\n",
      "04/29/2024 22:54:29 - INFO - __main__ -   eval_precision = 0.4632\n",
      "04/29/2024 22:54:29 - INFO - __main__ -   eval_recall = 0.2827\n",
      "100% 1024/1024 [25:45<00:00,  1.51s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [02:57<11:58,  1.14it/s]04/29/2024 22:57:30 - WARNING - __main__ - epoch 8 step 204 loss 0.09189\n",
      "[[0.99094486]\n",
      " [0.11900666]\n",
      " [0.24321066]\n",
      " ...\n",
      " [0.05168254]\n",
      " [0.01177464]\n",
      " [0.02051687]]\n",
      "04/29/2024 22:59:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 22:59:41 - INFO - __main__ -   auc_score = 0.8599\n",
      "04/29/2024 22:59:41 - INFO - __main__ -   eval_f1 = 0.3731\n",
      "04/29/2024 22:59:41 - INFO - __main__ -   eval_precision = 0.4579\n",
      "04/29/2024 22:59:41 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 40% 407/1024 [08:06<09:00,  1.14it/s]04/29/2024 23:02:39 - WARNING - __main__ - epoch 8 step 408 loss 0.11102\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.99143887]\n",
      " [0.3171147 ]\n",
      " [0.41380212]\n",
      " ...\n",
      " [0.038151  ]\n",
      " [0.01443503]\n",
      " [0.01946241]]\n",
      "04/29/2024 23:04:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:04:50 - INFO - __main__ -   auc_score = 0.8573\n",
      "04/29/2024 23:04:50 - INFO - __main__ -   eval_f1 = 0.3915\n",
      "04/29/2024 23:04:50 - INFO - __main__ -   eval_precision = 0.4388\n",
      "04/29/2024 23:04:50 - INFO - __main__ -   eval_recall = 0.3533\n",
      " 60% 611/1024 [13:15<06:01,  1.14it/s]04/29/2024 23:07:48 - WARNING - __main__ - epoch 8 step 612 loss 0.10653\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9905121 ]\n",
      " [0.11449791]\n",
      " [0.29409942]\n",
      " ...\n",
      " [0.03367102]\n",
      " [0.01478946]\n",
      " [0.01854227]]\n",
      "04/29/2024 23:09:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:09:58 - INFO - __main__ -   auc_score = 0.8604\n",
      "04/29/2024 23:09:58 - INFO - __main__ -   eval_f1 = 0.3766\n",
      "04/29/2024 23:09:58 - INFO - __main__ -   eval_precision = 0.4639\n",
      "04/29/2024 23:09:58 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 80% 815/1024 [18:23<03:03,  1.14it/s]04/29/2024 23:12:57 - WARNING - __main__ - epoch 8 step 816 loss 0.09247\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.98990333]\n",
      " [0.13214761]\n",
      " [0.42720795]\n",
      " ...\n",
      " [0.03799598]\n",
      " [0.01649794]\n",
      " [0.01701281]]\n",
      "04/29/2024 23:15:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 23:15:07 - INFO - __main__ -   auc_score = 0.8581\n",
      "04/29/2024 23:15:07 - INFO - __main__ -   eval_f1 = 0.3669\n",
      "04/29/2024 23:15:07 - INFO - __main__ -   eval_precision = 0.4528\n",
      "04/29/2024 23:15:07 - INFO - __main__ -   eval_recall = 0.3084\n",
      "04/29/2024 23:15:07 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 80% 815/1024 [20:34<05:16,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "797Q-t1kSgfZ",
    "outputId": "0f4b360d-9655-4265-efb8-53037d8d2637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949071786785058\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 23:20:41 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 23:20:41 - INFO - __main__ -   auc_score = 0.8713\n",
      "04/29/2024 23:20:41 - INFO - __main__ -   test_f1 = 0.4275\n",
      "04/29/2024 23:20:41 - INFO - __main__ -   test_precision = 0.4434\n",
      "04/29/2024 23:20:41 - INFO - __main__ -   test_recall = 0.4126\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTeCY-hd38hS"
   },
   "source": [
    "### codet5p-2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfCoEUBrAkAs"
   },
   "source": [
    "Test with tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "sgCaD2X4AxkG",
    "outputId": "893c81e4-e1af-45ec-8e01-50a53585be71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.cls_token:  <s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (RobertaModel, RobertaTokenizer, RobertaConfig, T5ForConditionalGeneration, T5Config,\n",
    "                          PLBartTokenizer, PLBartForConditionalGeneration, PLBartConfig, CodeGenTokenizer)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5p-220m-bimodal\")\n",
    "print('tokenizer.cls_token: ', tokenizer.cls_token)\n",
    "\n",
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "IN8pQCynCSCe",
    "outputId": "8a596e07-4b25-402e-8ca4-6869fe277bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.cls_token:  <s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5p-770m\")\n",
    "print('tokenizer.cls_token: ', tokenizer.cls_token)\n",
    "\n",
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "WkOMHIxCCvuk",
    "outputId": "e96476e9-02dd-499e-ba25-1ea3ed08bd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.cls_token:  None\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = CodeGenTokenizer.from_pretrained(\"Salesforce/codet5p-2b\")\n",
    "print('tokenizer.cls_token: ', tokenizer.cls_token)\n",
    "\n",
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "yse2Fk16EVzA",
    "outputId": "384c907b-5165-4e97-9c43-9a7caffb8b1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token = '<s>'\n",
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BfAE9yNdkTj"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_PEPzhg3DKp",
    "outputId": "6517bc93-9052-4a43-9345-1b6112c5f923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-2b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 20:42:36 - WARNING - __main__ - epoch 0 step 102 loss 0.29174\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 20:42:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:42:47 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 20:42:47 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 20:42:47 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 20:42:57 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:42:57 - INFO - __main__ -   auc_score = 0.7821\n",
      "04/26/2024 20:42:57 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 20:42:57 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 20:42:57 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [00:59<00:58,  5.32it/s]04/26/2024 20:43:16 - WARNING - __main__ - epoch 0 step 204 loss 0.26471\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 20:43:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:43:27 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 20:43:27 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 20:43:27 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 20:43:37 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:43:37 - INFO - __main__ -   auc_score = 0.7972\n",
      "04/26/2024 20:43:37 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 20:43:37 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 20:43:37 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [01:39<00:39,  5.30it/s]04/26/2024 20:43:56 - WARNING - __main__ - epoch 0 step 306 loss 0.25631\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:44:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:44:06 - INFO - __main__ -   eval_f1 = 0.0249\n",
      "04/26/2024 20:44:06 - INFO - __main__ -   eval_precision = 0.4\n",
      "04/26/2024 20:44:06 - INFO - __main__ -   eval_recall = 0.0128\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:44:18 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:44:18 - INFO - __main__ -   auc_score = 0.8149\n",
      "04/26/2024 20:44:18 - INFO - __main__ -   test_f1 = 0.0287\n",
      "04/26/2024 20:44:18 - INFO - __main__ -   test_precision = 0.5385\n",
      "04/26/2024 20:44:18 - INFO - __main__ -   test_recall = 0.0147\n",
      " 79% 407/512 [02:20<00:19,  5.31it/s]04/26/2024 20:44:37 - WARNING - __main__ - epoch 0 step 408 loss 0.25605\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:44:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:44:47 - INFO - __main__ -   eval_f1 = 0.112\n",
      "04/26/2024 20:44:47 - INFO - __main__ -   eval_precision = 0.5686\n",
      "04/26/2024 20:44:47 - INFO - __main__ -   eval_recall = 0.0621\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:44:59 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:44:59 - INFO - __main__ -   auc_score = 0.819\n",
      "04/26/2024 20:44:59 - INFO - __main__ -   test_f1 = 0.0838\n",
      "04/26/2024 20:44:59 - INFO - __main__ -   test_precision = 0.44\n",
      "04/26/2024 20:44:59 - INFO - __main__ -   test_recall = 0.0463\n",
      " 99% 509/512 [03:02<00:00,  5.29it/s]04/26/2024 20:45:19 - WARNING - __main__ - epoch 0 step 510 loss 0.23509\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:45:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:45:29 - INFO - __main__ -   eval_f1 = 0.1442\n",
      "04/26/2024 20:45:29 - INFO - __main__ -   eval_precision = 0.527\n",
      "04/26/2024 20:45:29 - INFO - __main__ -   eval_recall = 0.0835\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:45:41 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:45:41 - INFO - __main__ -   auc_score = 0.8263\n",
      "04/26/2024 20:45:41 - INFO - __main__ -   test_f1 = 0.0921\n",
      "04/26/2024 20:45:41 - INFO - __main__ -   test_precision = 0.5217\n",
      "04/26/2024 20:45:41 - INFO - __main__ -   test_recall = 0.0505\n",
      "100% 512/512 [03:25<00:00,  2.49it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 20:46:01 - WARNING - __main__ - epoch 1 step 102 loss 0.23441\n",
      "04/26/2024 20:46:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:46:11 - INFO - __main__ -   eval_f1 = 0.0719\n",
      "04/26/2024 20:46:11 - INFO - __main__ -   eval_precision = 0.5294\n",
      "04/26/2024 20:46:11 - INFO - __main__ -   eval_recall = 0.0385\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:46:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:46:21 - INFO - __main__ -   auc_score = 0.8407\n",
      "04/26/2024 20:46:21 - INFO - __main__ -   test_f1 = 0.048\n",
      "04/26/2024 20:46:21 - INFO - __main__ -   test_precision = 0.48\n",
      "04/26/2024 20:46:21 - INFO - __main__ -   test_recall = 0.0253\n",
      " 40% 203/512 [00:58<00:58,  5.30it/s]04/26/2024 20:46:41 - WARNING - __main__ - epoch 1 step 204 loss 0.22576\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:46:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:46:51 - INFO - __main__ -   eval_f1 = 0.2061\n",
      "04/26/2024 20:46:51 - INFO - __main__ -   eval_precision = 0.488\n",
      "04/26/2024 20:46:51 - INFO - __main__ -   eval_recall = 0.1306\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:47:03 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:47:03 - INFO - __main__ -   auc_score = 0.8388\n",
      "04/26/2024 20:47:03 - INFO - __main__ -   test_f1 = 0.1827\n",
      "04/26/2024 20:47:03 - INFO - __main__ -   test_precision = 0.4655\n",
      "04/26/2024 20:47:03 - INFO - __main__ -   test_recall = 0.1137\n",
      " 60% 305/512 [01:40<00:38,  5.32it/s]04/26/2024 20:47:22 - WARNING - __main__ - epoch 1 step 306 loss 0.23914\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:47:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:47:32 - INFO - __main__ -   eval_f1 = 0.342\n",
      "04/26/2024 20:47:32 - INFO - __main__ -   eval_precision = 0.384\n",
      "04/26/2024 20:47:32 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:47:44 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:47:44 - INFO - __main__ -   auc_score = 0.8323\n",
      "04/26/2024 20:47:44 - INFO - __main__ -   test_f1 = 0.3129\n",
      "04/26/2024 20:47:44 - INFO - __main__ -   test_precision = 0.3479\n",
      "04/26/2024 20:47:44 - INFO - __main__ -   test_recall = 0.2842\n",
      " 79% 407/512 [02:21<00:19,  5.31it/s]04/26/2024 20:48:03 - WARNING - __main__ - epoch 1 step 408 loss 0.23687\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:48:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:48:14 - INFO - __main__ -   eval_f1 = 0.3523\n",
      "04/26/2024 20:48:14 - INFO - __main__ -   eval_precision = 0.3838\n",
      "04/26/2024 20:48:14 - INFO - __main__ -   eval_recall = 0.3255\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:48:26 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:48:26 - INFO - __main__ -   auc_score = 0.8423\n",
      "04/26/2024 20:48:26 - INFO - __main__ -   test_f1 = 0.3425\n",
      "04/26/2024 20:48:26 - INFO - __main__ -   test_precision = 0.3741\n",
      "04/26/2024 20:48:26 - INFO - __main__ -   test_recall = 0.3158\n",
      " 99% 509/512 [03:03<00:00,  5.31it/s]04/26/2024 20:48:45 - WARNING - __main__ - epoch 1 step 510 loss 0.20334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:48:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:48:55 - INFO - __main__ -   eval_f1 = 0.214\n",
      "04/26/2024 20:48:55 - INFO - __main__ -   eval_precision = 0.4885\n",
      "04/26/2024 20:48:55 - INFO - __main__ -   eval_recall = 0.137\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:49:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:49:06 - INFO - __main__ -   auc_score = 0.8441\n",
      "04/26/2024 20:49:06 - INFO - __main__ -   test_f1 = 0.1938\n",
      "04/26/2024 20:49:06 - INFO - __main__ -   test_precision = 0.5437\n",
      "04/26/2024 20:49:06 - INFO - __main__ -   test_recall = 0.1179\n",
      "100% 512/512 [03:24<00:00,  2.50it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.32it/s]04/26/2024 20:49:25 - WARNING - __main__ - epoch 2 step 102 loss 0.21002\n",
      "04/26/2024 20:49:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:49:36 - INFO - __main__ -   eval_f1 = 0.352\n",
      "04/26/2024 20:49:36 - INFO - __main__ -   eval_precision = 0.4353\n",
      "04/26/2024 20:49:36 - INFO - __main__ -   eval_recall = 0.2955\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:49:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:49:46 - INFO - __main__ -   auc_score = 0.8444\n",
      "04/26/2024 20:49:46 - INFO - __main__ -   test_f1 = 0.3108\n",
      "04/26/2024 20:49:46 - INFO - __main__ -   test_precision = 0.3935\n",
      "04/26/2024 20:49:46 - INFO - __main__ -   test_recall = 0.2568\n",
      " 40% 203/512 [00:59<00:58,  5.28it/s]04/26/2024 20:50:05 - WARNING - __main__ - epoch 2 step 204 loss 0.20139\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:50:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:50:16 - INFO - __main__ -   eval_f1 = 0.1128\n",
      "04/26/2024 20:50:16 - INFO - __main__ -   eval_precision = 0.617\n",
      "04/26/2024 20:50:16 - INFO - __main__ -   eval_recall = 0.0621\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:50:26 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:50:26 - INFO - __main__ -   auc_score = 0.8476\n",
      "04/26/2024 20:50:26 - INFO - __main__ -   test_f1 = 0.0875\n",
      "04/26/2024 20:50:26 - INFO - __main__ -   test_precision = 0.7857\n",
      "04/26/2024 20:50:26 - INFO - __main__ -   test_recall = 0.0463\n",
      " 60% 305/512 [01:38<00:39,  5.27it/s]04/26/2024 20:50:45 - WARNING - __main__ - epoch 2 step 306 loss 0.21721\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:50:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:50:56 - INFO - __main__ -   eval_f1 = 0.2098\n",
      "04/26/2024 20:50:56 - INFO - __main__ -   eval_precision = 0.4476\n",
      "04/26/2024 20:50:56 - INFO - __main__ -   eval_recall = 0.137\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:51:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:51:06 - INFO - __main__ -   auc_score = 0.8473\n",
      "04/26/2024 20:51:06 - INFO - __main__ -   test_f1 = 0.1932\n",
      "04/26/2024 20:51:06 - INFO - __main__ -   test_precision = 0.4957\n",
      "04/26/2024 20:51:06 - INFO - __main__ -   test_recall = 0.12\n",
      " 79% 407/512 [02:18<00:19,  5.31it/s]04/26/2024 20:51:25 - WARNING - __main__ - epoch 2 step 408 loss 0.21699\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:51:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:51:36 - INFO - __main__ -   eval_f1 = 0.2259\n",
      "04/26/2024 20:51:36 - INFO - __main__ -   eval_precision = 0.5037\n",
      "04/26/2024 20:51:36 - INFO - __main__ -   eval_recall = 0.1456\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:51:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:51:46 - INFO - __main__ -   auc_score = 0.847\n",
      "04/26/2024 20:51:46 - INFO - __main__ -   test_f1 = 0.2133\n",
      "04/26/2024 20:51:46 - INFO - __main__ -   test_precision = 0.512\n",
      "04/26/2024 20:51:46 - INFO - __main__ -   test_recall = 0.1347\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 20:52:05 - WARNING - __main__ - epoch 2 step 510 loss 0.20854\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:52:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:52:16 - INFO - __main__ -   eval_f1 = 0.3474\n",
      "04/26/2024 20:52:16 - INFO - __main__ -   eval_precision = 0.3978\n",
      "04/26/2024 20:52:16 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:52:26 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:52:26 - INFO - __main__ -   auc_score = 0.8471\n",
      "04/26/2024 20:52:26 - INFO - __main__ -   test_f1 = 0.3208\n",
      "04/26/2024 20:52:26 - INFO - __main__ -   test_precision = 0.3793\n",
      "04/26/2024 20:52:26 - INFO - __main__ -   test_recall = 0.2779\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 20:52:45 - WARNING - __main__ - epoch 3 step 102 loss 0.19757\n",
      "04/26/2024 20:52:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:52:56 - INFO - __main__ -   eval_f1 = 0.2599\n",
      "04/26/2024 20:52:56 - INFO - __main__ -   eval_precision = 0.4545\n",
      "04/26/2024 20:52:56 - INFO - __main__ -   eval_recall = 0.182\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:53:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:53:06 - INFO - __main__ -   auc_score = 0.843\n",
      "04/26/2024 20:53:06 - INFO - __main__ -   test_f1 = 0.2399\n",
      "04/26/2024 20:53:06 - INFO - __main__ -   test_precision = 0.4611\n",
      "04/26/2024 20:53:06 - INFO - __main__ -   test_recall = 0.1621\n",
      " 40% 203/512 [00:59<00:58,  5.31it/s]04/26/2024 20:53:25 - WARNING - __main__ - epoch 3 step 204 loss 0.19615\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:53:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:53:36 - INFO - __main__ -   eval_f1 = 0.2614\n",
      "04/26/2024 20:53:36 - INFO - __main__ -   eval_precision = 0.4503\n",
      "04/26/2024 20:53:36 - INFO - __main__ -   eval_recall = 0.1842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:53:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:53:46 - INFO - __main__ -   auc_score = 0.8439\n",
      "04/26/2024 20:53:46 - INFO - __main__ -   test_f1 = 0.2466\n",
      "04/26/2024 20:53:46 - INFO - __main__ -   test_precision = 0.4451\n",
      "04/26/2024 20:53:46 - INFO - __main__ -   test_recall = 0.1705\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/26/2024 20:54:05 - WARNING - __main__ - epoch 3 step 306 loss 0.2051\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:54:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:54:16 - INFO - __main__ -   eval_f1 = 0.1296\n",
      "04/26/2024 20:54:16 - INFO - __main__ -   eval_precision = 0.4795\n",
      "04/26/2024 20:54:16 - INFO - __main__ -   eval_recall = 0.0749\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:54:26 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:54:26 - INFO - __main__ -   auc_score = 0.8392\n",
      "04/26/2024 20:54:26 - INFO - __main__ -   test_f1 = 0.1351\n",
      "04/26/2024 20:54:26 - INFO - __main__ -   test_precision = 0.6207\n",
      "04/26/2024 20:54:26 - INFO - __main__ -   test_recall = 0.0758\n",
      " 79% 407/512 [02:18<00:19,  5.28it/s]04/26/2024 20:54:45 - WARNING - __main__ - epoch 3 step 408 loss 0.18952\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:54:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:54:56 - INFO - __main__ -   eval_f1 = 0.2215\n",
      "04/26/2024 20:54:56 - INFO - __main__ -   eval_precision = 0.4855\n",
      "04/26/2024 20:54:56 - INFO - __main__ -   eval_recall = 0.1435\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:55:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:55:06 - INFO - __main__ -   auc_score = 0.8453\n",
      "04/26/2024 20:55:06 - INFO - __main__ -   test_f1 = 0.206\n",
      "04/26/2024 20:55:06 - INFO - __main__ -   test_precision = 0.4882\n",
      "04/26/2024 20:55:06 - INFO - __main__ -   test_recall = 0.1305\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 20:55:25 - WARNING - __main__ - epoch 3 step 510 loss 0.19958\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:55:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:55:36 - INFO - __main__ -   eval_f1 = 0.3156\n",
      "04/26/2024 20:55:36 - INFO - __main__ -   eval_precision = 0.4328\n",
      "04/26/2024 20:55:36 - INFO - __main__ -   eval_recall = 0.2484\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:55:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:55:46 - INFO - __main__ -   auc_score = 0.8409\n",
      "04/26/2024 20:55:46 - INFO - __main__ -   test_f1 = 0.296\n",
      "04/26/2024 20:55:46 - INFO - __main__ -   test_precision = 0.4315\n",
      "04/26/2024 20:55:46 - INFO - __main__ -   test_recall = 0.2253\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.28it/s]04/26/2024 20:56:06 - WARNING - __main__ - epoch 4 step 102 loss 0.17297\n",
      "04/26/2024 20:56:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:56:16 - INFO - __main__ -   eval_f1 = 0.3563\n",
      "04/26/2024 20:56:16 - INFO - __main__ -   eval_precision = 0.3297\n",
      "04/26/2024 20:56:16 - INFO - __main__ -   eval_recall = 0.3876\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:56:28 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:56:28 - INFO - __main__ -   auc_score = 0.8396\n",
      "04/26/2024 20:56:28 - INFO - __main__ -   test_f1 = 0.3445\n",
      "04/26/2024 20:56:28 - INFO - __main__ -   test_precision = 0.334\n",
      "04/26/2024 20:56:28 - INFO - __main__ -   test_recall = 0.3558\n",
      " 40% 203/512 [01:00<00:58,  5.32it/s]04/26/2024 20:56:47 - WARNING - __main__ - epoch 4 step 204 loss 0.1867\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:56:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:56:58 - INFO - __main__ -   eval_f1 = 0.2857\n",
      "04/26/2024 20:56:58 - INFO - __main__ -   eval_precision = 0.4798\n",
      "04/26/2024 20:56:58 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:57:08 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:57:08 - INFO - __main__ -   auc_score = 0.8376\n",
      "04/26/2024 20:57:08 - INFO - __main__ -   test_f1 = 0.2691\n",
      "04/26/2024 20:57:08 - INFO - __main__ -   test_precision = 0.4916\n",
      "04/26/2024 20:57:08 - INFO - __main__ -   test_recall = 0.1853\n",
      " 60% 305/512 [01:40<00:39,  5.31it/s]04/26/2024 20:57:27 - WARNING - __main__ - epoch 4 step 306 loss 0.1942\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:57:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:57:38 - INFO - __main__ -   eval_f1 = 0.354\n",
      "04/26/2024 20:57:38 - INFO - __main__ -   eval_precision = 0.4463\n",
      "04/26/2024 20:57:38 - INFO - __main__ -   eval_recall = 0.2934\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:57:48 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:57:48 - INFO - __main__ -   auc_score = 0.841\n",
      "04/26/2024 20:57:48 - INFO - __main__ -   test_f1 = 0.3191\n",
      "04/26/2024 20:57:48 - INFO - __main__ -   test_precision = 0.4332\n",
      "04/26/2024 20:57:48 - INFO - __main__ -   test_recall = 0.2526\n",
      " 79% 407/512 [02:20<00:19,  5.31it/s]04/26/2024 20:58:07 - WARNING - __main__ - epoch 4 step 408 loss 0.18396\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:58:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:58:18 - INFO - __main__ -   eval_f1 = 0.2777\n",
      "04/26/2024 20:58:18 - INFO - __main__ -   eval_precision = 0.4476\n",
      "04/26/2024 20:58:18 - INFO - __main__ -   eval_recall = 0.2013\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:58:28 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:58:28 - INFO - __main__ -   auc_score = 0.8404\n",
      "04/26/2024 20:58:28 - INFO - __main__ -   test_f1 = 0.2642\n",
      "04/26/2024 20:58:28 - INFO - __main__ -   test_precision = 0.4886\n",
      "04/26/2024 20:58:28 - INFO - __main__ -   test_recall = 0.1811\n",
      " 99% 509/512 [03:00<00:00,  5.31it/s]04/26/2024 20:58:47 - WARNING - __main__ - epoch 4 step 510 loss 0.17744\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:58:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:58:58 - INFO - __main__ -   eval_f1 = 0.3713\n",
      "04/26/2024 20:58:58 - INFO - __main__ -   eval_precision = 0.3836\n",
      "04/26/2024 20:58:58 - INFO - __main__ -   eval_recall = 0.3597\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:59:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:59:11 - INFO - __main__ -   auc_score = 0.8376\n",
      "04/26/2024 20:59:11 - INFO - __main__ -   test_f1 = 0.339\n",
      "04/26/2024 20:59:11 - INFO - __main__ -   test_precision = 0.3688\n",
      "04/26/2024 20:59:11 - INFO - __main__ -   test_recall = 0.3137\n",
      "100% 512/512 [03:24<00:00,  2.50it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 20:59:30 - WARNING - __main__ - epoch 5 step 102 loss 0.15531\n",
      "04/26/2024 20:59:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 20:59:41 - INFO - __main__ -   eval_f1 = 0.3201\n",
      "04/26/2024 20:59:41 - INFO - __main__ -   eval_precision = 0.4432\n",
      "04/26/2024 20:59:41 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 20:59:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 20:59:51 - INFO - __main__ -   auc_score = 0.836\n",
      "04/26/2024 20:59:51 - INFO - __main__ -   test_f1 = 0.2646\n",
      "04/26/2024 20:59:51 - INFO - __main__ -   test_precision = 0.4079\n",
      "04/26/2024 20:59:51 - INFO - __main__ -   test_recall = 0.1958\n",
      " 40% 203/512 [00:59<00:58,  5.32it/s]04/26/2024 21:00:10 - WARNING - __main__ - epoch 5 step 204 loss 0.1652\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:00:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:00:21 - INFO - __main__ -   eval_f1 = 0.3083\n",
      "04/26/2024 21:00:21 - INFO - __main__ -   eval_precision = 0.4007\n",
      "04/26/2024 21:00:21 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:00:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:00:31 - INFO - __main__ -   auc_score = 0.8298\n",
      "04/26/2024 21:00:31 - INFO - __main__ -   test_f1 = 0.3022\n",
      "04/26/2024 21:00:31 - INFO - __main__ -   test_precision = 0.4021\n",
      "04/26/2024 21:00:31 - INFO - __main__ -   test_recall = 0.2421\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/26/2024 21:00:50 - WARNING - __main__ - epoch 5 step 306 loss 0.16749\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:01:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:01:01 - INFO - __main__ -   eval_f1 = 0.2894\n",
      "04/26/2024 21:01:01 - INFO - __main__ -   eval_precision = 0.4286\n",
      "04/26/2024 21:01:01 - INFO - __main__ -   eval_recall = 0.2184\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:01:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:01:11 - INFO - __main__ -   auc_score = 0.8311\n",
      "04/26/2024 21:01:11 - INFO - __main__ -   test_f1 = 0.2894\n",
      "04/26/2024 21:01:11 - INFO - __main__ -   test_precision = 0.4435\n",
      "04/26/2024 21:01:11 - INFO - __main__ -   test_recall = 0.2147\n",
      " 79% 407/512 [02:18<00:19,  5.31it/s]04/26/2024 21:01:30 - WARNING - __main__ - epoch 5 step 408 loss 0.17636\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:01:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:01:41 - INFO - __main__ -   eval_f1 = 0.3561\n",
      "04/26/2024 21:01:41 - INFO - __main__ -   eval_precision = 0.3612\n",
      "04/26/2024 21:01:41 - INFO - __main__ -   eval_recall = 0.3512\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:01:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:01:51 - INFO - __main__ -   auc_score = 0.8346\n",
      "04/26/2024 21:01:51 - INFO - __main__ -   test_f1 = 0.3619\n",
      "04/26/2024 21:01:51 - INFO - __main__ -   test_precision = 0.3682\n",
      "04/26/2024 21:01:51 - INFO - __main__ -   test_recall = 0.3558\n",
      " 99% 509/512 [02:58<00:00,  5.32it/s]04/26/2024 21:02:10 - WARNING - __main__ - epoch 5 step 510 loss 0.16711\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:02:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:02:21 - INFO - __main__ -   eval_f1 = 0.3581\n",
      "04/26/2024 21:02:21 - INFO - __main__ -   eval_precision = 0.3777\n",
      "04/26/2024 21:02:21 - INFO - __main__ -   eval_recall = 0.3405\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:02:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:02:31 - INFO - __main__ -   auc_score = 0.8357\n",
      "04/26/2024 21:02:31 - INFO - __main__ -   test_f1 = 0.3322\n",
      "04/26/2024 21:02:31 - INFO - __main__ -   test_precision = 0.3673\n",
      "04/26/2024 21:02:31 - INFO - __main__ -   test_recall = 0.3032\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 21:02:50 - WARNING - __main__ - epoch 6 step 102 loss 0.14616\n",
      "04/26/2024 21:03:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:03:01 - INFO - __main__ -   eval_f1 = 0.2741\n",
      "04/26/2024 21:03:01 - INFO - __main__ -   eval_precision = 0.4619\n",
      "04/26/2024 21:03:01 - INFO - __main__ -   eval_recall = 0.1949\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:03:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:03:11 - INFO - __main__ -   auc_score = 0.8282\n",
      "04/26/2024 21:03:11 - INFO - __main__ -   test_f1 = 0.2537\n",
      "04/26/2024 21:03:11 - INFO - __main__ -   test_precision = 0.4359\n",
      "04/26/2024 21:03:11 - INFO - __main__ -   test_recall = 0.1789\n",
      " 40% 203/512 [00:58<00:58,  5.31it/s]04/26/2024 21:03:30 - WARNING - __main__ - epoch 6 step 204 loss 0.15641\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:03:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:03:41 - INFO - __main__ -   eval_f1 = 0.2895\n",
      "04/26/2024 21:03:41 - INFO - __main__ -   eval_precision = 0.4667\n",
      "04/26/2024 21:03:41 - INFO - __main__ -   eval_recall = 0.2099\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:03:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:03:51 - INFO - __main__ -   auc_score = 0.8343\n",
      "04/26/2024 21:03:51 - INFO - __main__ -   test_f1 = 0.2637\n",
      "04/26/2024 21:03:51 - INFO - __main__ -   test_precision = 0.445\n",
      "04/26/2024 21:03:51 - INFO - __main__ -   test_recall = 0.1874\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/26/2024 21:04:10 - WARNING - __main__ - epoch 6 step 306 loss 0.14154\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:04:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:04:21 - INFO - __main__ -   eval_f1 = 0.3624\n",
      "04/26/2024 21:04:21 - INFO - __main__ -   eval_precision = 0.3901\n",
      "04/26/2024 21:04:21 - INFO - __main__ -   eval_recall = 0.3383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:04:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:04:31 - INFO - __main__ -   auc_score = 0.829\n",
      "04/26/2024 21:04:31 - INFO - __main__ -   test_f1 = 0.3207\n",
      "04/26/2024 21:04:31 - INFO - __main__ -   test_precision = 0.3678\n",
      "04/26/2024 21:04:31 - INFO - __main__ -   test_recall = 0.2842\n",
      " 79% 407/512 [02:18<00:19,  5.32it/s]04/26/2024 21:04:50 - WARNING - __main__ - epoch 6 step 408 loss 0.1431\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:05:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:05:01 - INFO - __main__ -   eval_f1 = 0.355\n",
      "04/26/2024 21:05:01 - INFO - __main__ -   eval_precision = 0.3968\n",
      "04/26/2024 21:05:01 - INFO - __main__ -   eval_recall = 0.3212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:05:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:05:11 - INFO - __main__ -   auc_score = 0.829\n",
      "04/26/2024 21:05:11 - INFO - __main__ -   test_f1 = 0.3242\n",
      "04/26/2024 21:05:11 - INFO - __main__ -   test_precision = 0.3736\n",
      "04/26/2024 21:05:11 - INFO - __main__ -   test_recall = 0.2863\n",
      " 99% 509/512 [02:58<00:00,  5.32it/s]04/26/2024 21:05:30 - WARNING - __main__ - epoch 6 step 510 loss 0.16211\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:05:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:05:41 - INFO - __main__ -   eval_f1 = 0.3404\n",
      "04/26/2024 21:05:41 - INFO - __main__ -   eval_precision = 0.3568\n",
      "04/26/2024 21:05:41 - INFO - __main__ -   eval_recall = 0.3255\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:05:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:05:51 - INFO - __main__ -   auc_score = 0.8241\n",
      "04/26/2024 21:05:51 - INFO - __main__ -   test_f1 = 0.3172\n",
      "04/26/2024 21:05:51 - INFO - __main__ -   test_precision = 0.3494\n",
      "04/26/2024 21:05:51 - INFO - __main__ -   test_recall = 0.2905\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 21:06:11 - WARNING - __main__ - epoch 7 step 102 loss 0.13208\n",
      "04/26/2024 21:06:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:06:21 - INFO - __main__ -   eval_f1 = 0.3507\n",
      "04/26/2024 21:06:21 - INFO - __main__ -   eval_precision = 0.3717\n",
      "04/26/2024 21:06:21 - INFO - __main__ -   eval_recall = 0.3319\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:06:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:06:31 - INFO - __main__ -   auc_score = 0.828\n",
      "04/26/2024 21:06:31 - INFO - __main__ -   test_f1 = 0.3258\n",
      "04/26/2024 21:06:31 - INFO - __main__ -   test_precision = 0.3521\n",
      "04/26/2024 21:06:31 - INFO - __main__ -   test_recall = 0.3032\n",
      " 40% 203/512 [00:59<00:58,  5.31it/s]04/26/2024 21:06:51 - WARNING - __main__ - epoch 7 step 204 loss 0.13378\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:07:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:07:01 - INFO - __main__ -   eval_f1 = 0.3576\n",
      "04/26/2024 21:07:01 - INFO - __main__ -   eval_precision = 0.3303\n",
      "04/26/2024 21:07:01 - INFO - __main__ -   eval_recall = 0.3897\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:07:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:07:11 - INFO - __main__ -   auc_score = 0.8304\n",
      "04/26/2024 21:07:11 - INFO - __main__ -   test_f1 = 0.3525\n",
      "04/26/2024 21:07:11 - INFO - __main__ -   test_precision = 0.3327\n",
      "04/26/2024 21:07:11 - INFO - __main__ -   test_recall = 0.3747\n",
      " 60% 305/512 [01:39<00:38,  5.32it/s]04/26/2024 21:07:31 - WARNING - __main__ - epoch 7 step 306 loss 0.13719\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:07:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:07:41 - INFO - __main__ -   eval_f1 = 0.3468\n",
      "04/26/2024 21:07:41 - INFO - __main__ -   eval_precision = 0.3446\n",
      "04/26/2024 21:07:41 - INFO - __main__ -   eval_recall = 0.349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:07:51 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:07:51 - INFO - __main__ -   auc_score = 0.8276\n",
      "04/26/2024 21:07:51 - INFO - __main__ -   test_f1 = 0.3326\n",
      "04/26/2024 21:07:51 - INFO - __main__ -   test_precision = 0.3415\n",
      "04/26/2024 21:07:51 - INFO - __main__ -   test_recall = 0.3242\n",
      " 79% 407/512 [02:19<00:19,  5.30it/s]04/26/2024 21:08:11 - WARNING - __main__ - epoch 7 step 408 loss 0.13716\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:08:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:08:21 - INFO - __main__ -   eval_f1 = 0.36\n",
      "04/26/2024 21:08:21 - INFO - __main__ -   eval_precision = 0.3242\n",
      "04/26/2024 21:08:21 - INFO - __main__ -   eval_recall = 0.4047\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:08:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:08:31 - INFO - __main__ -   auc_score = 0.8236\n",
      "04/26/2024 21:08:31 - INFO - __main__ -   test_f1 = 0.3451\n",
      "04/26/2024 21:08:31 - INFO - __main__ -   test_precision = 0.3153\n",
      "04/26/2024 21:08:31 - INFO - __main__ -   test_recall = 0.3811\n",
      " 99% 509/512 [02:59<00:00,  5.32it/s]04/26/2024 21:08:50 - WARNING - __main__ - epoch 7 step 510 loss 0.1356\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:09:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:09:01 - INFO - __main__ -   eval_f1 = 0.3153\n",
      "04/26/2024 21:09:01 - INFO - __main__ -   eval_precision = 0.3599\n",
      "04/26/2024 21:09:01 - INFO - __main__ -   eval_recall = 0.2805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:09:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:09:11 - INFO - __main__ -   auc_score = 0.8188\n",
      "04/26/2024 21:09:11 - INFO - __main__ -   test_f1 = 0.3103\n",
      "04/26/2024 21:09:11 - INFO - __main__ -   test_precision = 0.3657\n",
      "04/26/2024 21:09:11 - INFO - __main__ -   test_recall = 0.2695\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 21:09:31 - WARNING - __main__ - epoch 8 step 102 loss 0.12637\n",
      "04/26/2024 21:09:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:09:41 - INFO - __main__ -   eval_f1 = 0.3071\n",
      "04/26/2024 21:09:41 - INFO - __main__ -   eval_precision = 0.3683\n",
      "04/26/2024 21:09:41 - INFO - __main__ -   eval_recall = 0.2634\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:09:53 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:09:53 - INFO - __main__ -   auc_score = 0.8173\n",
      "04/26/2024 21:09:53 - INFO - __main__ -   test_f1 = 0.2861\n",
      "04/26/2024 21:09:53 - INFO - __main__ -   test_precision = 0.354\n",
      "04/26/2024 21:09:53 - INFO - __main__ -   test_recall = 0.24\n",
      " 40% 203/512 [01:00<00:58,  5.31it/s]04/26/2024 21:10:12 - WARNING - __main__ - epoch 8 step 204 loss 0.12706\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:10:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:10:22 - INFO - __main__ -   eval_f1 = 0.3591\n",
      "04/26/2024 21:10:22 - INFO - __main__ -   eval_precision = 0.3607\n",
      "04/26/2024 21:10:22 - INFO - __main__ -   eval_recall = 0.3576\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:10:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:10:34 - INFO - __main__ -   auc_score = 0.8242\n",
      "04/26/2024 21:10:34 - INFO - __main__ -   test_f1 = 0.3362\n",
      "04/26/2024 21:10:34 - INFO - __main__ -   test_precision = 0.3468\n",
      "04/26/2024 21:10:34 - INFO - __main__ -   test_recall = 0.3263\n",
      " 60% 305/512 [01:41<00:39,  5.31it/s]04/26/2024 21:10:53 - WARNING - __main__ - epoch 8 step 306 loss 0.11391\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:11:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:11:03 - INFO - __main__ -   eval_f1 = 0.3273\n",
      "04/26/2024 21:11:03 - INFO - __main__ -   eval_precision = 0.3736\n",
      "04/26/2024 21:11:03 - INFO - __main__ -   eval_recall = 0.2912\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:11:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:11:15 - INFO - __main__ -   auc_score = 0.82\n",
      "04/26/2024 21:11:15 - INFO - __main__ -   test_f1 = 0.3103\n",
      "04/26/2024 21:11:15 - INFO - __main__ -   test_precision = 0.3657\n",
      "04/26/2024 21:11:15 - INFO - __main__ -   test_recall = 0.2695\n",
      " 79% 407/512 [02:22<00:19,  5.31it/s]04/26/2024 21:11:34 - WARNING - __main__ - epoch 8 step 408 loss 0.12414\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:11:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:11:44 - INFO - __main__ -   eval_f1 = 0.3646\n",
      "04/26/2024 21:11:44 - INFO - __main__ -   eval_precision = 0.3476\n",
      "04/26/2024 21:11:44 - INFO - __main__ -   eval_recall = 0.3833\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:11:56 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:11:56 - INFO - __main__ -   auc_score = 0.8247\n",
      "04/26/2024 21:11:56 - INFO - __main__ -   test_f1 = 0.3462\n",
      "04/26/2024 21:11:56 - INFO - __main__ -   test_precision = 0.3333\n",
      "04/26/2024 21:11:56 - INFO - __main__ -   test_recall = 0.36\n",
      " 99% 509/512 [03:03<00:00,  5.31it/s]04/26/2024 21:12:15 - WARNING - __main__ - epoch 8 step 510 loss 0.12667\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:12:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:12:25 - INFO - __main__ -   eval_f1 = 0.3225\n",
      "04/26/2024 21:12:25 - INFO - __main__ -   eval_precision = 0.3874\n",
      "04/26/2024 21:12:25 - INFO - __main__ -   eval_recall = 0.2762\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:12:37 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:12:37 - INFO - __main__ -   auc_score = 0.8194\n",
      "04/26/2024 21:12:37 - INFO - __main__ -   test_f1 = 0.3077\n",
      "04/26/2024 21:12:37 - INFO - __main__ -   test_precision = 0.3746\n",
      "04/26/2024 21:12:37 - INFO - __main__ -   test_recall = 0.2611\n",
      "100% 512/512 [03:25<00:00,  2.49it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 21:12:56 - WARNING - __main__ - epoch 9 step 102 loss 0.10441\n",
      "04/26/2024 21:13:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:13:07 - INFO - __main__ -   eval_f1 = 0.3357\n",
      "04/26/2024 21:13:07 - INFO - __main__ -   eval_precision = 0.3714\n",
      "04/26/2024 21:13:07 - INFO - __main__ -   eval_recall = 0.3062\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:13:18 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:13:18 - INFO - __main__ -   auc_score = 0.8196\n",
      "04/26/2024 21:13:18 - INFO - __main__ -   test_f1 = 0.3262\n",
      "04/26/2024 21:13:18 - INFO - __main__ -   test_precision = 0.372\n",
      "04/26/2024 21:13:18 - INFO - __main__ -   test_recall = 0.2905\n",
      " 40% 203/512 [01:00<00:58,  5.31it/s]04/26/2024 21:13:37 - WARNING - __main__ - epoch 9 step 204 loss 0.11818\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:13:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:13:48 - INFO - __main__ -   eval_f1 = 0.3509\n",
      "04/26/2024 21:13:48 - INFO - __main__ -   eval_precision = 0.3528\n",
      "04/26/2024 21:13:48 - INFO - __main__ -   eval_recall = 0.349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:13:59 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:13:59 - INFO - __main__ -   auc_score = 0.8207\n",
      "04/26/2024 21:13:59 - INFO - __main__ -   test_f1 = 0.3322\n",
      "04/26/2024 21:13:59 - INFO - __main__ -   test_precision = 0.3455\n",
      "04/26/2024 21:13:59 - INFO - __main__ -   test_recall = 0.32\n",
      " 60% 305/512 [01:41<00:38,  5.31it/s]04/26/2024 21:14:18 - WARNING - __main__ - epoch 9 step 306 loss 0.1312\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:14:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:14:29 - INFO - __main__ -   eval_f1 = 0.3367\n",
      "04/26/2024 21:14:29 - INFO - __main__ -   eval_precision = 0.3592\n",
      "04/26/2024 21:14:29 - INFO - __main__ -   eval_recall = 0.3169\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:14:40 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:14:40 - INFO - __main__ -   auc_score = 0.8187\n",
      "04/26/2024 21:14:40 - INFO - __main__ -   test_f1 = 0.3372\n",
      "04/26/2024 21:14:40 - INFO - __main__ -   test_precision = 0.3766\n",
      "04/26/2024 21:14:40 - INFO - __main__ -   test_recall = 0.3053\n",
      " 79% 407/512 [02:22<00:19,  5.30it/s]04/26/2024 21:15:00 - WARNING - __main__ - epoch 9 step 408 loss 0.10737\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:15:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:15:10 - INFO - __main__ -   eval_f1 = 0.3202\n",
      "04/26/2024 21:15:10 - INFO - __main__ -   eval_precision = 0.3622\n",
      "04/26/2024 21:15:10 - INFO - __main__ -   eval_recall = 0.2869\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:15:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:15:21 - INFO - __main__ -   auc_score = 0.8167\n",
      "04/26/2024 21:15:21 - INFO - __main__ -   test_f1 = 0.3162\n",
      "04/26/2024 21:15:21 - INFO - __main__ -   test_precision = 0.3667\n",
      "04/26/2024 21:15:21 - INFO - __main__ -   test_recall = 0.2779\n",
      " 99% 509/512 [03:03<00:00,  5.30it/s]04/26/2024 21:15:41 - WARNING - __main__ - epoch 9 step 510 loss 0.11383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:15:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 21:15:51 - INFO - __main__ -   eval_f1 = 0.3341\n",
      "04/26/2024 21:15:51 - INFO - __main__ -   eval_precision = 0.3532\n",
      "04/26/2024 21:15:51 - INFO - __main__ -   eval_recall = 0.3169\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:16:03 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:16:03 - INFO - __main__ -   auc_score = 0.8175\n",
      "04/26/2024 21:16:03 - INFO - __main__ -   test_f1 = 0.3333\n",
      "04/26/2024 21:16:03 - INFO - __main__ -   test_precision = 0.3702\n",
      "04/26/2024 21:16:03 - INFO - __main__ -   test_recall = 0.3032\n",
      "100% 512/512 [03:25<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-2b/single/checkpoints --pretrained_model codet5p-2b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhRNTPgC6lRF",
    "outputId": "f44036b8-0a3e-4a12-96c2-04edefaf79bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-2b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/26/2024 21:27:10 - INFO - __main__ - Successfully load epoch 4's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 21:27:21 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 21:27:21 - INFO - __main__ -   auc_score = 0.8346\n",
      "04/26/2024 21:27:21 - INFO - __main__ -   test_f1 = 0.3307\n",
      "04/26/2024 21:27:21 - INFO - __main__ -   test_precision = 0.3524\n",
      "04/26/2024 21:27:21 - INFO - __main__ -   test_recall = 0.3116\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-2b/single/checkpoints --pretrained_model codet5p-2b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTz53-EDdoPI"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYIGMbdidqJg",
    "outputId": "eebf2a02-273d-4511-8e33-f5c05b79c14d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "config.json:   0% 0.00/5.07k [00:00<?, ?B/s]\r",
      "config.json: 100% 5.07k/5.07k [00:00<00:00, 22.8MB/s]\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "tokenizer_config.json: 100% 284/284 [00:00<00:00, 1.80MB/s]\n",
      "vocab.json: 100% 798k/798k [00:00<00:00, 1.72MB/s]\n",
      "merges.txt: 100% 456k/456k [00:00<00:00, 27.4MB/s]\n",
      "added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 6.55MB/s]\n",
      "special_tokens_map.json: 100% 131/131 [00:00<00:00, 856kB/s]\n",
      "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.38MB/s]\n",
      "pytorch_model.bin: 100% 6.45G/6.45G [06:29<00:00, 16.6MB/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-2b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:16<01:02,  6.58it/s]04/30/2024 00:56:58 - WARNING - __main__ - epoch 0 step 102 loss 0.35268\n",
      "[[0.07789714]\n",
      " [0.04885957]\n",
      " [0.05758127]\n",
      " ...\n",
      " [0.07422125]\n",
      " [0.08015423]\n",
      " [0.08666659]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 00:57:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:57:09 - INFO - __main__ -   auc_score = 0.696\n",
      "04/30/2024 00:57:09 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 00:57:09 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 00:57:09 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [00:42<00:46,  6.59it/s]04/30/2024 00:57:24 - WARNING - __main__ - epoch 0 step 204 loss 0.27526\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.13716598]\n",
      " [0.02567887]\n",
      " [0.03398072]\n",
      " ...\n",
      " [0.09438576]\n",
      " [0.13660918]\n",
      " [0.1406519 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 00:57:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:57:35 - INFO - __main__ -   auc_score = 0.7725\n",
      "04/30/2024 00:57:35 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 00:57:35 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 00:57:35 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [01:09<00:31,  6.60it/s]04/30/2024 00:57:51 - WARNING - __main__ - epoch 0 step 306 loss 0.27814\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.18160777]\n",
      " [0.01718134]\n",
      " [0.02667422]\n",
      " ...\n",
      " [0.12765989]\n",
      " [0.16427447]\n",
      " [0.17469773]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 00:58:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:58:02 - INFO - __main__ -   auc_score = 0.7986\n",
      "04/30/2024 00:58:02 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 00:58:02 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 00:58:02 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [01:35<00:15,  6.61it/s]04/30/2024 00:58:17 - WARNING - __main__ - epoch 0 step 408 loss 0.26896\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.2746516 ]\n",
      " [0.01501228]\n",
      " [0.01850213]\n",
      " ...\n",
      " [0.16984293]\n",
      " [0.21098502]\n",
      " [0.2920337 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 00:58:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:58:28 - INFO - __main__ -   auc_score = 0.808\n",
      "04/30/2024 00:58:28 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 00:58:28 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 00:58:28 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [02:01<00:00,  6.60it/s]04/30/2024 00:58:44 - WARNING - __main__ - epoch 0 step 510 loss 0.23922\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.36030123]\n",
      " [0.01182548]\n",
      " [0.0212136 ]\n",
      " ...\n",
      " [0.18114291]\n",
      " [0.20531258]\n",
      " [0.26168507]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 00:58:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:58:54 - INFO - __main__ -   auc_score = 0.8176\n",
      "04/30/2024 00:58:54 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 00:58:54 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 00:58:54 - INFO - __main__ -   eval_recall = 0.0\n",
      "100% 512/512 [02:13<00:00,  3.85it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 00:59:10 - WARNING - __main__ - epoch 1 step 102 loss 0.25322\n",
      "[[0.5364383 ]\n",
      " [0.02103929]\n",
      " [0.03577302]\n",
      " ...\n",
      " [0.31665447]\n",
      " [0.29714942]\n",
      " [0.38475263]]\n",
      "04/30/2024 00:59:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:59:21 - INFO - __main__ -   auc_score = 0.8277\n",
      "04/30/2024 00:59:21 - INFO - __main__ -   eval_f1 = 0.1022\n",
      "04/30/2024 00:59:21 - INFO - __main__ -   eval_precision = 0.619\n",
      "04/30/2024 00:59:21 - INFO - __main__ -   eval_recall = 0.0557\n",
      " 40% 203/512 [00:42<00:46,  6.60it/s]04/30/2024 00:59:37 - WARNING - __main__ - epoch 1 step 204 loss 0.23248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.58169013]\n",
      " [0.01955262]\n",
      " [0.02375124]\n",
      " ...\n",
      " [0.34793437]\n",
      " [0.2662929 ]\n",
      " [0.40070298]]\n",
      "04/30/2024 00:59:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 00:59:48 - INFO - __main__ -   auc_score = 0.8327\n",
      "04/30/2024 00:59:48 - INFO - __main__ -   eval_f1 = 0.0797\n",
      "04/30/2024 00:59:48 - INFO - __main__ -   eval_precision = 0.5714\n",
      "04/30/2024 00:59:48 - INFO - __main__ -   eval_recall = 0.0428\n",
      " 60% 305/512 [01:08<00:31,  6.61it/s]04/30/2024 01:00:04 - WARNING - __main__ - epoch 1 step 306 loss 0.24883\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.45479804]\n",
      " [0.05477131]\n",
      " [0.02514092]\n",
      " ...\n",
      " [0.35456595]\n",
      " [0.15660624]\n",
      " [0.25801313]]\n",
      "04/30/2024 01:00:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:00:15 - INFO - __main__ -   auc_score = 0.844\n",
      "04/30/2024 01:00:15 - INFO - __main__ -   eval_f1 = 0.0458\n",
      "04/30/2024 01:00:15 - INFO - __main__ -   eval_precision = 0.8462\n",
      "04/30/2024 01:00:15 - INFO - __main__ -   eval_recall = 0.0236\n",
      " 79% 407/512 [01:35<00:15,  6.61it/s]04/30/2024 01:00:30 - WARNING - __main__ - epoch 1 step 408 loss 0.23433\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.57533556]\n",
      " [0.06216339]\n",
      " [0.0228384 ]\n",
      " ...\n",
      " [0.5073567 ]\n",
      " [0.21389413]\n",
      " [0.36479723]]\n",
      "04/30/2024 01:00:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:00:41 - INFO - __main__ -   auc_score = 0.8467\n",
      "04/30/2024 01:00:41 - INFO - __main__ -   eval_f1 = 0.1658\n",
      "04/30/2024 01:00:41 - INFO - __main__ -   eval_precision = 0.5227\n",
      "04/30/2024 01:00:41 - INFO - __main__ -   eval_recall = 0.0985\n",
      " 99% 509/512 [02:02<00:00,  6.56it/s]04/30/2024 01:00:57 - WARNING - __main__ - epoch 1 step 510 loss 0.22359\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5871836 ]\n",
      " [0.03961953]\n",
      " [0.00988693]\n",
      " ...\n",
      " [0.41569275]\n",
      " [0.1400317 ]\n",
      " [0.38278383]]\n",
      "04/30/2024 01:01:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:01:08 - INFO - __main__ -   auc_score = 0.8497\n",
      "04/30/2024 01:01:08 - INFO - __main__ -   eval_f1 = 0.1124\n",
      "04/30/2024 01:01:08 - INFO - __main__ -   eval_precision = 0.5918\n",
      "04/30/2024 01:01:08 - INFO - __main__ -   eval_recall = 0.0621\n",
      "100% 512/512 [02:13<00:00,  3.83it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.62it/s]04/30/2024 01:01:24 - WARNING - __main__ - epoch 2 step 102 loss 0.23373\n",
      "[[0.74759126]\n",
      " [0.09247218]\n",
      " [0.01689006]\n",
      " ...\n",
      " [0.59964484]\n",
      " [0.26511654]\n",
      " [0.5654135 ]]\n",
      "04/30/2024 01:01:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:01:35 - INFO - __main__ -   auc_score = 0.854\n",
      "04/30/2024 01:01:35 - INFO - __main__ -   eval_f1 = 0.2976\n",
      "04/30/2024 01:01:35 - INFO - __main__ -   eval_precision = 0.4483\n",
      "04/30/2024 01:01:35 - INFO - __main__ -   eval_recall = 0.2227\n",
      " 40% 203/512 [00:42<00:46,  6.62it/s]04/30/2024 01:01:51 - WARNING - __main__ - epoch 2 step 204 loss 0.22597\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.46279126]\n",
      " [0.03005615]\n",
      " [0.01034023]\n",
      " ...\n",
      " [0.3054149 ]\n",
      " [0.06012256]\n",
      " [0.23409155]]\n",
      "04/30/2024 01:02:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:02:02 - INFO - __main__ -   auc_score = 0.8551\n",
      "04/30/2024 01:02:02 - INFO - __main__ -   eval_f1 = 0.0336\n",
      "04/30/2024 01:02:02 - INFO - __main__ -   eval_precision = 0.8889\n",
      "04/30/2024 01:02:02 - INFO - __main__ -   eval_recall = 0.0171\n",
      " 60% 305/512 [01:08<00:31,  6.61it/s]04/30/2024 01:02:17 - WARNING - __main__ - epoch 2 step 306 loss 0.21996\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7408236 ]\n",
      " [0.04930614]\n",
      " [0.01379019]\n",
      " ...\n",
      " [0.55499715]\n",
      " [0.10718296]\n",
      " [0.40392992]]\n",
      "04/30/2024 01:02:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:02:28 - INFO - __main__ -   auc_score = 0.8556\n",
      "04/30/2024 01:02:28 - INFO - __main__ -   eval_f1 = 0.215\n",
      "04/30/2024 01:02:28 - INFO - __main__ -   eval_precision = 0.5294\n",
      "04/30/2024 01:02:28 - INFO - __main__ -   eval_recall = 0.1349\n",
      " 79% 407/512 [01:35<00:15,  6.59it/s]04/30/2024 01:02:44 - WARNING - __main__ - epoch 2 step 408 loss 0.21482\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8120654 ]\n",
      " [0.07033757]\n",
      " [0.01212654]\n",
      " ...\n",
      " [0.584873  ]\n",
      " [0.13442922]\n",
      " [0.42092925]]\n",
      "04/30/2024 01:02:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:02:55 - INFO - __main__ -   auc_score = 0.8599\n",
      "04/30/2024 01:02:55 - INFO - __main__ -   eval_f1 = 0.2457\n",
      "04/30/2024 01:02:55 - INFO - __main__ -   eval_precision = 0.4643\n",
      "04/30/2024 01:02:55 - INFO - __main__ -   eval_recall = 0.167\n",
      " 99% 509/512 [02:01<00:00,  6.60it/s]04/30/2024 01:03:10 - WARNING - __main__ - epoch 2 step 510 loss 0.2277\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8389162 ]\n",
      " [0.15244308]\n",
      " [0.02644726]\n",
      " ...\n",
      " [0.60360503]\n",
      " [0.16029486]\n",
      " [0.47842455]]\n",
      "04/30/2024 01:03:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:03:21 - INFO - __main__ -   auc_score = 0.8621\n",
      "04/30/2024 01:03:21 - INFO - __main__ -   eval_f1 = 0.3399\n",
      "04/30/2024 01:03:21 - INFO - __main__ -   eval_precision = 0.4362\n",
      "04/30/2024 01:03:21 - INFO - __main__ -   eval_recall = 0.2784\n",
      "100% 512/512 [02:13<00:00,  3.83it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 01:03:38 - WARNING - __main__ - epoch 3 step 102 loss 0.21418\n",
      "[[0.75074565]\n",
      " [0.08098646]\n",
      " [0.01609459]\n",
      " ...\n",
      " [0.33373663]\n",
      " [0.07163717]\n",
      " [0.20085743]]\n",
      "04/30/2024 01:03:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:03:49 - INFO - __main__ -   auc_score = 0.858\n",
      "04/30/2024 01:03:49 - INFO - __main__ -   eval_f1 = 0.1929\n",
      "04/30/2024 01:03:49 - INFO - __main__ -   eval_precision = 0.5806\n",
      "04/30/2024 01:03:49 - INFO - __main__ -   eval_recall = 0.1156\n",
      " 40% 203/512 [00:41<00:46,  6.61it/s]04/30/2024 01:04:04 - WARNING - __main__ - epoch 3 step 204 loss 0.2145\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9180796 ]\n",
      " [0.1835165 ]\n",
      " [0.02531343]\n",
      " ...\n",
      " [0.6514098 ]\n",
      " [0.22513245]\n",
      " [0.55720866]]\n",
      "04/30/2024 01:04:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:04:15 - INFO - __main__ -   auc_score = 0.8597\n",
      "04/30/2024 01:04:15 - INFO - __main__ -   eval_f1 = 0.3611\n",
      "04/30/2024 01:04:15 - INFO - __main__ -   eval_precision = 0.3929\n",
      "04/30/2024 01:04:15 - INFO - __main__ -   eval_recall = 0.334\n",
      " 60% 305/512 [01:08<00:31,  6.58it/s]04/30/2024 01:04:31 - WARNING - __main__ - epoch 3 step 306 loss 0.22197\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7652028 ]\n",
      " [0.05211083]\n",
      " [0.01202815]\n",
      " ...\n",
      " [0.32759315]\n",
      " [0.05433472]\n",
      " [0.24077581]]\n",
      "04/30/2024 01:04:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:04:42 - INFO - __main__ -   auc_score = 0.859\n",
      "04/30/2024 01:04:42 - INFO - __main__ -   eval_f1 = 0.1805\n",
      "04/30/2024 01:04:42 - INFO - __main__ -   eval_precision = 0.5747\n",
      "04/30/2024 01:04:42 - INFO - __main__ -   eval_recall = 0.1071\n",
      " 79% 407/512 [01:35<00:15,  6.59it/s]04/30/2024 01:04:58 - WARNING - __main__ - epoch 3 step 408 loss 0.21947\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8468468 ]\n",
      " [0.12569273]\n",
      " [0.01728522]\n",
      " ...\n",
      " [0.5489137 ]\n",
      " [0.09883269]\n",
      " [0.46553928]]\n",
      "04/30/2024 01:05:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:05:09 - INFO - __main__ -   auc_score = 0.8605\n",
      "04/30/2024 01:05:09 - INFO - __main__ -   eval_f1 = 0.2789\n",
      "04/30/2024 01:05:09 - INFO - __main__ -   eval_precision = 0.5366\n",
      "04/30/2024 01:05:09 - INFO - __main__ -   eval_recall = 0.1884\n",
      " 99% 509/512 [02:01<00:00,  6.62it/s]04/30/2024 01:05:24 - WARNING - __main__ - epoch 3 step 510 loss 0.21463\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7905873 ]\n",
      " [0.14887685]\n",
      " [0.02198939]\n",
      " ...\n",
      " [0.43391365]\n",
      " [0.10026525]\n",
      " [0.3862923 ]]\n",
      "04/30/2024 01:05:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:05:35 - INFO - __main__ -   auc_score = 0.8627\n",
      "04/30/2024 01:05:35 - INFO - __main__ -   eval_f1 = 0.2541\n",
      "04/30/2024 01:05:35 - INFO - __main__ -   eval_precision = 0.554\n",
      "04/30/2024 01:05:35 - INFO - __main__ -   eval_recall = 0.1649\n",
      "100% 512/512 [02:12<00:00,  3.85it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 01:05:51 - WARNING - __main__ - epoch 4 step 102 loss 0.20336\n",
      "[[0.8171014 ]\n",
      " [0.15665807]\n",
      " [0.01974396]\n",
      " ...\n",
      " [0.52239835]\n",
      " [0.11452199]\n",
      " [0.49180558]]\n",
      "04/30/2024 01:06:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:06:02 - INFO - __main__ -   auc_score = 0.8603\n",
      "04/30/2024 01:06:02 - INFO - __main__ -   eval_f1 = 0.3267\n",
      "04/30/2024 01:06:02 - INFO - __main__ -   eval_precision = 0.4852\n",
      "04/30/2024 01:06:02 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 40% 203/512 [00:41<00:47,  6.55it/s]04/30/2024 01:06:17 - WARNING - __main__ - epoch 4 step 204 loss 0.20647\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8385908 ]\n",
      " [0.13250498]\n",
      " [0.02179162]\n",
      " ...\n",
      " [0.5572142 ]\n",
      " [0.17357916]\n",
      " [0.5068715 ]]\n",
      "04/30/2024 01:06:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:06:28 - INFO - __main__ -   auc_score = 0.8606\n",
      "04/30/2024 01:06:28 - INFO - __main__ -   eval_f1 = 0.3355\n",
      "04/30/2024 01:06:28 - INFO - __main__ -   eval_precision = 0.4379\n",
      "04/30/2024 01:06:28 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 60% 305/512 [01:07<00:31,  6.63it/s]04/30/2024 01:06:43 - WARNING - __main__ - epoch 4 step 306 loss 0.21211\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.84258723]\n",
      " [0.09117875]\n",
      " [0.01343301]\n",
      " ...\n",
      " [0.5290273 ]\n",
      " [0.12058369]\n",
      " [0.55116916]]\n",
      "04/30/2024 01:06:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:06:54 - INFO - __main__ -   auc_score = 0.8601\n",
      "04/30/2024 01:06:54 - INFO - __main__ -   eval_f1 = 0.2964\n",
      "04/30/2024 01:06:54 - INFO - __main__ -   eval_precision = 0.4518\n",
      "04/30/2024 01:06:54 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 79% 407/512 [01:34<00:15,  6.61it/s]04/30/2024 01:07:09 - WARNING - __main__ - epoch 4 step 408 loss 0.20701\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8805373 ]\n",
      " [0.09017798]\n",
      " [0.01243671]\n",
      " ...\n",
      " [0.53696156]\n",
      " [0.18834704]\n",
      " [0.6686946 ]]\n",
      "04/30/2024 01:07:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:07:20 - INFO - __main__ -   auc_score = 0.8603\n",
      "04/30/2024 01:07:20 - INFO - __main__ -   eval_f1 = 0.3272\n",
      "04/30/2024 01:07:20 - INFO - __main__ -   eval_precision = 0.4261\n",
      "04/30/2024 01:07:20 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 99% 509/512 [02:00<00:00,  6.63it/s]04/30/2024 01:07:36 - WARNING - __main__ - epoch 4 step 510 loss 0.20792\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.89944005]\n",
      " [0.07727525]\n",
      " [0.01316228]\n",
      " ...\n",
      " [0.56482244]\n",
      " [0.15449409]\n",
      " [0.56534415]]\n",
      "04/30/2024 01:07:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:07:47 - INFO - __main__ -   auc_score = 0.8585\n",
      "04/30/2024 01:07:47 - INFO - __main__ -   eval_f1 = 0.3128\n",
      "04/30/2024 01:07:47 - INFO - __main__ -   eval_precision = 0.4498\n",
      "04/30/2024 01:07:47 - INFO - __main__ -   eval_recall = 0.2398\n",
      "100% 512/512 [02:11<00:00,  3.88it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.62it/s]04/30/2024 01:08:02 - WARNING - __main__ - epoch 5 step 102 loss 0.20436\n",
      "[[0.9288559 ]\n",
      " [0.140875  ]\n",
      " [0.02406937]\n",
      " ...\n",
      " [0.7399446 ]\n",
      " [0.29032448]\n",
      " [0.78092885]]\n",
      "04/30/2024 01:08:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:08:13 - INFO - __main__ -   auc_score = 0.8594\n",
      "04/30/2024 01:08:13 - INFO - __main__ -   eval_f1 = 0.3927\n",
      "04/30/2024 01:08:13 - INFO - __main__ -   eval_precision = 0.3724\n",
      "04/30/2024 01:08:13 - INFO - __main__ -   eval_recall = 0.4154\n",
      " 40% 203/512 [00:42<00:46,  6.63it/s]04/30/2024 01:08:29 - WARNING - __main__ - epoch 5 step 204 loss 0.20319\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9141234 ]\n",
      " [0.11223191]\n",
      " [0.01383493]\n",
      " ...\n",
      " [0.64623535]\n",
      " [0.26118204]\n",
      " [0.689845  ]]\n",
      "04/30/2024 01:08:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:08:40 - INFO - __main__ -   auc_score = 0.8585\n",
      "04/30/2024 01:08:40 - INFO - __main__ -   eval_f1 = 0.3859\n",
      "04/30/2024 01:08:40 - INFO - __main__ -   eval_precision = 0.4106\n",
      "04/30/2024 01:08:40 - INFO - __main__ -   eval_recall = 0.364\n",
      " 60% 305/512 [01:08<00:31,  6.62it/s]04/30/2024 01:08:56 - WARNING - __main__ - epoch 5 step 306 loss 0.18869\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.91336817]\n",
      " [0.09820592]\n",
      " [0.01311652]\n",
      " ...\n",
      " [0.64125705]\n",
      " [0.33303687]\n",
      " [0.74600583]]\n",
      "04/30/2024 01:09:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:09:07 - INFO - __main__ -   auc_score = 0.8583\n",
      "04/30/2024 01:09:07 - INFO - __main__ -   eval_f1 = 0.3873\n",
      "04/30/2024 01:09:07 - INFO - __main__ -   eval_precision = 0.4111\n",
      "04/30/2024 01:09:07 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 79% 407/512 [01:34<00:15,  6.62it/s]04/30/2024 01:09:22 - WARNING - __main__ - epoch 5 step 408 loss 0.20561\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8895709 ]\n",
      " [0.13337296]\n",
      " [0.01399063]\n",
      " ...\n",
      " [0.48802766]\n",
      " [0.30342102]\n",
      " [0.69596595]]\n",
      "04/30/2024 01:09:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:09:33 - INFO - __main__ -   auc_score = 0.8584\n",
      "04/30/2024 01:09:33 - INFO - __main__ -   eval_f1 = 0.3792\n",
      "04/30/2024 01:09:33 - INFO - __main__ -   eval_precision = 0.4349\n",
      "04/30/2024 01:09:33 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 99% 509/512 [02:01<00:00,  6.61it/s]04/30/2024 01:09:48 - WARNING - __main__ - epoch 5 step 510 loss 0.21821\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8726597 ]\n",
      " [0.11652368]\n",
      " [0.01384769]\n",
      " ...\n",
      " [0.41342315]\n",
      " [0.18788424]\n",
      " [0.6084655 ]]\n",
      "04/30/2024 01:09:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:09:59 - INFO - __main__ -   auc_score = 0.8581\n",
      "04/30/2024 01:09:59 - INFO - __main__ -   eval_f1 = 0.3378\n",
      "04/30/2024 01:09:59 - INFO - __main__ -   eval_precision = 0.4456\n",
      "04/30/2024 01:09:59 - INFO - __main__ -   eval_recall = 0.2719\n",
      "100% 512/512 [02:12<00:00,  3.86it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 01:10:15 - WARNING - __main__ - epoch 6 step 102 loss 0.19396\n",
      "[[0.92323506]\n",
      " [0.15433326]\n",
      " [0.01255976]\n",
      " ...\n",
      " [0.54470956]\n",
      " [0.18146318]\n",
      " [0.68463826]]\n",
      "04/30/2024 01:10:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:10:26 - INFO - __main__ -   auc_score = 0.8557\n",
      "04/30/2024 01:10:26 - INFO - __main__ -   eval_f1 = 0.3542\n",
      "04/30/2024 01:10:26 - INFO - __main__ -   eval_precision = 0.4162\n",
      "04/30/2024 01:10:26 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [00:41<00:46,  6.62it/s]04/30/2024 01:10:41 - WARNING - __main__ - epoch 6 step 204 loss 0.19545\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9254119 ]\n",
      " [0.1738264 ]\n",
      " [0.01194391]\n",
      " ...\n",
      " [0.6197488 ]\n",
      " [0.22422081]\n",
      " [0.7194105 ]]\n",
      "04/30/2024 01:10:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:10:52 - INFO - __main__ -   auc_score = 0.8557\n",
      "04/30/2024 01:10:52 - INFO - __main__ -   eval_f1 = 0.3747\n",
      "04/30/2024 01:10:52 - INFO - __main__ -   eval_precision = 0.4045\n",
      "04/30/2024 01:10:52 - INFO - __main__ -   eval_recall = 0.349\n",
      " 60% 305/512 [01:07<00:31,  6.63it/s]04/30/2024 01:11:07 - WARNING - __main__ - epoch 6 step 306 loss 0.19714\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.92676306]\n",
      " [0.1795454 ]\n",
      " [0.01231021]\n",
      " ...\n",
      " [0.6566972 ]\n",
      " [0.3621428 ]\n",
      " [0.7727281 ]]\n",
      "04/30/2024 01:11:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:11:18 - INFO - __main__ -   auc_score = 0.8571\n",
      "04/30/2024 01:11:18 - INFO - __main__ -   eval_f1 = 0.3896\n",
      "04/30/2024 01:11:18 - INFO - __main__ -   eval_precision = 0.396\n",
      "04/30/2024 01:11:18 - INFO - __main__ -   eval_recall = 0.3833\n",
      " 79% 407/512 [01:34<00:15,  6.59it/s]04/30/2024 01:11:34 - WARNING - __main__ - epoch 6 step 408 loss 0.20512\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8753668 ]\n",
      " [0.10968724]\n",
      " [0.00923256]\n",
      " ...\n",
      " [0.4921493 ]\n",
      " [0.23319578]\n",
      " [0.66352427]]\n",
      "04/30/2024 01:11:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:11:45 - INFO - __main__ -   auc_score = 0.8568\n",
      "04/30/2024 01:11:45 - INFO - __main__ -   eval_f1 = 0.3482\n",
      "04/30/2024 01:11:45 - INFO - __main__ -   eval_precision = 0.4478\n",
      "04/30/2024 01:11:45 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 99% 509/512 [02:00<00:00,  6.61it/s]04/30/2024 01:12:00 - WARNING - __main__ - epoch 6 step 510 loss 0.1967\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.92749596]\n",
      " [0.1428161 ]\n",
      " [0.01025543]\n",
      " ...\n",
      " [0.668688  ]\n",
      " [0.36900693]\n",
      " [0.7543504 ]]\n",
      "04/30/2024 01:12:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:12:11 - INFO - __main__ -   auc_score = 0.8573\n",
      "04/30/2024 01:12:11 - INFO - __main__ -   eval_f1 = 0.3915\n",
      "04/30/2024 01:12:11 - INFO - __main__ -   eval_precision = 0.389\n",
      "04/30/2024 01:12:11 - INFO - __main__ -   eval_recall = 0.394\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.63it/s]04/30/2024 01:12:27 - WARNING - __main__ - epoch 7 step 102 loss 0.21311\n",
      "[[0.8668798 ]\n",
      " [0.09085635]\n",
      " [0.00905018]\n",
      " ...\n",
      " [0.42921433]\n",
      " [0.2237585 ]\n",
      " [0.60830706]]\n",
      "04/30/2024 01:12:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:12:38 - INFO - __main__ -   auc_score = 0.8552\n",
      "04/30/2024 01:12:38 - INFO - __main__ -   eval_f1 = 0.3297\n",
      "04/30/2024 01:12:38 - INFO - __main__ -   eval_precision = 0.4469\n",
      "04/30/2024 01:12:38 - INFO - __main__ -   eval_recall = 0.2612\n",
      " 40% 203/512 [00:41<00:46,  6.62it/s]04/30/2024 01:12:53 - WARNING - __main__ - epoch 7 step 204 loss 0.1781\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.872548  ]\n",
      " [0.0692222 ]\n",
      " [0.00662936]\n",
      " ...\n",
      " [0.436319  ]\n",
      " [0.21042101]\n",
      " [0.5217468 ]]\n",
      "04/30/2024 01:13:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:13:04 - INFO - __main__ -   auc_score = 0.855\n",
      "04/30/2024 01:13:04 - INFO - __main__ -   eval_f1 = 0.305\n",
      "04/30/2024 01:13:04 - INFO - __main__ -   eval_precision = 0.4649\n",
      "04/30/2024 01:13:04 - INFO - __main__ -   eval_recall = 0.227\n",
      " 60% 305/512 [01:07<00:31,  6.61it/s]04/30/2024 01:13:19 - WARNING - __main__ - epoch 7 step 306 loss 0.19093\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9176575 ]\n",
      " [0.08796733]\n",
      " [0.00765878]\n",
      " ...\n",
      " [0.56283396]\n",
      " [0.28657374]\n",
      " [0.671344  ]]\n",
      "04/30/2024 01:13:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:13:30 - INFO - __main__ -   auc_score = 0.8553\n",
      "04/30/2024 01:13:30 - INFO - __main__ -   eval_f1 = 0.3695\n",
      "04/30/2024 01:13:30 - INFO - __main__ -   eval_precision = 0.4348\n",
      "04/30/2024 01:13:30 - INFO - __main__ -   eval_recall = 0.3212\n",
      " 79% 407/512 [01:34<00:15,  6.61it/s]04/30/2024 01:13:46 - WARNING - __main__ - epoch 7 step 408 loss 0.20206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9249409 ]\n",
      " [0.11781787]\n",
      " [0.00857192]\n",
      " ...\n",
      " [0.60892296]\n",
      " [0.3129041 ]\n",
      " [0.7199286 ]]\n",
      "04/30/2024 01:13:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:13:57 - INFO - __main__ -   auc_score = 0.8546\n",
      "04/30/2024 01:13:57 - INFO - __main__ -   eval_f1 = 0.3754\n",
      "04/30/2024 01:13:57 - INFO - __main__ -   eval_precision = 0.4091\n",
      "04/30/2024 01:13:57 - INFO - __main__ -   eval_recall = 0.3469\n",
      " 99% 509/512 [02:00<00:00,  6.60it/s]04/30/2024 01:14:12 - WARNING - __main__ - epoch 7 step 510 loss 0.18024\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.93582654]\n",
      " [0.10427515]\n",
      " [0.00757123]\n",
      " ...\n",
      " [0.62139225]\n",
      " [0.37438813]\n",
      " [0.77950215]]\n",
      "04/30/2024 01:14:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:14:23 - INFO - __main__ -   auc_score = 0.8554\n",
      "04/30/2024 01:14:23 - INFO - __main__ -   eval_f1 = 0.3813\n",
      "04/30/2024 01:14:23 - INFO - __main__ -   eval_precision = 0.4201\n",
      "04/30/2024 01:14:23 - INFO - __main__ -   eval_recall = 0.349\n",
      "100% 512/512 [02:11<00:00,  3.88it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.62it/s]04/30/2024 01:14:39 - WARNING - __main__ - epoch 8 step 102 loss 0.18087\n",
      "[[0.9466099 ]\n",
      " [0.12055056]\n",
      " [0.0079369 ]\n",
      " ...\n",
      " [0.6735277 ]\n",
      " [0.5068255 ]\n",
      " [0.84075713]]\n",
      "04/30/2024 01:14:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:14:49 - INFO - __main__ -   auc_score = 0.8554\n",
      "04/30/2024 01:14:49 - INFO - __main__ -   eval_f1 = 0.3835\n",
      "04/30/2024 01:14:49 - INFO - __main__ -   eval_precision = 0.3882\n",
      "04/30/2024 01:14:49 - INFO - __main__ -   eval_recall = 0.379\n",
      " 40% 203/512 [00:41<00:46,  6.63it/s]04/30/2024 01:15:05 - WARNING - __main__ - epoch 8 step 204 loss 0.19921\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9265637 ]\n",
      " [0.11298743]\n",
      " [0.00729732]\n",
      " ...\n",
      " [0.55501294]\n",
      " [0.40188968]\n",
      " [0.7922028 ]]\n",
      "04/30/2024 01:15:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:15:16 - INFO - __main__ -   auc_score = 0.8549\n",
      "04/30/2024 01:15:16 - INFO - __main__ -   eval_f1 = 0.3805\n",
      "04/30/2024 01:15:16 - INFO - __main__ -   eval_precision = 0.4152\n",
      "04/30/2024 01:15:16 - INFO - __main__ -   eval_recall = 0.3512\n",
      " 60% 305/512 [01:07<00:31,  6.63it/s]04/30/2024 01:15:31 - WARNING - __main__ - epoch 8 step 306 loss 0.18763\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9260126 ]\n",
      " [0.11208152]\n",
      " [0.00662436]\n",
      " ...\n",
      " [0.55360496]\n",
      " [0.4227263 ]\n",
      " [0.7921028 ]]\n",
      "04/30/2024 01:15:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:15:42 - INFO - __main__ -   auc_score = 0.8542\n",
      "04/30/2024 01:15:42 - INFO - __main__ -   eval_f1 = 0.3763\n",
      "04/30/2024 01:15:42 - INFO - __main__ -   eval_precision = 0.4112\n",
      "04/30/2024 01:15:42 - INFO - __main__ -   eval_recall = 0.3469\n",
      " 79% 407/512 [01:34<00:15,  6.62it/s]04/30/2024 01:15:57 - WARNING - __main__ - epoch 8 step 408 loss 0.19545\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9152181 ]\n",
      " [0.0927937 ]\n",
      " [0.00650417]\n",
      " ...\n",
      " [0.50934106]\n",
      " [0.42049038]\n",
      " [0.76356244]]\n",
      "04/30/2024 01:16:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:16:08 - INFO - __main__ -   auc_score = 0.8538\n",
      "04/30/2024 01:16:08 - INFO - __main__ -   eval_f1 = 0.3506\n",
      "04/30/2024 01:16:08 - INFO - __main__ -   eval_precision = 0.414\n",
      "04/30/2024 01:16:08 - INFO - __main__ -   eval_recall = 0.3041\n",
      " 99% 509/512 [02:00<00:00,  6.61it/s]04/30/2024 01:16:24 - WARNING - __main__ - epoch 8 step 510 loss 0.18388\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9261372 ]\n",
      " [0.10362833]\n",
      " [0.0069525 ]\n",
      " ...\n",
      " [0.60213614]\n",
      " [0.50133926]\n",
      " [0.8079635 ]]\n",
      "04/30/2024 01:16:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:16:35 - INFO - __main__ -   auc_score = 0.8545\n",
      "04/30/2024 01:16:35 - INFO - __main__ -   eval_f1 = 0.3869\n",
      "04/30/2024 01:16:35 - INFO - __main__ -   eval_precision = 0.4101\n",
      "04/30/2024 01:16:35 - INFO - __main__ -   eval_recall = 0.3662\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 01:16:50 - WARNING - __main__ - epoch 9 step 102 loss 0.19235\n",
      "[[0.917245  ]\n",
      " [0.08612777]\n",
      " [0.00630628]\n",
      " ...\n",
      " [0.5515752 ]\n",
      " [0.46297854]\n",
      " [0.79262185]]\n",
      "04/30/2024 01:17:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:17:01 - INFO - __main__ -   auc_score = 0.8539\n",
      "04/30/2024 01:17:01 - INFO - __main__ -   eval_f1 = 0.3696\n",
      "04/30/2024 01:17:01 - INFO - __main__ -   eval_precision = 0.4238\n",
      "04/30/2024 01:17:01 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 40% 203/512 [00:41<00:46,  6.63it/s]04/30/2024 01:17:17 - WARNING - __main__ - epoch 9 step 204 loss 0.18551\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9171696 ]\n",
      " [0.08183668]\n",
      " [0.00586819]\n",
      " ...\n",
      " [0.5686952 ]\n",
      " [0.48216033]\n",
      " [0.80111283]]\n",
      "04/30/2024 01:17:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:17:27 - INFO - __main__ -   auc_score = 0.8542\n",
      "04/30/2024 01:17:27 - INFO - __main__ -   eval_f1 = 0.3739\n",
      "04/30/2024 01:17:27 - INFO - __main__ -   eval_precision = 0.4282\n",
      "04/30/2024 01:17:27 - INFO - __main__ -   eval_recall = 0.3319\n",
      " 60% 305/512 [01:07<00:31,  6.62it/s]04/30/2024 01:17:43 - WARNING - __main__ - epoch 9 step 306 loss 0.18871\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9192644 ]\n",
      " [0.09336773]\n",
      " [0.00643576]\n",
      " ...\n",
      " [0.6051424 ]\n",
      " [0.52420413]\n",
      " [0.8138648 ]]\n",
      "04/30/2024 01:17:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:17:54 - INFO - __main__ -   auc_score = 0.8543\n",
      "04/30/2024 01:17:54 - INFO - __main__ -   eval_f1 = 0.3803\n",
      "04/30/2024 01:17:54 - INFO - __main__ -   eval_precision = 0.4089\n",
      "04/30/2024 01:17:54 - INFO - __main__ -   eval_recall = 0.3555\n",
      " 79% 407/512 [01:34<00:15,  6.63it/s]04/30/2024 01:18:09 - WARNING - __main__ - epoch 9 step 408 loss 0.18993\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9196602 ]\n",
      " [0.09682558]\n",
      " [0.00649331]\n",
      " ...\n",
      " [0.60703844]\n",
      " [0.5181705 ]\n",
      " [0.8107919 ]]\n",
      "04/30/2024 01:18:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:18:20 - INFO - __main__ -   auc_score = 0.8544\n",
      "04/30/2024 01:18:20 - INFO - __main__ -   eval_f1 = 0.3845\n",
      "04/30/2024 01:18:20 - INFO - __main__ -   eval_precision = 0.4102\n",
      "04/30/2024 01:18:20 - INFO - __main__ -   eval_recall = 0.3619\n",
      " 99% 509/512 [02:00<00:00,  6.61it/s]04/30/2024 01:18:35 - WARNING - __main__ - epoch 9 step 510 loss 0.17526\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.914537  ]\n",
      " [0.08970533]\n",
      " [0.00616518]\n",
      " ...\n",
      " [0.5769933 ]\n",
      " [0.4881725 ]\n",
      " [0.79419136]]\n",
      "04/30/2024 01:18:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:18:46 - INFO - __main__ -   auc_score = 0.8542\n",
      "04/30/2024 01:18:46 - INFO - __main__ -   eval_f1 = 0.3834\n",
      "04/30/2024 01:18:46 - INFO - __main__ -   eval_precision = 0.4286\n",
      "04/30/2024 01:18:46 - INFO - __main__ -   eval_recall = 0.3469\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-2b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-2b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aF0F2lUAmdiC",
    "outputId": "19328a9f-9a95-4789-d792-ca7477ac3f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-2b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/30/2024 01:25:04 - INFO - __main__ - ***** Test results *****\n",
      "04/30/2024 01:25:04 - INFO - __main__ -   auc_score = 0.8336\n",
      "04/30/2024 01:25:04 - INFO - __main__ -   test_f1 = 0.3661\n",
      "04/30/2024 01:25:04 - INFO - __main__ -   test_precision = 0.3598\n",
      "04/30/2024 01:25:04 - INFO - __main__ -   test_recall = 0.3726\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-2b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-2b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuj21f92Ts-D"
   },
   "source": [
    "### codet5p-6b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qyWxD7em-tL"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ILzZVqTUzw",
    "outputId": "ee1d6525-9fb7-4b05-d759-e3ea4c16971b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  5.61it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-6b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:20<01:17,  5.31it/s]04/26/2024 22:03:45 - WARNING - __main__ - epoch 0 step 102 loss 0.29005\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 22:03:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:03:55 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 22:03:55 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 22:03:55 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 22:04:06 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:04:06 - INFO - __main__ -   auc_score = 0.765\n",
      "04/26/2024 22:04:06 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 22:04:06 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 22:04:06 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [00:59<00:58,  5.31it/s]04/26/2024 22:04:25 - WARNING - __main__ - epoch 0 step 204 loss 0.26357\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 22:04:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:04:35 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/26/2024 22:04:35 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/26/2024 22:04:35 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/26/2024 22:04:46 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:04:46 - INFO - __main__ -   auc_score = 0.797\n",
      "04/26/2024 22:04:46 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/26/2024 22:04:46 - INFO - __main__ -   test_precision = 0.0\n",
      "04/26/2024 22:04:46 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [01:39<00:39,  5.30it/s]04/26/2024 22:05:05 - WARNING - __main__ - epoch 0 step 306 loss 0.25746\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:05:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:05:15 - INFO - __main__ -   eval_f1 = 0.0531\n",
      "04/26/2024 22:05:15 - INFO - __main__ -   eval_precision = 0.5652\n",
      "04/26/2024 22:05:15 - INFO - __main__ -   eval_recall = 0.0278\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:05:28 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:05:28 - INFO - __main__ -   auc_score = 0.8203\n",
      "04/26/2024 22:05:28 - INFO - __main__ -   test_f1 = 0.0165\n",
      "04/26/2024 22:05:28 - INFO - __main__ -   test_precision = 0.3636\n",
      "04/26/2024 22:05:28 - INFO - __main__ -   test_recall = 0.0084\n",
      " 79% 407/512 [02:22<00:19,  5.32it/s]04/26/2024 22:05:47 - WARNING - __main__ - epoch 0 step 408 loss 0.25693\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:05:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:05:58 - INFO - __main__ -   eval_f1 = 0.2064\n",
      "04/26/2024 22:05:58 - INFO - __main__ -   eval_precision = 0.4919\n",
      "04/26/2024 22:05:58 - INFO - __main__ -   eval_recall = 0.1306\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:06:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:06:11 - INFO - __main__ -   auc_score = 0.8138\n",
      "04/26/2024 22:06:11 - INFO - __main__ -   test_f1 = 0.1739\n",
      "04/26/2024 22:06:11 - INFO - __main__ -   test_precision = 0.4228\n",
      "04/26/2024 22:06:11 - INFO - __main__ -   test_recall = 0.1095\n",
      " 99% 509/512 [03:04<00:00,  5.31it/s]04/26/2024 22:06:30 - WARNING - __main__ - epoch 0 step 510 loss 0.23687\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:06:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:06:40 - INFO - __main__ -   eval_f1 = 0.1854\n",
      "04/26/2024 22:06:40 - INFO - __main__ -   eval_precision = 0.5532\n",
      "04/26/2024 22:06:40 - INFO - __main__ -   eval_recall = 0.1113\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:06:50 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:06:50 - INFO - __main__ -   auc_score = 0.8272\n",
      "04/26/2024 22:06:50 - INFO - __main__ -   test_f1 = 0.1289\n",
      "04/26/2024 22:06:50 - INFO - __main__ -   test_precision = 0.5147\n",
      "04/26/2024 22:06:50 - INFO - __main__ -   test_recall = 0.0737\n",
      "100% 512/512 [03:25<00:00,  2.49it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 22:07:10 - WARNING - __main__ - epoch 1 step 102 loss 0.23363\n",
      "04/26/2024 22:07:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:07:20 - INFO - __main__ -   eval_f1 = 0.0802\n",
      "04/26/2024 22:07:20 - INFO - __main__ -   eval_precision = 0.625\n",
      "04/26/2024 22:07:20 - INFO - __main__ -   eval_recall = 0.0428\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:07:31 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:07:31 - INFO - __main__ -   auc_score = 0.8374\n",
      "04/26/2024 22:07:31 - INFO - __main__ -   test_f1 = 0.049\n",
      "04/26/2024 22:07:31 - INFO - __main__ -   test_precision = 0.8\n",
      "04/26/2024 22:07:31 - INFO - __main__ -   test_recall = 0.0253\n",
      " 40% 203/512 [00:58<00:58,  5.29it/s]04/26/2024 22:07:50 - WARNING - __main__ - epoch 1 step 204 loss 0.22674\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:08:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:08:00 - INFO - __main__ -   eval_f1 = 0.1976\n",
      "04/26/2024 22:08:00 - INFO - __main__ -   eval_precision = 0.5182\n",
      "04/26/2024 22:08:00 - INFO - __main__ -   eval_recall = 0.1221\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:08:11 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:08:11 - INFO - __main__ -   auc_score = 0.8378\n",
      "04/26/2024 22:08:11 - INFO - __main__ -   test_f1 = 0.1394\n",
      "04/26/2024 22:08:11 - INFO - __main__ -   test_precision = 0.5429\n",
      "04/26/2024 22:08:11 - INFO - __main__ -   test_recall = 0.08\n",
      " 60% 305/512 [01:38<00:39,  5.31it/s]04/26/2024 22:08:30 - WARNING - __main__ - epoch 1 step 306 loss 0.23345\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:08:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:08:40 - INFO - __main__ -   eval_f1 = 0.3484\n",
      "04/26/2024 22:08:40 - INFO - __main__ -   eval_precision = 0.3935\n",
      "04/26/2024 22:08:40 - INFO - __main__ -   eval_recall = 0.3126\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:08:52 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:08:52 - INFO - __main__ -   auc_score = 0.8329\n",
      "04/26/2024 22:08:52 - INFO - __main__ -   test_f1 = 0.3373\n",
      "04/26/2024 22:08:52 - INFO - __main__ -   test_precision = 0.3906\n",
      "04/26/2024 22:08:52 - INFO - __main__ -   test_recall = 0.2968\n",
      " 79% 407/512 [02:20<00:19,  5.30it/s]04/26/2024 22:09:11 - WARNING - __main__ - epoch 1 step 408 loss 0.24014\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:09:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:09:22 - INFO - __main__ -   eval_f1 = 0.3535\n",
      "04/26/2024 22:09:22 - INFO - __main__ -   eval_precision = 0.3963\n",
      "04/26/2024 22:09:22 - INFO - __main__ -   eval_recall = 0.3191\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:09:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:09:34 - INFO - __main__ -   auc_score = 0.8332\n",
      "04/26/2024 22:09:34 - INFO - __main__ -   test_f1 = 0.3329\n",
      "04/26/2024 22:09:34 - INFO - __main__ -   test_precision = 0.3861\n",
      "04/26/2024 22:09:34 - INFO - __main__ -   test_recall = 0.2926\n",
      " 99% 509/512 [03:01<00:00,  5.30it/s]04/26/2024 22:09:53 - WARNING - __main__ - epoch 1 step 510 loss 0.20429\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:10:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:10:03 - INFO - __main__ -   eval_f1 = 0.1958\n",
      "04/26/2024 22:10:03 - INFO - __main__ -   eval_precision = 0.5333\n",
      "04/26/2024 22:10:03 - INFO - __main__ -   eval_recall = 0.1199\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:10:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:10:14 - INFO - __main__ -   auc_score = 0.8422\n",
      "04/26/2024 22:10:14 - INFO - __main__ -   test_f1 = 0.1457\n",
      "04/26/2024 22:10:14 - INFO - __main__ -   test_precision = 0.5405\n",
      "04/26/2024 22:10:14 - INFO - __main__ -   test_recall = 0.0842\n",
      "100% 512/512 [03:23<00:00,  2.52it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.32it/s]04/26/2024 22:10:33 - WARNING - __main__ - epoch 2 step 102 loss 0.20955\n",
      "04/26/2024 22:10:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:10:44 - INFO - __main__ -   eval_f1 = 0.3289\n",
      "04/26/2024 22:10:44 - INFO - __main__ -   eval_precision = 0.4377\n",
      "04/26/2024 22:10:44 - INFO - __main__ -   eval_recall = 0.2634\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:10:54 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:10:54 - INFO - __main__ -   auc_score = 0.8408\n",
      "04/26/2024 22:10:54 - INFO - __main__ -   test_f1 = 0.3008\n",
      "04/26/2024 22:10:54 - INFO - __main__ -   test_precision = 0.4028\n",
      "04/26/2024 22:10:54 - INFO - __main__ -   test_recall = 0.24\n",
      " 40% 203/512 [00:58<00:58,  5.32it/s]04/26/2024 22:11:13 - WARNING - __main__ - epoch 2 step 204 loss 0.20491\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:11:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:11:23 - INFO - __main__ -   eval_f1 = 0.0885\n",
      "04/26/2024 22:11:23 - INFO - __main__ -   eval_precision = 0.7333\n",
      "04/26/2024 22:11:23 - INFO - __main__ -   eval_recall = 0.0471\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:11:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:11:34 - INFO - __main__ -   auc_score = 0.8457\n",
      "04/26/2024 22:11:34 - INFO - __main__ -   test_f1 = 0.0644\n",
      "04/26/2024 22:11:34 - INFO - __main__ -   test_precision = 0.7273\n",
      "04/26/2024 22:11:34 - INFO - __main__ -   test_recall = 0.0337\n",
      " 60% 305/512 [01:38<00:38,  5.32it/s]04/26/2024 22:11:53 - WARNING - __main__ - epoch 2 step 306 loss 0.21761\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:12:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:12:03 - INFO - __main__ -   eval_f1 = 0.232\n",
      "04/26/2024 22:12:03 - INFO - __main__ -   eval_precision = 0.4897\n",
      "04/26/2024 22:12:03 - INFO - __main__ -   eval_recall = 0.152\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:12:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:12:14 - INFO - __main__ -   auc_score = 0.8463\n",
      "04/26/2024 22:12:14 - INFO - __main__ -   test_f1 = 0.1629\n",
      "04/26/2024 22:12:14 - INFO - __main__ -   test_precision = 0.4608\n",
      "04/26/2024 22:12:14 - INFO - __main__ -   test_recall = 0.0989\n",
      " 79% 407/512 [02:18<00:19,  5.32it/s]04/26/2024 22:12:33 - WARNING - __main__ - epoch 2 step 408 loss 0.22128\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:12:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:12:43 - INFO - __main__ -   eval_f1 = 0.2118\n",
      "04/26/2024 22:12:43 - INFO - __main__ -   eval_precision = 0.4922\n",
      "04/26/2024 22:12:43 - INFO - __main__ -   eval_recall = 0.1349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:12:53 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:12:53 - INFO - __main__ -   auc_score = 0.8471\n",
      "04/26/2024 22:12:53 - INFO - __main__ -   test_f1 = 0.1519\n",
      "04/26/2024 22:12:53 - INFO - __main__ -   test_precision = 0.4725\n",
      "04/26/2024 22:12:53 - INFO - __main__ -   test_recall = 0.0905\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 22:13:13 - WARNING - __main__ - epoch 2 step 510 loss 0.21373\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:13:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:13:23 - INFO - __main__ -   eval_f1 = 0.3954\n",
      "04/26/2024 22:13:23 - INFO - __main__ -   eval_precision = 0.3884\n",
      "04/26/2024 22:13:23 - INFO - __main__ -   eval_recall = 0.4026\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:13:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:13:35 - INFO - __main__ -   auc_score = 0.8407\n",
      "04/26/2024 22:13:35 - INFO - __main__ -   test_f1 = 0.3519\n",
      "04/26/2024 22:13:35 - INFO - __main__ -   test_precision = 0.3659\n",
      "04/26/2024 22:13:35 - INFO - __main__ -   test_recall = 0.3389\n",
      "100% 512/512 [03:21<00:00,  2.54it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 22:13:55 - WARNING - __main__ - epoch 3 step 102 loss 0.19819\n",
      "04/26/2024 22:14:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:14:05 - INFO - __main__ -   eval_f1 = 0.2125\n",
      "04/26/2024 22:14:05 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/26/2024 22:14:05 - INFO - __main__ -   eval_recall = 0.1349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:14:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:14:15 - INFO - __main__ -   auc_score = 0.8432\n",
      "04/26/2024 22:14:15 - INFO - __main__ -   test_f1 = 0.1941\n",
      "04/26/2024 22:14:15 - INFO - __main__ -   test_precision = 0.549\n",
      "04/26/2024 22:14:15 - INFO - __main__ -   test_recall = 0.1179\n",
      " 40% 203/512 [00:58<00:58,  5.31it/s]04/26/2024 22:14:34 - WARNING - __main__ - epoch 3 step 204 loss 0.19571\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:14:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:14:45 - INFO - __main__ -   eval_f1 = 0.3029\n",
      "04/26/2024 22:14:45 - INFO - __main__ -   eval_precision = 0.4173\n",
      "04/26/2024 22:14:45 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:14:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:14:55 - INFO - __main__ -   auc_score = 0.8458\n",
      "04/26/2024 22:14:55 - INFO - __main__ -   test_f1 = 0.2901\n",
      "04/26/2024 22:14:55 - INFO - __main__ -   test_precision = 0.4298\n",
      "04/26/2024 22:14:55 - INFO - __main__ -   test_recall = 0.2189\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/26/2024 22:15:14 - WARNING - __main__ - epoch 3 step 306 loss 0.202\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:15:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:15:25 - INFO - __main__ -   eval_f1 = 0.1908\n",
      "04/26/2024 22:15:25 - INFO - __main__ -   eval_precision = 0.5455\n",
      "04/26/2024 22:15:25 - INFO - __main__ -   eval_recall = 0.1156\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:15:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:15:35 - INFO - __main__ -   auc_score = 0.8358\n",
      "04/26/2024 22:15:35 - INFO - __main__ -   test_f1 = 0.1365\n",
      "04/26/2024 22:15:35 - INFO - __main__ -   test_precision = 0.5522\n",
      "04/26/2024 22:15:35 - INFO - __main__ -   test_recall = 0.0779\n",
      " 79% 407/512 [02:18<00:19,  5.31it/s]04/26/2024 22:15:54 - WARNING - __main__ - epoch 3 step 408 loss 0.19537\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:16:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:16:05 - INFO - __main__ -   eval_f1 = 0.2633\n",
      "04/26/2024 22:16:05 - INFO - __main__ -   eval_precision = 0.4258\n",
      "04/26/2024 22:16:05 - INFO - __main__ -   eval_recall = 0.1906\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:16:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:16:15 - INFO - __main__ -   auc_score = 0.8393\n",
      "04/26/2024 22:16:15 - INFO - __main__ -   test_f1 = 0.2443\n",
      "04/26/2024 22:16:15 - INFO - __main__ -   test_precision = 0.4444\n",
      "04/26/2024 22:16:15 - INFO - __main__ -   test_recall = 0.1684\n",
      " 99% 509/512 [02:58<00:00,  5.32it/s]04/26/2024 22:16:34 - WARNING - __main__ - epoch 3 step 510 loss 0.20129\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:16:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:16:44 - INFO - __main__ -   eval_f1 = 0.3153\n",
      "04/26/2024 22:16:44 - INFO - __main__ -   eval_precision = 0.3834\n",
      "04/26/2024 22:16:44 - INFO - __main__ -   eval_recall = 0.2677\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:16:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:16:55 - INFO - __main__ -   auc_score = 0.8429\n",
      "04/26/2024 22:16:55 - INFO - __main__ -   test_f1 = 0.3143\n",
      "04/26/2024 22:16:55 - INFO - __main__ -   test_precision = 0.4102\n",
      "04/26/2024 22:16:55 - INFO - __main__ -   test_recall = 0.2547\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:18,  5.20it/s]04/26/2024 22:17:14 - WARNING - __main__ - epoch 4 step 102 loss 0.17556\n",
      "04/26/2024 22:17:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:17:25 - INFO - __main__ -   eval_f1 = 0.3952\n",
      "04/26/2024 22:17:25 - INFO - __main__ -   eval_precision = 0.345\n",
      "04/26/2024 22:17:25 - INFO - __main__ -   eval_recall = 0.4625\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:17:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:17:35 - INFO - __main__ -   auc_score = 0.8373\n",
      "04/26/2024 22:17:35 - INFO - __main__ -   test_f1 = 0.3585\n",
      "04/26/2024 22:17:35 - INFO - __main__ -   test_precision = 0.3352\n",
      "04/26/2024 22:17:35 - INFO - __main__ -   test_recall = 0.3853\n",
      " 40% 203/512 [00:58<00:58,  5.32it/s]04/26/2024 22:17:54 - WARNING - __main__ - epoch 4 step 204 loss 0.18663\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:18:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:18:05 - INFO - __main__ -   eval_f1 = 0.2971\n",
      "04/26/2024 22:18:05 - INFO - __main__ -   eval_precision = 0.4154\n",
      "04/26/2024 22:18:05 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:18:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:18:15 - INFO - __main__ -   auc_score = 0.835\n",
      "04/26/2024 22:18:15 - INFO - __main__ -   test_f1 = 0.255\n",
      "04/26/2024 22:18:15 - INFO - __main__ -   test_precision = 0.3991\n",
      "04/26/2024 22:18:15 - INFO - __main__ -   test_recall = 0.1874\n",
      " 60% 305/512 [01:38<00:38,  5.32it/s]04/26/2024 22:18:34 - WARNING - __main__ - epoch 4 step 306 loss 0.18867\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:18:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:18:44 - INFO - __main__ -   eval_f1 = 0.327\n",
      "04/26/2024 22:18:44 - INFO - __main__ -   eval_precision = 0.4006\n",
      "04/26/2024 22:18:44 - INFO - __main__ -   eval_recall = 0.2762\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:18:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:18:55 - INFO - __main__ -   auc_score = 0.8388\n",
      "04/26/2024 22:18:55 - INFO - __main__ -   test_f1 = 0.2864\n",
      "04/26/2024 22:18:55 - INFO - __main__ -   test_precision = 0.3599\n",
      "04/26/2024 22:18:55 - INFO - __main__ -   test_recall = 0.2379\n",
      " 79% 407/512 [02:18<00:19,  5.31it/s]04/26/2024 22:19:14 - WARNING - __main__ - epoch 4 step 408 loss 0.1846\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:19:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:19:24 - INFO - __main__ -   eval_f1 = 0.3129\n",
      "04/26/2024 22:19:24 - INFO - __main__ -   eval_precision = 0.3765\n",
      "04/26/2024 22:19:24 - INFO - __main__ -   eval_recall = 0.2677\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:19:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:19:35 - INFO - __main__ -   auc_score = 0.8328\n",
      "04/26/2024 22:19:35 - INFO - __main__ -   test_f1 = 0.294\n",
      "04/26/2024 22:19:35 - INFO - __main__ -   test_precision = 0.3645\n",
      "04/26/2024 22:19:35 - INFO - __main__ -   test_recall = 0.2463\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 22:19:54 - WARNING - __main__ - epoch 4 step 510 loss 0.1845\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:20:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:20:04 - INFO - __main__ -   eval_f1 = 0.3906\n",
      "04/26/2024 22:20:04 - INFO - __main__ -   eval_precision = 0.3738\n",
      "04/26/2024 22:20:04 - INFO - __main__ -   eval_recall = 0.409\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:20:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:20:14 - INFO - __main__ -   auc_score = 0.8356\n",
      "04/26/2024 22:20:14 - INFO - __main__ -   test_f1 = 0.3369\n",
      "04/26/2024 22:20:14 - INFO - __main__ -   test_precision = 0.339\n",
      "04/26/2024 22:20:14 - INFO - __main__ -   test_recall = 0.3347\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 22:20:34 - WARNING - __main__ - epoch 5 step 102 loss 0.16795\n",
      "04/26/2024 22:20:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:20:44 - INFO - __main__ -   eval_f1 = 0.3592\n",
      "04/26/2024 22:20:44 - INFO - __main__ -   eval_precision = 0.3974\n",
      "04/26/2024 22:20:44 - INFO - __main__ -   eval_recall = 0.3276\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:20:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:20:55 - INFO - __main__ -   auc_score = 0.8331\n",
      "04/26/2024 22:20:55 - INFO - __main__ -   test_f1 = 0.3034\n",
      "04/26/2024 22:20:55 - INFO - __main__ -   test_precision = 0.3582\n",
      "04/26/2024 22:20:55 - INFO - __main__ -   test_recall = 0.2632\n",
      " 40% 203/512 [00:58<00:58,  5.31it/s]04/26/2024 22:21:14 - WARNING - __main__ - epoch 5 step 204 loss 0.16731\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:21:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:21:24 - INFO - __main__ -   eval_f1 = 0.3393\n",
      "04/26/2024 22:21:24 - INFO - __main__ -   eval_precision = 0.3803\n",
      "04/26/2024 22:21:24 - INFO - __main__ -   eval_recall = 0.3062\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:21:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:21:35 - INFO - __main__ -   auc_score = 0.8277\n",
      "04/26/2024 22:21:35 - INFO - __main__ -   test_f1 = 0.3083\n",
      "04/26/2024 22:21:35 - INFO - __main__ -   test_precision = 0.3639\n",
      "04/26/2024 22:21:35 - INFO - __main__ -   test_recall = 0.2674\n",
      " 60% 305/512 [01:38<00:39,  5.30it/s]04/26/2024 22:21:54 - WARNING - __main__ - epoch 5 step 306 loss 0.16722\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:22:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:22:04 - INFO - __main__ -   eval_f1 = 0.2869\n",
      "04/26/2024 22:22:04 - INFO - __main__ -   eval_precision = 0.418\n",
      "04/26/2024 22:22:04 - INFO - __main__ -   eval_recall = 0.2184\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:22:14 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:22:14 - INFO - __main__ -   auc_score = 0.8253\n",
      "04/26/2024 22:22:14 - INFO - __main__ -   test_f1 = 0.2428\n",
      "04/26/2024 22:22:14 - INFO - __main__ -   test_precision = 0.352\n",
      "04/26/2024 22:22:14 - INFO - __main__ -   test_recall = 0.1853\n",
      " 79% 407/512 [02:18<00:19,  5.32it/s]04/26/2024 22:22:34 - WARNING - __main__ - epoch 5 step 408 loss 0.16936\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:22:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:22:44 - INFO - __main__ -   eval_f1 = 0.375\n",
      "04/26/2024 22:22:44 - INFO - __main__ -   eval_precision = 0.3184\n",
      "04/26/2024 22:22:44 - INFO - __main__ -   eval_recall = 0.4561\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:22:54 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:22:54 - INFO - __main__ -   auc_score = 0.8294\n",
      "04/26/2024 22:22:54 - INFO - __main__ -   test_f1 = 0.3653\n",
      "04/26/2024 22:22:54 - INFO - __main__ -   test_precision = 0.3278\n",
      "04/26/2024 22:22:54 - INFO - __main__ -   test_recall = 0.4126\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 22:23:14 - WARNING - __main__ - epoch 5 step 510 loss 0.16864\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:23:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:23:24 - INFO - __main__ -   eval_f1 = 0.3749\n",
      "04/26/2024 22:23:24 - INFO - __main__ -   eval_precision = 0.3864\n",
      "04/26/2024 22:23:24 - INFO - __main__ -   eval_recall = 0.364\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:23:34 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:23:34 - INFO - __main__ -   auc_score = 0.8303\n",
      "04/26/2024 22:23:34 - INFO - __main__ -   test_f1 = 0.3213\n",
      "04/26/2024 22:23:34 - INFO - __main__ -   test_precision = 0.3472\n",
      "04/26/2024 22:23:34 - INFO - __main__ -   test_recall = 0.2989\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.30it/s]04/26/2024 22:23:54 - WARNING - __main__ - epoch 6 step 102 loss 0.15127\n",
      "04/26/2024 22:24:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:24:04 - INFO - __main__ -   eval_f1 = 0.329\n",
      "04/26/2024 22:24:04 - INFO - __main__ -   eval_precision = 0.4116\n",
      "04/26/2024 22:24:04 - INFO - __main__ -   eval_recall = 0.2741\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:24:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:24:15 - INFO - __main__ -   auc_score = 0.8199\n",
      "04/26/2024 22:24:15 - INFO - __main__ -   test_f1 = 0.251\n",
      "04/26/2024 22:24:15 - INFO - __main__ -   test_precision = 0.3566\n",
      "04/26/2024 22:24:15 - INFO - __main__ -   test_recall = 0.1937\n",
      " 40% 203/512 [00:59<00:58,  5.30it/s]04/26/2024 22:24:34 - WARNING - __main__ - epoch 6 step 204 loss 0.14942\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:24:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:24:44 - INFO - __main__ -   eval_f1 = 0.3162\n",
      "04/26/2024 22:24:44 - INFO - __main__ -   eval_precision = 0.411\n",
      "04/26/2024 22:24:44 - INFO - __main__ -   eval_recall = 0.257\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:24:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:24:55 - INFO - __main__ -   auc_score = 0.823\n",
      "04/26/2024 22:24:55 - INFO - __main__ -   test_f1 = 0.2561\n",
      "04/26/2024 22:24:55 - INFO - __main__ -   test_precision = 0.3558\n",
      "04/26/2024 22:24:55 - INFO - __main__ -   test_recall = 0.2\n",
      " 60% 305/512 [01:39<00:38,  5.31it/s]04/26/2024 22:25:14 - WARNING - __main__ - epoch 6 step 306 loss 0.14849\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:25:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:25:24 - INFO - __main__ -   eval_f1 = 0.3385\n",
      "04/26/2024 22:25:24 - INFO - __main__ -   eval_precision = 0.3817\n",
      "04/26/2024 22:25:24 - INFO - __main__ -   eval_recall = 0.3041\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:25:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:25:35 - INFO - __main__ -   auc_score = 0.8215\n",
      "04/26/2024 22:25:35 - INFO - __main__ -   test_f1 = 0.2797\n",
      "04/26/2024 22:25:35 - INFO - __main__ -   test_precision = 0.3436\n",
      "04/26/2024 22:25:35 - INFO - __main__ -   test_recall = 0.2358\n",
      " 79% 407/512 [02:19<00:19,  5.31it/s]04/26/2024 22:25:54 - WARNING - __main__ - epoch 6 step 408 loss 0.15681\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:26:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:26:04 - INFO - __main__ -   eval_f1 = 0.3511\n",
      "04/26/2024 22:26:04 - INFO - __main__ -   eval_precision = 0.3649\n",
      "04/26/2024 22:26:04 - INFO - __main__ -   eval_recall = 0.3383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:26:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:26:15 - INFO - __main__ -   auc_score = 0.8237\n",
      "04/26/2024 22:26:15 - INFO - __main__ -   test_f1 = 0.297\n",
      "04/26/2024 22:26:15 - INFO - __main__ -   test_precision = 0.3307\n",
      "04/26/2024 22:26:15 - INFO - __main__ -   test_recall = 0.2695\n",
      " 99% 509/512 [02:59<00:00,  5.31it/s]04/26/2024 22:26:34 - WARNING - __main__ - epoch 6 step 510 loss 0.16822\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:26:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:26:44 - INFO - __main__ -   eval_f1 = 0.3608\n",
      "04/26/2024 22:26:44 - INFO - __main__ -   eval_precision = 0.3479\n",
      "04/26/2024 22:26:44 - INFO - __main__ -   eval_recall = 0.3747\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:26:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:26:55 - INFO - __main__ -   auc_score = 0.8196\n",
      "04/26/2024 22:26:55 - INFO - __main__ -   test_f1 = 0.3032\n",
      "04/26/2024 22:26:55 - INFO - __main__ -   test_precision = 0.3145\n",
      "04/26/2024 22:26:55 - INFO - __main__ -   test_recall = 0.2926\n",
      "100% 512/512 [03:20<00:00,  2.55it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/26/2024 22:27:14 - WARNING - __main__ - epoch 7 step 102 loss 0.138\n",
      "04/26/2024 22:27:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:27:25 - INFO - __main__ -   eval_f1 = 0.3727\n",
      "04/26/2024 22:27:25 - INFO - __main__ -   eval_precision = 0.3503\n",
      "04/26/2024 22:27:25 - INFO - __main__ -   eval_recall = 0.3983\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:27:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:27:35 - INFO - __main__ -   auc_score = 0.8228\n",
      "04/26/2024 22:27:35 - INFO - __main__ -   test_f1 = 0.3229\n",
      "04/26/2024 22:27:35 - INFO - __main__ -   test_precision = 0.3215\n",
      "04/26/2024 22:27:35 - INFO - __main__ -   test_recall = 0.3242\n",
      " 40% 203/512 [00:59<00:58,  5.31it/s]04/26/2024 22:27:54 - WARNING - __main__ - epoch 7 step 204 loss 0.13868\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:28:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:28:05 - INFO - __main__ -   eval_f1 = 0.3599\n",
      "04/26/2024 22:28:05 - INFO - __main__ -   eval_precision = 0.3114\n",
      "04/26/2024 22:28:05 - INFO - __main__ -   eval_recall = 0.4261\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:28:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:28:15 - INFO - __main__ -   auc_score = 0.8205\n",
      "04/26/2024 22:28:15 - INFO - __main__ -   test_f1 = 0.345\n",
      "04/26/2024 22:28:15 - INFO - __main__ -   test_precision = 0.3138\n",
      "04/26/2024 22:28:15 - INFO - __main__ -   test_recall = 0.3832\n",
      " 60% 305/512 [01:39<00:38,  5.31it/s]04/26/2024 22:28:34 - WARNING - __main__ - epoch 7 step 306 loss 0.14619\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:28:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:28:45 - INFO - __main__ -   eval_f1 = 0.3584\n",
      "04/26/2024 22:28:45 - INFO - __main__ -   eval_precision = 0.3257\n",
      "04/26/2024 22:28:45 - INFO - __main__ -   eval_recall = 0.3983\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:28:55 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:28:55 - INFO - __main__ -   auc_score = 0.815\n",
      "04/26/2024 22:28:55 - INFO - __main__ -   test_f1 = 0.3333\n",
      "04/26/2024 22:28:55 - INFO - __main__ -   test_precision = 0.3135\n",
      "04/26/2024 22:28:55 - INFO - __main__ -   test_recall = 0.3558\n",
      " 79% 407/512 [02:19<00:19,  5.31it/s]04/26/2024 22:29:14 - WARNING - __main__ - epoch 7 step 408 loss 0.13776\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:29:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:29:25 - INFO - __main__ -   eval_f1 = 0.352\n",
      "04/26/2024 22:29:25 - INFO - __main__ -   eval_precision = 0.3255\n",
      "04/26/2024 22:29:25 - INFO - __main__ -   eval_recall = 0.3833\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:29:35 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:29:35 - INFO - __main__ -   auc_score = 0.8114\n",
      "04/26/2024 22:29:35 - INFO - __main__ -   test_f1 = 0.3245\n",
      "04/26/2024 22:29:35 - INFO - __main__ -   test_precision = 0.3131\n",
      "04/26/2024 22:29:35 - INFO - __main__ -   test_recall = 0.3368\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/26/2024 22:29:54 - WARNING - __main__ - epoch 7 step 510 loss 0.1405\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:30:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:30:05 - INFO - __main__ -   eval_f1 = 0.3436\n",
      "04/26/2024 22:30:05 - INFO - __main__ -   eval_precision = 0.3537\n",
      "04/26/2024 22:30:05 - INFO - __main__ -   eval_recall = 0.334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:30:15 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:30:15 - INFO - __main__ -   auc_score = 0.8119\n",
      "04/26/2024 22:30:15 - INFO - __main__ -   test_f1 = 0.2921\n",
      "04/26/2024 22:30:15 - INFO - __main__ -   test_precision = 0.3104\n",
      "04/26/2024 22:30:15 - INFO - __main__ -   test_recall = 0.2758\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.29it/s]04/26/2024 22:30:35 - WARNING - __main__ - epoch 8 step 102 loss 0.13221\n",
      "04/26/2024 22:30:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/26/2024 22:30:45 - INFO - __main__ -   eval_f1 = 0.3254\n",
      "04/26/2024 22:30:45 - INFO - __main__ -   eval_precision = 0.3297\n",
      "04/26/2024 22:30:45 - INFO - __main__ -   eval_recall = 0.3212\n",
      "04/26/2024 22:30:46 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 101/512 [00:30<02:05,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-6b/single/checkpoints --pretrained_model codet5p-6b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8HfHX6xVVni",
    "outputId": "d3869259-798c-48be-b457-52db0cff73e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  5.72it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-6b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/26/2024 22:34:32 - INFO - __main__ - Successfully load epoch 2's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/26/2024 22:34:44 - INFO - __main__ - ***** Test results *****\n",
      "04/26/2024 22:34:44 - INFO - __main__ -   auc_score = 0.8438\n",
      "04/26/2024 22:34:44 - INFO - __main__ -   test_f1 = 0.3558\n",
      "04/26/2024 22:34:44 - INFO - __main__ -   test_precision = 0.3744\n",
      "04/26/2024 22:34:44 - INFO - __main__ -   test_recall = 0.3389\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-6b/single/checkpoints --pretrained_model codet5p-6b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZYrMBVTnF4h"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1aFyJREnQ8o",
    "outputId": "5e41d771-b421-4c57-f87c-b56575a7e691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100% 5.06k/5.06k [00:00<00:00, 26.1MB/s]\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "tokenizer_config.json: 100% 284/284 [00:00<00:00, 2.06MB/s]\n",
      "vocab.json: 100% 798k/798k [00:00<00:00, 50.9MB/s]\n",
      "merges.txt: 100% 456k/456k [00:00<00:00, 58.4MB/s]\n",
      "added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 7.31MB/s]\n",
      "special_tokens_map.json: 100% 131/131 [00:00<00:00, 789kB/s]\n",
      "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.40MB/s]\n",
      "pytorch_model.bin.index.json: 100% 39.0k/39.0k [00:00<00:00, 126MB/s]\n",
      "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
      "pytorch_model-00001-of-00002.bin:   0% 0.00/7.90G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0% 10.5M/7.90G [00:02<26:17, 5.00MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0% 21.0M/7.90G [00:02<15:52, 8.26MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0% 31.5M/7.90G [00:03<12:32, 10.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 41.9M/7.90G [00:04<10:56, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 52.4M/7.90G [00:04<09:06, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 62.9M/7.90G [00:05<08:56, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 73.4M/7.90G [00:06<08:48, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 83.9M/7.90G [00:06<07:52, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 94.4M/7.90G [00:07<08:07, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 105M/7.90G [00:07<07:24, 17.5MB/s] \u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1% 115M/7.90G [00:08<07:45, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 126M/7.90G [00:09<07:57, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 136M/7.90G [00:09<08:07, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 147M/7.90G [00:10<08:16, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 157M/7.90G [00:10<07:32, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 168M/7.90G [00:11<07:48, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 178M/7.90G [00:12<08:00, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2% 189M/7.90G [00:12<07:19, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 199M/7.90G [00:13<07:39, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 210M/7.90G [00:14<07:53, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 220M/7.90G [00:14<07:23, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 231M/7.90G [00:15<07:47, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 241M/7.90G [00:16<07:57, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 252M/7.90G [00:16<07:19, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 262M/7.90G [00:17<07:35, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3% 273M/7.90G [00:17<07:02, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 283M/7.90G [00:18<07:25, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 294M/7.90G [00:19<07:38, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 304M/7.90G [00:19<07:05, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 315M/7.90G [00:20<07:24, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 325M/7.90G [00:20<06:55, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 336M/7.90G [00:21<07:19, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4% 346M/7.90G [00:22<07:32, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 357M/7.90G [00:22<07:00, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 367M/7.90G [00:23<07:19, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 377M/7.90G [00:23<06:50, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 388M/7.90G [00:24<07:15, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 398M/7.90G [00:25<07:32, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 409M/7.90G [00:25<06:57, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 419M/7.90G [00:26<07:17, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5% 430M/7.90G [00:26<06:46, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 440M/7.90G [00:27<07:11, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 451M/7.90G [00:27<06:47, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 461M/7.90G [00:28<07:05, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 472M/7.90G [00:29<07:23, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 482M/7.90G [00:29<06:49, 18.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 493M/7.90G [00:30<07:11, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6% 503M/7.90G [00:30<06:40, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 514M/7.90G [00:31<07:06, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 524M/7.90G [00:32<07:23, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 535M/7.90G [00:32<06:49, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 545M/7.90G [00:33<07:10, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 556M/7.90G [00:33<06:39, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 566M/7.90G [00:34<07:03, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 577M/7.90G [00:35<07:19, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7% 587M/7.90G [00:35<06:46, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 598M/7.90G [00:36<07:55, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 608M/7.90G [00:37<07:56, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 619M/7.90G [00:38<07:56, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 629M/7.90G [00:38<07:56, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 640M/7.90G [00:39<07:59, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 650M/7.90G [00:40<07:57, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8% 661M/7.90G [00:41<08:42, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 671M/7.90G [00:41<08:28, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 682M/7.90G [00:42<08:59, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 692M/7.90G [00:43<08:43, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 703M/7.90G [00:44<08:27, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 713M/7.90G [00:44<08:16, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 724M/7.90G [00:45<08:08, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 734M/7.90G [00:46<08:03, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9% 744M/7.90G [00:46<08:35, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 755M/7.90G [00:47<08:20, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 765M/7.90G [00:48<08:19, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 776M/7.90G [00:49<08:09, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 786M/7.90G [00:49<08:02, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 797M/7.90G [00:50<07:57, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 807M/7.90G [00:51<07:53, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 818M/7.90G [00:51<07:50, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10% 828M/7.90G [00:52<07:48, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 839M/7.90G [00:53<07:48, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 849M/7.90G [00:53<07:47, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 860M/7.90G [00:54<08:25, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 870M/7.90G [00:55<08:17, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 881M/7.90G [00:56<08:05, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 891M/7.90G [00:56<07:57, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11% 902M/7.90G [00:57<07:08, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 912M/7.90G [00:58<07:16, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 923M/7.90G [00:58<07:22, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 933M/7.90G [00:59<07:26, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 944M/7.90G [00:59<06:45, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 954M/7.90G [01:00<07:00, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 965M/7.90G [01:01<07:12, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 975M/7.90G [01:02<08:00, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12% 986M/7.90G [01:02<07:54, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 996M/7.90G [01:03<07:47, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.01G/7.90G [01:04<07:43, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.02G/7.90G [01:04<07:40, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.03G/7.90G [01:05<07:36, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.04G/7.90G [01:06<07:35, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.05G/7.90G [01:07<07:32, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13% 1.06G/7.90G [01:07<07:30, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.07G/7.90G [01:08<06:47, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.08G/7.90G [01:08<06:58, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.09G/7.90G [01:09<07:07, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.10G/7.90G [01:10<07:12, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.11G/7.90G [01:10<06:33, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.12G/7.90G [01:11<06:55, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.13G/7.90G [01:12<07:02, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14% 1.14G/7.90G [01:12<06:26, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.15G/7.90G [01:13<06:43, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.16G/7.90G [01:13<06:54, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.17G/7.90G [01:14<07:01, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.18G/7.90G [01:15<06:25, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.20G/7.90G [01:16<07:25, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.21G/7.90G [01:16<08:06, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15% 1.22G/7.90G [01:17<07:52, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.23G/7.90G [01:18<07:42, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.24G/7.90G [01:19<07:34, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.25G/7.90G [01:19<08:07, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.26G/7.90G [01:20<07:14, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.27G/7.90G [01:21<07:14, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.28G/7.90G [01:21<07:14, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.29G/7.90G [01:22<08:37, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16% 1.30G/7.90G [01:23<08:12, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.31G/7.90G [01:24<08:36, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.32G/7.90G [01:25<08:12, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.33G/7.90G [01:26<08:33, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.34G/7.90G [01:26<08:08, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.35G/7.90G [01:27<07:51, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.36G/7.90G [01:28<08:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17% 1.37G/7.90G [01:29<09:11, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.38G/7.90G [01:30<09:15, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.39G/7.90G [01:31<09:18, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.41G/7.90G [01:32<09:19, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.42G/7.90G [01:33<09:20, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.43G/7.90G [01:34<09:19, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.44G/7.90G [01:35<09:13, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.45G/7.90G [01:35<08:41, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18% 1.46G/7.90G [01:36<08:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.47G/7.90G [01:37<08:59, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.48G/7.90G [01:38<09:03, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.49G/7.90G [01:39<09:06, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.50G/7.90G [01:40<09:01, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.51G/7.90G [01:41<08:33, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.52G/7.90G [01:41<08:45, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19% 1.53G/7.90G [01:42<08:51, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.54G/7.90G [01:43<08:18, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.55G/7.90G [01:44<08:34, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.56G/7.90G [01:45<08:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.57G/7.90G [01:46<08:13, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.58G/7.90G [01:46<07:49, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.59G/7.90G [01:47<08:02, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.60G/7.90G [01:48<07:51, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20% 1.61G/7.90G [01:49<07:33, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.63G/7.90G [01:49<07:20, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.64G/7.90G [01:50<06:31, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.65G/7.90G [01:50<06:36, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.66G/7.90G [01:51<06:40, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.67G/7.90G [01:52<06:02, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.68G/7.90G [01:52<07:00, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21% 1.69G/7.90G [01:53<07:32, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.70G/7.90G [01:54<07:18, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.71G/7.90G [01:55<07:09, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.72G/7.90G [01:55<07:01, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.73G/7.90G [01:57<08:14, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.74G/7.90G [01:57<07:48, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.75G/7.90G [01:58<08:07, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.76G/7.90G [01:59<08:19, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22% 1.77G/7.90G [02:00<07:51, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.78G/7.90G [02:01<08:07, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.79G/7.90G [02:01<07:43, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.80G/7.90G [02:02<07:58, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.81G/7.90G [02:03<07:38, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.82G/7.90G [02:04<07:24, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.84G/7.90G [02:05<07:44, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23% 1.85G/7.90G [02:05<07:24, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.86G/7.90G [02:06<07:12, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.87G/7.90G [02:07<07:36, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.88G/7.90G [02:08<07:17, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.89G/7.90G [02:08<07:13, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.90G/7.90G [02:09<07:30, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.91G/7.90G [02:10<07:50, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.92G/7.90G [02:11<07:27, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24% 1.93G/7.90G [02:11<07:10, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.94G/7.90G [02:12<07:35, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.95G/7.90G [02:13<07:16, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.96G/7.90G [02:14<07:02, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.97G/7.90G [02:14<06:56, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.98G/7.90G [02:15<06:49, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 1.99G/7.90G [02:16<06:39, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25% 2.00G/7.90G [02:17<07:10, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.01G/7.90G [02:17<06:21, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.02G/7.90G [02:18<06:23, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.03G/7.90G [02:19<06:24, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.04G/7.90G [02:19<05:48, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.06G/7.90G [02:20<05:58, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.07G/7.90G [02:20<06:04, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.08G/7.90G [02:21<05:33, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26% 2.09G/7.90G [02:22<05:47, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.10G/7.90G [02:22<05:57, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.11G/7.90G [02:23<05:27, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.12G/7.90G [02:23<05:43, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.13G/7.90G [02:24<05:54, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.14G/7.90G [02:25<05:24, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.15G/7.90G [02:25<05:40, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.16G/7.90G [02:26<05:51, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27% 2.17G/7.90G [02:27<05:22, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.18G/7.90G [02:27<05:37, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.19G/7.90G [02:28<05:13, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.20G/7.90G [02:28<05:31, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.21G/7.90G [02:29<06:20, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.22G/7.90G [02:30<06:18, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.23G/7.90G [02:31<06:16, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28% 2.24G/7.90G [02:31<06:14, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.25G/7.90G [02:32<05:39, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.26G/7.90G [02:33<05:48, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.28G/7.90G [02:33<05:53, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.29G/7.90G [02:34<05:22, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.30G/7.90G [02:35<07:27, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.31G/7.90G [02:36<07:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.32G/7.90G [02:37<07:11, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29% 2.33G/7.90G [02:37<06:52, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.34G/7.90G [02:38<06:36, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.35G/7.90G [02:39<06:57, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.36G/7.90G [02:40<06:40, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.37G/7.90G [02:40<06:33, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.38G/7.90G [02:41<06:23, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.39G/7.90G [02:42<06:17, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30% 2.40G/7.90G [02:42<06:11, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.41G/7.90G [02:43<06:08, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.42G/7.90G [02:44<06:05, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.43G/7.90G [02:44<06:04, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.44G/7.90G [02:45<06:01, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.45G/7.90G [02:46<06:00, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.46G/7.90G [02:46<05:26, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.47G/7.90G [02:47<05:34, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31% 2.49G/7.90G [02:48<05:39, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.50G/7.90G [02:49<06:52, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.51G/7.90G [02:50<07:09, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.52G/7.90G [02:50<06:51, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.53G/7.90G [02:51<07:03, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.54G/7.90G [02:52<06:43, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.55G/7.90G [02:53<06:29, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32% 2.56G/7.90G [02:54<06:45, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.57G/7.90G [02:54<06:30, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.58G/7.90G [02:55<06:17, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.59G/7.90G [02:56<06:17, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.60G/7.90G [02:56<06:05, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.61G/7.90G [02:57<05:58, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.62G/7.90G [02:58<05:53, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.63G/7.90G [02:59<05:49, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33% 2.64G/7.90G [02:59<05:48, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.65G/7.90G [03:00<05:46, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.66G/7.90G [03:01<05:45, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.67G/7.90G [03:01<05:44, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.68G/7.90G [03:02<05:43, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.69G/7.90G [03:03<05:43, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.71G/7.90G [03:03<05:42, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34% 2.72G/7.90G [03:04<05:41, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.73G/7.90G [03:05<05:40, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.74G/7.90G [03:05<05:39, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.75G/7.90G [03:06<05:07, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.76G/7.90G [03:07<05:16, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.77G/7.90G [03:07<05:21, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.78G/7.90G [03:08<05:25, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.79G/7.90G [03:09<05:28, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35% 2.80G/7.90G [03:09<05:30, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.81G/7.90G [03:10<04:59, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.82G/7.90G [03:11<05:09, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.83G/7.90G [03:11<05:15, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.84G/7.90G [03:12<05:20, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.85G/7.90G [03:12<04:51, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.86G/7.90G [03:13<05:02, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36% 2.87G/7.90G [03:14<05:10, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.88G/7.90G [03:14<04:44, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.89G/7.90G [03:15<04:56, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.90G/7.90G [03:15<04:34, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.92G/7.90G [03:16<04:51, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.93G/7.90G [03:17<05:34, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.94G/7.90G [03:18<05:30, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.95G/7.90G [03:18<05:29, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37% 2.96G/7.90G [03:19<05:27, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 2.97G/7.90G [03:20<05:25, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 2.98G/7.90G [03:20<05:24, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 2.99G/7.90G [03:21<05:23, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 3.00G/7.90G [03:22<04:51, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 3.01G/7.90G [03:22<05:00, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 3.02G/7.90G [03:23<05:05, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38% 3.03G/7.90G [03:23<04:40, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.04G/7.90G [03:24<04:49, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.05G/7.90G [03:25<05:30, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.06G/7.90G [03:26<05:25, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.07G/7.90G [03:26<05:23, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.08G/7.90G [03:27<05:20, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.09G/7.90G [03:28<05:18, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.10G/7.90G [03:28<04:47, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39% 3.11G/7.90G [03:29<04:55, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.12G/7.90G [03:30<05:00, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.14G/7.90G [03:30<05:03, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.15G/7.90G [03:31<04:35, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.16G/7.90G [03:32<04:53, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.17G/7.90G [03:32<05:28, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.18G/7.90G [03:33<05:22, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40% 3.19G/7.90G [03:34<05:47, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.20G/7.90G [03:35<05:35, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.21G/7.90G [03:36<05:33, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.22G/7.90G [03:36<05:48, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.23G/7.90G [03:37<05:35, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.24G/7.90G [03:38<05:26, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.25G/7.90G [03:38<05:20, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.26G/7.90G [03:39<05:43, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41% 3.27G/7.90G [03:40<05:31, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.28G/7.90G [03:41<05:22, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.29G/7.90G [03:41<05:16, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.30G/7.90G [03:42<05:11, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.31G/7.90G [03:43<05:08, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.32G/7.90G [03:44<05:08, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.33G/7.90G [03:44<05:28, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42% 3.34G/7.90G [03:45<05:21, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.36G/7.90G [03:46<05:14, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.37G/7.90G [03:46<05:08, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.38G/7.90G [03:47<05:05, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.39G/7.90G [03:48<05:01, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.40G/7.90G [03:49<04:59, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.41G/7.90G [03:49<04:57, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.42G/7.90G [03:50<04:56, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43% 3.43G/7.90G [03:51<04:54, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.44G/7.90G [03:51<04:53, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.45G/7.90G [03:52<04:53, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.46G/7.90G [03:52<04:24, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.47G/7.90G [03:53<04:31, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.48G/7.90G [03:54<04:36, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.49G/7.90G [03:54<04:12, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.50G/7.90G [03:55<04:22, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44% 3.51G/7.90G [03:55<04:03, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.52G/7.90G [03:56<04:14, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.53G/7.90G [03:57<04:23, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.54G/7.90G [03:58<04:30, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.55G/7.90G [03:58<04:06, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.57G/7.90G [03:59<04:17, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.58G/7.90G [03:59<03:57, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45% 3.59G/7.90G [04:00<04:12, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.60G/7.90G [04:00<03:53, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.61G/7.90G [04:01<04:07, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.62G/7.90G [04:02<04:17, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.63G/7.90G [04:02<03:56, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.64G/7.90G [04:03<04:37, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.65G/7.90G [04:04<05:03, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.66G/7.90G [04:04<04:29, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46% 3.67G/7.90G [04:05<04:31, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.68G/7.90G [04:06<04:32, 15.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.69G/7.90G [04:06<04:07, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.70G/7.90G [04:07<04:15, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.71G/7.90G [04:08<04:19, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.72G/7.90G [04:08<03:58, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.73G/7.90G [04:09<04:08, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47% 3.74G/7.90G [04:10<04:14, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.75G/7.90G [04:10<03:54, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.76G/7.90G [04:11<04:04, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.77G/7.90G [04:11<04:11, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.79G/7.90G [04:12<03:51, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.80G/7.90G [04:13<04:01, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.81G/7.90G [04:13<03:44, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.82G/7.90G [04:14<03:56, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48% 3.83G/7.90G [04:14<04:04, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.84G/7.90G [04:15<03:45, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.85G/7.90G [04:16<03:57, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.86G/7.90G [04:16<04:06, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.87G/7.90G [04:17<04:11, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.88G/7.90G [04:17<03:52, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.89G/7.90G [04:18<03:58, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49% 3.90G/7.90G [04:19<03:40, 18.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.91G/7.90G [04:19<03:52, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.92G/7.90G [04:20<04:26, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.93G/7.90G [04:21<04:24, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.94G/7.90G [04:22<04:22, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.95G/7.90G [04:22<04:21, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.96G/7.90G [04:23<04:19, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.97G/7.90G [04:24<04:19, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50% 3.98G/7.90G [04:25<04:42, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.00G/7.90G [04:25<04:35, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.01G/7.90G [04:26<04:53, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.02G/7.90G [04:27<05:04, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.03G/7.90G [04:28<04:51, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.04G/7.90G [04:28<04:41, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.05G/7.90G [04:29<04:54, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51% 4.06G/7.90G [04:30<04:41, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.07G/7.90G [04:31<04:33, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.08G/7.90G [04:32<04:47, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.09G/7.90G [04:32<04:37, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.10G/7.90G [04:33<04:28, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.11G/7.90G [04:34<04:44, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.12G/7.90G [04:35<04:34, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.13G/7.90G [04:36<04:47, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52% 4.14G/7.90G [04:36<04:39, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.15G/7.90G [04:37<04:29, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.16G/7.90G [04:38<04:43, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.17G/7.90G [04:39<05:15, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.18G/7.90G [04:40<05:19, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.19G/7.90G [04:41<04:57, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.20G/7.90G [04:41<05:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53% 4.22G/7.90G [04:42<05:07, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.23G/7.90G [04:43<04:48, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.24G/7.90G [04:44<04:56, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.25G/7.90G [04:45<04:39, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.26G/7.90G [04:45<04:28, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.27G/7.90G [04:46<04:40, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.28G/7.90G [04:47<04:26, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.29G/7.90G [04:48<04:17, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54% 4.30G/7.90G [04:48<04:10, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.31G/7.90G [04:49<04:28, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.32G/7.90G [04:50<04:18, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.33G/7.90G [04:51<04:10, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.34G/7.90G [04:51<04:05, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.35G/7.90G [04:52<04:21, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.36G/7.90G [04:53<04:14, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55% 4.37G/7.90G [04:54<04:07, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.38G/7.90G [04:54<04:02, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.39G/7.90G [04:55<04:19, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.40G/7.90G [04:56<04:10, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.41G/7.90G [04:57<04:03, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.42G/7.90G [04:57<03:58, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.44G/7.90G [04:58<03:54, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.45G/7.90G [04:59<03:52, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56% 4.46G/7.90G [04:59<03:49, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.47G/7.90G [05:00<03:47, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.48G/7.90G [05:01<03:46, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.49G/7.90G [05:01<03:24, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.50G/7.90G [05:02<03:29, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.51G/7.90G [05:03<03:32, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.52G/7.90G [05:03<03:35, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57% 4.53G/7.90G [05:04<03:15, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.54G/7.90G [05:04<03:22, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.55G/7.90G [05:05<03:27, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.56G/7.90G [05:06<03:09, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.57G/7.90G [05:06<03:18, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.58G/7.90G [05:07<03:23, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.59G/7.90G [05:07<03:06, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.60G/7.90G [05:08<03:14, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58% 4.61G/7.90G [05:09<03:21, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.62G/7.90G [05:09<03:04, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.63G/7.90G [05:10<03:14, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.65G/7.90G [05:11<03:20, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.66G/7.90G [05:11<03:04, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.67G/7.90G [05:12<03:11, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.68G/7.90G [05:13<03:37, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59% 4.69G/7.90G [05:14<03:35, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.70G/7.90G [05:14<03:33, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.71G/7.90G [05:15<03:12, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.72G/7.90G [05:15<03:16, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.73G/7.90G [05:16<03:00, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.74G/7.90G [05:17<03:07, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.75G/7.90G [05:17<03:12, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.76G/7.90G [05:18<02:56, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60% 4.77G/7.90G [05:19<03:25, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.78G/7.90G [05:19<03:24, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.79G/7.90G [05:20<03:24, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.80G/7.90G [05:21<03:23, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.81G/7.90G [05:22<04:01, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.82G/7.90G [05:23<04:28, 11.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.83G/7.90G [05:24<04:47, 10.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.84G/7.90G [05:25<05:02, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61% 4.85G/7.90G [05:26<05:10, 9.79MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.87G/7.90G [05:28<05:15, 9.61MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.88G/7.90G [05:29<05:18, 9.47MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.89G/7.90G [05:30<05:20, 9.40MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.90G/7.90G [05:31<05:21, 9.34MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.91G/7.90G [05:32<05:21, 9.30MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.92G/7.90G [05:33<05:21, 9.27MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62% 4.93G/7.90G [05:34<05:20, 9.25MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.94G/7.90G [05:36<05:19, 9.24MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.95G/7.90G [05:36<05:00, 9.80MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.96G/7.90G [05:38<05:05, 9.61MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.97G/7.90G [05:38<04:49, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.98G/7.90G [05:39<04:40, 10.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 4.99G/7.90G [05:40<04:44, 10.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 5.00G/7.90G [05:41<04:18, 11.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63% 5.01G/7.90G [05:42<04:15, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.02G/7.90G [05:43<03:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.03G/7.90G [05:44<03:57, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.04G/7.90G [05:44<03:42, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.05G/7.90G [05:45<03:30, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.06G/7.90G [05:46<03:05, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.08G/7.90G [05:46<03:04, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64% 5.09G/7.90G [05:47<03:04, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.10G/7.90G [05:47<02:45, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.11G/7.90G [05:48<02:54, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.12G/7.90G [05:49<02:39, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.13G/7.90G [05:49<02:45, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.14G/7.90G [05:50<02:49, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.15G/7.90G [05:51<02:52, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.16G/7.90G [05:51<02:36, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65% 5.17G/7.90G [05:52<02:44, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.18G/7.90G [05:53<02:47, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.19G/7.90G [05:53<02:33, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.20G/7.90G [05:54<02:40, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.21G/7.90G [05:54<02:29, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.22G/7.90G [05:55<02:35, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.23G/7.90G [05:56<02:40, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66% 5.24G/7.90G [05:56<02:44, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.25G/7.90G [05:57<02:30, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.26G/7.90G [05:57<02:36, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.27G/7.90G [05:58<02:40, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.28G/7.90G [05:59<02:27, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.30G/7.90G [05:59<02:33, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.31G/7.90G [06:00<02:38, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.32G/7.90G [06:00<02:25, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67% 5.33G/7.90G [06:01<02:50, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.34G/7.90G [06:02<02:49, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.35G/7.90G [06:03<02:48, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.36G/7.90G [06:03<02:47, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.37G/7.90G [06:04<02:30, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.38G/7.90G [06:05<02:35, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.39G/7.90G [06:05<02:37, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68% 5.40G/7.90G [06:06<02:23, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.41G/7.90G [06:06<02:28, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.42G/7.90G [06:07<02:48, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.43G/7.90G [06:08<03:01, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.44G/7.90G [06:09<02:55, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.45G/7.90G [06:10<02:50, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.46G/7.90G [06:10<02:46, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.47G/7.90G [06:11<02:48, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69% 5.48G/7.90G [06:12<02:44, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.49G/7.90G [06:12<02:42, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.51G/7.90G [06:13<02:51, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.52G/7.90G [06:14<02:46, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.53G/7.90G [06:15<02:42, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.54G/7.90G [06:15<02:39, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.55G/7.90G [06:16<02:37, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70% 5.56G/7.90G [06:17<02:36, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.57G/7.90G [06:17<02:35, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.58G/7.90G [06:18<02:33, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.59G/7.90G [06:19<02:33, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.60G/7.90G [06:20<02:32, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.61G/7.90G [06:20<02:31, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.62G/7.90G [06:21<02:29, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.63G/7.90G [06:22<02:26, 15.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71% 5.64G/7.90G [06:22<02:26, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.65G/7.90G [06:23<02:31, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.66G/7.90G [06:24<02:23, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.67G/7.90G [06:24<02:15, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.68G/7.90G [06:25<02:18, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.69G/7.90G [06:26<02:19, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.70G/7.90G [06:26<02:20, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72% 5.71G/7.90G [06:27<02:07, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.73G/7.90G [06:27<02:11, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.74G/7.90G [06:28<02:14, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.75G/7.90G [06:29<02:02, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.76G/7.90G [06:29<02:07, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.77G/7.90G [06:30<02:10, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.78G/7.90G [06:30<01:59, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.79G/7.90G [06:31<02:04, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73% 5.80G/7.90G [06:32<01:54, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.81G/7.90G [06:32<02:01, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.82G/7.90G [06:33<02:05, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.83G/7.90G [06:33<01:54, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.84G/7.90G [06:34<02:13, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.85G/7.90G [06:35<02:13, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.86G/7.90G [06:36<02:13, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74% 5.87G/7.90G [06:37<02:25, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.88G/7.90G [06:38<02:33, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.89G/7.90G [06:38<02:26, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.90G/7.90G [06:39<02:34, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.91G/7.90G [06:40<02:26, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.92G/7.90G [06:41<02:32, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.93G/7.90G [06:41<02:26, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.95G/7.90G [06:42<02:21, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75% 5.96G/7.90G [06:43<02:25, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 5.97G/7.90G [06:44<02:22, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 5.98G/7.90G [06:45<02:41, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 5.99G/7.90G [06:46<02:42, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 6.00G/7.90G [06:47<02:42, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 6.01G/7.90G [06:48<02:42, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 6.02G/7.90G [06:49<02:42, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76% 6.03G/7.90G [06:49<02:41, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.04G/7.90G [06:50<02:40, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.05G/7.90G [06:51<02:39, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.06G/7.90G [06:52<02:28, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.07G/7.90G [06:53<02:30, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.08G/7.90G [06:54<02:32, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.09G/7.90G [06:55<02:32, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.10G/7.90G [06:56<02:32, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77% 6.11G/7.90G [06:56<02:22, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.12G/7.90G [06:57<02:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.13G/7.90G [06:58<02:27, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.14G/7.90G [06:59<02:26, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.16G/7.90G [07:00<02:17, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.17G/7.90G [07:01<02:20, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.18G/7.90G [07:01<02:12, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.19G/7.90G [07:02<02:15, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78% 6.20G/7.90G [07:03<02:08, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.21G/7.90G [07:04<02:02, 13.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.22G/7.90G [07:04<01:58, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.23G/7.90G [07:05<01:55, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.24G/7.90G [07:06<01:52, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.25G/7.90G [07:06<01:51, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.26G/7.90G [07:07<01:39, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79% 6.27G/7.90G [07:08<01:40, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.28G/7.90G [07:08<01:43, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.29G/7.90G [07:09<01:43, 15.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.30G/7.90G [07:09<01:33, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.31G/7.90G [07:10<01:36, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.32G/7.90G [07:11<01:38, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.33G/7.90G [07:11<01:29, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.34G/7.90G [07:12<01:52, 13.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80% 6.35G/7.90G [07:13<01:50, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.36G/7.90G [07:14<01:46, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.38G/7.90G [07:15<01:44, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.39G/7.90G [07:15<01:42, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.40G/7.90G [07:16<01:32, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.41G/7.90G [07:16<01:32, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.42G/7.90G [07:17<01:33, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81% 6.43G/7.90G [07:18<01:33, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.44G/7.90G [07:19<01:43, 14.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.45G/7.90G [07:19<01:40, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.46G/7.90G [07:20<01:46, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.47G/7.90G [07:21<01:42, 13.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.48G/7.90G [07:22<01:39, 14.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.49G/7.90G [07:22<01:36, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.50G/7.90G [07:23<01:34, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82% 6.51G/7.90G [07:24<01:33, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.52G/7.90G [07:24<01:31, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.53G/7.90G [07:25<01:30, 15.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.54G/7.90G [07:26<01:36, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.55G/7.90G [07:27<01:33, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.56G/7.90G [07:27<01:24, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.57G/7.90G [07:28<01:39, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83% 6.59G/7.90G [07:29<01:43, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.60G/7.90G [07:30<01:45, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.61G/7.90G [07:31<01:39, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.62G/7.90G [07:32<01:36, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.63G/7.90G [07:32<01:37, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.64G/7.90G [07:33<01:32, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.65G/7.90G [07:34<01:28, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.66G/7.90G [07:34<01:26, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84% 6.67G/7.90G [07:35<01:24, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.68G/7.90G [07:36<01:37, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.69G/7.90G [07:37<01:39, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.70G/7.90G [07:38<01:40, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.71G/7.90G [07:39<01:40, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.72G/7.90G [07:40<01:32, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.73G/7.90G [07:41<01:34, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85% 6.74G/7.90G [07:42<01:35, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.75G/7.90G [07:42<01:29, 12.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.76G/7.90G [07:43<01:31, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.77G/7.90G [07:44<01:25, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.78G/7.90G [07:45<01:28, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.79G/7.90G [07:45<01:22, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.81G/7.90G [07:46<01:25, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.82G/7.90G [07:47<01:27, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86% 6.83G/7.90G [07:48<01:22, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.84G/7.90G [07:49<01:24, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.85G/7.90G [07:50<01:19, 13.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.86G/7.90G [07:50<01:21, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.87G/7.90G [07:51<01:23, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.88G/7.90G [07:52<01:18, 13.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.89G/7.90G [07:53<01:13, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87% 6.90G/7.90G [07:54<01:17, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.91G/7.90G [07:54<01:13, 13.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.92G/7.90G [07:55<01:09, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.93G/7.90G [07:56<01:07, 14.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.94G/7.90G [07:56<01:05, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.95G/7.90G [07:57<01:03, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.96G/7.90G [07:58<01:02, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.97G/7.90G [07:58<00:55, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88% 6.98G/7.90G [07:59<00:56, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 6.99G/7.90G [08:00<00:56, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.00G/7.90G [08:00<00:51, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.01G/7.90G [08:01<00:52, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.03G/7.90G [08:02<00:53, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.04G/7.90G [08:02<00:48, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.05G/7.90G [08:03<00:50, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89% 7.06G/7.90G [08:03<00:51, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.07G/7.90G [08:04<00:46, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.08G/7.90G [08:05<00:48, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.09G/7.90G [08:05<00:44, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.10G/7.90G [08:06<00:46, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.11G/7.90G [08:06<00:47, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.12G/7.90G [08:07<00:44, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.13G/7.90G [08:08<00:44, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90% 7.14G/7.90G [08:08<00:46, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.15G/7.90G [08:09<00:43, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.16G/7.90G [08:09<00:43, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.17G/7.90G [08:10<00:44, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.18G/7.90G [08:11<00:41, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.19G/7.90G [08:11<00:41, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.20G/7.90G [08:12<00:41, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91% 7.21G/7.90G [08:12<00:39, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.22G/7.90G [08:13<00:38, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.24G/7.90G [08:14<00:36, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.25G/7.90G [08:14<00:37, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.26G/7.90G [08:15<00:38, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.27G/7.90G [08:15<00:35, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.28G/7.90G [08:16<00:35, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.29G/7.90G [08:17<00:33, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92% 7.30G/7.90G [08:17<00:34, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.31G/7.90G [08:18<00:32, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.32G/7.90G [08:19<00:33, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.33G/7.90G [08:19<00:33, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.34G/7.90G [08:20<00:31, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.35G/7.90G [08:20<00:31, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.36G/7.90G [08:21<00:31, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93% 7.37G/7.90G [08:22<00:29, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.38G/7.90G [08:22<00:29, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.39G/7.90G [08:23<00:30, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.40G/7.90G [08:23<00:28, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.41G/7.90G [08:24<00:28, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.42G/7.90G [08:25<00:29, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.43G/7.90G [08:25<00:26, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.44G/7.90G [08:26<00:26, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94% 7.46G/7.90G [08:27<00:27, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.47G/7.90G [08:27<00:26, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.48G/7.90G [08:28<00:26, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.49G/7.90G [08:28<00:23, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.50G/7.90G [08:29<00:23, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.51G/7.90G [08:30<00:23, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.52G/7.90G [08:30<00:21, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.53G/7.90G [08:31<00:21, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95% 7.54G/7.90G [08:31<00:19, 18.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.55G/7.90G [08:32<00:20, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.56G/7.90G [08:33<00:20, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.57G/7.90G [08:34<00:20, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.58G/7.90G [08:34<00:17, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.59G/7.90G [08:35<00:20, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.60G/7.90G [08:36<00:19, 15.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96% 7.61G/7.90G [08:36<00:18, 15.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.62G/7.90G [08:37<00:16, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.63G/7.90G [08:37<00:16, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.64G/7.90G [08:38<00:15, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.65G/7.90G [08:39<00:15, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.67G/7.90G [08:39<00:13, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.68G/7.90G [08:40<00:13, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.69G/7.90G [08:41<00:13, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97% 7.70G/7.90G [08:41<00:11, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.71G/7.90G [08:42<00:11, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.72G/7.90G [08:43<00:10, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.73G/7.90G [08:43<00:09, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.74G/7.90G [08:44<00:09, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.75G/7.90G [08:44<00:08, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.76G/7.90G [08:45<00:07, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98% 7.77G/7.90G [08:46<00:07, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.78G/7.90G [08:46<00:06, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.79G/7.90G [08:47<00:05, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.80G/7.90G [08:47<00:05, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.81G/7.90G [08:48<00:04, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.82G/7.90G [08:49<00:04, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.83G/7.90G [08:49<00:03, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.84G/7.90G [08:50<00:03, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99% 7.85G/7.90G [08:51<00:02, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100% 7.86G/7.90G [08:52<00:02, 14.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100% 7.87G/7.90G [08:52<00:01, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100% 7.89G/7.90G [08:53<00:00, 14.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100% 7.90G/7.90G [08:54<00:00, 14.8MB/s]\n",
      "Downloading shards:  50% 1/2 [08:55<08:55, 535.63s/it]\n",
      "pytorch_model-00002-of-00002.bin:   0% 0.00/7.21G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0% 10.5M/7.21G [00:02<23:44, 5.06MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0% 21.0M/7.21G [00:02<14:22, 8.34MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0% 31.5M/7.21G [00:03<11:20, 10.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 41.9M/7.21G [00:03<08:58, 13.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 52.4M/7.21G [00:04<08:31, 14.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 62.9M/7.21G [00:05<07:26, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 73.4M/7.21G [00:05<07:32, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 83.9M/7.21G [00:06<07:36, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 94.4M/7.21G [00:06<06:53, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1% 105M/7.21G [00:07<07:08, 16.6MB/s] \u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 115M/7.21G [00:08<07:19, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 126M/7.21G [00:08<06:41, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 136M/7.21G [00:09<07:01, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 147M/7.21G [00:09<06:28, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 157M/7.21G [00:10<06:48, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 168M/7.21G [00:11<07:04, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2% 178M/7.21G [00:11<06:31, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 189M/7.21G [00:12<06:50, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 199M/7.21G [00:12<06:22, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 210M/7.21G [00:13<06:44, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 220M/7.21G [00:14<06:59, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 231M/7.21G [00:14<06:27, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 241M/7.21G [00:15<06:46, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3% 252M/7.21G [00:16<07:01, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 262M/7.21G [00:16<06:28, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 273M/7.21G [00:17<06:48, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 283M/7.21G [00:17<06:18, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 294M/7.21G [00:18<06:40, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 304M/7.21G [00:19<06:55, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4% 315M/7.21G [00:19<06:23, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 325M/7.21G [00:20<06:43, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 336M/7.21G [00:20<06:58, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 346M/7.21G [00:21<06:23, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 357M/7.21G [00:22<06:45, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 367M/7.21G [00:22<06:58, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 377M/7.21G [00:23<07:07, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5% 388M/7.21G [00:23<06:30, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 398M/7.21G [00:24<06:48, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 409M/7.21G [00:25<06:59, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 419M/7.21G [00:25<06:24, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 430M/7.21G [00:26<06:42, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 440M/7.21G [00:27<06:55, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 451M/7.21G [00:27<07:02, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6% 461M/7.21G [00:28<06:26, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 472M/7.21G [00:29<06:42, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 482M/7.21G [00:29<06:11, 18.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 493M/7.21G [00:30<06:32, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 503M/7.21G [00:30<06:45, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 514M/7.21G [00:31<06:12, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 524M/7.21G [00:32<06:32, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7% 535M/7.21G [00:32<06:03, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 545M/7.21G [00:33<06:25, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 556M/7.21G [00:33<06:39, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 566M/7.21G [00:34<06:08, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 577M/7.21G [00:35<06:27, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 587M/7.21G [00:35<06:40, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 598M/7.21G [00:36<06:08, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8% 608M/7.21G [00:36<06:27, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 619M/7.21G [00:37<05:59, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 629M/7.21G [00:38<06:20, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 640M/7.21G [00:38<06:35, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 650M/7.21G [00:39<06:06, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 661M/7.21G [00:39<06:23, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 671M/7.21G [00:40<06:36, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9% 682M/7.21G [00:41<06:05, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 692M/7.21G [00:41<06:21, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 703M/7.21G [00:42<05:56, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 713M/7.21G [00:42<06:15, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 724M/7.21G [00:43<06:28, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 734M/7.21G [00:44<05:59, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 744M/7.21G [00:44<06:17, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10% 755M/7.21G [00:45<05:51, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 765M/7.21G [00:45<06:11, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 776M/7.21G [00:46<06:25, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 786M/7.21G [00:47<05:56, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 797M/7.21G [00:47<06:14, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 807M/7.21G [00:48<05:47, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 818M/7.21G [00:48<06:08, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11% 828M/7.21G [00:49<06:22, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 839M/7.21G [00:50<05:56, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 849M/7.21G [00:50<06:10, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 860M/7.21G [00:51<05:44, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 870M/7.21G [00:51<06:06, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 881M/7.21G [00:52<06:19, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12% 891M/7.21G [00:53<05:51, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 902M/7.21G [00:53<06:08, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 912M/7.21G [00:54<06:20, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 923M/7.21G [00:54<05:51, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 933M/7.21G [00:55<06:07, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 944M/7.21G [00:56<05:42, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 954M/7.21G [00:56<06:00, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13% 965M/7.21G [00:57<06:14, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 975M/7.21G [00:57<05:46, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 986M/7.21G [00:58<06:02, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 996M/7.21G [00:59<05:38, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 1.01G/7.21G [00:59<05:58, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 1.02G/7.21G [01:00<06:10, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 1.03G/7.21G [01:00<05:43, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14% 1.04G/7.21G [01:01<05:58, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.05G/7.21G [01:02<05:36, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.06G/7.21G [01:02<05:54, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.07G/7.21G [01:03<06:07, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.08G/7.21G [01:03<05:40, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.09G/7.21G [01:04<05:57, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.10G/7.21G [01:05<06:08, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15% 1.11G/7.21G [01:05<05:40, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.12G/7.21G [01:06<05:56, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.13G/7.21G [01:06<05:32, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.14G/7.21G [01:07<05:50, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.15G/7.21G [01:08<06:04, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.16G/7.21G [01:08<06:13, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.17G/7.21G [01:09<05:43, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16% 1.18G/7.21G [01:10<05:57, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.20G/7.21G [01:10<06:08, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.21G/7.21G [01:11<06:15, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.22G/7.21G [01:11<05:42, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.23G/7.21G [01:12<05:57, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.24G/7.21G [01:13<06:06, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.25G/7.21G [01:13<05:36, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17% 1.26G/7.21G [01:14<05:51, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.27G/7.21G [01:15<06:02, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.28G/7.21G [01:15<05:32, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.29G/7.21G [01:16<05:49, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.30G/7.21G [01:16<05:24, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.31G/7.21G [01:17<05:41, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.32G/7.21G [01:18<05:54, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18% 1.33G/7.21G [01:18<05:27, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.34G/7.21G [01:19<05:43, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.35G/7.21G [01:19<05:54, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.36G/7.21G [01:20<05:26, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.37G/7.21G [01:21<05:42, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.38G/7.21G [01:21<05:18, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.39G/7.21G [01:22<05:36, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19% 1.41G/7.21G [01:22<05:48, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.42G/7.21G [01:23<05:21, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.43G/7.21G [01:24<05:38, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.44G/7.21G [01:24<05:15, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.45G/7.21G [01:25<05:32, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.46G/7.21G [01:25<05:45, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20% 1.47G/7.21G [01:26<05:18, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.48G/7.21G [01:27<05:35, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.49G/7.21G [01:27<05:46, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.50G/7.21G [01:28<05:19, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.51G/7.21G [01:28<05:34, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.52G/7.21G [01:29<05:46, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.53G/7.21G [01:30<05:18, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21% 1.54G/7.21G [01:30<05:34, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.55G/7.21G [01:31<05:09, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.56G/7.21G [01:31<05:27, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.57G/7.21G [01:32<05:39, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.58G/7.21G [01:33<05:13, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.59G/7.21G [01:33<05:28, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.60G/7.21G [01:34<05:40, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22% 1.61G/7.21G [01:35<05:12, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.63G/7.21G [01:35<05:28, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.64G/7.21G [01:36<05:03, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.65G/7.21G [01:36<05:22, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.66G/7.21G [01:37<05:34, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.67G/7.21G [01:37<05:07, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.68G/7.21G [01:38<05:24, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23% 1.69G/7.21G [01:39<05:01, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.70G/7.21G [01:39<05:17, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.71G/7.21G [01:40<05:30, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.72G/7.21G [01:40<05:04, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.73G/7.21G [01:41<05:20, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.74G/7.21G [01:42<05:31, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.75G/7.21G [01:42<05:04, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24% 1.76G/7.21G [01:43<05:21, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.77G/7.21G [01:44<04:56, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.78G/7.21G [01:44<05:13, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.79G/7.21G [01:45<05:25, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.80G/7.21G [01:45<05:00, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.81G/7.21G [01:46<05:15, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.82G/7.21G [01:47<05:27, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25% 1.84G/7.21G [01:47<05:34, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.85G/7.21G [01:48<05:06, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.86G/7.21G [01:49<05:18, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.87G/7.21G [01:49<04:55, 18.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.88G/7.21G [01:50<05:09, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.89G/7.21G [01:50<05:20, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.90G/7.21G [01:51<04:57, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26% 1.91G/7.21G [01:52<05:10, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.92G/7.21G [01:52<04:50, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.93G/7.21G [01:53<05:06, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.94G/7.21G [01:53<05:15, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.95G/7.21G [01:54<04:53, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.96G/7.21G [01:55<05:07, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.97G/7.21G [01:55<05:15, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27% 1.98G/7.21G [01:56<04:52, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 1.99G/7.21G [01:56<05:05, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 2.00G/7.21G [01:57<04:44, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 2.01G/7.21G [01:58<05:01, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 2.02G/7.21G [01:58<05:10, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 2.03G/7.21G [01:59<04:49, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28% 2.04G/7.21G [01:59<05:01, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.06G/7.21G [02:00<05:11, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.07G/7.21G [02:01<04:49, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.08G/7.21G [02:01<05:01, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.09G/7.21G [02:02<04:41, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.10G/7.21G [02:02<04:57, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.11G/7.21G [02:03<05:05, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29% 2.12G/7.21G [02:04<04:44, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.13G/7.21G [02:04<04:55, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.14G/7.21G [02:05<04:36, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.15G/7.21G [02:05<04:50, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.16G/7.21G [02:06<05:01, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.17G/7.21G [02:07<04:40, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.18G/7.21G [02:07<04:52, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30% 2.19G/7.21G [02:08<04:34, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.20G/7.21G [02:08<04:49, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.21G/7.21G [02:09<04:58, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.22G/7.21G [02:10<04:37, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.23G/7.21G [02:10<04:49, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.24G/7.21G [02:11<05:00, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.25G/7.21G [02:11<04:37, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31% 2.26G/7.21G [02:12<04:51, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.28G/7.21G [02:13<05:00, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.29G/7.21G [02:13<04:36, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.30G/7.21G [02:14<04:51, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.31G/7.21G [02:14<04:27, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.32G/7.21G [02:15<04:43, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.33G/7.21G [02:16<04:53, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32% 2.34G/7.21G [02:16<04:30, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.35G/7.21G [02:17<04:44, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.36G/7.21G [02:18<04:54, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.37G/7.21G [02:18<04:30, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.38G/7.21G [02:19<04:43, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.39G/7.21G [02:19<04:22, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.40G/7.21G [02:20<04:38, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33% 2.41G/7.21G [02:21<04:49, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.42G/7.21G [02:21<04:56, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.43G/7.21G [02:22<04:30, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.44G/7.21G [02:22<04:42, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.45G/7.21G [02:23<04:51, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.46G/7.21G [02:24<04:27, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.47G/7.21G [02:24<04:39, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34% 2.49G/7.21G [02:25<04:19, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.50G/7.21G [02:25<04:33, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.51G/7.21G [02:26<04:43, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.52G/7.21G [02:27<04:22, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.53G/7.21G [02:27<04:34, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.54G/7.21G [02:28<04:43, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.55G/7.21G [02:28<04:20, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35% 2.56G/7.21G [02:29<04:33, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.57G/7.21G [02:30<04:42, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.58G/7.21G [02:30<04:19, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.59G/7.21G [02:31<04:32, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.60G/7.21G [02:32<04:40, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.61G/7.21G [02:32<04:18, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.62G/7.21G [02:33<04:29, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36% 2.63G/7.21G [02:33<04:09, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.64G/7.21G [02:34<04:24, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.65G/7.21G [02:35<04:34, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.66G/7.21G [02:35<04:13, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.67G/7.21G [02:36<04:24, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.68G/7.21G [02:37<04:34, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37% 2.69G/7.21G [02:37<04:12, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.71G/7.21G [02:38<04:24, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.72G/7.21G [02:38<04:33, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.73G/7.21G [02:39<04:11, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.74G/7.21G [02:40<04:23, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.75G/7.21G [02:40<04:03, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.76G/7.21G [02:41<04:17, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38% 2.77G/7.21G [02:41<04:27, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.78G/7.21G [02:42<04:06, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.79G/7.21G [02:43<04:18, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.80G/7.21G [02:43<04:27, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.81G/7.21G [02:44<04:05, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.82G/7.21G [02:44<04:18, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.83G/7.21G [02:45<03:58, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39% 2.84G/7.21G [02:46<04:12, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.85G/7.21G [02:46<04:22, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.86G/7.21G [02:47<04:01, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.87G/7.21G [02:47<04:14, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.88G/7.21G [02:48<04:22, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.89G/7.21G [02:49<04:01, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.90G/7.21G [02:49<04:13, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40% 2.92G/7.21G [02:50<03:54, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.93G/7.21G [02:50<04:09, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.94G/7.21G [02:51<04:16, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.95G/7.21G [02:52<03:56, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.96G/7.21G [02:52<04:09, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.97G/7.21G [02:53<04:17, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.98G/7.21G [02:53<03:56, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41% 2.99G/7.21G [02:54<04:08, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.00G/7.21G [02:55<03:49, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.01G/7.21G [02:55<04:03, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.02G/7.21G [02:56<04:12, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.03G/7.21G [02:56<03:54, 17.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.04G/7.21G [02:57<04:04, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.05G/7.21G [02:58<03:47, 18.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42% 3.06G/7.21G [02:58<04:00, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.07G/7.21G [02:59<04:09, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.08G/7.21G [02:59<03:49, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.09G/7.21G [03:00<04:00, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.10G/7.21G [03:01<04:14, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.11G/7.21G [03:01<03:52, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.12G/7.21G [03:02<04:02, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43% 3.14G/7.21G [03:02<03:43, 18.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.15G/7.21G [03:03<03:55, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.16G/7.21G [03:04<04:04, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.17G/7.21G [03:04<03:44, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.18G/7.21G [03:05<03:56, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.19G/7.21G [03:06<04:03, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.20G/7.21G [03:06<03:44, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44% 3.21G/7.21G [03:07<03:55, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.22G/7.21G [03:07<03:37, 18.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.23G/7.21G [03:08<03:50, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.24G/7.21G [03:09<03:58, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.25G/7.21G [03:09<03:39, 18.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.26G/7.21G [03:10<03:51, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45% 3.27G/7.21G [03:10<03:58, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.28G/7.21G [03:11<03:39, 17.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.29G/7.21G [03:12<03:50, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.30G/7.21G [03:12<04:01, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.31G/7.21G [03:13<03:42, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.32G/7.21G [03:14<03:55, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.33G/7.21G [03:14<03:39, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46% 3.34G/7.21G [03:15<03:51, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.36G/7.21G [03:16<04:01, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.37G/7.21G [03:16<03:42, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.38G/7.21G [03:17<03:55, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.39G/7.21G [03:17<04:02, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.40G/7.21G [03:18<03:42, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.41G/7.21G [03:19<03:53, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47% 3.42G/7.21G [03:19<03:36, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.43G/7.21G [03:20<03:48, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.44G/7.21G [03:21<03:57, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.45G/7.21G [03:21<03:39, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.46G/7.21G [03:22<03:49, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.47G/7.21G [03:23<03:56, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.48G/7.21G [03:23<03:38, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48% 3.49G/7.21G [03:24<03:48, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.50G/7.21G [03:24<03:32, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.51G/7.21G [03:25<03:42, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.52G/7.21G [03:25<03:28, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.53G/7.21G [03:26<03:39, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.54G/7.21G [03:27<03:48, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.55G/7.21G [03:27<03:32, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49% 3.57G/7.21G [03:28<03:42, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.58G/7.21G [03:29<03:26, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.59G/7.21G [03:29<03:38, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.60G/7.21G [03:30<03:45, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.61G/7.21G [03:30<03:28, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.62G/7.21G [03:31<03:38, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.63G/7.21G [03:32<03:46, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50% 3.64G/7.21G [03:32<03:28, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.65G/7.21G [03:33<03:38, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.66G/7.21G [03:34<03:23, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.67G/7.21G [03:34<03:33, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.68G/7.21G [03:35<03:41, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.69G/7.21G [03:36<03:25, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.70G/7.21G [03:36<03:34, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51% 3.71G/7.21G [03:37<03:41, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.72G/7.21G [03:37<03:24, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.73G/7.21G [03:38<03:33, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.74G/7.21G [03:39<03:18, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.75G/7.21G [03:39<03:29, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.76G/7.21G [03:40<03:35, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.77G/7.21G [03:41<03:19, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52% 3.79G/7.21G [03:41<03:28, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.80G/7.21G [03:42<03:35, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.81G/7.21G [03:43<03:20, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.82G/7.21G [03:43<03:27, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.83G/7.21G [03:44<03:13, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.84G/7.21G [03:44<03:24, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53% 3.85G/7.21G [03:45<03:30, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.86G/7.21G [03:46<03:14, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.87G/7.21G [03:46<03:23, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.88G/7.21G [03:47<03:30, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.89G/7.21G [03:48<03:14, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.90G/7.21G [03:48<03:22, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.91G/7.21G [03:49<03:10, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54% 3.92G/7.21G [03:49<03:17, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.93G/7.21G [03:50<03:25, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.94G/7.21G [03:51<03:09, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.95G/7.21G [03:51<03:18, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.96G/7.21G [03:52<03:25, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.97G/7.21G [03:53<03:09, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 3.98G/7.21G [03:53<03:17, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55% 4.00G/7.21G [03:54<03:03, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.01G/7.21G [03:55<03:13, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.02G/7.21G [03:55<03:20, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.03G/7.21G [03:56<03:05, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.04G/7.21G [03:56<03:14, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.05G/7.21G [03:57<03:00, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.06G/7.21G [03:58<03:09, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56% 4.07G/7.21G [03:58<03:17, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.08G/7.21G [03:59<03:02, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.09G/7.21G [04:00<03:10, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.10G/7.21G [04:00<03:17, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.11G/7.21G [04:01<03:01, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.12G/7.21G [04:02<03:09, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.13G/7.21G [04:02<02:57, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57% 4.14G/7.21G [04:03<03:04, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.15G/7.21G [04:03<03:11, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.16G/7.21G [04:04<02:57, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.17G/7.21G [04:05<03:05, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.18G/7.21G [04:05<02:52, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.19G/7.21G [04:06<03:01, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.20G/7.21G [04:07<03:08, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58% 4.22G/7.21G [04:07<02:54, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.23G/7.21G [04:08<03:02, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.24G/7.21G [04:09<03:07, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.25G/7.21G [04:09<02:53, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.26G/7.21G [04:10<03:00, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.27G/7.21G [04:10<03:06, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.28G/7.21G [04:11<02:52, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59% 4.29G/7.21G [04:12<02:59, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.30G/7.21G [04:12<02:47, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.31G/7.21G [04:13<02:54, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.32G/7.21G [04:14<03:01, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.33G/7.21G [04:14<02:48, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.34G/7.21G [04:15<02:55, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.35G/7.21G [04:15<02:43, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60% 4.36G/7.21G [04:16<02:51, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.37G/7.21G [04:17<02:58, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.38G/7.21G [04:17<02:44, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.39G/7.21G [04:18<02:52, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.40G/7.21G [04:18<02:40, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.41G/7.21G [04:19<02:48, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61% 4.42G/7.21G [04:20<02:54, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.44G/7.21G [04:20<02:41, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.45G/7.21G [04:21<02:49, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.46G/7.21G [04:22<02:54, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.47G/7.21G [04:22<02:41, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.48G/7.21G [04:23<02:47, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.49G/7.21G [04:24<02:36, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62% 4.50G/7.21G [04:24<02:43, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.51G/7.21G [04:25<02:49, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.52G/7.21G [04:25<02:37, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.53G/7.21G [04:26<02:43, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.54G/7.21G [04:27<02:49, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.55G/7.21G [04:28<02:53, 15.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.56G/7.21G [04:28<02:37, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63% 4.57G/7.21G [04:29<02:44, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.58G/7.21G [04:30<02:49, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.59G/7.21G [04:30<02:34, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.60G/7.21G [04:31<02:41, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.61G/7.21G [04:31<02:46, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.62G/7.21G [04:32<02:32, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.63G/7.21G [04:33<02:39, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64% 4.65G/7.21G [04:33<02:43, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.66G/7.21G [04:34<02:30, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.67G/7.21G [04:35<02:36, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.68G/7.21G [04:35<02:24, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.69G/7.21G [04:36<02:32, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.70G/7.21G [04:37<02:37, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.71G/7.21G [04:37<02:25, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65% 4.72G/7.21G [04:38<02:32, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.73G/7.21G [04:38<02:37, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.74G/7.21G [04:39<02:24, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.75G/7.21G [04:40<02:31, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.76G/7.21G [04:40<02:19, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.77G/7.21G [04:41<02:27, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.78G/7.21G [04:42<02:32, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66% 4.79G/7.21G [04:42<02:20, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.80G/7.21G [04:43<02:27, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.81G/7.21G [04:44<02:31, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.82G/7.21G [04:44<02:19, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.83G/7.21G [04:45<02:25, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.84G/7.21G [04:45<02:15, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.85G/7.21G [04:46<02:22, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67% 4.87G/7.21G [04:47<02:27, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.88G/7.21G [04:47<02:15, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.89G/7.21G [04:48<02:22, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.90G/7.21G [04:48<02:11, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.91G/7.21G [04:49<02:18, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.92G/7.21G [04:50<02:24, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.93G/7.21G [04:50<02:12, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68% 4.94G/7.21G [04:51<02:18, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 4.95G/7.21G [04:51<02:08, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 4.96G/7.21G [04:52<02:15, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 4.97G/7.21G [04:53<02:20, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 4.98G/7.21G [04:53<02:09, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 4.99G/7.21G [04:54<02:15, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69% 5.00G/7.21G [04:55<02:19, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.01G/7.21G [04:55<02:08, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.02G/7.21G [04:56<02:14, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.03G/7.21G [04:57<02:18, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.04G/7.21G [04:57<02:07, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.05G/7.21G [04:58<02:12, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.06G/7.21G [04:59<02:16, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70% 5.08G/7.21G [04:59<02:05, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.09G/7.21G [05:00<02:10, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.10G/7.21G [05:00<02:00, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.11G/7.21G [05:01<02:07, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.12G/7.21G [05:02<02:11, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.13G/7.21G [05:02<02:00, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.14G/7.21G [05:03<02:06, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71% 5.15G/7.21G [05:04<02:10, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.16G/7.21G [05:04<01:59, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.17G/7.21G [05:05<02:05, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.18G/7.21G [05:05<01:57, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.19G/7.21G [05:06<02:01, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.20G/7.21G [05:07<02:06, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.21G/7.21G [05:07<01:55, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72% 5.22G/7.21G [05:08<02:01, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.23G/7.21G [05:09<01:52, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.24G/7.21G [05:09<01:58, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.25G/7.21G [05:10<02:03, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.26G/7.21G [05:11<02:05, 15.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.27G/7.21G [05:11<01:54, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.28G/7.21G [05:12<01:59, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73% 5.30G/7.21G [05:12<01:50, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.31G/7.21G [05:13<01:55, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.32G/7.21G [05:14<01:59, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.33G/7.21G [05:14<01:49, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.34G/7.21G [05:15<01:54, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.35G/7.21G [05:16<01:58, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.36G/7.21G [05:16<01:48, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74% 5.37G/7.21G [05:17<01:53, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.38G/7.21G [05:18<01:44, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.39G/7.21G [05:18<01:50, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.40G/7.21G [05:19<01:53, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.41G/7.21G [05:19<01:44, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.42G/7.21G [05:20<01:49, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.43G/7.21G [05:21<01:52, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75% 5.44G/7.21G [05:21<01:43, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.45G/7.21G [05:22<01:47, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.46G/7.21G [05:23<01:39, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.47G/7.21G [05:23<01:45, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.48G/7.21G [05:24<01:48, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.49G/7.21G [05:25<01:39, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.51G/7.21G [05:25<01:44, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76% 5.52G/7.21G [05:26<01:47, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.53G/7.21G [05:26<01:38, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.54G/7.21G [05:27<01:42, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.55G/7.21G [05:28<01:34, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.56G/7.21G [05:28<01:40, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.57G/7.21G [05:29<01:43, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77% 5.58G/7.21G [05:30<01:34, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.59G/7.21G [05:30<01:39, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.60G/7.21G [05:31<01:31, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.61G/7.21G [05:32<01:37, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.62G/7.21G [05:32<01:39, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.63G/7.21G [05:33<01:31, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.64G/7.21G [05:33<01:35, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78% 5.65G/7.21G [05:34<01:29, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.66G/7.21G [05:35<01:33, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.67G/7.21G [05:35<01:36, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.68G/7.21G [05:36<01:28, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.69G/7.21G [05:37<01:32, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.70G/7.21G [05:37<01:35, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.71G/7.21G [05:38<01:27, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79% 5.73G/7.21G [05:38<01:31, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.74G/7.21G [05:39<01:24, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.75G/7.21G [05:40<01:28, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.76G/7.21G [05:40<01:31, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.77G/7.21G [05:41<01:23, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.78G/7.21G [05:42<01:27, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.79G/7.21G [05:42<01:30, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80% 5.80G/7.21G [05:43<01:22, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.81G/7.21G [05:44<01:26, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.82G/7.21G [05:44<01:19, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.83G/7.21G [05:45<01:23, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.84G/7.21G [05:45<01:17, 17.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.85G/7.21G [05:46<01:21, 16.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.86G/7.21G [05:47<01:24, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81% 5.87G/7.21G [05:47<01:17, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.88G/7.21G [05:48<01:20, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.89G/7.21G [05:49<01:23, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.90G/7.21G [05:49<01:15, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.91G/7.21G [05:50<01:19, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.92G/7.21G [05:50<01:13, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.93G/7.21G [05:51<01:17, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82% 5.95G/7.21G [05:52<01:19, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 5.96G/7.21G [05:52<01:12, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 5.97G/7.21G [05:53<01:15, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 5.98G/7.21G [05:53<01:09, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 5.99G/7.21G [05:54<01:13, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 6.00G/7.21G [05:55<01:16, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 6.01G/7.21G [05:55<01:09, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83% 6.02G/7.21G [05:56<01:12, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.03G/7.21G [05:57<01:14, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.04G/7.21G [05:57<01:08, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.05G/7.21G [05:58<01:11, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.06G/7.21G [05:59<01:05, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.07G/7.21G [05:59<01:08, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.08G/7.21G [06:00<01:10, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84% 6.09G/7.21G [06:00<01:04, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.10G/7.21G [06:01<01:07, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.11G/7.21G [06:02<01:02, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.12G/7.21G [06:02<01:05, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.13G/7.21G [06:03<01:07, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.14G/7.21G [06:04<01:01, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85% 6.16G/7.21G [06:04<01:04, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.17G/7.21G [06:05<01:06, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.18G/7.21G [06:05<01:00, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.19G/7.21G [06:06<01:02, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.20G/7.21G [06:07<00:57, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.21G/7.21G [06:07<01:00, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.22G/7.21G [06:08<01:02, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86% 6.23G/7.21G [06:09<00:57, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.24G/7.21G [06:09<00:59, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.25G/7.21G [06:10<00:54, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.26G/7.21G [06:11<00:57, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.27G/7.21G [06:11<00:58, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.28G/7.21G [06:12<00:54, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.29G/7.21G [06:12<00:56, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87% 6.30G/7.21G [06:13<00:51, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.31G/7.21G [06:14<00:54, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.32G/7.21G [06:14<00:55, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.33G/7.21G [06:15<00:50, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.34G/7.21G [06:16<00:52, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.35G/7.21G [06:16<00:48, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.36G/7.21G [06:17<00:50, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88% 6.38G/7.21G [06:18<00:52, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.39G/7.21G [06:18<00:47, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.40G/7.21G [06:19<00:49, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.41G/7.21G [06:19<00:45, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.42G/7.21G [06:20<00:47, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.43G/7.21G [06:21<00:49, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.44G/7.21G [06:21<00:45, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89% 6.45G/7.21G [06:22<00:46, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.46G/7.21G [06:22<00:43, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.47G/7.21G [06:23<00:45, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.48G/7.21G [06:24<00:45, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.49G/7.21G [06:24<00:41, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.50G/7.21G [06:25<00:43, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.51G/7.21G [06:26<00:44, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90% 6.52G/7.21G [06:26<00:40, 17.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.53G/7.21G [06:27<00:41, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.54G/7.21G [06:27<00:38, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.55G/7.21G [06:28<00:39, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.56G/7.21G [06:29<00:40, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.57G/7.21G [06:29<00:37, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.59G/7.21G [06:30<00:38, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91% 6.60G/7.21G [06:31<00:39, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.61G/7.21G [06:31<00:35, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.62G/7.21G [06:32<00:36, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.63G/7.21G [06:33<00:33, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.64G/7.21G [06:33<00:34, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.65G/7.21G [06:34<00:35, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.66G/7.21G [06:34<00:32, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92% 6.67G/7.21G [06:35<00:33, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.68G/7.21G [06:36<00:33, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.69G/7.21G [06:37<00:33, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.70G/7.21G [06:37<00:30, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.71G/7.21G [06:38<00:31, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.72G/7.21G [06:39<00:31, 15.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.73G/7.21G [06:39<00:28, 16.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93% 6.74G/7.21G [06:40<00:28, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.75G/7.21G [06:40<00:26, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.76G/7.21G [06:41<00:27, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.77G/7.21G [06:42<00:27, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.78G/7.21G [06:42<00:24, 17.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.79G/7.21G [06:43<00:25, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94% 6.81G/7.21G [06:43<00:23, 17.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.82G/7.21G [06:44<00:23, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.83G/7.21G [06:45<00:24, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.84G/7.21G [06:45<00:21, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.85G/7.21G [06:46<00:22, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.86G/7.21G [06:47<00:22, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.87G/7.21G [06:47<00:20, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95% 6.88G/7.21G [06:48<00:20, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.89G/7.21G [06:48<00:18, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.90G/7.21G [06:49<00:18, 16.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.91G/7.21G [06:50<00:18, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.92G/7.21G [06:50<00:16, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.93G/7.21G [06:51<00:17, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.94G/7.21G [06:52<00:17, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96% 6.95G/7.21G [06:52<00:15, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 6.96G/7.21G [06:53<00:15, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 6.97G/7.21G [06:54<00:15, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 6.98G/7.21G [06:54<00:13, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 6.99G/7.21G [06:55<00:13, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 7.00G/7.21G [06:56<00:13, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 7.01G/7.21G [06:56<00:11, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97% 7.03G/7.21G [06:57<00:11, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.04G/7.21G [06:58<00:11, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.05G/7.21G [06:58<00:09, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.06G/7.21G [06:59<00:09, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.07G/7.21G [07:00<00:09, 15.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.08G/7.21G [07:00<00:07, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.09G/7.21G [07:01<00:07, 16.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98% 7.10G/7.21G [07:01<00:06, 17.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.11G/7.21G [07:02<00:06, 16.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.12G/7.21G [07:03<00:05, 15.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.13G/7.21G [07:03<00:05, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.14G/7.21G [07:04<00:04, 16.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.15G/7.21G [07:05<00:03, 16.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.16G/7.21G [07:05<00:02, 17.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99% 7.17G/7.21G [07:06<00:02, 16.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100% 7.18G/7.21G [07:07<00:01, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100% 7.19G/7.21G [07:07<00:01, 17.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100% 7.20G/7.21G [07:08<00:00, 16.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100% 7.21G/7.21G [07:08<00:00, 16.8MB/s]\n",
      "Downloading shards: 100% 2/2 [16:05<00:00, 482.90s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  6.07it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-6b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:16<01:02,  6.61it/s]04/30/2024 01:48:44 - WARNING - __main__ - epoch 0 step 102 loss 0.35247\n",
      "[[0.08556639]\n",
      " [0.048322  ]\n",
      " [0.05496649]\n",
      " ...\n",
      " [0.07706971]\n",
      " [0.064886  ]\n",
      " [0.09699358]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 01:48:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:48:55 - INFO - __main__ -   auc_score = 0.6838\n",
      "04/30/2024 01:48:55 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 01:48:55 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 01:48:55 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [00:42<00:46,  6.59it/s]04/30/2024 01:49:10 - WARNING - __main__ - epoch 0 step 204 loss 0.2758\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.11989953]\n",
      " [0.02233313]\n",
      " [0.03470868]\n",
      " ...\n",
      " [0.08980563]\n",
      " [0.04950585]\n",
      " [0.13568433]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 01:49:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:49:21 - INFO - __main__ -   auc_score = 0.772\n",
      "04/30/2024 01:49:21 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 01:49:21 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 01:49:21 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [01:09<00:31,  6.61it/s]04/30/2024 01:49:36 - WARNING - __main__ - epoch 0 step 306 loss 0.27558\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.22028364]\n",
      " [0.01587292]\n",
      " [0.02795507]\n",
      " ...\n",
      " [0.13902579]\n",
      " [0.05120613]\n",
      " [0.1973478 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 01:49:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:49:47 - INFO - __main__ -   auc_score = 0.8027\n",
      "04/30/2024 01:49:47 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 01:49:47 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 01:49:47 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [01:35<00:15,  6.60it/s]04/30/2024 01:50:03 - WARNING - __main__ - epoch 0 step 408 loss 0.2671\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.2614757 ]\n",
      " [0.01525171]\n",
      " [0.01979046]\n",
      " ...\n",
      " [0.16396426]\n",
      " [0.05861102]\n",
      " [0.22759694]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 01:50:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:50:14 - INFO - __main__ -   auc_score = 0.8151\n",
      "04/30/2024 01:50:14 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 01:50:14 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 01:50:14 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [02:01<00:00,  6.60it/s]04/30/2024 01:50:29 - WARNING - __main__ - epoch 0 step 510 loss 0.23608\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.3540359 ]\n",
      " [0.0186732 ]\n",
      " [0.01633777]\n",
      " ...\n",
      " [0.17562869]\n",
      " [0.06421894]\n",
      " [0.28404403]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 01:50:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:50:40 - INFO - __main__ -   auc_score = 0.8243\n",
      "04/30/2024 01:50:40 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 01:50:40 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 01:50:40 - INFO - __main__ -   eval_recall = 0.0\n",
      "100% 512/512 [02:13<00:00,  3.84it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 01:50:56 - WARNING - __main__ - epoch 1 step 102 loss 0.25081\n",
      "[[0.55611485]\n",
      " [0.04041553]\n",
      " [0.03864789]\n",
      " ...\n",
      " [0.29778585]\n",
      " [0.17645352]\n",
      " [0.47856474]]\n",
      "04/30/2024 01:51:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:51:07 - INFO - __main__ -   auc_score = 0.8327\n",
      "04/30/2024 01:51:07 - INFO - __main__ -   eval_f1 = 0.195\n",
      "04/30/2024 01:51:07 - INFO - __main__ -   eval_precision = 0.4531\n",
      "04/30/2024 01:51:07 - INFO - __main__ -   eval_recall = 0.1242\n",
      " 40% 203/512 [00:42<00:46,  6.59it/s]04/30/2024 01:51:23 - WARNING - __main__ - epoch 1 step 204 loss 0.22926\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5740178 ]\n",
      " [0.04673082]\n",
      " [0.03447786]\n",
      " ...\n",
      " [0.25343567]\n",
      " [0.1355596 ]\n",
      " [0.41682756]]\n",
      "04/30/2024 01:51:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:51:34 - INFO - __main__ -   auc_score = 0.837\n",
      "04/30/2024 01:51:34 - INFO - __main__ -   eval_f1 = 0.1073\n",
      "04/30/2024 01:51:34 - INFO - __main__ -   eval_precision = 0.5091\n",
      "04/30/2024 01:51:34 - INFO - __main__ -   eval_recall = 0.06\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 01:51:49 - WARNING - __main__ - epoch 1 step 306 loss 0.24429\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.46518162]\n",
      " [0.05367676]\n",
      " [0.05324796]\n",
      " ...\n",
      " [0.19893673]\n",
      " [0.12743723]\n",
      " [0.33440936]]\n",
      "04/30/2024 01:52:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:52:00 - INFO - __main__ -   auc_score = 0.8429\n",
      "04/30/2024 01:52:00 - INFO - __main__ -   eval_f1 = 0.0691\n",
      "04/30/2024 01:52:00 - INFO - __main__ -   eval_precision = 0.68\n",
      "04/30/2024 01:52:00 - INFO - __main__ -   eval_recall = 0.0364\n",
      " 79% 407/512 [01:35<00:15,  6.61it/s]04/30/2024 01:52:16 - WARNING - __main__ - epoch 1 step 408 loss 0.23226\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.511704  ]\n",
      " [0.05047621]\n",
      " [0.04246308]\n",
      " ...\n",
      " [0.2790041 ]\n",
      " [0.1717337 ]\n",
      " [0.32063892]]\n",
      "04/30/2024 01:52:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:52:27 - INFO - __main__ -   auc_score = 0.8432\n",
      "04/30/2024 01:52:27 - INFO - __main__ -   eval_f1 = 0.1883\n",
      "04/30/2024 01:52:27 - INFO - __main__ -   eval_precision = 0.5521\n",
      "04/30/2024 01:52:27 - INFO - __main__ -   eval_recall = 0.1135\n",
      " 99% 509/512 [02:01<00:00,  6.61it/s]04/30/2024 01:52:42 - WARNING - __main__ - epoch 1 step 510 loss 0.22777\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5587204 ]\n",
      " [0.03720348]\n",
      " [0.02895503]\n",
      " ...\n",
      " [0.2399496 ]\n",
      " [0.11831904]\n",
      " [0.29377025]]\n",
      "04/30/2024 01:52:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:52:53 - INFO - __main__ -   auc_score = 0.8483\n",
      "04/30/2024 01:52:53 - INFO - __main__ -   eval_f1 = 0.098\n",
      "04/30/2024 01:52:53 - INFO - __main__ -   eval_precision = 0.5814\n",
      "04/30/2024 01:52:53 - INFO - __main__ -   eval_recall = 0.0535\n",
      "100% 512/512 [02:12<00:00,  3.86it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 01:53:09 - WARNING - __main__ - epoch 2 step 102 loss 0.23059\n",
      "[[0.75293416]\n",
      " [0.10861443]\n",
      " [0.08643006]\n",
      " ...\n",
      " [0.4224766 ]\n",
      " [0.30803663]\n",
      " [0.54456836]]\n",
      "04/30/2024 01:53:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:53:20 - INFO - __main__ -   auc_score = 0.85\n",
      "04/30/2024 01:53:20 - INFO - __main__ -   eval_f1 = 0.3215\n",
      "04/30/2024 01:53:20 - INFO - __main__ -   eval_precision = 0.4419\n",
      "04/30/2024 01:53:20 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 40% 203/512 [00:42<00:46,  6.61it/s]04/30/2024 01:53:36 - WARNING - __main__ - epoch 2 step 204 loss 0.22701\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.49356157]\n",
      " [0.02428134]\n",
      " [0.02174754]\n",
      " ...\n",
      " [0.15434173]\n",
      " [0.09381031]\n",
      " [0.21669112]]\n",
      "04/30/2024 01:53:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:53:47 - INFO - __main__ -   auc_score = 0.8492\n",
      "04/30/2024 01:53:47 - INFO - __main__ -   eval_f1 = 0.0575\n",
      "04/30/2024 01:53:47 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/30/2024 01:53:47 - INFO - __main__ -   eval_recall = 0.03\n",
      " 60% 305/512 [01:08<00:31,  6.62it/s]04/30/2024 01:54:02 - WARNING - __main__ - epoch 2 step 306 loss 0.2182\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7470029 ]\n",
      " [0.03683045]\n",
      " [0.02935668]\n",
      " ...\n",
      " [0.29158756]\n",
      " [0.20205568]\n",
      " [0.36598092]]\n",
      "04/30/2024 01:54:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:54:13 - INFO - __main__ -   auc_score = 0.8523\n",
      "04/30/2024 01:54:13 - INFO - __main__ -   eval_f1 = 0.2162\n",
      "04/30/2024 01:54:13 - INFO - __main__ -   eval_precision = 0.512\n",
      "04/30/2024 01:54:13 - INFO - __main__ -   eval_recall = 0.137\n",
      " 79% 407/512 [01:35<00:15,  6.61it/s]04/30/2024 01:54:28 - WARNING - __main__ - epoch 2 step 408 loss 0.21716\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.73333895]\n",
      " [0.05497263]\n",
      " [0.02082741]\n",
      " ...\n",
      " [0.27035892]\n",
      " [0.21343899]\n",
      " [0.3206057 ]]\n",
      "04/30/2024 01:54:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:54:39 - INFO - __main__ -   auc_score = 0.8552\n",
      "04/30/2024 01:54:39 - INFO - __main__ -   eval_f1 = 0.1942\n",
      "04/30/2024 01:54:39 - INFO - __main__ -   eval_precision = 0.475\n",
      "04/30/2024 01:54:39 - INFO - __main__ -   eval_recall = 0.1221\n",
      " 99% 509/512 [02:01<00:00,  6.62it/s]04/30/2024 01:54:55 - WARNING - __main__ - epoch 2 step 510 loss 0.2294\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.77337074]\n",
      " [0.1008366 ]\n",
      " [0.05551033]\n",
      " ...\n",
      " [0.34581617]\n",
      " [0.31165248]\n",
      " [0.3849103 ]]\n",
      "04/30/2024 01:55:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:55:06 - INFO - __main__ -   auc_score = 0.8538\n",
      "04/30/2024 01:55:06 - INFO - __main__ -   eval_f1 = 0.3382\n",
      "04/30/2024 01:55:06 - INFO - __main__ -   eval_precision = 0.4472\n",
      "04/30/2024 01:55:06 - INFO - __main__ -   eval_recall = 0.2719\n",
      "100% 512/512 [02:13<00:00,  3.83it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.56it/s]04/30/2024 01:55:22 - WARNING - __main__ - epoch 3 step 102 loss 0.21223\n",
      "[[0.6460578 ]\n",
      " [0.02702337]\n",
      " [0.02501533]\n",
      " ...\n",
      " [0.1382219 ]\n",
      " [0.13182376]\n",
      " [0.18363592]]\n",
      "04/30/2024 01:55:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:55:33 - INFO - __main__ -   auc_score = 0.8528\n",
      "04/30/2024 01:55:33 - INFO - __main__ -   eval_f1 = 0.1533\n",
      "04/30/2024 01:55:33 - INFO - __main__ -   eval_precision = 0.4574\n",
      "04/30/2024 01:55:33 - INFO - __main__ -   eval_recall = 0.0921\n",
      " 40% 203/512 [00:41<00:46,  6.61it/s]04/30/2024 01:55:49 - WARNING - __main__ - epoch 3 step 204 loss 0.21597\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.84088403]\n",
      " [0.06996115]\n",
      " [0.04470045]\n",
      " ...\n",
      " [0.3139929 ]\n",
      " [0.31423488]\n",
      " [0.4189445 ]]\n",
      "04/30/2024 01:56:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:56:00 - INFO - __main__ -   auc_score = 0.8531\n",
      "04/30/2024 01:56:00 - INFO - __main__ -   eval_f1 = 0.3428\n",
      "04/30/2024 01:56:00 - INFO - __main__ -   eval_precision = 0.4304\n",
      "04/30/2024 01:56:00 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 60% 305/512 [01:08<00:31,  6.61it/s]04/30/2024 01:56:16 - WARNING - __main__ - epoch 3 step 306 loss 0.22129\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6660092 ]\n",
      " [0.02316492]\n",
      " [0.02491639]\n",
      " ...\n",
      " [0.18203993]\n",
      " [0.13628651]\n",
      " [0.14756246]]\n",
      "04/30/2024 01:56:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:56:27 - INFO - __main__ -   auc_score = 0.8505\n",
      "04/30/2024 01:56:27 - INFO - __main__ -   eval_f1 = 0.1831\n",
      "04/30/2024 01:56:27 - INFO - __main__ -   eval_precision = 0.5667\n",
      "04/30/2024 01:56:27 - INFO - __main__ -   eval_recall = 0.1092\n",
      " 79% 407/512 [01:35<00:15,  6.61it/s]04/30/2024 01:56:42 - WARNING - __main__ - epoch 3 step 408 loss 0.21805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.82843167]\n",
      " [0.05214625]\n",
      " [0.03257716]\n",
      " ...\n",
      " [0.31403938]\n",
      " [0.25766096]\n",
      " [0.41125998]]\n",
      "04/30/2024 01:56:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:56:53 - INFO - __main__ -   auc_score = 0.8538\n",
      "04/30/2024 01:56:53 - INFO - __main__ -   eval_f1 = 0.2658\n",
      "04/30/2024 01:56:53 - INFO - __main__ -   eval_precision = 0.5091\n",
      "04/30/2024 01:56:53 - INFO - __main__ -   eval_recall = 0.1799\n",
      " 99% 509/512 [02:01<00:00,  6.59it/s]04/30/2024 01:57:09 - WARNING - __main__ - epoch 3 step 510 loss 0.21591\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8348414 ]\n",
      " [0.04554785]\n",
      " [0.04592042]\n",
      " ...\n",
      " [0.23553692]\n",
      " [0.2710771 ]\n",
      " [0.3039046 ]]\n",
      "04/30/2024 01:57:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:57:20 - INFO - __main__ -   auc_score = 0.8564\n",
      "04/30/2024 01:57:20 - INFO - __main__ -   eval_f1 = 0.2625\n",
      "04/30/2024 01:57:20 - INFO - __main__ -   eval_precision = 0.4855\n",
      "04/30/2024 01:57:20 - INFO - __main__ -   eval_recall = 0.1799\n",
      "100% 512/512 [02:13<00:00,  3.85it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 01:57:35 - WARNING - __main__ - epoch 4 step 102 loss 0.205\n",
      "[[0.88025725]\n",
      " [0.05078543]\n",
      " [0.04480728]\n",
      " ...\n",
      " [0.42978936]\n",
      " [0.30140972]\n",
      " [0.35666403]]\n",
      "04/30/2024 01:57:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:57:46 - INFO - __main__ -   auc_score = 0.8546\n",
      "04/30/2024 01:57:46 - INFO - __main__ -   eval_f1 = 0.3118\n",
      "04/30/2024 01:57:46 - INFO - __main__ -   eval_precision = 0.4069\n",
      "04/30/2024 01:57:46 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 40% 203/512 [00:41<00:46,  6.60it/s]04/30/2024 01:58:02 - WARNING - __main__ - epoch 4 step 204 loss 0.20754\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.83515084]\n",
      " [0.05817353]\n",
      " [0.03951871]\n",
      " ...\n",
      " [0.3485107 ]\n",
      " [0.2775183 ]\n",
      " [0.3124806 ]]\n",
      "04/30/2024 01:58:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:58:13 - INFO - __main__ -   auc_score = 0.8545\n",
      "04/30/2024 01:58:13 - INFO - __main__ -   eval_f1 = 0.2906\n",
      "04/30/2024 01:58:13 - INFO - __main__ -   eval_precision = 0.4256\n",
      "04/30/2024 01:58:13 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 60% 305/512 [01:08<00:31,  6.60it/s]04/30/2024 01:58:28 - WARNING - __main__ - epoch 4 step 306 loss 0.21379\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.87783784]\n",
      " [0.04264626]\n",
      " [0.03577133]\n",
      " ...\n",
      " [0.2688609 ]\n",
      " [0.23302662]\n",
      " [0.37328672]]\n",
      "04/30/2024 01:58:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:58:39 - INFO - __main__ -   auc_score = 0.8559\n",
      "04/30/2024 01:58:39 - INFO - __main__ -   eval_f1 = 0.258\n",
      "04/30/2024 01:58:39 - INFO - __main__ -   eval_precision = 0.3991\n",
      "04/30/2024 01:58:39 - INFO - __main__ -   eval_recall = 0.1906\n",
      " 79% 407/512 [01:34<00:15,  6.60it/s]04/30/2024 01:58:55 - WARNING - __main__ - epoch 4 step 408 loss 0.20418\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9007254 ]\n",
      " [0.05753138]\n",
      " [0.04094297]\n",
      " ...\n",
      " [0.3612701 ]\n",
      " [0.30071893]\n",
      " [0.44901338]]\n",
      "04/30/2024 01:59:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:59:06 - INFO - __main__ -   auc_score = 0.8574\n",
      "04/30/2024 01:59:06 - INFO - __main__ -   eval_f1 = 0.2948\n",
      "04/30/2024 01:59:06 - INFO - __main__ -   eval_precision = 0.3881\n",
      "04/30/2024 01:59:06 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 99% 509/512 [02:00<00:00,  6.58it/s]04/30/2024 01:59:21 - WARNING - __main__ - epoch 4 step 510 loss 0.21129\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.84784746]\n",
      " [0.06597245]\n",
      " [0.0406382 ]\n",
      " ...\n",
      " [0.24953744]\n",
      " [0.2646142 ]\n",
      " [0.38784134]]\n",
      "04/30/2024 01:59:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:59:32 - INFO - __main__ -   auc_score = 0.8577\n",
      "04/30/2024 01:59:32 - INFO - __main__ -   eval_f1 = 0.2703\n",
      "04/30/2024 01:59:32 - INFO - __main__ -   eval_precision = 0.4208\n",
      "04/30/2024 01:59:32 - INFO - __main__ -   eval_recall = 0.1991\n",
      "100% 512/512 [02:12<00:00,  3.87it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 01:59:48 - WARNING - __main__ - epoch 5 step 102 loss 0.20521\n",
      "[[0.91772234]\n",
      " [0.13616042]\n",
      " [0.07448364]\n",
      " ...\n",
      " [0.4928522 ]\n",
      " [0.50660247]\n",
      " [0.6311454 ]]\n",
      "04/30/2024 01:59:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 01:59:59 - INFO - __main__ -   auc_score = 0.8574\n",
      "04/30/2024 01:59:59 - INFO - __main__ -   eval_f1 = 0.3738\n",
      "04/30/2024 01:59:59 - INFO - __main__ -   eval_precision = 0.3688\n",
      "04/30/2024 01:59:59 - INFO - __main__ -   eval_recall = 0.379\n",
      " 40% 203/512 [00:42<00:46,  6.58it/s]04/30/2024 02:00:15 - WARNING - __main__ - epoch 5 step 204 loss 0.20078\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9347656 ]\n",
      " [0.13690363]\n",
      " [0.05149632]\n",
      " ...\n",
      " [0.425171  ]\n",
      " [0.43039498]\n",
      " [0.55924445]]\n",
      "04/30/2024 02:00:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:00:26 - INFO - __main__ -   auc_score = 0.8578\n",
      "04/30/2024 02:00:26 - INFO - __main__ -   eval_f1 = 0.3835\n",
      "04/30/2024 02:00:26 - INFO - __main__ -   eval_precision = 0.3795\n",
      "04/30/2024 02:00:26 - INFO - __main__ -   eval_recall = 0.3876\n",
      " 60% 305/512 [01:09<00:31,  6.59it/s]04/30/2024 02:00:42 - WARNING - __main__ - epoch 5 step 306 loss 0.1897\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9454246 ]\n",
      " [0.15344578]\n",
      " [0.05209618]\n",
      " ...\n",
      " [0.42326143]\n",
      " [0.4911593 ]\n",
      " [0.689264  ]]\n",
      "04/30/2024 02:00:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:00:53 - INFO - __main__ -   auc_score = 0.8573\n",
      "04/30/2024 02:00:53 - INFO - __main__ -   eval_f1 = 0.3764\n",
      "04/30/2024 02:00:53 - INFO - __main__ -   eval_precision = 0.3698\n",
      "04/30/2024 02:00:53 - INFO - __main__ -   eval_recall = 0.3833\n",
      " 79% 407/512 [01:36<00:15,  6.59it/s]04/30/2024 02:01:08 - WARNING - __main__ - epoch 5 step 408 loss 0.2071\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.92985326]\n",
      " [0.16619968]\n",
      " [0.06329889]\n",
      " ...\n",
      " [0.35767993]\n",
      " [0.48133788]\n",
      " [0.5864138 ]]\n",
      "04/30/2024 02:01:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:01:20 - INFO - __main__ -   auc_score = 0.8571\n",
      "04/30/2024 02:01:20 - INFO - __main__ -   eval_f1 = 0.3744\n",
      "04/30/2024 02:01:20 - INFO - __main__ -   eval_precision = 0.3855\n",
      "04/30/2024 02:01:20 - INFO - __main__ -   eval_recall = 0.364\n",
      " 99% 509/512 [02:02<00:00,  6.62it/s]04/30/2024 02:01:35 - WARNING - __main__ - epoch 5 step 510 loss 0.21274\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9000542 ]\n",
      " [0.0952512 ]\n",
      " [0.0335993 ]\n",
      " ...\n",
      " [0.18984008]\n",
      " [0.29167873]\n",
      " [0.39991152]]\n",
      "04/30/2024 02:01:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:01:46 - INFO - __main__ -   auc_score = 0.8571\n",
      "04/30/2024 02:01:46 - INFO - __main__ -   eval_f1 = 0.2865\n",
      "04/30/2024 02:01:46 - INFO - __main__ -   eval_precision = 0.4087\n",
      "04/30/2024 02:01:46 - INFO - __main__ -   eval_recall = 0.2206\n",
      "100% 512/512 [02:14<00:00,  3.82it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 02:02:02 - WARNING - __main__ - epoch 6 step 102 loss 0.19313\n",
      "[[0.9306928 ]\n",
      " [0.14004254]\n",
      " [0.03218364]\n",
      " ...\n",
      " [0.23214382]\n",
      " [0.434873  ]\n",
      " [0.44414183]]\n",
      "04/30/2024 02:02:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:02:13 - INFO - __main__ -   auc_score = 0.8561\n",
      "04/30/2024 02:02:13 - INFO - __main__ -   eval_f1 = 0.3266\n",
      "04/30/2024 02:02:13 - INFO - __main__ -   eval_precision = 0.3994\n",
      "04/30/2024 02:02:13 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 40% 203/512 [00:41<00:46,  6.62it/s]04/30/2024 02:02:28 - WARNING - __main__ - epoch 6 step 204 loss 0.1965\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.95243883]\n",
      " [0.19968392]\n",
      " [0.03874721]\n",
      " ...\n",
      " [0.2771539 ]\n",
      " [0.5059374 ]\n",
      " [0.5357234 ]]\n",
      "04/30/2024 02:02:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:02:39 - INFO - __main__ -   auc_score = 0.8561\n",
      "04/30/2024 02:02:39 - INFO - __main__ -   eval_f1 = 0.3573\n",
      "04/30/2024 02:02:39 - INFO - __main__ -   eval_precision = 0.3759\n",
      "04/30/2024 02:02:39 - INFO - __main__ -   eval_recall = 0.3405\n",
      " 60% 305/512 [01:07<00:31,  6.63it/s]04/30/2024 02:02:54 - WARNING - __main__ - epoch 6 step 306 loss 0.19531\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.95698225]\n",
      " [0.21629846]\n",
      " [0.03884705]\n",
      " ...\n",
      " [0.30848658]\n",
      " [0.5733465 ]\n",
      " [0.57811207]]\n",
      "04/30/2024 02:03:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:03:05 - INFO - __main__ -   auc_score = 0.8568\n",
      "04/30/2024 02:03:05 - INFO - __main__ -   eval_f1 = 0.3691\n",
      "04/30/2024 02:03:05 - INFO - __main__ -   eval_precision = 0.3559\n",
      "04/30/2024 02:03:05 - INFO - __main__ -   eval_recall = 0.3833\n",
      " 79% 407/512 [01:34<00:15,  6.59it/s]04/30/2024 02:03:20 - WARNING - __main__ - epoch 6 step 408 loss 0.20368\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.92331004]\n",
      " [0.10473024]\n",
      " [0.02622603]\n",
      " ...\n",
      " [0.20249753]\n",
      " [0.27768698]\n",
      " [0.3788913 ]]\n",
      "04/30/2024 02:03:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:03:31 - INFO - __main__ -   auc_score = 0.856\n",
      "04/30/2024 02:03:31 - INFO - __main__ -   eval_f1 = 0.3155\n",
      "04/30/2024 02:03:31 - INFO - __main__ -   eval_precision = 0.3887\n",
      "04/30/2024 02:03:31 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 99% 509/512 [02:00<00:00,  6.63it/s]04/30/2024 02:03:47 - WARNING - __main__ - epoch 6 step 510 loss 0.19434\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9546286 ]\n",
      " [0.17842992]\n",
      " [0.03077456]\n",
      " ...\n",
      " [0.370621  ]\n",
      " [0.46188217]\n",
      " [0.5705482 ]]\n",
      "04/30/2024 02:03:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:03:58 - INFO - __main__ -   auc_score = 0.8581\n",
      "04/30/2024 02:03:58 - INFO - __main__ -   eval_f1 = 0.3731\n",
      "04/30/2024 02:03:58 - INFO - __main__ -   eval_precision = 0.356\n",
      "04/30/2024 02:03:58 - INFO - __main__ -   eval_recall = 0.3919\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.62it/s]04/30/2024 02:04:13 - WARNING - __main__ - epoch 7 step 102 loss 0.20743\n",
      "[[0.8987048 ]\n",
      " [0.06997899]\n",
      " [0.0207628 ]\n",
      " ...\n",
      " [0.12868766]\n",
      " [0.3246694 ]\n",
      " [0.4119313 ]]\n",
      "04/30/2024 02:04:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:04:24 - INFO - __main__ -   auc_score = 0.8539\n",
      "04/30/2024 02:04:24 - INFO - __main__ -   eval_f1 = 0.2912\n",
      "04/30/2024 02:04:24 - INFO - __main__ -   eval_precision = 0.4061\n",
      "04/30/2024 02:04:24 - INFO - __main__ -   eval_recall = 0.227\n",
      " 40% 203/512 [00:41<00:46,  6.62it/s]04/30/2024 02:04:40 - WARNING - __main__ - epoch 7 step 204 loss 0.1805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9142534 ]\n",
      " [0.06613543]\n",
      " [0.01851809]\n",
      " ...\n",
      " [0.14231549]\n",
      " [0.31180236]\n",
      " [0.35402206]]\n",
      "04/30/2024 02:04:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:04:51 - INFO - __main__ -   auc_score = 0.8547\n",
      "04/30/2024 02:04:51 - INFO - __main__ -   eval_f1 = 0.302\n",
      "04/30/2024 02:04:51 - INFO - __main__ -   eval_precision = 0.3958\n",
      "04/30/2024 02:04:51 - INFO - __main__ -   eval_recall = 0.2441\n",
      " 60% 305/512 [01:07<00:31,  6.58it/s]04/30/2024 02:05:06 - WARNING - __main__ - epoch 7 step 306 loss 0.19301\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9345087 ]\n",
      " [0.07613705]\n",
      " [0.02031366]\n",
      " ...\n",
      " [0.18695869]\n",
      " [0.30916032]\n",
      " [0.4063014 ]]\n",
      "04/30/2024 02:05:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:05:17 - INFO - __main__ -   auc_score = 0.8542\n",
      "04/30/2024 02:05:17 - INFO - __main__ -   eval_f1 = 0.311\n",
      "04/30/2024 02:05:17 - INFO - __main__ -   eval_precision = 0.3796\n",
      "04/30/2024 02:05:17 - INFO - __main__ -   eval_recall = 0.2634\n",
      " 79% 407/512 [01:34<00:15,  6.63it/s]04/30/2024 02:05:32 - WARNING - __main__ - epoch 7 step 408 loss 0.19842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.93748003]\n",
      " [0.1469018 ]\n",
      " [0.02349143]\n",
      " ...\n",
      " [0.25949457]\n",
      " [0.35269132]\n",
      " [0.46106574]]\n",
      "04/30/2024 02:05:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:05:43 - INFO - __main__ -   auc_score = 0.8545\n",
      "04/30/2024 02:05:43 - INFO - __main__ -   eval_f1 = 0.3462\n",
      "04/30/2024 02:05:43 - INFO - __main__ -   eval_precision = 0.3698\n",
      "04/30/2024 02:05:43 - INFO - __main__ -   eval_recall = 0.3255\n",
      " 99% 509/512 [02:00<00:00,  6.63it/s]04/30/2024 02:05:58 - WARNING - __main__ - epoch 7 step 510 loss 0.18094\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9435561 ]\n",
      " [0.128358  ]\n",
      " [0.01979134]\n",
      " ...\n",
      " [0.21719714]\n",
      " [0.3972225 ]\n",
      " [0.53550524]]\n",
      "04/30/2024 02:06:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:06:09 - INFO - __main__ -   auc_score = 0.8554\n",
      "04/30/2024 02:06:09 - INFO - __main__ -   eval_f1 = 0.3163\n",
      "04/30/2024 02:06:09 - INFO - __main__ -   eval_precision = 0.3662\n",
      "04/30/2024 02:06:09 - INFO - __main__ -   eval_recall = 0.2784\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.63it/s]04/30/2024 02:06:25 - WARNING - __main__ - epoch 8 step 102 loss 0.18471\n",
      "[[0.9611572 ]\n",
      " [0.17816955]\n",
      " [0.02164682]\n",
      " ...\n",
      " [0.28964755]\n",
      " [0.5197185 ]\n",
      " [0.6489039 ]]\n",
      "04/30/2024 02:06:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:06:36 - INFO - __main__ -   auc_score = 0.8563\n",
      "04/30/2024 02:06:36 - INFO - __main__ -   eval_f1 = 0.3593\n",
      "04/30/2024 02:06:36 - INFO - __main__ -   eval_precision = 0.3632\n",
      "04/30/2024 02:06:36 - INFO - __main__ -   eval_recall = 0.3555\n",
      " 40% 203/512 [00:41<00:46,  6.63it/s]04/30/2024 02:06:51 - WARNING - __main__ - epoch 8 step 204 loss 0.1956\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.95015246]\n",
      " [0.145443  ]\n",
      " [0.01879194]\n",
      " ...\n",
      " [0.2249187 ]\n",
      " [0.44821954]\n",
      " [0.5547551 ]]\n",
      "04/30/2024 02:07:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:07:02 - INFO - __main__ -   auc_score = 0.8555\n",
      "04/30/2024 02:07:02 - INFO - __main__ -   eval_f1 = 0.3447\n",
      "04/30/2024 02:07:02 - INFO - __main__ -   eval_precision = 0.3808\n",
      "04/30/2024 02:07:02 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 60% 305/512 [01:07<00:31,  6.60it/s]04/30/2024 02:07:18 - WARNING - __main__ - epoch 8 step 306 loss 0.18703\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.94886714]\n",
      " [0.13217531]\n",
      " [0.01784351]\n",
      " ...\n",
      " [0.19911586]\n",
      " [0.43524727]\n",
      " [0.49973902]]\n",
      "04/30/2024 02:07:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:07:28 - INFO - __main__ -   auc_score = 0.8545\n",
      "04/30/2024 02:07:28 - INFO - __main__ -   eval_f1 = 0.3361\n",
      "04/30/2024 02:07:28 - INFO - __main__ -   eval_precision = 0.3825\n",
      "04/30/2024 02:07:28 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 79% 407/512 [01:34<00:15,  6.63it/s]04/30/2024 02:07:44 - WARNING - __main__ - epoch 8 step 408 loss 0.1928\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9489673 ]\n",
      " [0.14127183]\n",
      " [0.01847487]\n",
      " ...\n",
      " [0.19928369]\n",
      " [0.4038726 ]\n",
      " [0.5306017 ]]\n",
      "04/30/2024 02:07:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:07:55 - INFO - __main__ -   auc_score = 0.8543\n",
      "04/30/2024 02:07:55 - INFO - __main__ -   eval_f1 = 0.3349\n",
      "04/30/2024 02:07:55 - INFO - __main__ -   eval_precision = 0.376\n",
      "04/30/2024 02:07:55 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 99% 509/512 [02:00<00:00,  6.63it/s]04/30/2024 02:08:10 - WARNING - __main__ - epoch 8 step 510 loss 0.17515\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.953579  ]\n",
      " [0.13525587]\n",
      " [0.01865418]\n",
      " ...\n",
      " [0.22115576]\n",
      " [0.42502826]\n",
      " [0.5422312 ]]\n",
      "04/30/2024 02:08:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:08:21 - INFO - __main__ -   auc_score = 0.8544\n",
      "04/30/2024 02:08:21 - INFO - __main__ -   eval_f1 = 0.3462\n",
      "04/30/2024 02:08:21 - INFO - __main__ -   eval_precision = 0.3698\n",
      "04/30/2024 02:08:21 - INFO - __main__ -   eval_recall = 0.3255\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.63it/s]04/30/2024 02:08:37 - WARNING - __main__ - epoch 9 step 102 loss 0.19588\n",
      "[[0.95205724]\n",
      " [0.13117748]\n",
      " [0.01884605]\n",
      " ...\n",
      " [0.1856448 ]\n",
      " [0.43072382]\n",
      " [0.55254537]]\n",
      "04/30/2024 02:08:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:08:48 - INFO - __main__ -   auc_score = 0.8541\n",
      "04/30/2024 02:08:48 - INFO - __main__ -   eval_f1 = 0.3372\n",
      "04/30/2024 02:08:48 - INFO - __main__ -   eval_precision = 0.3721\n",
      "04/30/2024 02:08:48 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [00:41<00:46,  6.62it/s]04/30/2024 02:09:03 - WARNING - __main__ - epoch 9 step 204 loss 0.18556\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.94684637]\n",
      " [0.10828448]\n",
      " [0.0152867 ]\n",
      " ...\n",
      " [0.17377523]\n",
      " [0.40168992]\n",
      " [0.5275489 ]]\n",
      "04/30/2024 02:09:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:09:14 - INFO - __main__ -   auc_score = 0.8541\n",
      "04/30/2024 02:09:14 - INFO - __main__ -   eval_f1 = 0.3236\n",
      "04/30/2024 02:09:14 - INFO - __main__ -   eval_precision = 0.3746\n",
      "04/30/2024 02:09:14 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 60% 305/512 [01:07<00:31,  6.61it/s]04/30/2024 02:09:29 - WARNING - __main__ - epoch 9 step 306 loss 0.18433\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.95217645]\n",
      " [0.13351454]\n",
      " [0.01748719]\n",
      " ...\n",
      " [0.21378534]\n",
      " [0.44669852]\n",
      " [0.5739976 ]]\n",
      "04/30/2024 02:09:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:09:40 - INFO - __main__ -   auc_score = 0.8541\n",
      "04/30/2024 02:09:40 - INFO - __main__ -   eval_f1 = 0.341\n",
      "04/30/2024 02:09:40 - INFO - __main__ -   eval_precision = 0.3691\n",
      "04/30/2024 02:09:40 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 79% 407/512 [01:34<00:15,  6.63it/s]04/30/2024 02:09:56 - WARNING - __main__ - epoch 9 step 408 loss 0.18682\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9532649 ]\n",
      " [0.13863964]\n",
      " [0.01788406]\n",
      " ...\n",
      " [0.21967916]\n",
      " [0.45480406]\n",
      " [0.57449317]]\n",
      "04/30/2024 02:10:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:10:06 - INFO - __main__ -   auc_score = 0.8543\n",
      "04/30/2024 02:10:06 - INFO - __main__ -   eval_f1 = 0.3466\n",
      "04/30/2024 02:10:06 - INFO - __main__ -   eval_precision = 0.3707\n",
      "04/30/2024 02:10:06 - INFO - __main__ -   eval_recall = 0.3255\n",
      " 99% 509/512 [02:00<00:00,  6.63it/s]04/30/2024 02:10:22 - WARNING - __main__ - epoch 9 step 510 loss 0.16969\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.9496414 ]\n",
      " [0.12346811]\n",
      " [0.01641668]\n",
      " ...\n",
      " [0.19221742]\n",
      " [0.4124088 ]\n",
      " [0.5381337 ]]\n",
      "04/30/2024 02:10:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 02:10:33 - INFO - __main__ -   auc_score = 0.8539\n",
      "04/30/2024 02:10:33 - INFO - __main__ -   eval_f1 = 0.3353\n",
      "04/30/2024 02:10:33 - INFO - __main__ -   eval_precision = 0.3737\n",
      "04/30/2024 02:10:33 - INFO - __main__ -   eval_recall = 0.3041\n",
      "100% 512/512 [02:11<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-6b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-6b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMrTKbnYxxot",
    "outputId": "d8ae8ba3-3fd4-4b7d-8ebd-60842c7da35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  5.93it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-6b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/30/2024 02:14:27 - INFO - __main__ - ***** Test results *****\n",
      "04/30/2024 02:14:27 - INFO - __main__ -   auc_score = 0.8375\n",
      "04/30/2024 02:14:27 - INFO - __main__ -   test_f1 = 0.3497\n",
      "04/30/2024 02:14:27 - INFO - __main__ -   test_precision = 0.3542\n",
      "04/30/2024 02:14:27 - INFO - __main__ -   test_recall = 0.3453\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-6b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-6b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LHoTH9F3CfJ"
   },
   "source": [
    "### codet5p-16b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33WC8ZVkVsAM"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIZezK8Fiv9t",
    "outputId": "655e3bf7-552f-4f88-ff8a-414ed09b9682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 5/5 [00:00<00:00,  7.04it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-16b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:20<01:17,  5.29it/s]04/27/2024 00:59:26 - WARNING - __main__ - epoch 0 step 102 loss 0.29165\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 00:59:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 00:59:36 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 00:59:36 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 00:59:36 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 00:59:47 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 00:59:47 - INFO - __main__ -   auc_score = 0.7725\n",
      "04/27/2024 00:59:47 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 00:59:47 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 00:59:47 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 203/512 [01:00<00:58,  5.32it/s]04/27/2024 01:00:06 - WARNING - __main__ - epoch 0 step 204 loss 0.26534\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 01:00:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:00:16 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 01:00:16 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 01:00:16 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 01:00:26 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:00:26 - INFO - __main__ -   auc_score = 0.8092\n",
      "04/27/2024 01:00:26 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 01:00:26 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 01:00:26 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 305/512 [01:40<00:38,  5.33it/s]04/27/2024 01:00:46 - WARNING - __main__ - epoch 0 step 306 loss 0.25412\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:00:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:00:56 - INFO - __main__ -   eval_f1 = 0.064\n",
      "04/27/2024 01:00:56 - INFO - __main__ -   eval_precision = 0.4848\n",
      "04/27/2024 01:00:56 - INFO - __main__ -   eval_recall = 0.0343\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:01:09 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:01:09 - INFO - __main__ -   auc_score = 0.8183\n",
      "04/27/2024 01:01:09 - INFO - __main__ -   test_f1 = 0.0478\n",
      "04/27/2024 01:01:09 - INFO - __main__ -   test_precision = 0.4444\n",
      "04/27/2024 01:01:09 - INFO - __main__ -   test_recall = 0.0253\n",
      " 79% 407/512 [02:22<00:19,  5.27it/s]04/27/2024 01:01:28 - WARNING - __main__ - epoch 0 step 408 loss 0.25821\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:01:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:01:38 - INFO - __main__ -   eval_f1 = 0.1063\n",
      "04/27/2024 01:01:38 - INFO - __main__ -   eval_precision = 0.6585\n",
      "04/27/2024 01:01:38 - INFO - __main__ -   eval_recall = 0.0578\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:01:50 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:01:50 - INFO - __main__ -   auc_score = 0.8155\n",
      "04/27/2024 01:01:50 - INFO - __main__ -   test_f1 = 0.0519\n",
      "04/27/2024 01:01:50 - INFO - __main__ -   test_precision = 0.5\n",
      "04/27/2024 01:01:50 - INFO - __main__ -   test_recall = 0.0274\n",
      " 99% 509/512 [03:03<00:00,  5.31it/s]04/27/2024 01:02:09 - WARNING - __main__ - epoch 0 step 510 loss 0.23455\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:02:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:02:20 - INFO - __main__ -   eval_f1 = 0.2007\n",
      "04/27/2024 01:02:20 - INFO - __main__ -   eval_precision = 0.5644\n",
      "04/27/2024 01:02:20 - INFO - __main__ -   eval_recall = 0.1221\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:02:32 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:02:32 - INFO - __main__ -   auc_score = 0.8242\n",
      "04/27/2024 01:02:32 - INFO - __main__ -   test_f1 = 0.125\n",
      "04/27/2024 01:02:32 - INFO - __main__ -   test_precision = 0.4928\n",
      "04/27/2024 01:02:32 - INFO - __main__ -   test_recall = 0.0716\n",
      "100% 512/512 [03:26<00:00,  2.48it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/27/2024 01:02:51 - WARNING - __main__ - epoch 1 step 102 loss 0.22942\n",
      "04/27/2024 01:03:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:03:01 - INFO - __main__ -   eval_f1 = 0.1288\n",
      "04/27/2024 01:03:01 - INFO - __main__ -   eval_precision = 0.5574\n",
      "04/27/2024 01:03:01 - INFO - __main__ -   eval_recall = 0.0728\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:03:12 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:03:12 - INFO - __main__ -   auc_score = 0.834\n",
      "04/27/2024 01:03:12 - INFO - __main__ -   test_f1 = 0.0902\n",
      "04/27/2024 01:03:12 - INFO - __main__ -   test_precision = 0.6571\n",
      "04/27/2024 01:03:12 - INFO - __main__ -   test_recall = 0.0484\n",
      " 40% 203/512 [00:58<00:58,  5.32it/s]04/27/2024 01:03:31 - WARNING - __main__ - epoch 1 step 204 loss 0.22975\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:03:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:03:41 - INFO - __main__ -   eval_f1 = 0.2277\n",
      "04/27/2024 01:03:41 - INFO - __main__ -   eval_precision = 0.4964\n",
      "04/27/2024 01:03:41 - INFO - __main__ -   eval_recall = 0.1478\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:03:53 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:03:53 - INFO - __main__ -   auc_score = 0.8295\n",
      "04/27/2024 01:03:53 - INFO - __main__ -   test_f1 = 0.2167\n",
      "04/27/2024 01:03:53 - INFO - __main__ -   test_precision = 0.52\n",
      "04/27/2024 01:03:53 - INFO - __main__ -   test_recall = 0.1368\n",
      " 60% 305/512 [01:40<00:38,  5.31it/s]04/27/2024 01:04:12 - WARNING - __main__ - epoch 1 step 306 loss 0.23564\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:04:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:04:23 - INFO - __main__ -   eval_f1 = 0.3657\n",
      "04/27/2024 01:04:23 - INFO - __main__ -   eval_precision = 0.3866\n",
      "04/27/2024 01:04:23 - INFO - __main__ -   eval_recall = 0.3469\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:04:35 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:04:35 - INFO - __main__ -   auc_score = 0.827\n",
      "04/27/2024 01:04:35 - INFO - __main__ -   test_f1 = 0.3351\n",
      "04/27/2024 01:04:35 - INFO - __main__ -   test_precision = 0.3468\n",
      "04/27/2024 01:04:35 - INFO - __main__ -   test_recall = 0.3242\n",
      " 79% 407/512 [02:21<00:19,  5.32it/s]04/27/2024 01:04:54 - WARNING - __main__ - epoch 1 step 408 loss 0.2378\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:05:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:05:04 - INFO - __main__ -   eval_f1 = 0.3671\n",
      "04/27/2024 01:05:04 - INFO - __main__ -   eval_precision = 0.4073\n",
      "04/27/2024 01:05:04 - INFO - __main__ -   eval_recall = 0.334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:05:16 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:05:16 - INFO - __main__ -   auc_score = 0.83\n",
      "04/27/2024 01:05:16 - INFO - __main__ -   test_f1 = 0.3159\n",
      "04/27/2024 01:05:16 - INFO - __main__ -   test_precision = 0.3523\n",
      "04/27/2024 01:05:16 - INFO - __main__ -   test_recall = 0.2863\n",
      " 99% 509/512 [03:03<00:00,  5.31it/s]04/27/2024 01:05:36 - WARNING - __main__ - epoch 1 step 510 loss 0.20325\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:05:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:05:46 - INFO - __main__ -   eval_f1 = 0.2073\n",
      "04/27/2024 01:05:46 - INFO - __main__ -   eval_precision = 0.5357\n",
      "04/27/2024 01:05:46 - INFO - __main__ -   eval_recall = 0.1285\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:05:56 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:05:56 - INFO - __main__ -   auc_score = 0.8354\n",
      "04/27/2024 01:05:56 - INFO - __main__ -   test_f1 = 0.1604\n",
      "04/27/2024 01:05:56 - INFO - __main__ -   test_precision = 0.5233\n",
      "04/27/2024 01:05:56 - INFO - __main__ -   test_recall = 0.0947\n",
      "100% 512/512 [03:24<00:00,  2.50it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.30it/s]04/27/2024 01:06:16 - WARNING - __main__ - epoch 2 step 102 loss 0.2113\n",
      "04/27/2024 01:06:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:06:26 - INFO - __main__ -   eval_f1 = 0.3676\n",
      "04/27/2024 01:06:26 - INFO - __main__ -   eval_precision = 0.4298\n",
      "04/27/2024 01:06:26 - INFO - __main__ -   eval_recall = 0.3212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:06:38 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:06:38 - INFO - __main__ -   auc_score = 0.8335\n",
      "04/27/2024 01:06:38 - INFO - __main__ -   test_f1 = 0.3038\n",
      "04/27/2024 01:06:38 - INFO - __main__ -   test_precision = 0.3518\n",
      "04/27/2024 01:06:38 - INFO - __main__ -   test_recall = 0.2674\n",
      " 40% 203/512 [01:00<00:58,  5.30it/s]04/27/2024 01:06:57 - WARNING - __main__ - epoch 2 step 204 loss 0.20392\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:07:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:07:08 - INFO - __main__ -   eval_f1 = 0.1126\n",
      "04/27/2024 01:07:08 - INFO - __main__ -   eval_precision = 0.6042\n",
      "04/27/2024 01:07:08 - INFO - __main__ -   eval_recall = 0.0621\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:07:18 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:07:18 - INFO - __main__ -   auc_score = 0.8383\n",
      "04/27/2024 01:07:18 - INFO - __main__ -   test_f1 = 0.0787\n",
      "04/27/2024 01:07:18 - INFO - __main__ -   test_precision = 0.6061\n",
      "04/27/2024 01:07:18 - INFO - __main__ -   test_recall = 0.0421\n",
      " 60% 305/512 [01:40<00:38,  5.32it/s]04/27/2024 01:07:37 - WARNING - __main__ - epoch 2 step 306 loss 0.21716\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:07:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:07:48 - INFO - __main__ -   eval_f1 = 0.2347\n",
      "04/27/2024 01:07:48 - INFO - __main__ -   eval_precision = 0.5145\n",
      "04/27/2024 01:07:48 - INFO - __main__ -   eval_recall = 0.152\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:07:58 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:07:58 - INFO - __main__ -   auc_score = 0.8406\n",
      "04/27/2024 01:07:58 - INFO - __main__ -   test_f1 = 0.2017\n",
      "04/27/2024 01:07:58 - INFO - __main__ -   test_precision = 0.5\n",
      "04/27/2024 01:07:58 - INFO - __main__ -   test_recall = 0.1263\n",
      " 79% 407/512 [02:20<00:19,  5.29it/s]04/27/2024 01:08:17 - WARNING - __main__ - epoch 2 step 408 loss 0.21963\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:08:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:08:28 - INFO - __main__ -   eval_f1 = 0.2892\n",
      "04/27/2024 01:08:28 - INFO - __main__ -   eval_precision = 0.5137\n",
      "04/27/2024 01:08:28 - INFO - __main__ -   eval_recall = 0.2013\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:08:38 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:08:38 - INFO - __main__ -   auc_score = 0.8447\n",
      "04/27/2024 01:08:38 - INFO - __main__ -   test_f1 = 0.2208\n",
      "04/27/2024 01:08:38 - INFO - __main__ -   test_precision = 0.46\n",
      "04/27/2024 01:08:38 - INFO - __main__ -   test_recall = 0.1453\n",
      " 99% 509/512 [03:00<00:00,  5.31it/s]04/27/2024 01:08:57 - WARNING - __main__ - epoch 2 step 510 loss 0.2065\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:09:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:09:07 - INFO - __main__ -   eval_f1 = 0.4192\n",
      "04/27/2024 01:09:07 - INFO - __main__ -   eval_precision = 0.4012\n",
      "04/27/2024 01:09:07 - INFO - __main__ -   eval_recall = 0.439\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:09:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:09:19 - INFO - __main__ -   auc_score = 0.8437\n",
      "04/27/2024 01:09:19 - INFO - __main__ -   test_f1 = 0.3551\n",
      "04/27/2024 01:09:19 - INFO - __main__ -   test_precision = 0.3504\n",
      "04/27/2024 01:09:19 - INFO - __main__ -   test_recall = 0.36\n",
      "100% 512/512 [03:23<00:00,  2.52it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.30it/s]04/27/2024 01:09:39 - WARNING - __main__ - epoch 3 step 102 loss 0.19481\n",
      "04/27/2024 01:09:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:09:49 - INFO - __main__ -   eval_f1 = 0.2633\n",
      "04/27/2024 01:09:49 - INFO - __main__ -   eval_precision = 0.4912\n",
      "04/27/2024 01:09:49 - INFO - __main__ -   eval_recall = 0.1799\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:10:00 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:10:00 - INFO - __main__ -   auc_score = 0.8371\n",
      "04/27/2024 01:10:00 - INFO - __main__ -   test_f1 = 0.2347\n",
      "04/27/2024 01:10:00 - INFO - __main__ -   test_precision = 0.4966\n",
      "04/27/2024 01:10:00 - INFO - __main__ -   test_recall = 0.1537\n",
      " 40% 203/512 [00:58<00:58,  5.30it/s]04/27/2024 01:10:19 - WARNING - __main__ - epoch 3 step 204 loss 0.2006\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:10:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:10:29 - INFO - __main__ -   eval_f1 = 0.3189\n",
      "04/27/2024 01:10:29 - INFO - __main__ -   eval_precision = 0.4597\n",
      "04/27/2024 01:10:29 - INFO - __main__ -   eval_recall = 0.2441\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:10:40 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:10:40 - INFO - __main__ -   auc_score = 0.8412\n",
      "04/27/2024 01:10:40 - INFO - __main__ -   test_f1 = 0.2898\n",
      "04/27/2024 01:10:40 - INFO - __main__ -   test_precision = 0.455\n",
      "04/27/2024 01:10:40 - INFO - __main__ -   test_recall = 0.2126\n",
      " 60% 305/512 [01:38<00:39,  5.30it/s]04/27/2024 01:10:59 - WARNING - __main__ - epoch 3 step 306 loss 0.203\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:11:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:11:09 - INFO - __main__ -   eval_f1 = 0.1555\n",
      "04/27/2024 01:11:09 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/27/2024 01:11:09 - INFO - __main__ -   eval_recall = 0.0921\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:11:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:11:20 - INFO - __main__ -   auc_score = 0.8315\n",
      "04/27/2024 01:11:20 - INFO - __main__ -   test_f1 = 0.1418\n",
      "04/27/2024 01:11:20 - INFO - __main__ -   test_precision = 0.52\n",
      "04/27/2024 01:11:20 - INFO - __main__ -   test_recall = 0.0821\n",
      " 79% 407/512 [02:18<00:19,  5.31it/s]04/27/2024 01:11:39 - WARNING - __main__ - epoch 3 step 408 loss 0.19797\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:11:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:11:49 - INFO - __main__ -   eval_f1 = 0.2266\n",
      "04/27/2024 01:11:49 - INFO - __main__ -   eval_precision = 0.4859\n",
      "04/27/2024 01:11:49 - INFO - __main__ -   eval_recall = 0.1478\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:11:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:11:59 - INFO - __main__ -   auc_score = 0.841\n",
      "04/27/2024 01:11:59 - INFO - __main__ -   test_f1 = 0.1897\n",
      "04/27/2024 01:11:59 - INFO - __main__ -   test_precision = 0.4524\n",
      "04/27/2024 01:11:59 - INFO - __main__ -   test_recall = 0.12\n",
      " 99% 509/512 [02:58<00:00,  5.30it/s]04/27/2024 01:12:19 - WARNING - __main__ - epoch 3 step 510 loss 0.20208\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:12:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:12:29 - INFO - __main__ -   eval_f1 = 0.3144\n",
      "04/27/2024 01:12:29 - INFO - __main__ -   eval_precision = 0.428\n",
      "04/27/2024 01:12:29 - INFO - __main__ -   eval_recall = 0.2484\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:12:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:12:39 - INFO - __main__ -   auc_score = 0.8412\n",
      "04/27/2024 01:12:39 - INFO - __main__ -   test_f1 = 0.2889\n",
      "04/27/2024 01:12:39 - INFO - __main__ -   test_precision = 0.4245\n",
      "04/27/2024 01:12:39 - INFO - __main__ -   test_recall = 0.2189\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/27/2024 01:12:59 - WARNING - __main__ - epoch 4 step 102 loss 0.16843\n",
      "04/27/2024 01:13:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:13:09 - INFO - __main__ -   eval_f1 = 0.3856\n",
      "04/27/2024 01:13:09 - INFO - __main__ -   eval_precision = 0.3452\n",
      "04/27/2024 01:13:09 - INFO - __main__ -   eval_recall = 0.4368\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:13:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:13:20 - INFO - __main__ -   auc_score = 0.8356\n",
      "04/27/2024 01:13:20 - INFO - __main__ -   test_f1 = 0.3448\n",
      "04/27/2024 01:13:20 - INFO - __main__ -   test_precision = 0.3223\n",
      "04/27/2024 01:13:20 - INFO - __main__ -   test_recall = 0.3705\n",
      " 40% 203/512 [00:58<00:58,  5.30it/s]04/27/2024 01:13:39 - WARNING - __main__ - epoch 4 step 204 loss 0.19201\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:13:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:13:49 - INFO - __main__ -   eval_f1 = 0.281\n",
      "04/27/2024 01:13:49 - INFO - __main__ -   eval_precision = 0.4769\n",
      "04/27/2024 01:13:49 - INFO - __main__ -   eval_recall = 0.1991\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:14:00 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:14:00 - INFO - __main__ -   auc_score = 0.8347\n",
      "04/27/2024 01:14:00 - INFO - __main__ -   test_f1 = 0.2165\n",
      "04/27/2024 01:14:00 - INFO - __main__ -   test_precision = 0.3923\n",
      "04/27/2024 01:14:00 - INFO - __main__ -   test_recall = 0.1495\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/27/2024 01:14:19 - WARNING - __main__ - epoch 4 step 306 loss 0.19353\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:14:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:14:29 - INFO - __main__ -   eval_f1 = 0.3575\n",
      "04/27/2024 01:14:29 - INFO - __main__ -   eval_precision = 0.4525\n",
      "04/27/2024 01:14:29 - INFO - __main__ -   eval_recall = 0.2955\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:14:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:14:39 - INFO - __main__ -   auc_score = 0.8385\n",
      "04/27/2024 01:14:39 - INFO - __main__ -   test_f1 = 0.2895\n",
      "04/27/2024 01:14:39 - INFO - __main__ -   test_precision = 0.3921\n",
      "04/27/2024 01:14:39 - INFO - __main__ -   test_recall = 0.2295\n",
      " 79% 407/512 [02:18<00:19,  5.30it/s]04/27/2024 01:14:59 - WARNING - __main__ - epoch 4 step 408 loss 0.18409\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:15:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:15:09 - INFO - __main__ -   eval_f1 = 0.324\n",
      "04/27/2024 01:15:09 - INFO - __main__ -   eval_precision = 0.4659\n",
      "04/27/2024 01:15:09 - INFO - __main__ -   eval_recall = 0.2484\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:15:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:15:19 - INFO - __main__ -   auc_score = 0.8389\n",
      "04/27/2024 01:15:19 - INFO - __main__ -   test_f1 = 0.27\n",
      "04/27/2024 01:15:19 - INFO - __main__ -   test_precision = 0.4068\n",
      "04/27/2024 01:15:19 - INFO - __main__ -   test_recall = 0.2021\n",
      " 99% 509/512 [02:58<00:00,  5.31it/s]04/27/2024 01:15:39 - WARNING - __main__ - epoch 4 step 510 loss 0.17785\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:15:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:15:49 - INFO - __main__ -   eval_f1 = 0.3757\n",
      "04/27/2024 01:15:49 - INFO - __main__ -   eval_precision = 0.3957\n",
      "04/27/2024 01:15:49 - INFO - __main__ -   eval_recall = 0.3576\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:15:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:15:59 - INFO - __main__ -   auc_score = 0.8356\n",
      "04/27/2024 01:15:59 - INFO - __main__ -   test_f1 = 0.3265\n",
      "04/27/2024 01:15:59 - INFO - __main__ -   test_precision = 0.3566\n",
      "04/27/2024 01:15:59 - INFO - __main__ -   test_recall = 0.3011\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/27/2024 01:16:19 - WARNING - __main__ - epoch 5 step 102 loss 0.16149\n",
      "04/27/2024 01:16:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:16:29 - INFO - __main__ -   eval_f1 = 0.345\n",
      "04/27/2024 01:16:29 - INFO - __main__ -   eval_precision = 0.4655\n",
      "04/27/2024 01:16:29 - INFO - __main__ -   eval_recall = 0.2741\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:16:40 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:16:40 - INFO - __main__ -   auc_score = 0.8293\n",
      "04/27/2024 01:16:40 - INFO - __main__ -   test_f1 = 0.2713\n",
      "04/27/2024 01:16:40 - INFO - __main__ -   test_precision = 0.3682\n",
      "04/27/2024 01:16:40 - INFO - __main__ -   test_recall = 0.2147\n",
      " 40% 203/512 [00:58<00:58,  5.28it/s]04/27/2024 01:16:59 - WARNING - __main__ - epoch 5 step 204 loss 0.17171\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:17:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:17:09 - INFO - __main__ -   eval_f1 = 0.3405\n",
      "04/27/2024 01:17:09 - INFO - __main__ -   eval_precision = 0.3869\n",
      "04/27/2024 01:17:09 - INFO - __main__ -   eval_recall = 0.3041\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:17:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:17:20 - INFO - __main__ -   auc_score = 0.8283\n",
      "04/27/2024 01:17:20 - INFO - __main__ -   test_f1 = 0.3123\n",
      "04/27/2024 01:17:20 - INFO - __main__ -   test_precision = 0.3599\n",
      "04/27/2024 01:17:20 - INFO - __main__ -   test_recall = 0.2758\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/27/2024 01:17:39 - WARNING - __main__ - epoch 5 step 306 loss 0.15897\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:17:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:17:49 - INFO - __main__ -   eval_f1 = 0.2598\n",
      "04/27/2024 01:17:49 - INFO - __main__ -   eval_precision = 0.4826\n",
      "04/27/2024 01:17:49 - INFO - __main__ -   eval_recall = 0.1777\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:17:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:17:59 - INFO - __main__ -   auc_score = 0.8272\n",
      "04/27/2024 01:17:59 - INFO - __main__ -   test_f1 = 0.2266\n",
      "04/27/2024 01:17:59 - INFO - __main__ -   test_precision = 0.4157\n",
      "04/27/2024 01:17:59 - INFO - __main__ -   test_recall = 0.1558\n",
      " 79% 407/512 [02:18<00:19,  5.32it/s]04/27/2024 01:18:18 - WARNING - __main__ - epoch 5 step 408 loss 0.17385\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:18:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:18:29 - INFO - __main__ -   eval_f1 = 0.339\n",
      "04/27/2024 01:18:29 - INFO - __main__ -   eval_precision = 0.3617\n",
      "04/27/2024 01:18:29 - INFO - __main__ -   eval_recall = 0.3191\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:18:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:18:39 - INFO - __main__ -   auc_score = 0.8262\n",
      "04/27/2024 01:18:39 - INFO - __main__ -   test_f1 = 0.3177\n",
      "04/27/2024 01:18:39 - INFO - __main__ -   test_precision = 0.3475\n",
      "04/27/2024 01:18:39 - INFO - __main__ -   test_recall = 0.2926\n",
      " 99% 509/512 [02:58<00:00,  5.32it/s]04/27/2024 01:18:58 - WARNING - __main__ - epoch 5 step 510 loss 0.17429\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:19:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:19:09 - INFO - __main__ -   eval_f1 = 0.3893\n",
      "04/27/2024 01:19:09 - INFO - __main__ -   eval_precision = 0.4075\n",
      "04/27/2024 01:19:09 - INFO - __main__ -   eval_recall = 0.3726\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:19:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:19:19 - INFO - __main__ -   auc_score = 0.8364\n",
      "04/27/2024 01:19:19 - INFO - __main__ -   test_f1 = 0.3268\n",
      "04/27/2024 01:19:19 - INFO - __main__ -   test_precision = 0.3386\n",
      "04/27/2024 01:19:19 - INFO - __main__ -   test_recall = 0.3158\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/27/2024 01:19:39 - WARNING - __main__ - epoch 6 step 102 loss 0.15287\n",
      "04/27/2024 01:19:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:19:49 - INFO - __main__ -   eval_f1 = 0.3325\n",
      "04/27/2024 01:19:49 - INFO - __main__ -   eval_precision = 0.433\n",
      "04/27/2024 01:19:49 - INFO - __main__ -   eval_recall = 0.2698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:19:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:19:59 - INFO - __main__ -   auc_score = 0.8269\n",
      "04/27/2024 01:19:59 - INFO - __main__ -   test_f1 = 0.264\n",
      "04/27/2024 01:19:59 - INFO - __main__ -   test_precision = 0.36\n",
      "04/27/2024 01:19:59 - INFO - __main__ -   test_recall = 0.2084\n",
      " 40% 203/512 [00:58<00:58,  5.31it/s]04/27/2024 01:20:18 - WARNING - __main__ - epoch 6 step 204 loss 0.15262\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:20:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:20:29 - INFO - __main__ -   eval_f1 = 0.3517\n",
      "04/27/2024 01:20:29 - INFO - __main__ -   eval_precision = 0.4712\n",
      "04/27/2024 01:20:29 - INFO - __main__ -   eval_recall = 0.2805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:20:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:20:39 - INFO - __main__ -   auc_score = 0.8306\n",
      "04/27/2024 01:20:39 - INFO - __main__ -   test_f1 = 0.2583\n",
      "04/27/2024 01:20:39 - INFO - __main__ -   test_precision = 0.3514\n",
      "04/27/2024 01:20:39 - INFO - __main__ -   test_recall = 0.2042\n",
      " 60% 305/512 [01:38<00:38,  5.31it/s]04/27/2024 01:20:58 - WARNING - __main__ - epoch 6 step 306 loss 0.14615\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:21:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:21:09 - INFO - __main__ -   eval_f1 = 0.3379\n",
      "04/27/2024 01:21:09 - INFO - __main__ -   eval_precision = 0.4066\n",
      "04/27/2024 01:21:09 - INFO - __main__ -   eval_recall = 0.2891\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:21:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:21:19 - INFO - __main__ -   auc_score = 0.8238\n",
      "04/27/2024 01:21:19 - INFO - __main__ -   test_f1 = 0.271\n",
      "04/27/2024 01:21:19 - INFO - __main__ -   test_precision = 0.3354\n",
      "04/27/2024 01:21:19 - INFO - __main__ -   test_recall = 0.2274\n",
      " 79% 407/512 [02:18<00:19,  5.32it/s]04/27/2024 01:21:38 - WARNING - __main__ - epoch 6 step 408 loss 0.15217\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:21:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:21:48 - INFO - __main__ -   eval_f1 = 0.3603\n",
      "04/27/2024 01:21:48 - INFO - __main__ -   eval_precision = 0.3854\n",
      "04/27/2024 01:21:48 - INFO - __main__ -   eval_recall = 0.3383\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:21:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:21:59 - INFO - __main__ -   auc_score = 0.8291\n",
      "04/27/2024 01:21:59 - INFO - __main__ -   test_f1 = 0.2939\n",
      "04/27/2024 01:21:59 - INFO - __main__ -   test_precision = 0.3232\n",
      "04/27/2024 01:21:59 - INFO - __main__ -   test_recall = 0.2695\n",
      " 99% 509/512 [02:58<00:00,  5.32it/s]04/27/2024 01:22:18 - WARNING - __main__ - epoch 6 step 510 loss 0.17311\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:22:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:22:28 - INFO - __main__ -   eval_f1 = 0.3374\n",
      "04/27/2024 01:22:28 - INFO - __main__ -   eval_precision = 0.3528\n",
      "04/27/2024 01:22:28 - INFO - __main__ -   eval_recall = 0.3233\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:22:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:22:39 - INFO - __main__ -   auc_score = 0.8269\n",
      "04/27/2024 01:22:39 - INFO - __main__ -   test_f1 = 0.3084\n",
      "04/27/2024 01:22:39 - INFO - __main__ -   test_precision = 0.3286\n",
      "04/27/2024 01:22:39 - INFO - __main__ -   test_recall = 0.2905\n",
      "100% 512/512 [03:19<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.30it/s]04/27/2024 01:22:58 - WARNING - __main__ - epoch 7 step 102 loss 0.14302\n",
      "04/27/2024 01:23:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:23:09 - INFO - __main__ -   eval_f1 = 0.3697\n",
      "04/27/2024 01:23:09 - INFO - __main__ -   eval_precision = 0.3499\n",
      "04/27/2024 01:23:09 - INFO - __main__ -   eval_recall = 0.3919\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:23:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:23:19 - INFO - __main__ -   auc_score = 0.8276\n",
      "04/27/2024 01:23:19 - INFO - __main__ -   test_f1 = 0.3441\n",
      "04/27/2024 01:23:19 - INFO - __main__ -   test_precision = 0.3314\n",
      "04/27/2024 01:23:19 - INFO - __main__ -   test_recall = 0.3579\n",
      " 40% 203/512 [00:59<00:58,  5.30it/s]04/27/2024 01:23:38 - WARNING - __main__ - epoch 7 step 204 loss 0.13188\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:23:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:23:49 - INFO - __main__ -   eval_f1 = 0.3775\n",
      "04/27/2024 01:23:49 - INFO - __main__ -   eval_precision = 0.3445\n",
      "04/27/2024 01:23:49 - INFO - __main__ -   eval_recall = 0.4176\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:23:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:23:59 - INFO - __main__ -   auc_score = 0.8316\n",
      "04/27/2024 01:23:59 - INFO - __main__ -   test_f1 = 0.3494\n",
      "04/27/2024 01:23:59 - INFO - __main__ -   test_precision = 0.3226\n",
      "04/27/2024 01:23:59 - INFO - __main__ -   test_recall = 0.3811\n",
      " 60% 305/512 [01:39<00:38,  5.32it/s]04/27/2024 01:24:18 - WARNING - __main__ - epoch 7 step 306 loss 0.14447\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:24:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:24:29 - INFO - __main__ -   eval_f1 = 0.3699\n",
      "04/27/2024 01:24:29 - INFO - __main__ -   eval_precision = 0.3438\n",
      "04/27/2024 01:24:29 - INFO - __main__ -   eval_recall = 0.4004\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:24:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:24:39 - INFO - __main__ -   auc_score = 0.827\n",
      "04/27/2024 01:24:39 - INFO - __main__ -   test_f1 = 0.348\n",
      "04/27/2024 01:24:39 - INFO - __main__ -   test_precision = 0.3248\n",
      "04/27/2024 01:24:39 - INFO - __main__ -   test_recall = 0.3747\n",
      " 79% 407/512 [02:18<00:19,  5.30it/s]04/27/2024 01:24:58 - WARNING - __main__ - epoch 7 step 408 loss 0.14639\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:25:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:25:08 - INFO - __main__ -   eval_f1 = 0.3725\n",
      "04/27/2024 01:25:08 - INFO - __main__ -   eval_precision = 0.3682\n",
      "04/27/2024 01:25:08 - INFO - __main__ -   eval_recall = 0.3769\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:25:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:25:19 - INFO - __main__ -   auc_score = 0.8209\n",
      "04/27/2024 01:25:19 - INFO - __main__ -   test_f1 = 0.3122\n",
      "04/27/2024 01:25:19 - INFO - __main__ -   test_precision = 0.3129\n",
      "04/27/2024 01:25:19 - INFO - __main__ -   test_recall = 0.3116\n",
      " 99% 509/512 [02:58<00:00,  5.30it/s]04/27/2024 01:25:38 - WARNING - __main__ - epoch 7 step 510 loss 0.13087\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:25:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:25:48 - INFO - __main__ -   eval_f1 = 0.341\n",
      "04/27/2024 01:25:48 - INFO - __main__ -   eval_precision = 0.3955\n",
      "04/27/2024 01:25:48 - INFO - __main__ -   eval_recall = 0.2998\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:25:59 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:25:59 - INFO - __main__ -   auc_score = 0.8217\n",
      "04/27/2024 01:25:59 - INFO - __main__ -   test_f1 = 0.2736\n",
      "04/27/2024 01:25:59 - INFO - __main__ -   test_precision = 0.3219\n",
      "04/27/2024 01:25:59 - INFO - __main__ -   test_recall = 0.2379\n",
      "100% 512/512 [03:20<00:00,  2.56it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:19<01:17,  5.31it/s]04/27/2024 01:26:18 - WARNING - __main__ - epoch 8 step 102 loss 0.13144\n",
      "04/27/2024 01:26:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:26:29 - INFO - __main__ -   eval_f1 = 0.3306\n",
      "04/27/2024 01:26:29 - INFO - __main__ -   eval_precision = 0.3717\n",
      "04/27/2024 01:26:29 - INFO - __main__ -   eval_recall = 0.2976\n",
      "04/27/2024 01:26:30 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 101/512 [00:30<02:04,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-16b/single/checkpoints --pretrained_model codet5p-16b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbyv6smdKsRB"
   },
   "source": [
    "The code above ran in an A100, spending 9GB for VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbXaMNqo5aoQ",
    "outputId": "2cc7a519-bcd9-4f42-9a8c-ac44b59d788c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 5/5 [00:00<00:00,  7.26it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-16b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/27/2024 01:29:47 - INFO - __main__ - Successfully load epoch 2's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 01:29:58 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:29:58 - INFO - __main__ -   auc_score = 0.8473\n",
      "04/27/2024 01:29:58 - INFO - __main__ -   test_f1 = 0.3642\n",
      "04/27/2024 01:29:58 - INFO - __main__ -   test_precision = 0.3601\n",
      "04/27/2024 01:29:58 - INFO - __main__ -   test_recall = 0.3684\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-16b/single/checkpoints --pretrained_model codet5p-16b --learning_rate 2e-5 --epochs 10 --hidden_size 512 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Oq-1dx8V59m"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbJMDDu8WG0b",
    "outputId": "e2f3914a-60a8-47b9-a511-37212cfa60b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100% 5.07k/5.07k [00:00<00:00, 21.8MB/s]\n",
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "tokenizer_config.json: 100% 284/284 [00:00<00:00, 1.10MB/s]\n",
      "vocab.json: 100% 798k/798k [00:00<00:00, 4.09MB/s]\n",
      "merges.txt: 100% 456k/456k [00:00<00:00, 3.55MB/s]\n",
      "added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 6.33MB/s]\n",
      "special_tokens_map.json: 100% 131/131 [00:00<00:00, 694kB/s]\n",
      "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 6.40MB/s]\n",
      "pytorch_model.bin.index.json: 100% 39.8k/39.8k [00:00<00:00, 126MB/s]\n",
      "Downloading shards:   0% 0/5 [00:00<?, ?it/s]\n",
      "pytorch_model-00001-of-00005.bin:   0% 0.00/8.00G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   0% 10.5M/8.00G [00:00<09:00, 14.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   0% 21.0M/8.00G [00:00<05:06, 26.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   0% 31.5M/8.00G [00:01<04:00, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 41.9M/8.00G [00:01<03:34, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 52.4M/8.00G [00:01<03:02, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 62.9M/8.00G [00:01<03:02, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 73.4M/8.00G [00:01<03:00, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 83.9M/8.00G [00:02<02:43, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 94.4M/8.00G [00:02<02:46, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 105M/8.00G [00:02<02:50, 46.2MB/s] \u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   1% 115M/8.00G [00:02<02:38, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 126M/8.00G [00:03<02:43, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 136M/8.00G [00:03<02:47, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 147M/8.00G [00:03<02:34, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 157M/8.00G [00:03<02:42, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 168M/8.00G [00:03<02:45, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 178M/8.00G [00:04<02:32, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 189M/8.00G [00:04<02:39, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   2% 199M/8.00G [00:04<02:44, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 210M/8.00G [00:04<02:32, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 220M/8.00G [00:04<02:38, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 231M/8.00G [00:05<02:44, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 241M/8.00G [00:05<02:46, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 252M/8.00G [00:05<02:48, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 262M/8.00G [00:05<02:35, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   3% 273M/8.00G [00:06<02:41, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 283M/8.00G [00:06<02:32, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 294M/8.00G [00:06<02:52, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 304M/8.00G [00:06<02:52, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 315M/8.00G [00:07<02:52, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 325M/8.00G [00:07<02:43, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 336M/8.00G [00:07<02:40, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 346M/8.00G [00:07<03:15, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   4% 357M/8.00G [00:08<03:07, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 367M/8.00G [00:08<02:51, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 377M/8.00G [00:08<02:48, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 388M/8.00G [00:08<02:37, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 398M/8.00G [00:08<02:48, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 409M/8.00G [00:09<03:21, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 419M/8.00G [00:09<02:58, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   5% 430M/8.00G [00:09<02:57, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 440M/8.00G [00:09<02:55, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 451M/8.00G [00:10<02:40, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 461M/8.00G [00:10<02:41, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 472M/8.00G [00:10<02:50, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 482M/8.00G [00:11<03:33, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 493M/8.00G [00:11<03:20, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 503M/8.00G [00:11<03:23, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   6% 514M/8.00G [00:12<03:59, 31.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 524M/8.00G [00:12<03:38, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 535M/8.00G [00:12<04:28, 27.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 545M/8.00G [00:12<03:44, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 556M/8.00G [00:13<03:26, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 566M/8.00G [00:13<03:02, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 577M/8.00G [00:13<02:58, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 587M/8.00G [00:13<02:53, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   7% 598M/8.00G [00:14<02:37, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 608M/8.00G [00:14<02:38, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 619M/8.00G [00:14<02:26, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 629M/8.00G [00:14<02:31, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 640M/8.00G [00:14<02:35, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 650M/8.00G [00:15<02:38, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 661M/8.00G [00:15<02:27, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   8% 671M/8.00G [00:15<02:34, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 682M/8.00G [00:15<02:22, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 692M/8.00G [00:15<02:28, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 703M/8.00G [00:16<02:33, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 713M/8.00G [00:16<02:22, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 724M/8.00G [00:16<02:28, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 734M/8.00G [00:16<02:32, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 744M/8.00G [00:17<02:22, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:   9% 755M/8.00G [00:17<02:27, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 765M/8.00G [00:17<02:17, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 776M/8.00G [00:17<02:24, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 786M/8.00G [00:17<02:31, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 797M/8.00G [00:18<02:19, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 807M/8.00G [00:18<02:25, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 818M/8.00G [00:18<02:30, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 828M/8.00G [00:18<02:20, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  10% 839M/8.00G [00:18<02:25, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 849M/8.00G [00:19<02:17, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 860M/8.00G [00:19<02:23, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 870M/8.00G [00:19<02:27, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 881M/8.00G [00:19<02:17, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 891M/8.00G [00:19<02:25, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 902M/8.00G [00:20<02:29, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  11% 912M/8.00G [00:20<02:25, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 923M/8.00G [00:20<02:23, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 933M/8.00G [00:20<02:27, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 944M/8.00G [00:21<02:25, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 954M/8.00G [00:21<02:20, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 965M/8.00G [00:21<02:21, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 975M/8.00G [00:21<02:16, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 986M/8.00G [00:21<02:23, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  12% 996M/8.00G [00:22<02:33, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.01G/8.00G [00:22<02:34, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.02G/8.00G [00:22<02:51, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.03G/8.00G [00:22<02:33, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.04G/8.00G [00:23<02:34, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.05G/8.00G [00:23<02:34, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.06G/8.00G [00:23<02:33, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  13% 1.07G/8.00G [00:23<02:52, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.08G/8.00G [00:24<02:45, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.09G/8.00G [00:24<02:42, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.10G/8.00G [00:24<02:42, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.11G/8.00G [00:24<02:27, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.12G/8.00G [00:25<02:29, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.13G/8.00G [00:25<02:31, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.14G/8.00G [00:25<02:19, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  14% 1.15G/8.00G [00:25<02:22, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.16G/8.00G [00:25<02:13, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.17G/8.00G [00:26<02:17, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.18G/8.00G [00:26<02:22, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.20G/8.00G [00:26<02:14, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.21G/8.00G [00:26<02:18, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.22G/8.00G [00:26<02:22, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.23G/8.00G [00:27<02:14, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  15% 1.24G/8.00G [00:27<02:17, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.25G/8.00G [00:27<02:11, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.26G/8.00G [00:27<02:17, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.27G/8.00G [00:28<02:18, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.28G/8.00G [00:28<02:11, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.29G/8.00G [00:28<02:14, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.30G/8.00G [00:28<02:08, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  16% 1.31G/8.00G [00:28<02:15, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.32G/8.00G [00:29<03:04, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.33G/8.00G [00:29<02:41, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.34G/8.00G [00:29<02:39, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.35G/8.00G [00:30<02:54, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.36G/8.00G [00:30<02:37, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.37G/8.00G [00:30<02:32, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.38G/8.00G [00:30<02:59, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  17% 1.39G/8.00G [00:31<03:07, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.41G/8.00G [00:31<03:02, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.42G/8.00G [00:31<03:04, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.43G/8.00G [00:32<03:01, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.44G/8.00G [00:32<02:52, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.45G/8.00G [00:32<02:33, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.46G/8.00G [00:32<02:29, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.47G/8.00G [00:32<02:17, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  18% 1.48G/8.00G [00:33<02:21, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.49G/8.00G [00:33<02:22, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.50G/8.00G [00:33<02:12, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.51G/8.00G [00:33<02:15, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.52G/8.00G [00:33<02:23, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.53G/8.00G [00:34<02:12, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.54G/8.00G [00:34<02:16, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  19% 1.55G/8.00G [00:34<02:17, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.56G/8.00G [00:34<02:08, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.57G/8.00G [00:35<02:10, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.58G/8.00G [00:35<02:04, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.59G/8.00G [00:35<02:10, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.60G/8.00G [00:35<02:14, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.61G/8.00G [00:35<02:08, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.63G/8.00G [00:36<02:33, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  20% 1.64G/8.00G [00:36<02:41, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.65G/8.00G [00:36<02:36, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.66G/8.00G [00:37<02:54, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.67G/8.00G [00:37<02:34, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.68G/8.00G [00:37<02:29, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.69G/8.00G [00:37<02:28, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.70G/8.00G [00:37<02:14, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.71G/8.00G [00:38<02:17, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  21% 1.72G/8.00G [00:38<02:17, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.73G/8.00G [00:38<02:08, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.74G/8.00G [00:38<02:12, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.75G/8.00G [00:39<02:14, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.76G/8.00G [00:39<02:04, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.77G/8.00G [00:39<02:08, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.78G/8.00G [00:39<02:12, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  22% 1.79G/8.00G [00:40<02:28, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.80G/8.00G [00:40<02:25, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.81G/8.00G [00:40<02:36, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.82G/8.00G [00:40<02:31, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.84G/8.00G [00:41<02:37, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.85G/8.00G [00:41<02:52, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.86G/8.00G [00:41<02:41, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.87G/8.00G [00:41<02:35, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  23% 1.88G/8.00G [00:42<02:32, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.89G/8.00G [00:42<02:28, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.90G/8.00G [00:42<02:49, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.91G/8.00G [00:43<02:49, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.92G/8.00G [00:43<03:34, 28.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.93G/8.00G [00:43<03:11, 31.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.94G/8.00G [00:44<02:55, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  24% 1.95G/8.00G [00:44<02:44, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 1.96G/8.00G [00:44<02:42, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 1.97G/8.00G [00:44<02:33, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 1.98G/8.00G [00:45<02:27, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 1.99G/8.00G [00:45<02:27, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 2.00G/8.00G [00:45<02:26, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 2.01G/8.00G [00:45<02:14, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 2.02G/8.00G [00:46<02:18, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  25% 2.03G/8.00G [00:46<02:10, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.04G/8.00G [00:46<02:13, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.06G/8.00G [00:46<02:11, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.07G/8.00G [00:46<02:11, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.08G/8.00G [00:47<02:11, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.09G/8.00G [00:47<02:15, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.10G/8.00G [00:47<02:16, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.11G/8.00G [00:47<02:15, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  26% 2.12G/8.00G [00:48<02:14, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.13G/8.00G [00:48<02:22, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.14G/8.00G [00:48<02:18, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.15G/8.00G [00:48<02:10, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.16G/8.00G [00:49<02:10, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.17G/8.00G [00:49<02:10, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.18G/8.00G [00:49<02:09, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  27% 2.19G/8.00G [00:49<02:09, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.20G/8.00G [00:50<02:09, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.21G/8.00G [00:50<02:11, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.22G/8.00G [00:50<02:08, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.23G/8.00G [00:50<02:11, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.24G/8.00G [00:51<02:08, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.25G/8.00G [00:51<02:08, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.26G/8.00G [00:51<02:07, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  28% 2.28G/8.00G [00:51<02:06, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.29G/8.00G [00:51<01:58, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.30G/8.00G [00:52<02:01, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.31G/8.00G [00:52<02:03, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.32G/8.00G [00:52<02:05, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.33G/8.00G [00:52<02:05, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.34G/8.00G [00:53<02:07, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.35G/8.00G [00:53<02:07, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  29% 2.36G/8.00G [00:53<02:07, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.37G/8.00G [00:53<02:07, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.38G/8.00G [00:54<02:05, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.39G/8.00G [00:54<02:07, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.40G/8.00G [00:54<02:07, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.41G/8.00G [00:54<02:05, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.42G/8.00G [00:54<02:04, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  30% 2.43G/8.00G [00:55<02:05, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.44G/8.00G [00:55<02:05, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.45G/8.00G [00:55<02:05, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.46G/8.00G [00:56<02:17, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.47G/8.00G [00:56<02:03, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.49G/8.00G [00:56<02:15, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.50G/8.00G [00:56<02:12, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.51G/8.00G [00:56<02:05, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  31% 2.52G/8.00G [00:57<02:02, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.53G/8.00G [00:57<02:00, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.54G/8.00G [00:57<02:00, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.55G/8.00G [00:57<02:00, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.56G/8.00G [00:58<01:59, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.57G/8.00G [00:58<01:57, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.58G/8.00G [00:58<02:06, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  32% 2.59G/8.00G [00:58<02:05, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.60G/8.00G [00:59<02:12, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.61G/8.00G [00:59<02:06, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.62G/8.00G [00:59<02:04, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.63G/8.00G [00:59<02:02, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.64G/8.00G [00:59<01:51, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.65G/8.00G [01:00<01:53, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.66G/8.00G [01:00<01:55, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  33% 2.67G/8.00G [01:00<01:48, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.68G/8.00G [01:00<01:49, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.69G/8.00G [01:01<01:42, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.71G/8.00G [01:01<01:46, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.72G/8.00G [01:01<01:50, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.73G/8.00G [01:01<01:43, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.74G/8.00G [01:01<01:48, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.75G/8.00G [01:02<01:50, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  34% 2.76G/8.00G [01:02<01:43, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.77G/8.00G [01:02<01:47, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.78G/8.00G [01:02<01:50, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.79G/8.00G [01:02<01:42, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.80G/8.00G [01:03<01:47, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.81G/8.00G [01:03<02:02, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.82G/8.00G [01:03<02:03, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  35% 2.83G/8.00G [01:04<02:07, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.84G/8.00G [01:04<02:05, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.85G/8.00G [01:04<02:02, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.86G/8.00G [01:04<02:08, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.87G/8.00G [01:05<02:07, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.88G/8.00G [01:05<02:03, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.89G/8.00G [01:05<02:02, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.90G/8.00G [01:05<01:59, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  36% 2.92G/8.00G [01:06<01:58, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.93G/8.00G [01:06<01:57, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.94G/8.00G [01:06<01:56, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.95G/8.00G [01:06<01:55, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.96G/8.00G [01:06<01:54, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.97G/8.00G [01:07<01:54, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.98G/8.00G [01:07<01:53, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 2.99G/8.00G [01:07<01:49, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  37% 3.00G/8.00G [01:07<01:44, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.01G/8.00G [01:08<01:55, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.02G/8.00G [01:08<01:54, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.03G/8.00G [01:08<01:54, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.04G/8.00G [01:08<01:44, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.05G/8.00G [01:09<01:46, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.06G/8.00G [01:09<02:32, 32.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  38% 3.07G/8.00G [01:09<02:19, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.08G/8.00G [01:10<02:00, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.09G/8.00G [01:10<01:57, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.10G/8.00G [01:10<01:54, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.11G/8.00G [01:10<02:00, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.12G/8.00G [01:11<02:04, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.14G/8.00G [01:11<01:52, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.15G/8.00G [01:11<01:49, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  39% 3.16G/8.00G [01:11<01:55, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.17G/8.00G [01:11<01:48, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.18G/8.00G [01:12<01:51, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.19G/8.00G [01:12<01:40, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.20G/8.00G [01:12<01:42, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.21G/8.00G [01:12<01:43, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.22G/8.00G [01:13<01:36, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  40% 3.23G/8.00G [01:13<01:39, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.24G/8.00G [01:13<01:41, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.25G/8.00G [01:13<01:33, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.26G/8.00G [01:13<01:37, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.27G/8.00G [01:14<01:30, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.28G/8.00G [01:14<01:35, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.29G/8.00G [01:14<01:38, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.30G/8.00G [01:14<01:40, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  41% 3.31G/8.00G [01:14<01:41, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.32G/8.00G [01:15<01:42, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.33G/8.00G [01:15<01:43, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.34G/8.00G [01:15<01:35, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.36G/8.00G [01:15<01:38, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.37G/8.00G [01:16<01:31, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.38G/8.00G [01:16<01:34, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.39G/8.00G [01:16<01:36, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  42% 3.40G/8.00G [01:16<01:30, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.41G/8.00G [01:16<01:35, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.42G/8.00G [01:17<01:39, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.43G/8.00G [01:17<02:09, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.44G/8.00G [01:17<02:02, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.45G/8.00G [01:18<01:49, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.46G/8.00G [01:18<01:45, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  43% 3.47G/8.00G [01:18<01:44, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.48G/8.00G [01:18<01:36, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.49G/8.00G [01:18<01:36, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.50G/8.00G [01:19<01:38, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.51G/8.00G [01:19<01:39, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.52G/8.00G [01:19<01:36, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.53G/8.00G [01:19<01:32, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.54G/8.00G [01:20<01:35, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  44% 3.55G/8.00G [01:20<01:36, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.57G/8.00G [01:20<01:28, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.58G/8.00G [01:20<02:07, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.59G/8.00G [01:21<01:58, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.60G/8.00G [01:21<01:47, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.61G/8.00G [01:21<01:40, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.62G/8.00G [01:21<01:40, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.63G/8.00G [01:22<01:35, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  45% 3.64G/8.00G [01:22<01:31, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.65G/8.00G [01:22<01:29, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.66G/8.00G [01:22<01:31, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.67G/8.00G [01:22<01:28, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.68G/8.00G [01:23<01:27, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.69G/8.00G [01:23<01:29, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.70G/8.00G [01:23<01:28, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  46% 3.71G/8.00G [01:23<01:27, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.72G/8.00G [01:23<01:25, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.73G/8.00G [01:24<01:28, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.74G/8.00G [01:24<01:26, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.75G/8.00G [01:24<01:48, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.76G/8.00G [01:25<01:44, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.77G/8.00G [01:25<01:34, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.79G/8.00G [01:25<01:39, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  47% 3.80G/8.00G [01:25<01:42, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.81G/8.00G [01:25<01:37, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.82G/8.00G [01:26<01:47, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.83G/8.00G [01:26<01:45, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.84G/8.00G [01:26<01:48, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.85G/8.00G [01:27<01:43, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.86G/8.00G [01:27<01:40, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.87G/8.00G [01:27<01:43, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  48% 3.88G/8.00G [01:27<01:54, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.89G/8.00G [01:28<01:47, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.90G/8.00G [01:28<01:43, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.91G/8.00G [01:28<01:40, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.92G/8.00G [01:28<01:39, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.93G/8.00G [01:29<01:36, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.94G/8.00G [01:29<01:42, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  49% 3.95G/8.00G [01:29<01:39, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 3.96G/8.00G [01:29<01:36, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 3.97G/8.00G [01:30<01:34, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 3.98G/8.00G [01:30<01:33, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 4.00G/8.00G [01:30<01:32, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 4.01G/8.00G [01:30<01:31, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 4.02G/8.00G [01:31<01:24, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 4.03G/8.00G [01:31<01:25, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  50% 4.04G/8.00G [01:31<01:25, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.05G/8.00G [01:31<01:18, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.06G/8.00G [01:31<01:21, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.07G/8.00G [01:32<01:20, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.08G/8.00G [01:32<01:17, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.09G/8.00G [01:32<01:20, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.10G/8.00G [01:32<01:24, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  51% 4.11G/8.00G [01:33<01:24, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.12G/8.00G [01:33<01:24, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.13G/8.00G [01:33<01:19, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.14G/8.00G [01:33<01:19, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.15G/8.00G [01:33<01:25, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.16G/8.00G [01:34<01:42, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.17G/8.00G [01:34<01:37, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.18G/8.00G [01:34<01:33, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  52% 4.19G/8.00G [01:35<01:31, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.20G/8.00G [01:35<01:29, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.22G/8.00G [01:35<01:20, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.23G/8.00G [01:35<01:21, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.24G/8.00G [01:35<01:22, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.25G/8.00G [01:36<01:28, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.26G/8.00G [01:36<01:15, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.27G/8.00G [01:36<01:22, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  53% 4.28G/8.00G [01:36<01:22, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.29G/8.00G [01:37<01:15, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.30G/8.00G [01:37<01:17, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.31G/8.00G [01:37<01:18, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.32G/8.00G [01:37<01:12, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.33G/8.00G [01:37<01:16, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.34G/8.00G [01:38<01:17, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  54% 4.35G/8.00G [01:38<01:15, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.36G/8.00G [01:38<01:13, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.37G/8.00G [01:38<01:16, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.38G/8.00G [01:38<01:10, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.39G/8.00G [01:39<01:20, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.40G/8.00G [01:39<01:27, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.41G/8.00G [01:39<01:25, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.42G/8.00G [01:40<01:30, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  55% 4.44G/8.00G [01:40<01:28, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.45G/8.00G [01:40<01:25, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.46G/8.00G [01:40<01:28, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.47G/8.00G [01:41<01:42, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.48G/8.00G [01:41<01:40, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.49G/8.00G [01:41<01:35, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.50G/8.00G [01:42<01:30, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.51G/8.00G [01:42<01:26, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  56% 4.52G/8.00G [01:42<01:23, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.53G/8.00G [01:42<01:22, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.54G/8.00G [01:43<01:20, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.55G/8.00G [01:43<01:19, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.56G/8.00G [01:43<01:18, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.57G/8.00G [01:43<01:18, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.58G/8.00G [01:44<01:24, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  57% 4.59G/8.00G [01:44<01:16, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.60G/8.00G [01:44<01:16, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.61G/8.00G [01:44<01:15, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.62G/8.00G [01:44<01:16, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.63G/8.00G [01:45<01:16, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.65G/8.00G [01:45<01:17, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.66G/8.00G [01:45<01:15, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.67G/8.00G [01:45<01:15, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  58% 4.68G/8.00G [01:46<01:15, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.69G/8.00G [01:46<01:14, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.70G/8.00G [01:46<01:14, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.71G/8.00G [01:46<01:08, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.72G/8.00G [01:46<01:10, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.73G/8.00G [01:47<01:16, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.74G/8.00G [01:47<01:15, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  59% 4.75G/8.00G [01:47<01:15, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.76G/8.00G [01:47<01:12, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.77G/8.00G [01:48<01:15, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.78G/8.00G [01:48<01:09, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.79G/8.00G [01:48<01:11, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.80G/8.00G [01:48<01:11, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.81G/8.00G [01:49<01:11, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.82G/8.00G [01:49<01:11, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  60% 4.83G/8.00G [01:49<01:10, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.84G/8.00G [01:49<01:11, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.85G/8.00G [01:50<01:11, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.87G/8.00G [01:50<01:10, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.88G/8.00G [01:50<01:10, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.89G/8.00G [01:50<01:09, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.90G/8.00G [01:51<01:10, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.91G/8.00G [01:51<01:10, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  61% 4.92G/8.00G [01:51<01:04, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.93G/8.00G [01:51<01:07, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.94G/8.00G [01:51<01:06, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.95G/8.00G [01:52<01:06, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.96G/8.00G [01:52<01:07, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.97G/8.00G [01:52<01:07, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.98G/8.00G [01:52<01:10, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  62% 4.99G/8.00G [01:53<01:09, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.00G/8.00G [01:53<01:08, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.01G/8.00G [01:53<01:04, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.02G/8.00G [01:53<01:05, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.03G/8.00G [01:54<01:05, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.04G/8.00G [01:54<01:06, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.05G/8.00G [01:54<01:06, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.06G/8.00G [01:54<01:06, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  63% 5.08G/8.00G [01:55<01:06, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.09G/8.00G [01:55<01:09, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.10G/8.00G [01:55<00:59, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.11G/8.00G [01:55<01:01, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.12G/8.00G [01:55<01:02, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.13G/8.00G [01:56<01:03, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.14G/8.00G [01:56<01:03, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.15G/8.00G [01:56<01:03, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  64% 5.16G/8.00G [01:56<01:13, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.17G/8.00G [01:57<01:16, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.18G/8.00G [01:57<01:12, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.19G/8.00G [01:57<01:08, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.20G/8.00G [01:58<01:12, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.21G/8.00G [01:58<01:04, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.22G/8.00G [01:58<01:03, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  65% 5.23G/8.00G [01:58<01:03, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.24G/8.00G [01:58<00:57, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.25G/8.00G [01:59<00:58, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.26G/8.00G [01:59<00:58, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.27G/8.00G [01:59<01:05, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.28G/8.00G [02:00<01:32, 29.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.30G/8.00G [02:00<01:17, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.31G/8.00G [02:00<01:13, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  66% 5.32G/8.00G [02:00<01:09, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.33G/8.00G [02:01<01:01, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.34G/8.00G [02:01<01:13, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.35G/8.00G [02:01<01:11, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.36G/8.00G [02:02<01:07, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.37G/8.00G [02:02<01:11, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.38G/8.00G [02:02<01:05, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  67% 5.39G/8.00G [02:02<01:02, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.40G/8.00G [02:03<01:01, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.41G/8.00G [02:03<00:55, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.42G/8.00G [02:03<00:56, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.43G/8.00G [02:03<00:51, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.44G/8.00G [02:03<00:53, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.45G/8.00G [02:04<00:54, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.46G/8.00G [02:04<00:56, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  68% 5.47G/8.00G [02:04<00:56, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.48G/8.00G [02:04<00:56, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.49G/8.00G [02:05<00:58, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.51G/8.00G [02:05<01:09, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.52G/8.00G [02:05<01:05, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.53G/8.00G [02:06<01:18, 31.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.55G/8.00G [02:06<00:56, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  69% 5.56G/8.00G [02:06<00:54, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.57G/8.00G [02:06<00:51, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.58G/8.00G [02:07<00:51, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.59G/8.00G [02:07<00:51, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.60G/8.00G [02:07<00:48, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.61G/8.00G [02:07<00:48, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.62G/8.00G [02:07<00:49, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  70% 5.63G/8.00G [02:08<00:47, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.64G/8.00G [02:08<00:48, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.65G/8.00G [02:08<00:45, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.66G/8.00G [02:08<00:47, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.67G/8.00G [02:08<00:48, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.68G/8.00G [02:09<00:45, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.69G/8.00G [02:09<00:46, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.70G/8.00G [02:09<00:47, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  71% 5.71G/8.00G [02:09<00:52, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.73G/8.00G [02:10<00:51, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.74G/8.00G [02:10<00:46, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.75G/8.00G [02:10<00:52, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.76G/8.00G [02:10<00:51, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.77G/8.00G [02:11<00:51, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.78G/8.00G [02:11<00:46, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.79G/8.00G [02:11<00:47, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  72% 5.80G/8.00G [02:11<00:47, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.81G/8.00G [02:11<00:43, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.82G/8.00G [02:12<00:45, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.83G/8.00G [02:12<00:41, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.84G/8.00G [02:12<00:43, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.85G/8.00G [02:12<00:45, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.86G/8.00G [02:12<00:41, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  73% 5.87G/8.00G [02:13<00:43, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.88G/8.00G [02:13<00:44, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.89G/8.00G [02:13<00:41, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.90G/8.00G [02:13<00:42, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.91G/8.00G [02:14<00:43, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.92G/8.00G [02:14<00:40, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.93G/8.00G [02:14<00:42, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.95G/8.00G [02:14<00:43, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  74% 5.96G/8.00G [02:14<00:44, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 5.97G/8.00G [02:15<00:40, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 5.98G/8.00G [02:15<00:41, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 5.99G/8.00G [02:15<00:43, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 6.00G/8.00G [02:15<00:44, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 6.01G/8.00G [02:16<00:53, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 6.02G/8.00G [02:16<00:48, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  75% 6.03G/8.00G [02:16<00:47, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.04G/8.00G [02:16<00:49, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.05G/8.00G [02:17<00:44, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.06G/8.00G [02:17<00:44, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.07G/8.00G [02:17<00:43, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.08G/8.00G [02:17<00:43, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.09G/8.00G [02:18<00:42, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.10G/8.00G [02:18<00:50, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  76% 6.11G/8.00G [02:18<00:48, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.12G/8.00G [02:18<00:45, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.13G/8.00G [02:19<00:41, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.14G/8.00G [02:19<00:45, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.16G/8.00G [02:19<00:40, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.17G/8.00G [02:19<00:40, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.18G/8.00G [02:20<00:39, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.19G/8.00G [02:20<00:36, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  77% 6.20G/8.00G [02:20<00:37, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.21G/8.00G [02:20<00:34, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.22G/8.00G [02:21<00:46, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.23G/8.00G [02:21<00:46, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.24G/8.00G [02:21<00:41, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.25G/8.00G [02:21<00:39, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.26G/8.00G [02:21<00:36, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  78% 6.27G/8.00G [02:22<00:36, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.28G/8.00G [02:22<00:37, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.29G/8.00G [02:22<00:33, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.30G/8.00G [02:22<00:35, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.31G/8.00G [02:23<00:35, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.32G/8.00G [02:23<00:33, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.33G/8.00G [02:23<00:34, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.34G/8.00G [02:23<00:32, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  79% 6.35G/8.00G [02:23<00:36, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.36G/8.00G [02:24<00:35, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.38G/8.00G [02:24<00:34, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.39G/8.00G [02:24<00:37, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.40G/8.00G [02:24<00:37, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.41G/8.00G [02:25<00:34, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.42G/8.00G [02:25<00:34, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.43G/8.00G [02:25<00:34, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  80% 6.44G/8.00G [02:25<00:31, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.45G/8.00G [02:25<00:32, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.46G/8.00G [02:26<00:29, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.47G/8.00G [02:26<00:34, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.48G/8.00G [02:26<00:33, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.49G/8.00G [02:26<00:31, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.50G/8.00G [02:27<00:31, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  81% 6.51G/8.00G [02:27<00:31, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.52G/8.00G [02:27<00:29, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.53G/8.00G [02:27<00:32, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.54G/8.00G [02:27<00:29, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.55G/8.00G [02:28<00:30, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.56G/8.00G [02:28<00:30, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.57G/8.00G [02:28<00:28, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.59G/8.00G [02:28<00:35, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  82% 6.60G/8.00G [02:29<00:30, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.61G/8.00G [02:29<00:30, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.62G/8.00G [02:29<00:32, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.63G/8.00G [02:29<00:29, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.64G/8.00G [02:30<00:30, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.65G/8.00G [02:30<00:29, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.66G/8.00G [02:30<00:33, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.67G/8.00G [02:30<00:32, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  83% 6.68G/8.00G [02:31<00:34, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.69G/8.00G [02:31<00:32, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.70G/8.00G [02:31<00:31, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.71G/8.00G [02:31<00:30, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.72G/8.00G [02:32<00:35, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.73G/8.00G [02:32<00:33, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.74G/8.00G [02:32<00:34, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  84% 6.75G/8.00G [02:33<00:32, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.76G/8.00G [02:33<00:30, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.77G/8.00G [02:33<00:30, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.78G/8.00G [02:33<00:30, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.79G/8.00G [02:34<00:29, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.81G/8.00G [02:34<00:28, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.82G/8.00G [02:34<00:28, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.83G/8.00G [02:34<00:27, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  85% 6.84G/8.00G [02:35<00:29, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.85G/8.00G [02:35<00:27, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.86G/8.00G [02:35<00:27, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.87G/8.00G [02:35<00:27, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.88G/8.00G [02:36<00:26, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.89G/8.00G [02:36<00:25, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.90G/8.00G [02:36<00:23, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  86% 6.91G/8.00G [02:36<00:24, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.92G/8.00G [02:36<00:25, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.93G/8.00G [02:37<00:24, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.94G/8.00G [02:37<00:24, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.95G/8.00G [02:37<00:22, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.96G/8.00G [02:37<00:23, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.97G/8.00G [02:38<00:21, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.98G/8.00G [02:38<00:21, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  87% 6.99G/8.00G [02:38<00:22, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.00G/8.00G [02:38<00:21, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.01G/8.00G [02:39<00:21, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.03G/8.00G [02:39<00:21, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.04G/8.00G [02:39<00:21, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.05G/8.00G [02:39<00:22, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.06G/8.00G [02:40<00:21, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.07G/8.00G [02:40<00:21, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  88% 7.08G/8.00G [02:40<00:21, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.09G/8.00G [02:40<00:20, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.10G/8.00G [02:40<00:20, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.11G/8.00G [02:41<00:18, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.12G/8.00G [02:41<00:18, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.13G/8.00G [02:41<00:21, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.14G/8.00G [02:42<00:21, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  89% 7.15G/8.00G [02:42<00:21, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.16G/8.00G [02:42<00:21, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.17G/8.00G [02:42<00:22, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.18G/8.00G [02:43<00:21, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.19G/8.00G [02:43<00:21, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.20G/8.00G [02:43<00:21, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.21G/8.00G [02:44<00:21, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.22G/8.00G [02:44<00:23, 33.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  90% 7.24G/8.00G [02:44<00:23, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.25G/8.00G [02:45<00:24, 31.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.26G/8.00G [02:45<00:23, 31.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.27G/8.00G [02:45<00:24, 30.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.28G/8.00G [02:46<00:23, 31.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.29G/8.00G [02:46<00:22, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.30G/8.00G [02:46<00:23, 30.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.31G/8.00G [02:47<00:22, 31.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  91% 7.32G/8.00G [02:47<00:21, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.33G/8.00G [02:47<00:20, 32.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.34G/8.00G [02:48<00:20, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.35G/8.00G [02:48<00:19, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.36G/8.00G [02:48<00:19, 33.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.37G/8.00G [02:48<00:18, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.38G/8.00G [02:49<00:18, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  92% 7.39G/8.00G [02:49<00:18, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.40G/8.00G [02:49<00:18, 32.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.41G/8.00G [02:50<00:17, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.42G/8.00G [02:50<00:17, 33.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.43G/8.00G [02:50<00:16, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.44G/8.00G [02:51<00:15, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.46G/8.00G [02:51<00:15, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.47G/8.00G [02:51<00:15, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  93% 7.48G/8.00G [02:52<00:15, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.49G/8.00G [02:52<00:14, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.50G/8.00G [02:52<00:14, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.51G/8.00G [02:52<00:14, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.52G/8.00G [02:53<00:14, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.53G/8.00G [02:53<00:13, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.54G/8.00G [02:53<00:13, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  94% 7.55G/8.00G [02:54<00:13, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.56G/8.00G [02:54<00:12, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.57G/8.00G [02:54<00:12, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.58G/8.00G [02:55<00:12, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.59G/8.00G [02:55<00:11, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.60G/8.00G [02:55<00:11, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.61G/8.00G [02:56<00:11, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.62G/8.00G [02:56<00:11, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  95% 7.63G/8.00G [02:56<00:10, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.64G/8.00G [02:56<00:10, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.65G/8.00G [02:57<00:10, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.67G/8.00G [02:57<00:09, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.68G/8.00G [02:57<00:09, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.69G/8.00G [02:58<00:08, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.70G/8.00G [02:58<00:08, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.71G/8.00G [02:58<00:08, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  96% 7.72G/8.00G [02:59<00:08, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.73G/8.00G [02:59<00:07, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.74G/8.00G [02:59<00:07, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.75G/8.00G [02:59<00:06, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.76G/8.00G [03:00<00:06, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.77G/8.00G [03:00<00:06, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.78G/8.00G [03:00<00:05, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  97% 7.79G/8.00G [03:01<00:05, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.80G/8.00G [03:01<00:05, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.81G/8.00G [03:01<00:04, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.82G/8.00G [03:01<00:04, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.83G/8.00G [03:02<00:04, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.84G/8.00G [03:02<00:04, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.85G/8.00G [03:02<00:03, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.86G/8.00G [03:02<00:03, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  98% 7.87G/8.00G [03:03<00:03, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.89G/8.00G [03:03<00:02, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.90G/8.00G [03:03<00:02, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.91G/8.00G [03:04<00:02, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.92G/8.00G [03:04<00:02, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.93G/8.00G [03:04<00:01, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.94G/8.00G [03:04<00:01, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.95G/8.00G [03:04<00:01, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin:  99% 7.96G/8.00G [03:05<00:00, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin: 100% 7.97G/8.00G [03:05<00:00, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin: 100% 7.98G/8.00G [03:05<00:00, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin: 100% 7.99G/8.00G [03:05<00:00, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00005.bin: 100% 8.00G/8.00G [03:06<00:00, 42.9MB/s]\n",
      "Downloading shards:  20% 1/5 [03:06<12:27, 186.99s/it]\n",
      "pytorch_model-00002-of-00005.bin:   0% 0.00/7.89G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   0% 10.5M/7.89G [00:00<07:35, 17.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   0% 21.0M/7.89G [00:00<04:19, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   0% 31.5M/7.89G [00:00<03:22, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 41.9M/7.89G [00:01<03:06, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 52.4M/7.89G [00:01<02:54, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 62.9M/7.89G [00:01<03:45, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 83.9M/7.89G [00:01<02:17, 56.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 94.4M/7.89G [00:02<02:09, 60.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 105M/7.89G [00:02<02:14, 58.0MB/s] \u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   1% 115M/7.89G [00:02<02:18, 56.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 126M/7.89G [00:02<02:22, 54.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 136M/7.89G [00:03<02:48, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 147M/7.89G [00:03<03:05, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 157M/7.89G [00:03<02:55, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 168M/7.89G [00:03<02:48, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 178M/7.89G [00:03<02:51, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   2% 189M/7.89G [00:04<02:49, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 199M/7.89G [00:04<02:38, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 210M/7.89G [00:04<03:02, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 220M/7.89G [00:04<02:52, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 231M/7.89G [00:05<02:32, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 241M/7.89G [00:05<02:31, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 252M/7.89G [00:05<02:30, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 262M/7.89G [00:05<02:47, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   3% 273M/7.89G [00:06<03:04, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 283M/7.89G [00:06<02:40, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 294M/7.89G [00:06<02:55, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 304M/7.89G [00:06<03:06, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 315M/7.89G [00:06<02:43, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 325M/7.89G [00:07<02:53, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 336M/7.89G [00:07<02:32, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   4% 346M/7.89G [00:07<02:45, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 357M/7.89G [00:07<02:39, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 367M/7.89G [00:08<02:35, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 377M/7.89G [00:08<02:23, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 388M/7.89G [00:08<02:20, 53.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 398M/7.89G [00:08<02:10, 57.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 409M/7.89G [00:08<02:13, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 419M/7.89G [00:08<02:16, 54.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   5% 430M/7.89G [00:09<02:14, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 440M/7.89G [00:09<02:38, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 451M/7.89G [00:09<02:21, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 461M/7.89G [00:09<02:22, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 472M/7.89G [00:10<02:56, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 482M/7.89G [00:10<03:25, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 493M/7.89G [00:10<03:06, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   6% 503M/7.89G [00:10<02:43, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 514M/7.89G [00:11<02:35, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 524M/7.89G [00:11<02:31, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 535M/7.89G [00:11<02:34, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 545M/7.89G [00:11<02:53, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 556M/7.89G [00:11<02:32, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 566M/7.89G [00:12<02:35, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 577M/7.89G [00:12<02:41, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   7% 587M/7.89G [00:12<02:26, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 598M/7.89G [00:13<03:10, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 608M/7.89G [00:13<03:16, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 619M/7.89G [00:13<02:51, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 629M/7.89G [00:13<02:41, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 640M/7.89G [00:13<02:24, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 650M/7.89G [00:14<02:35, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   8% 661M/7.89G [00:14<02:52, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 671M/7.89G [00:14<02:30, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 682M/7.89G [00:14<02:46, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 692M/7.89G [00:15<02:38, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 703M/7.89G [00:15<02:23, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 713M/7.89G [00:15<02:21, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 724M/7.89G [00:15<02:25, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 734M/7.89G [00:15<02:22, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:   9% 744M/7.89G [00:16<02:21, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 755M/7.89G [00:16<02:09, 55.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 765M/7.89G [00:16<02:11, 54.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 776M/7.89G [00:16<02:01, 58.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 786M/7.89G [00:16<02:11, 53.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 797M/7.89G [00:17<02:13, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 807M/7.89G [00:17<03:14, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 818M/7.89G [00:17<03:24, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  10% 828M/7.89G [00:18<03:02, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 839M/7.89G [00:18<02:57, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 849M/7.89G [00:18<02:38, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 860M/7.89G [00:18<02:32, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 870M/7.89G [00:18<02:17, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 881M/7.89G [00:19<02:22, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  11% 891M/7.89G [00:19<02:35, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 912M/7.89G [00:19<02:05, 55.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 923M/7.89G [00:19<02:00, 57.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 933M/7.89G [00:19<02:01, 57.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 944M/7.89G [00:20<02:08, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 954M/7.89G [00:20<02:26, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 965M/7.89G [00:20<02:44, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 975M/7.89G [00:20<02:24, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  12% 986M/7.89G [00:21<02:38, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 996M/7.89G [00:21<02:56, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.01G/7.89G [00:21<02:33, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.02G/7.89G [00:21<02:32, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.03G/7.89G [00:22<02:39, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.04G/7.89G [00:22<02:29, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.05G/7.89G [00:22<02:14, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  13% 1.06G/7.89G [00:22<02:19, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.07G/7.89G [00:22<02:17, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.08G/7.89G [00:23<02:15, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.09G/7.89G [00:23<02:03, 55.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.10G/7.89G [00:23<02:05, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.11G/7.89G [00:23<01:55, 58.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.12G/7.89G [00:23<02:00, 56.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.13G/7.89G [00:24<02:03, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  14% 1.14G/7.89G [00:24<02:07, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.15G/7.89G [00:24<01:56, 57.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.16G/7.89G [00:24<02:00, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.17G/7.89G [00:25<02:45, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.18G/7.89G [00:25<02:35, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.20G/7.89G [00:25<02:17, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.21G/7.89G [00:25<02:14, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  15% 1.22G/7.89G [00:25<02:12, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.23G/7.89G [00:25<02:01, 54.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.24G/7.89G [00:26<02:02, 54.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.25G/7.89G [00:26<01:54, 57.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.26G/7.89G [00:26<02:33, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.27G/7.89G [00:26<02:25, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.28G/7.89G [00:27<02:20, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.29G/7.89G [00:27<02:12, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  16% 1.30G/7.89G [00:27<02:04, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.31G/7.89G [00:27<02:05, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.32G/7.89G [00:27<01:56, 56.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.33G/7.89G [00:28<02:29, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.34G/7.89G [00:28<02:22, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.35G/7.89G [00:28<02:56, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.36G/7.89G [00:29<02:49, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  17% 1.37G/7.89G [00:29<02:36, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.38G/7.89G [00:29<02:27, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.39G/7.89G [00:29<02:14, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.41G/7.89G [00:29<02:11, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.42G/7.89G [00:29<01:59, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.43G/7.89G [00:30<02:00, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.44G/7.89G [00:30<02:01, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.45G/7.89G [00:30<01:52, 57.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  18% 1.46G/7.89G [00:30<01:55, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.47G/7.89G [00:30<01:47, 59.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.48G/7.89G [00:31<01:51, 57.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.49G/7.89G [00:31<01:55, 55.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.50G/7.89G [00:31<01:50, 57.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.51G/7.89G [00:31<01:54, 55.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.52G/7.89G [00:31<02:05, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  19% 1.53G/7.89G [00:32<02:04, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.54G/7.89G [00:32<02:42, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.55G/7.89G [00:32<02:40, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.56G/7.89G [00:33<03:10, 33.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.57G/7.89G [00:33<02:49, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.58G/7.89G [00:33<02:44, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.59G/7.89G [00:33<02:33, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.60G/7.89G [00:34<02:24, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  20% 1.61G/7.89G [00:34<02:23, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.63G/7.89G [00:34<02:20, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.64G/7.89G [00:34<02:14, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.65G/7.89G [00:34<02:10, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.66G/7.89G [00:35<02:07, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.67G/7.89G [00:35<02:10, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.68G/7.89G [00:35<02:06, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  21% 1.69G/7.89G [00:35<02:10, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.70G/7.89G [00:36<02:07, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.71G/7.89G [00:36<02:04, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.72G/7.89G [00:36<02:03, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.73G/7.89G [00:36<02:01, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.74G/7.89G [00:36<02:01, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.75G/7.89G [00:37<02:23, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.76G/7.89G [00:37<02:20, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  22% 1.77G/7.89G [00:37<02:13, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.78G/7.89G [00:37<02:09, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.79G/7.89G [00:38<02:05, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.80G/7.89G [00:38<02:03, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.81G/7.89G [00:38<02:01, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.82G/7.89G [00:38<02:00, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.84G/7.89G [00:38<01:59, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  23% 1.85G/7.89G [00:39<01:58, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.86G/7.89G [00:39<01:58, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.87G/7.89G [00:39<01:57, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.88G/7.89G [00:39<01:56, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.89G/7.89G [00:39<01:56, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.90G/7.89G [00:40<01:55, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.91G/7.89G [00:40<01:55, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.92G/7.89G [00:40<01:55, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  24% 1.93G/7.89G [00:40<01:54, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.94G/7.89G [00:40<01:54, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.95G/7.89G [00:41<01:55, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.96G/7.89G [00:41<01:54, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.97G/7.89G [00:41<01:54, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.98G/7.89G [00:41<01:54, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 1.99G/7.89G [00:41<01:54, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  25% 2.00G/7.89G [00:42<02:01, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.01G/7.89G [00:42<02:00, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.02G/7.89G [00:42<01:57, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.03G/7.89G [00:42<01:55, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.04G/7.89G [00:42<01:55, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.06G/7.89G [00:43<01:54, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.07G/7.89G [00:43<01:54, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.08G/7.89G [00:43<01:53, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  26% 2.09G/7.89G [00:43<01:53, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.10G/7.89G [00:43<01:53, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.11G/7.89G [00:44<01:52, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.12G/7.89G [00:44<01:43, 55.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.13G/7.89G [00:44<01:45, 54.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.14G/7.89G [00:44<01:47, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.15G/7.89G [00:44<01:48, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  27% 2.16G/7.89G [00:45<01:50, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.17G/7.89G [00:45<01:50, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.18G/7.89G [00:45<02:21, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.19G/7.89G [00:45<02:13, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.20G/7.89G [00:46<02:40, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.21G/7.89G [00:46<02:43, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.22G/7.89G [00:46<02:27, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.23G/7.89G [00:47<02:16, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  28% 2.24G/7.89G [00:47<02:19, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.25G/7.89G [00:47<02:10, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.26G/7.89G [00:47<02:20, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.28G/7.89G [00:48<02:11, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.29G/7.89G [00:48<02:04, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.30G/7.89G [00:48<01:59, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.31G/7.89G [00:48<01:55, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  29% 2.32G/7.89G [00:48<01:54, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.33G/7.89G [00:49<01:52, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.34G/7.89G [00:49<02:02, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.35G/7.89G [00:49<01:48, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.36G/7.89G [00:49<01:57, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.37G/7.89G [00:50<02:03, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.38G/7.89G [00:50<02:07, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.39G/7.89G [00:50<02:02, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  30% 2.40G/7.89G [00:50<02:06, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.41G/7.89G [00:51<02:10, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.42G/7.89G [00:51<02:17, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.43G/7.89G [00:51<02:14, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.44G/7.89G [00:51<02:06, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.45G/7.89G [00:52<02:08, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.46G/7.89G [00:52<02:01, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.47G/7.89G [00:52<01:58, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  31% 2.49G/7.89G [00:52<02:00, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.50G/7.89G [00:52<01:56, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.51G/7.89G [00:53<01:53, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.52G/7.89G [00:53<01:58, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.53G/7.89G [00:53<01:54, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.54G/7.89G [00:53<01:54, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.55G/7.89G [00:54<02:07, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  32% 2.56G/7.89G [00:54<02:00, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.57G/7.89G [00:54<01:55, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.58G/7.89G [00:54<02:05, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.59G/7.89G [00:55<01:58, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.60G/7.89G [00:55<01:56, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.61G/7.89G [00:55<01:52, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.62G/7.89G [00:55<01:48, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.63G/7.89G [00:55<01:47, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  33% 2.64G/7.89G [00:56<01:46, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.65G/7.89G [00:56<01:45, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.66G/7.89G [00:56<01:43, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.67G/7.89G [00:56<01:42, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.68G/7.89G [00:56<01:42, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.69G/7.89G [00:57<01:41, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.71G/7.89G [00:57<01:42, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  34% 2.72G/7.89G [00:57<01:41, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.73G/7.89G [00:58<02:25, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.74G/7.89G [00:58<02:15, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.75G/7.89G [00:58<02:04, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.76G/7.89G [00:58<02:24, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.77G/7.89G [00:59<02:59, 28.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.78G/7.89G [00:59<02:36, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.79G/7.89G [00:59<02:24, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  35% 2.80G/7.89G [01:00<02:10, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.81G/7.89G [01:00<02:00, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.82G/7.89G [01:00<01:56, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.83G/7.89G [01:00<01:49, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.84G/7.89G [01:00<01:44, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.85G/7.89G [01:01<01:46, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.86G/7.89G [01:01<01:43, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  36% 2.87G/7.89G [01:01<01:45, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.88G/7.89G [01:01<01:58, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.89G/7.89G [01:02<01:46, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.90G/7.89G [01:02<02:06, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.92G/7.89G [01:02<01:57, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.93G/7.89G [01:02<02:09, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.94G/7.89G [01:03<01:58, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.95G/7.89G [01:03<01:51, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  37% 2.96G/7.89G [01:03<01:40, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 2.97G/7.89G [01:03<02:15, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 2.98G/7.89G [01:04<02:03, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 2.99G/7.89G [01:04<01:54, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 3.00G/7.89G [01:04<02:09, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 3.01G/7.89G [01:04<02:06, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 3.02G/7.89G [01:05<01:56, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  38% 3.03G/7.89G [01:05<02:01, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.04G/7.89G [01:05<01:53, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.05G/7.89G [01:05<01:47, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.06G/7.89G [01:06<01:51, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.07G/7.89G [01:06<01:49, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.08G/7.89G [01:06<01:45, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.09G/7.89G [01:06<01:48, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.10G/7.89G [01:07<01:43, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  39% 3.11G/7.89G [01:07<01:40, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.12G/7.89G [01:07<02:12, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.14G/7.89G [01:07<02:00, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.15G/7.89G [01:08<01:48, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.16G/7.89G [01:08<01:43, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.17G/7.89G [01:08<01:40, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.18G/7.89G [01:09<02:38, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  40% 3.19G/7.89G [01:09<02:36, 30.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.20G/7.89G [01:09<02:11, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.21G/7.89G [01:09<02:12, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.22G/7.89G [01:10<02:09, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.23G/7.89G [01:10<01:57, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.24G/7.89G [01:10<01:50, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.25G/7.89G [01:11<02:18, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.26G/7.89G [01:11<01:59, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  41% 3.27G/7.89G [01:11<02:01, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.28G/7.89G [01:11<01:46, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.29G/7.89G [01:11<01:41, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.30G/7.89G [01:12<01:41, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.31G/7.89G [01:12<01:38, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.32G/7.89G [01:12<01:35, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.33G/7.89G [01:12<01:33, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  42% 3.34G/7.89G [01:13<01:42, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.36G/7.89G [01:13<01:36, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.37G/7.89G [01:13<01:27, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.38G/7.89G [01:13<01:27, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.39G/7.89G [01:13<01:27, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.40G/7.89G [01:13<01:20, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.41G/7.89G [01:14<01:23, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.42G/7.89G [01:14<01:36, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  43% 3.43G/7.89G [01:15<02:19, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.44G/7.89G [01:15<01:55, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.45G/7.89G [01:15<01:46, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.46G/7.89G [01:15<01:40, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.47G/7.89G [01:15<01:51, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.49G/7.89G [01:16<01:26, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  44% 3.50G/7.89G [01:16<01:59, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.51G/7.89G [01:17<02:08, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.52G/7.89G [01:17<02:48, 25.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.53G/7.89G [01:18<02:45, 26.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.54G/7.89G [01:18<02:40, 27.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.55G/7.89G [01:18<02:35, 27.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.57G/7.89G [01:19<02:13, 32.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.58G/7.89G [01:19<02:06, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  45% 3.59G/7.89G [01:19<02:07, 33.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.60G/7.89G [01:19<01:53, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.61G/7.89G [01:20<01:46, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.62G/7.89G [01:20<01:39, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.63G/7.89G [01:20<01:34, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.64G/7.89G [01:20<01:33, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.65G/7.89G [01:20<01:36, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  46% 3.66G/7.89G [01:21<01:25, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.67G/7.89G [01:21<01:27, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.68G/7.89G [01:21<01:50, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.69G/7.89G [01:21<01:37, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.70G/7.89G [01:22<01:30, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.71G/7.89G [01:22<01:20, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.72G/7.89G [01:22<01:19, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.73G/7.89G [01:22<01:19, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  47% 3.74G/7.89G [01:22<01:12, 56.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.75G/7.89G [01:23<01:15, 55.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.76G/7.89G [01:23<01:31, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.77G/7.89G [01:23<01:21, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.79G/7.89G [01:24<01:57, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.80G/7.89G [01:24<01:48, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.81G/7.89G [01:24<01:34, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  48% 3.82G/7.89G [01:24<01:32, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.83G/7.89G [01:24<01:28, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.84G/7.89G [01:25<01:24, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.85G/7.89G [01:25<01:22, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.86G/7.89G [01:25<01:27, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.87G/7.89G [01:25<01:24, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.88G/7.89G [01:25<01:26, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.89G/7.89G [01:26<01:27, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  49% 3.90G/7.89G [01:26<01:30, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.91G/7.89G [01:26<01:26, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.92G/7.89G [01:26<01:25, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.93G/7.89G [01:27<01:27, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.94G/7.89G [01:27<01:24, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.95G/7.89G [01:27<01:23, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.96G/7.89G [01:27<01:20, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.97G/7.89G [01:27<01:24, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  50% 3.98G/7.89G [01:28<01:22, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.00G/7.89G [01:28<01:20, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.01G/7.89G [01:28<01:19, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.02G/7.89G [01:28<01:25, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.03G/7.89G [01:29<01:17, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.04G/7.89G [01:29<01:28, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.05G/7.89G [01:29<01:24, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  51% 4.06G/7.89G [01:29<01:21, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.07G/7.89G [01:29<01:18, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.08G/7.89G [01:30<01:13, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.09G/7.89G [01:30<01:13, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.10G/7.89G [01:30<01:11, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.11G/7.89G [01:30<01:11, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.12G/7.89G [01:31<01:38, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.13G/7.89G [01:31<01:30, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  52% 4.14G/7.89G [01:31<01:23, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.15G/7.89G [01:31<01:42, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.16G/7.89G [01:32<01:33, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.17G/7.89G [01:32<01:26, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.18G/7.89G [01:32<01:22, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.19G/7.89G [01:32<01:12, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.20G/7.89G [01:32<01:12, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  53% 4.22G/7.89G [01:33<01:11, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.23G/7.89G [01:33<01:21, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.24G/7.89G [01:33<01:18, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.25G/7.89G [01:34<01:35, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.26G/7.89G [01:34<01:27, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.27G/7.89G [01:34<01:21, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.28G/7.89G [01:34<01:24, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.29G/7.89G [01:34<01:21, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  54% 4.30G/7.89G [01:35<01:46, 33.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.32G/7.89G [01:35<01:08, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.33G/7.89G [01:35<01:03, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.34G/7.89G [01:35<01:04, 54.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.35G/7.89G [01:36<01:06, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.36G/7.89G [01:36<01:01, 57.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  55% 4.37G/7.89G [01:36<01:08, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.38G/7.89G [01:36<01:15, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.39G/7.89G [01:37<01:25, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.40G/7.89G [01:37<01:32, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.41G/7.89G [01:37<01:37, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.42G/7.89G [01:38<01:34, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.44G/7.89G [01:38<01:38, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.45G/7.89G [01:38<01:41, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  56% 4.46G/7.89G [01:38<01:37, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.47G/7.89G [01:39<01:39, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.48G/7.89G [01:39<01:36, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.49G/7.89G [01:39<01:38, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.50G/7.89G [01:40<01:37, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.51G/7.89G [01:40<01:33, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.52G/7.89G [01:40<01:34, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  57% 4.53G/7.89G [01:41<01:34, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.54G/7.89G [01:41<01:31, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.55G/7.89G [01:41<01:32, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.56G/7.89G [01:41<01:30, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.57G/7.89G [01:42<01:30, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.58G/7.89G [01:42<01:28, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.59G/7.89G [01:42<01:29, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.60G/7.89G [01:43<01:28, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  58% 4.61G/7.89G [01:43<01:30, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.62G/7.89G [01:43<01:50, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.63G/7.89G [01:44<01:41, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.65G/7.89G [01:44<01:35, 33.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.66G/7.89G [01:44<01:31, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.67G/7.89G [01:44<01:28, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.68G/7.89G [01:45<01:31, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  59% 4.69G/7.89G [01:45<01:28, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.70G/7.89G [01:45<01:26, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.71G/7.89G [01:46<01:24, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.72G/7.89G [01:46<01:23, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.73G/7.89G [01:46<01:22, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.74G/7.89G [01:46<01:26, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.75G/7.89G [01:47<01:24, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.76G/7.89G [01:47<01:22, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  60% 4.77G/7.89G [01:47<01:21, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.78G/7.89G [01:47<01:20, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.79G/7.89G [01:48<01:20, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.80G/7.89G [01:48<01:23, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.81G/7.89G [01:48<01:22, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.82G/7.89G [01:49<01:21, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.83G/7.89G [01:49<01:19, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  61% 4.84G/7.89G [01:49<01:19, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.85G/7.89G [01:49<01:18, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.87G/7.89G [01:50<01:21, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.88G/7.89G [01:50<01:23, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.89G/7.89G [01:50<01:21, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.90G/7.89G [01:51<01:19, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.91G/7.89G [01:51<01:18, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.92G/7.89G [01:51<01:21, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  62% 4.93G/7.89G [01:51<01:26, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.94G/7.89G [01:52<01:22, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.95G/7.89G [01:52<01:19, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.96G/7.89G [01:52<01:17, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.97G/7.89G [01:53<01:16, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.98G/7.89G [01:53<01:11, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 4.99G/7.89G [01:53<01:11, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  63% 5.00G/7.89G [01:53<01:11, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.01G/7.89G [01:54<01:11, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.02G/7.89G [01:54<01:11, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.03G/7.89G [01:54<01:07, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.04G/7.89G [01:54<01:08, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.05G/7.89G [01:55<01:08, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.06G/7.89G [01:55<01:05, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.08G/7.89G [01:55<01:06, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  64% 5.09G/7.89G [01:55<01:06, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.10G/7.89G [01:55<01:03, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.11G/7.89G [01:56<01:04, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.12G/7.89G [01:56<01:02, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.13G/7.89G [01:56<01:00, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.14G/7.89G [01:56<01:01, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.15G/7.89G [01:57<00:59, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  65% 5.16G/7.89G [01:57<00:57, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.17G/7.89G [01:57<00:58, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.18G/7.89G [01:57<00:58, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.19G/7.89G [01:58<00:59, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.20G/7.89G [01:58<00:57, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.21G/7.89G [01:58<00:55, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.22G/7.89G [01:58<00:54, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.23G/7.89G [01:58<00:57, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  66% 5.24G/7.89G [01:59<00:55, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.25G/7.89G [01:59<00:57, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.26G/7.89G [01:59<00:57, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.27G/7.89G [01:59<00:59, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.28G/7.89G [02:00<01:01, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.30G/7.89G [02:00<01:01, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.31G/7.89G [02:00<00:58, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  67% 5.32G/7.89G [02:00<01:00, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.33G/7.89G [02:01<00:57, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.34G/7.89G [02:01<01:00, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.35G/7.89G [02:01<01:21, 31.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.36G/7.89G [02:02<01:11, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.37G/7.89G [02:02<01:08, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.38G/7.89G [02:02<01:03, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.39G/7.89G [02:02<00:58, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  68% 5.40G/7.89G [02:02<00:55, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.41G/7.89G [02:03<00:55, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.42G/7.89G [02:03<00:54, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.43G/7.89G [02:03<00:52, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.44G/7.89G [02:03<00:50, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.45G/7.89G [02:04<00:49, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.46G/7.89G [02:04<00:49, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  69% 5.47G/7.89G [02:04<00:54, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.48G/7.89G [02:04<00:52, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.49G/7.89G [02:04<00:50, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.51G/7.89G [02:05<00:59, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.52G/7.89G [02:05<00:54, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.53G/7.89G [02:05<00:52, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.54G/7.89G [02:05<00:49, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.55G/7.89G [02:06<00:48, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  70% 5.56G/7.89G [02:06<00:54, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.57G/7.89G [02:06<00:51, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.58G/7.89G [02:06<00:49, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.59G/7.89G [02:07<00:51, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.60G/7.89G [02:07<00:49, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.61G/7.89G [02:07<00:48, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.62G/7.89G [02:07<00:55, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.63G/7.89G [02:08<00:51, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  71% 5.64G/7.89G [02:08<00:56, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.65G/7.89G [02:08<01:06, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.66G/7.89G [02:08<00:55, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.67G/7.89G [02:09<00:52, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.68G/7.89G [02:09<00:49, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.69G/7.89G [02:09<00:47, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.70G/7.89G [02:09<00:45, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  72% 5.71G/7.89G [02:09<00:44, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.73G/7.89G [02:10<00:43, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.74G/7.89G [02:10<00:43, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.75G/7.89G [02:10<00:43, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.76G/7.89G [02:10<00:46, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.77G/7.89G [02:11<00:48, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.78G/7.89G [02:11<00:50, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.79G/7.89G [02:11<00:51, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  73% 5.80G/7.89G [02:11<00:51, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.81G/7.89G [02:12<00:48, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.82G/7.89G [02:12<00:49, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.83G/7.89G [02:12<00:51, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.84G/7.89G [02:12<00:49, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.85G/7.89G [02:13<01:09, 29.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  74% 5.86G/7.89G [02:13<00:54, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.88G/7.89G [02:13<00:42, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.89G/7.89G [02:14<00:44, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.90G/7.89G [02:14<00:45, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.91G/7.89G [02:14<00:45, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.92G/7.89G [02:15<00:53, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.93G/7.89G [02:15<00:48, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.95G/7.89G [02:15<00:48, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  75% 5.96G/7.89G [02:15<00:45, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 5.97G/7.89G [02:16<00:45, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 5.98G/7.89G [02:16<00:43, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 5.99G/7.89G [02:16<00:43, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 6.00G/7.89G [02:16<00:42, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 6.01G/7.89G [02:16<00:40, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 6.02G/7.89G [02:17<00:42, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  76% 6.03G/7.89G [02:17<00:40, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.04G/7.89G [02:17<00:41, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.05G/7.89G [02:18<00:48, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.06G/7.89G [02:18<00:46, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.07G/7.89G [02:18<00:45, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.08G/7.89G [02:18<00:42, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.09G/7.89G [02:18<00:42, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.10G/7.89G [02:19<00:40, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  77% 6.11G/7.89G [02:19<00:38, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.12G/7.89G [02:19<00:39, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.13G/7.89G [02:19<00:38, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.14G/7.89G [02:20<00:39, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.16G/7.89G [02:20<00:37, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.17G/7.89G [02:20<00:45, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.18G/7.89G [02:21<00:49, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  78% 6.19G/7.89G [02:21<00:44, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.20G/7.89G [02:21<00:40, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.21G/7.89G [02:21<00:40, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.22G/7.89G [02:21<00:39, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.23G/7.89G [02:22<00:38, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.24G/7.89G [02:22<00:37, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.25G/7.89G [02:22<00:35, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.26G/7.89G [02:22<00:35, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  79% 6.27G/7.89G [02:23<00:44, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.28G/7.89G [02:23<00:38, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.29G/7.89G [02:23<00:40, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.30G/7.89G [02:24<00:40, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.31G/7.89G [02:24<00:42, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.32G/7.89G [02:24<00:42, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.33G/7.89G [02:24<00:42, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  80% 6.34G/7.89G [02:25<00:42, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.35G/7.89G [02:25<00:42, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.36G/7.89G [02:25<00:43, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.38G/7.89G [02:26<00:41, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.39G/7.89G [02:26<00:37, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.40G/7.89G [02:26<00:37, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.41G/7.89G [02:26<00:37, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.42G/7.89G [02:27<00:37, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  81% 6.43G/7.89G [02:27<00:36, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.44G/7.89G [02:27<00:34, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.45G/7.89G [02:27<00:37, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.46G/7.89G [02:28<00:34, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.47G/7.89G [02:28<00:34, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.48G/7.89G [02:28<00:34, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.49G/7.89G [02:28<00:33, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  82% 6.50G/7.89G [02:29<00:36, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.51G/7.89G [02:29<00:35, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.52G/7.89G [02:29<00:36, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.53G/7.89G [02:29<00:33, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.54G/7.89G [02:30<00:33, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.55G/7.89G [02:30<00:33, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.56G/7.89G [02:30<00:34, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.57G/7.89G [02:31<00:35, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  83% 6.59G/7.89G [02:31<00:36, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.60G/7.89G [02:31<00:37, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.61G/7.89G [02:32<00:36, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.62G/7.89G [02:32<00:36, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.63G/7.89G [02:32<00:35, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.64G/7.89G [02:32<00:35, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.65G/7.89G [02:33<00:34, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  84% 6.66G/7.89G [02:33<00:33, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.67G/7.89G [02:33<00:32, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.68G/7.89G [02:34<00:33, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.69G/7.89G [02:34<00:32, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.70G/7.89G [02:34<00:31, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.71G/7.89G [02:34<00:31, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.72G/7.89G [02:35<00:30, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.73G/7.89G [02:35<00:30, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  85% 6.74G/7.89G [02:35<00:30, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.75G/7.89G [02:35<00:30, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.76G/7.89G [02:36<00:29, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.77G/7.89G [02:36<00:28, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.78G/7.89G [02:36<00:28, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.79G/7.89G [02:37<00:28, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.81G/7.89G [02:37<00:27, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  86% 6.82G/7.89G [02:37<00:27, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.83G/7.89G [02:37<00:27, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.84G/7.89G [02:38<00:26, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.85G/7.89G [02:38<00:26, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.86G/7.89G [02:38<00:26, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.87G/7.89G [02:38<00:26, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.88G/7.89G [02:39<00:30, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  87% 6.90G/7.89G [02:39<00:24, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.91G/7.89G [02:39<00:24, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.92G/7.89G [02:40<00:24, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.93G/7.89G [02:40<00:24, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.94G/7.89G [02:40<00:24, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.95G/7.89G [02:41<00:23, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.96G/7.89G [02:41<00:23, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  88% 6.97G/7.89G [02:41<00:23, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 6.98G/7.89G [02:41<00:23, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 6.99G/7.89G [02:42<00:22, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.00G/7.89G [02:42<00:22, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.01G/7.89G [02:42<00:22, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.03G/7.89G [02:42<00:21, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.04G/7.89G [02:43<00:21, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.05G/7.89G [02:43<00:21, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  89% 7.06G/7.89G [02:43<00:21, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.07G/7.89G [02:43<00:20, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.08G/7.89G [02:44<00:20, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.09G/7.89G [02:44<00:19, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.10G/7.89G [02:44<00:19, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.11G/7.89G [02:45<00:19, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.12G/7.89G [02:45<00:19, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  90% 7.13G/7.89G [02:45<00:18, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.14G/7.89G [02:45<00:18, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.15G/7.89G [02:46<00:18, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.16G/7.89G [02:46<00:18, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.17G/7.89G [02:46<00:18, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.18G/7.89G [02:46<00:17, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.19G/7.89G [02:47<00:16, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.20G/7.89G [02:47<00:16, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  91% 7.21G/7.89G [02:47<00:16, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.22G/7.89G [02:47<00:15, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.24G/7.89G [02:48<00:15, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.25G/7.89G [02:48<00:15, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.26G/7.89G [02:48<00:14, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.27G/7.89G [02:48<00:15, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.28G/7.89G [02:49<00:16, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.29G/7.89G [02:49<00:16, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  92% 7.30G/7.89G [02:49<00:16, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.31G/7.89G [02:50<00:16, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.32G/7.89G [02:50<00:16, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.33G/7.89G [02:50<00:15, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.34G/7.89G [02:50<00:14, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.35G/7.89G [02:51<00:14, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.36G/7.89G [02:51<00:14, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  93% 7.37G/7.89G [02:51<00:13, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.38G/7.89G [02:52<00:13, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.39G/7.89G [02:52<00:12, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.40G/7.89G [02:52<00:12, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.41G/7.89G [02:52<00:12, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.42G/7.89G [02:53<00:11, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.43G/7.89G [02:53<00:11, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.44G/7.89G [02:53<00:10, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  94% 7.46G/7.89G [02:53<00:10, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.47G/7.89G [02:54<00:10, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.48G/7.89G [02:54<00:10, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.49G/7.89G [02:54<00:10, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.50G/7.89G [02:54<00:09, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.51G/7.89G [02:55<00:09, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.52G/7.89G [02:55<00:08, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  95% 7.53G/7.89G [02:55<00:08, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.54G/7.89G [02:55<00:08, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.55G/7.89G [02:56<00:07, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.56G/7.89G [02:56<00:07, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.57G/7.89G [02:56<00:07, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.58G/7.89G [02:56<00:07, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.59G/7.89G [02:57<00:09, 30.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.60G/7.89G [02:57<00:09, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  96% 7.61G/7.89G [02:57<00:08, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.62G/7.89G [02:58<00:07, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.63G/7.89G [02:58<00:06, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.64G/7.89G [02:58<00:05, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.65G/7.89G [02:58<00:05, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.67G/7.89G [02:59<00:05, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.68G/7.89G [02:59<00:04, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  97% 7.69G/7.89G [02:59<00:04, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.70G/7.89G [02:59<00:04, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.71G/7.89G [03:00<00:04, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.72G/7.89G [03:00<00:03, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.73G/7.89G [03:00<00:03, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.74G/7.89G [03:00<00:03, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.75G/7.89G [03:01<00:03, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.76G/7.89G [03:01<00:02, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  98% 7.77G/7.89G [03:01<00:02, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.78G/7.89G [03:01<00:02, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.79G/7.89G [03:01<00:02, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.80G/7.89G [03:02<00:01, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.81G/7.89G [03:02<00:01, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.82G/7.89G [03:02<00:01, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.83G/7.89G [03:02<00:01, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin:  99% 7.84G/7.89G [03:03<00:01, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin: 100% 7.85G/7.89G [03:03<00:00, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin: 100% 7.86G/7.89G [03:03<00:00, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin: 100% 7.87G/7.89G [03:03<00:00, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin: 100% 7.89G/7.89G [03:04<00:00, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00005.bin: 100% 7.89G/7.89G [03:04<00:00, 42.8MB/s]\n",
      "Downloading shards:  40% 2/5 [06:11<09:17, 185.76s/it]\n",
      "pytorch_model-00003-of-00005.bin:   0% 0.00/7.89G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   0% 10.5M/7.89G [00:00<10:23, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   0% 31.5M/7.89G [00:01<03:48, 34.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 41.9M/7.89G [00:01<03:28, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 52.4M/7.89G [00:01<03:37, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 62.9M/7.89G [00:01<03:11, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 73.4M/7.89G [00:02<03:00, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 83.9M/7.89G [00:02<03:08, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 94.4M/7.89G [00:02<02:54, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 105M/7.89G [00:02<02:53, 44.8MB/s] \u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   1% 115M/7.89G [00:02<02:52, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 126M/7.89G [00:03<02:37, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 136M/7.89G [00:03<02:39, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 147M/7.89G [00:03<02:49, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 157M/7.89G [00:03<02:38, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 168M/7.89G [00:04<03:20, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 178M/7.89G [00:04<03:36, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   2% 189M/7.89G [00:04<03:21, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 199M/7.89G [00:05<04:55, 26.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 210M/7.89G [00:05<04:16, 30.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 220M/7.89G [00:05<03:49, 33.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 231M/7.89G [00:06<03:15, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 241M/7.89G [00:06<03:06, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 252M/7.89G [00:06<02:45, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 262M/7.89G [00:06<03:00, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   3% 273M/7.89G [00:07<03:16, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 283M/7.89G [00:07<03:05, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 294M/7.89G [00:07<03:37, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 304M/7.89G [00:07<03:21, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 315M/7.89G [00:08<02:57, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 325M/7.89G [00:08<02:53, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 336M/7.89G [00:08<02:36, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   4% 346M/7.89G [00:08<02:37, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 357M/7.89G [00:08<02:40, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 367M/7.89G [00:09<02:42, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 377M/7.89G [00:09<02:43, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 388M/7.89G [00:09<02:44, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 398M/7.89G [00:09<02:44, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 409M/7.89G [00:10<02:31, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 419M/7.89G [00:10<02:32, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   5% 430M/7.89G [00:10<02:23, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 440M/7.89G [00:10<02:27, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 451M/7.89G [00:10<02:31, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 461M/7.89G [00:11<02:20, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 472M/7.89G [00:11<02:26, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 482M/7.89G [00:11<02:17, 53.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 493M/7.89G [00:11<02:24, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   6% 503M/7.89G [00:11<02:30, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 514M/7.89G [00:12<02:38, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 524M/7.89G [00:12<02:39, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 535M/7.89G [00:12<02:28, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 545M/7.89G [00:12<02:29, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 556M/7.89G [00:12<02:19, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 566M/7.89G [00:13<02:25, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 577M/7.89G [00:13<02:27, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   7% 587M/7.89G [00:13<02:19, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 598M/7.89G [00:13<02:21, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 608M/7.89G [00:14<02:27, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 619M/7.89G [00:14<02:19, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 629M/7.89G [00:14<02:22, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 640M/7.89G [00:14<02:15, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 650M/7.89G [00:14<02:21, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   8% 661M/7.89G [00:15<02:26, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 671M/7.89G [00:15<02:16, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 682M/7.89G [00:15<02:22, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 692M/7.89G [00:15<02:33, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 703M/7.89G [00:15<02:21, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 713M/7.89G [00:16<02:25, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 724M/7.89G [00:16<02:32, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 734M/7.89G [00:16<02:33, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:   9% 744M/7.89G [00:16<02:40, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 755M/7.89G [00:17<03:08, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 765M/7.89G [00:17<02:57, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 776M/7.89G [00:17<02:51, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 786M/7.89G [00:18<03:14, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 797M/7.89G [00:18<03:02, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 807M/7.89G [00:18<03:01, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  10% 818M/7.89G [00:18<03:40, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 828M/7.89G [00:19<03:32, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 839M/7.89G [00:19<03:46, 31.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 849M/7.89G [00:19<03:25, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 860M/7.89G [00:20<03:21, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 870M/7.89G [00:20<03:08, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 881M/7.89G [00:20<02:58, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 891M/7.89G [00:20<03:00, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  11% 902M/7.89G [00:21<02:52, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 912M/7.89G [00:21<02:46, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 923M/7.89G [00:21<02:43, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 933M/7.89G [00:21<02:41, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 944M/7.89G [00:22<02:37, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 954M/7.89G [00:22<03:03, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 965M/7.89G [00:22<02:55, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 975M/7.89G [00:22<02:48, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  12% 986M/7.89G [00:23<02:43, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 996M/7.89G [00:23<02:39, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.01G/7.89G [00:23<02:36, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.02G/7.89G [00:23<02:34, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.03G/7.89G [00:24<02:33, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.04G/7.89G [00:24<02:31, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.05G/7.89G [00:24<02:31, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  13% 1.06G/7.89G [00:24<02:41, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.07G/7.89G [00:25<02:37, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.08G/7.89G [00:25<02:50, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.09G/7.89G [00:25<02:45, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.10G/7.89G [00:25<02:39, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.11G/7.89G [00:26<02:34, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.12G/7.89G [00:26<02:35, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.13G/7.89G [00:26<02:32, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  14% 1.14G/7.89G [00:26<02:31, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.15G/7.89G [00:26<02:29, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.16G/7.89G [00:27<02:42, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.17G/7.89G [00:27<02:50, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.18G/7.89G [00:27<02:56, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.20G/7.89G [00:28<03:00, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.21G/7.89G [00:28<03:02, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  15% 1.22G/7.89G [00:28<03:04, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.23G/7.89G [00:29<02:53, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.24G/7.89G [00:29<02:57, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.25G/7.89G [00:29<03:00, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.26G/7.89G [00:29<03:06, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.27G/7.89G [00:30<03:28, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.28G/7.89G [00:30<03:22, 32.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.29G/7.89G [00:30<03:05, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  16% 1.30G/7.89G [00:31<03:04, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.31G/7.89G [00:31<03:03, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.32G/7.89G [00:31<02:52, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.33G/7.89G [00:31<02:55, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.34G/7.89G [00:32<02:46, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.35G/7.89G [00:32<02:49, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.36G/7.89G [00:32<02:43, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  17% 1.37G/7.89G [00:33<02:47, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.38G/7.89G [00:33<02:42, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.39G/7.89G [00:33<02:48, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.41G/7.89G [00:33<02:40, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.42G/7.89G [00:34<02:45, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.43G/7.89G [00:34<02:39, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.44G/7.89G [00:34<02:40, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.45G/7.89G [00:34<02:48, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  18% 1.46G/7.89G [00:35<02:40, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.47G/7.89G [00:35<02:45, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.48G/7.89G [00:35<02:37, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.49G/7.89G [00:35<02:47, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.50G/7.89G [00:36<02:40, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.51G/7.89G [00:36<02:44, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.52G/7.89G [00:36<02:37, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  19% 1.53G/7.89G [00:37<02:41, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.54G/7.89G [00:37<02:36, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.55G/7.89G [00:37<02:31, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.56G/7.89G [00:37<02:39, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.57G/7.89G [00:38<02:32, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.58G/7.89G [00:38<02:39, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.59G/7.89G [00:38<02:34, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.60G/7.89G [00:38<02:38, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  20% 1.61G/7.89G [00:39<02:34, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.63G/7.89G [00:39<02:35, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.64G/7.89G [00:39<02:36, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.65G/7.89G [00:39<02:33, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.66G/7.89G [00:40<02:36, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.67G/7.89G [00:40<02:30, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.68G/7.89G [00:40<02:37, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  21% 1.69G/7.89G [00:40<02:31, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.70G/7.89G [00:41<02:31, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.71G/7.89G [00:41<02:32, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.72G/7.89G [00:41<02:32, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.73G/7.89G [00:42<02:47, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.74G/7.89G [00:42<02:28, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.75G/7.89G [00:42<02:24, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.76G/7.89G [00:42<02:28, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  22% 1.77G/7.89G [00:42<02:26, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.78G/7.89G [00:43<02:24, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.79G/7.89G [00:43<02:25, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.80G/7.89G [00:43<02:26, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.81G/7.89G [00:43<02:23, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.82G/7.89G [00:44<02:24, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.84G/7.89G [00:44<02:23, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  23% 1.85G/7.89G [00:44<02:54, 34.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.86G/7.89G [00:45<02:41, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.87G/7.89G [00:45<02:33, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.88G/7.89G [00:45<02:26, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.89G/7.89G [00:45<02:22, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.90G/7.89G [00:46<02:24, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.91G/7.89G [00:46<02:22, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.92G/7.89G [00:46<02:18, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  24% 1.93G/7.89G [00:46<02:16, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.94G/7.89G [00:46<02:14, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.95G/7.89G [00:47<02:12, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.96G/7.89G [00:47<02:11, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.97G/7.89G [00:47<02:10, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.98G/7.89G [00:47<02:10, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 1.99G/7.89G [00:48<02:09, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  25% 2.00G/7.89G [00:48<02:09, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.01G/7.89G [00:48<02:01, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.02G/7.89G [00:48<02:01, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.03G/7.89G [00:48<02:02, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.04G/7.89G [00:49<02:02, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.06G/7.89G [00:49<01:52, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.07G/7.89G [00:49<01:57, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.08G/7.89G [00:49<02:15, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  26% 2.09G/7.89G [00:50<02:11, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.10G/7.89G [00:50<02:08, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.11G/7.89G [00:50<01:57, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.12G/7.89G [00:50<01:58, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.13G/7.89G [00:50<01:59, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.14G/7.89G [00:51<02:05, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.15G/7.89G [00:51<02:51, 33.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  27% 2.16G/7.89G [00:52<03:22, 28.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.17G/7.89G [00:52<03:13, 29.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.18G/7.89G [00:53<03:35, 26.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.19G/7.89G [00:53<02:57, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.20G/7.89G [00:53<02:40, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.21G/7.89G [00:53<02:29, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.22G/7.89G [00:53<02:14, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.23G/7.89G [00:54<02:07, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  28% 2.24G/7.89G [00:54<02:05, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.25G/7.89G [00:54<01:54, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.26G/7.89G [00:54<02:04, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.28G/7.89G [00:54<02:03, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.29G/7.89G [00:55<01:56, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.30G/7.89G [00:55<01:59, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.31G/7.89G [00:55<02:02, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  29% 2.32G/7.89G [00:55<02:01, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.33G/7.89G [00:56<02:42, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.34G/7.89G [00:56<02:35, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.35G/7.89G [00:56<02:24, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.36G/7.89G [00:57<02:09, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.37G/7.89G [00:57<02:03, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.38G/7.89G [00:57<02:02, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.39G/7.89G [00:57<02:25, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  30% 2.40G/7.89G [00:58<02:34, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.41G/7.89G [00:58<02:13, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.42G/7.89G [00:58<02:50, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.43G/7.89G [00:59<02:32, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.44G/7.89G [00:59<02:31, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.45G/7.89G [00:59<02:37, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.46G/7.89G [00:59<02:25, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  31% 2.47G/7.89G [01:00<02:06, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.49G/7.89G [01:00<02:25, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.50G/7.89G [01:00<02:17, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.51G/7.89G [01:00<02:22, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.52G/7.89G [01:01<02:47, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.53G/7.89G [01:01<02:21, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.54G/7.89G [01:01<02:19, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.55G/7.89G [01:02<02:13, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  32% 2.56G/7.89G [01:02<01:56, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.57G/7.89G [01:02<01:56, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.58G/7.89G [01:02<01:55, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.59G/7.89G [01:02<01:45, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.60G/7.89G [01:03<01:56, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.61G/7.89G [01:03<02:22, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.62G/7.89G [01:03<02:14, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  33% 2.63G/7.89G [01:04<02:41, 32.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.64G/7.89G [01:04<02:21, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.65G/7.89G [01:04<02:12, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.66G/7.89G [01:04<02:16, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.67G/7.89G [01:05<02:09, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.68G/7.89G [01:05<02:04, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.69G/7.89G [01:05<02:22, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.71G/7.89G [01:05<02:13, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  34% 2.72G/7.89G [01:06<02:06, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.73G/7.89G [01:06<01:52, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.74G/7.89G [01:06<01:52, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.75G/7.89G [01:06<01:42, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.76G/7.89G [01:07<02:15, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.77G/7.89G [01:08<03:54, 21.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.78G/7.89G [01:08<03:11, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  35% 2.79G/7.89G [01:08<02:44, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.80G/7.89G [01:08<02:27, 34.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.81G/7.89G [01:08<02:09, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.82G/7.89G [01:09<02:03, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.83G/7.89G [01:09<01:49, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.84G/7.89G [01:09<01:49, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.85G/7.89G [01:09<01:49, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.86G/7.89G [01:09<01:39, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  36% 2.87G/7.89G [01:10<01:42, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.88G/7.89G [01:10<01:35, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.89G/7.89G [01:10<01:39, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.90G/7.89G [01:10<01:41, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.92G/7.89G [01:10<01:33, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.93G/7.89G [01:11<01:37, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.94G/7.89G [01:11<01:40, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.95G/7.89G [01:12<02:49, 29.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  37% 2.96G/7.89G [01:12<02:30, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 2.97G/7.89G [01:12<02:16, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 2.98G/7.89G [01:12<01:58, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 2.99G/7.89G [01:12<01:54, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 3.00G/7.89G [01:13<01:51, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 3.01G/7.89G [01:13<01:43, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 3.02G/7.89G [01:13<01:41, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  38% 3.03G/7.89G [01:13<01:42, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.04G/7.89G [01:14<01:48, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.05G/7.89G [01:14<01:39, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.06G/7.89G [01:14<01:48, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.07G/7.89G [01:14<01:46, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.08G/7.89G [01:14<01:37, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.09G/7.89G [01:15<01:39, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.10G/7.89G [01:15<01:40, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  39% 3.11G/7.89G [01:15<01:32, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.12G/7.89G [01:15<01:50, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.14G/7.89G [01:16<01:41, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.15G/7.89G [01:16<01:54, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.16G/7.89G [01:16<01:51, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.17G/7.89G [01:16<01:41, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.18G/7.89G [01:16<01:39, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  40% 3.19G/7.89G [01:17<01:37, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.20G/7.89G [01:17<01:39, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.21G/7.89G [01:17<01:39, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.22G/7.89G [01:18<02:15, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.23G/7.89G [01:18<02:05, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.24G/7.89G [01:18<01:57, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.25G/7.89G [01:18<01:48, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.26G/7.89G [01:19<01:46, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  41% 3.27G/7.89G [01:19<01:57, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.28G/7.89G [01:19<01:48, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.29G/7.89G [01:19<01:46, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.30G/7.89G [01:19<01:36, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.31G/7.89G [01:20<01:36, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.32G/7.89G [01:20<01:37, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.33G/7.89G [01:20<01:31, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  42% 3.34G/7.89G [01:20<01:31, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.36G/7.89G [01:20<01:25, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.37G/7.89G [01:21<01:29, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.38G/7.89G [01:21<01:47, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.39G/7.89G [01:21<01:36, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.40G/7.89G [01:21<01:41, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.41G/7.89G [01:22<01:31, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.42G/7.89G [01:22<01:42, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  43% 3.43G/7.89G [01:22<01:54, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.44G/7.89G [01:23<01:49, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.45G/7.89G [01:23<01:36, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.46G/7.89G [01:23<01:42, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.47G/7.89G [01:23<01:40, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.48G/7.89G [01:24<01:59, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.49G/7.89G [01:24<01:55, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  44% 3.50G/7.89G [01:24<01:42, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.51G/7.89G [01:24<01:39, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.52G/7.89G [01:24<01:38, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.53G/7.89G [01:25<01:30, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.54G/7.89G [01:25<01:29, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.55G/7.89G [01:25<01:23, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.57G/7.89G [01:25<01:25, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.58G/7.89G [01:25<01:27, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  45% 3.59G/7.89G [01:26<01:21, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.60G/7.89G [01:26<01:24, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.61G/7.89G [01:26<01:27, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.62G/7.89G [01:26<01:24, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.63G/7.89G [01:27<01:26, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.64G/7.89G [01:27<01:47, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.65G/7.89G [01:27<01:45, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  46% 3.66G/7.89G [01:27<01:33, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.67G/7.89G [01:28<01:34, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.68G/7.89G [01:28<01:41, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.69G/7.89G [01:28<01:39, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.70G/7.89G [01:28<01:36, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.71G/7.89G [01:29<01:42, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.72G/7.89G [01:29<01:39, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.73G/7.89G [01:29<01:37, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  47% 3.74G/7.89G [01:29<01:40, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.75G/7.89G [01:30<01:40, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.76G/7.89G [01:30<01:51, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.77G/7.89G [01:30<01:44, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.79G/7.89G [01:30<01:39, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.80G/7.89G [01:31<01:36, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.81G/7.89G [01:31<01:34, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  48% 3.82G/7.89G [01:31<01:32, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.83G/7.89G [01:31<01:28, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.84G/7.89G [01:32<01:30, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.85G/7.89G [01:32<01:22, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.86G/7.89G [01:32<01:25, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.87G/7.89G [01:32<01:25, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.88G/7.89G [01:32<01:25, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.89G/7.89G [01:33<01:23, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  49% 3.90G/7.89G [01:33<01:19, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.91G/7.89G [01:33<01:21, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.92G/7.89G [01:33<01:22, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.93G/7.89G [01:33<01:19, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.94G/7.89G [01:34<01:20, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.95G/7.89G [01:34<01:21, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.96G/7.89G [01:34<01:22, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  50% 3.97G/7.89G [01:34<01:16, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 3.98G/7.89G [01:35<01:18, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.00G/7.89G [01:35<01:19, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.01G/7.89G [01:35<01:21, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.02G/7.89G [01:35<01:22, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.03G/7.89G [01:35<01:15, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.04G/7.89G [01:36<01:18, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.05G/7.89G [01:36<01:19, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  51% 4.06G/7.89G [01:36<01:14, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.07G/7.89G [01:36<01:15, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.08G/7.89G [01:36<01:17, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.09G/7.89G [01:37<01:12, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.10G/7.89G [01:37<01:19, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.11G/7.89G [01:37<01:15, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.12G/7.89G [01:37<01:17, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  52% 4.13G/7.89G [01:37<01:12, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.14G/7.89G [01:38<01:13, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.15G/7.89G [01:38<01:15, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.16G/7.89G [01:38<01:10, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.17G/7.89G [01:38<01:13, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.18G/7.89G [01:38<01:08, 54.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.19G/7.89G [01:39<01:18, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.20G/7.89G [01:39<01:19, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  53% 4.22G/7.89G [01:39<01:20, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.23G/7.89G [01:40<01:26, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.24G/7.89G [01:40<01:24, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.25G/7.89G [01:40<01:18, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.26G/7.89G [01:40<01:42, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.27G/7.89G [01:41<01:35, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.28G/7.89G [01:41<01:25, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  54% 4.29G/7.89G [01:41<01:23, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.30G/7.89G [01:41<01:14, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.31G/7.89G [01:41<01:15, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.32G/7.89G [01:42<01:27, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.33G/7.89G [01:42<01:17, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.34G/7.89G [01:42<01:18, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.35G/7.89G [01:42<01:17, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.36G/7.89G [01:43<01:10, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  55% 4.37G/7.89G [01:43<01:12, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.38G/7.89G [01:43<01:20, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.39G/7.89G [01:43<01:19, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.40G/7.89G [01:44<01:24, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.41G/7.89G [01:44<01:51, 31.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.42G/7.89G [01:45<01:58, 29.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.44G/7.89G [01:45<01:51, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  56% 4.45G/7.89G [01:45<01:41, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.46G/7.89G [01:45<01:33, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.47G/7.89G [01:46<01:32, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.48G/7.89G [01:46<01:28, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.49G/7.89G [01:46<01:24, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.50G/7.89G [01:46<01:20, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.51G/7.89G [01:47<01:32, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.52G/7.89G [01:47<01:15, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  57% 4.53G/7.89G [01:47<01:16, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.54G/7.89G [01:47<01:17, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.55G/7.89G [01:48<01:16, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.56G/7.89G [01:48<01:18, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.57G/7.89G [01:48<01:16, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.58G/7.89G [01:48<01:15, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.59G/7.89G [01:48<01:14, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  58% 4.60G/7.89G [01:49<01:13, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.61G/7.89G [01:49<01:12, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.62G/7.89G [01:49<01:12, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.63G/7.89G [01:49<01:11, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.65G/7.89G [01:50<01:15, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.66G/7.89G [01:50<01:26, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.67G/7.89G [01:50<01:21, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.68G/7.89G [01:51<01:25, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  59% 4.69G/7.89G [01:51<01:20, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.70G/7.89G [01:51<01:17, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.71G/7.89G [01:51<01:14, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.72G/7.89G [01:52<01:12, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.73G/7.89G [01:52<01:11, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.74G/7.89G [01:52<01:10, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.75G/7.89G [01:52<01:06, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.76G/7.89G [01:52<01:06, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  60% 4.77G/7.89G [01:53<01:06, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.78G/7.89G [01:53<01:05, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.79G/7.89G [01:53<01:06, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.80G/7.89G [01:53<01:06, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.81G/7.89G [01:54<01:06, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.82G/7.89G [01:54<01:06, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.83G/7.89G [01:54<01:06, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  61% 4.84G/7.89G [01:54<01:06, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.85G/7.89G [01:54<01:06, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.87G/7.89G [01:55<01:05, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.88G/7.89G [01:55<01:05, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.89G/7.89G [01:55<01:05, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.90G/7.89G [01:55<01:05, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.91G/7.89G [01:56<01:01, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.92G/7.89G [01:56<01:01, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  62% 4.93G/7.89G [01:56<01:43, 28.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.94G/7.89G [01:57<01:35, 30.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.95G/7.89G [01:57<01:22, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.96G/7.89G [01:57<01:16, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.97G/7.89G [01:57<01:12, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.98G/7.89G [01:58<01:09, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 4.99G/7.89G [01:58<01:06, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  63% 5.00G/7.89G [01:58<01:05, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.01G/7.89G [01:58<01:04, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.02G/7.89G [01:59<01:03, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.03G/7.89G [01:59<01:03, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.04G/7.89G [01:59<01:02, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.05G/7.89G [01:59<01:02, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.06G/7.89G [01:59<01:02, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.08G/7.89G [02:00<01:02, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  64% 5.09G/7.89G [02:00<01:01, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.10G/7.89G [02:00<00:55, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.11G/7.89G [02:00<00:57, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.12G/7.89G [02:01<00:58, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.13G/7.89G [02:01<00:58, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.14G/7.89G [02:01<01:00, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.15G/7.89G [02:01<00:59, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  65% 5.16G/7.89G [02:01<00:59, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.17G/7.89G [02:02<00:58, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.18G/7.89G [02:02<00:54, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.19G/7.89G [02:02<00:55, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.20G/7.89G [02:02<00:56, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.21G/7.89G [02:03<01:02, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.22G/7.89G [02:03<01:11, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.23G/7.89G [02:03<01:07, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  66% 5.24G/7.89G [02:04<01:09, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.25G/7.89G [02:04<01:05, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.26G/7.89G [02:04<01:08, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.27G/7.89G [02:04<01:05, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.28G/7.89G [02:05<01:24, 30.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.30G/7.89G [02:05<01:15, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.31G/7.89G [02:05<01:14, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  67% 5.32G/7.89G [02:06<01:09, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.33G/7.89G [02:06<01:04, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.34G/7.89G [02:06<01:02, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.35G/7.89G [02:06<01:02, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.36G/7.89G [02:07<01:00, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.37G/7.89G [02:07<01:00, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.38G/7.89G [02:07<00:58, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.39G/7.89G [02:07<00:57, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  68% 5.40G/7.89G [02:07<00:56, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.41G/7.89G [02:08<00:55, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.42G/7.89G [02:08<00:56, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.43G/7.89G [02:08<00:49, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.44G/7.89G [02:08<00:51, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.45G/7.89G [02:09<00:50, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.46G/7.89G [02:09<00:51, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  69% 5.47G/7.89G [02:09<00:51, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.48G/7.89G [02:09<00:51, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.49G/7.89G [02:09<00:51, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.51G/7.89G [02:10<00:49, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.52G/7.89G [02:10<00:47, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.53G/7.89G [02:10<00:48, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.54G/7.89G [02:10<00:49, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.55G/7.89G [02:11<00:49, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  70% 5.56G/7.89G [02:11<00:50, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.57G/7.89G [02:11<00:49, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.58G/7.89G [02:11<00:46, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.59G/7.89G [02:11<00:46, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.60G/7.89G [02:12<00:47, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.61G/7.89G [02:12<00:47, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.62G/7.89G [02:12<00:48, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  71% 5.63G/7.89G [02:12<00:48, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.64G/7.89G [02:13<00:53, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.65G/7.89G [02:13<00:56, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.66G/7.89G [02:13<00:57, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.67G/7.89G [02:13<00:55, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.68G/7.89G [02:14<00:56, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.69G/7.89G [02:14<01:02, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.70G/7.89G [02:15<01:12, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  72% 5.71G/7.89G [02:15<01:04, 33.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.73G/7.89G [02:15<01:03, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.74G/7.89G [02:15<00:58, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.75G/7.89G [02:16<00:58, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.76G/7.89G [02:16<00:55, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.77G/7.89G [02:16<00:55, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.78G/7.89G [02:16<00:53, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  73% 5.79G/7.89G [02:17<00:54, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.80G/7.89G [02:17<00:51, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.81G/7.89G [02:17<00:49, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.82G/7.89G [02:17<00:51, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.83G/7.89G [02:18<00:49, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.84G/7.89G [02:18<00:51, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.85G/7.89G [02:18<00:49, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.86G/7.89G [02:18<00:47, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  74% 5.87G/7.89G [02:19<00:48, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.88G/7.89G [02:19<00:48, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.89G/7.89G [02:19<00:46, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.90G/7.89G [02:19<00:47, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.91G/7.89G [02:20<00:47, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.92G/7.89G [02:20<00:48, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.93G/7.89G [02:20<00:49, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  75% 5.95G/7.89G [02:20<00:46, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 5.96G/7.89G [02:21<00:46, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 5.97G/7.89G [02:21<00:47, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 5.98G/7.89G [02:21<00:45, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 5.99G/7.89G [02:21<00:44, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 6.00G/7.89G [02:22<00:43, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 6.01G/7.89G [02:22<00:45, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 6.02G/7.89G [02:22<00:44, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  76% 6.03G/7.89G [02:22<00:46, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.04G/7.89G [02:23<00:44, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.05G/7.89G [02:23<00:43, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.06G/7.89G [02:23<00:44, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.07G/7.89G [02:24<00:55, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.08G/7.89G [02:24<00:50, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.09G/7.89G [02:24<00:47, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  77% 6.10G/7.89G [02:24<00:46, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.11G/7.89G [02:25<00:45, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.12G/7.89G [02:25<00:43, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.13G/7.89G [02:25<00:42, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.14G/7.89G [02:25<00:45, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.16G/7.89G [02:26<00:43, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.17G/7.89G [02:26<00:41, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.18G/7.89G [02:26<00:40, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  78% 6.19G/7.89G [02:26<00:41, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.20G/7.89G [02:27<00:40, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.21G/7.89G [02:27<00:39, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.22G/7.89G [02:27<00:38, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.23G/7.89G [02:28<00:50, 33.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.24G/7.89G [02:28<00:53, 31.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  79% 6.26G/7.89G [02:28<00:39, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.27G/7.89G [02:29<00:37, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.28G/7.89G [02:29<00:38, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.29G/7.89G [02:29<00:37, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.30G/7.89G [02:29<00:36, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.31G/7.89G [02:30<00:39, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.32G/7.89G [02:30<00:37, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.33G/7.89G [02:30<00:35, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  80% 6.34G/7.89G [02:30<00:35, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.35G/7.89G [02:31<00:43, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.36G/7.89G [02:31<00:40, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.38G/7.89G [02:31<00:42, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.39G/7.89G [02:31<00:39, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.40G/7.89G [02:32<00:37, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.41G/7.89G [02:32<00:35, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  81% 6.42G/7.89G [02:32<00:34, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.43G/7.89G [02:32<00:36, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.44G/7.89G [02:33<00:37, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.45G/7.89G [02:33<00:41, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.46G/7.89G [02:34<00:44, 32.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.47G/7.89G [02:34<00:48, 29.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.48G/7.89G [02:34<00:48, 28.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.49G/7.89G [02:35<00:48, 28.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  82% 6.50G/7.89G [02:35<00:48, 28.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.51G/7.89G [02:35<00:48, 28.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.52G/7.89G [02:36<00:48, 28.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.53G/7.89G [02:36<00:45, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.54G/7.89G [02:37<00:45, 29.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.55G/7.89G [02:37<00:45, 29.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.56G/7.89G [02:37<00:45, 28.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  83% 6.57G/7.89G [02:38<00:43, 30.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.59G/7.89G [02:38<00:43, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.60G/7.89G [02:38<00:43, 29.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.61G/7.89G [02:39<00:41, 30.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.62G/7.89G [02:39<00:45, 28.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.63G/7.89G [02:40<00:47, 26.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.64G/7.89G [02:40<00:49, 25.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.65G/7.89G [02:40<00:50, 24.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  84% 6.66G/7.89G [02:41<00:50, 24.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.67G/7.89G [02:41<00:50, 24.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.68G/7.89G [02:42<00:50, 24.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.69G/7.89G [02:42<00:49, 24.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.70G/7.89G [02:43<00:47, 24.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.71G/7.89G [02:43<00:47, 24.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.72G/7.89G [02:43<00:46, 25.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.73G/7.89G [02:44<00:46, 24.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  85% 6.74G/7.89G [02:44<00:44, 25.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.75G/7.89G [02:45<00:45, 25.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.76G/7.89G [02:45<00:43, 25.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.77G/7.89G [02:45<00:43, 25.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.78G/7.89G [02:46<00:42, 25.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.79G/7.89G [02:46<00:42, 25.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.81G/7.89G [02:47<00:42, 25.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  86% 6.82G/7.89G [02:47<00:41, 26.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.83G/7.89G [02:47<00:41, 25.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.84G/7.89G [02:48<00:44, 23.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.85G/7.89G [02:48<00:39, 26.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.86G/7.89G [02:49<00:38, 26.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.87G/7.89G [02:49<00:38, 26.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.88G/7.89G [02:49<00:38, 26.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.89G/7.89G [02:50<00:37, 26.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  87% 6.90G/7.89G [02:50<00:38, 26.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.91G/7.89G [02:51<00:37, 26.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.92G/7.89G [02:51<00:36, 26.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.93G/7.89G [02:51<00:36, 26.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.94G/7.89G [02:52<00:35, 26.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.95G/7.89G [02:52<00:35, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.96G/7.89G [02:53<00:34, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  88% 6.97G/7.89G [02:53<00:34, 26.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 6.98G/7.89G [02:53<00:33, 26.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 6.99G/7.89G [02:54<00:32, 27.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.00G/7.89G [02:54<00:32, 27.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.01G/7.89G [02:55<00:31, 27.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.03G/7.89G [02:55<00:30, 28.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.04G/7.89G [02:55<00:29, 28.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.05G/7.89G [02:56<00:29, 28.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  89% 7.06G/7.89G [02:56<00:28, 29.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.07G/7.89G [02:56<00:27, 29.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.08G/7.89G [02:57<00:26, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.09G/7.89G [02:57<00:25, 30.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.10G/7.89G [02:57<00:24, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.11G/7.89G [02:58<00:23, 32.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.12G/7.89G [02:58<00:23, 33.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  90% 7.13G/7.89G [02:58<00:22, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.14G/7.89G [02:58<00:21, 34.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.15G/7.89G [02:59<00:21, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.16G/7.89G [02:59<00:20, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.17G/7.89G [02:59<00:19, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.18G/7.89G [03:00<00:18, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.19G/7.89G [03:00<00:17, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.20G/7.89G [03:00<00:18, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  91% 7.21G/7.89G [03:00<00:17, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.22G/7.89G [03:01<00:17, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.24G/7.89G [03:01<00:16, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.25G/7.89G [03:01<00:16, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.26G/7.89G [03:01<00:16, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.27G/7.89G [03:02<00:15, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.28G/7.89G [03:02<00:14, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  92% 7.29G/7.89G [03:02<00:15, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.30G/7.89G [03:02<00:14, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.31G/7.89G [03:03<00:13, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.32G/7.89G [03:03<00:13, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.33G/7.89G [03:03<00:12, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.34G/7.89G [03:03<00:11, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.35G/7.89G [03:04<00:11, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.36G/7.89G [03:04<00:11, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  93% 7.37G/7.89G [03:04<00:10, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.38G/7.89G [03:04<00:10, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.39G/7.89G [03:04<00:10, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.40G/7.89G [03:05<00:10, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.41G/7.89G [03:05<00:10, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.42G/7.89G [03:05<00:09, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.43G/7.89G [03:05<00:11, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  94% 7.44G/7.89G [03:06<00:10, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.46G/7.89G [03:06<00:09, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.47G/7.89G [03:06<00:09, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.48G/7.89G [03:06<00:10, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.49G/7.89G [03:07<00:09, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.50G/7.89G [03:07<00:12, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.51G/7.89G [03:07<00:10, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.52G/7.89G [03:08<00:09, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  95% 7.53G/7.89G [03:08<00:10, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.54G/7.89G [03:08<00:08, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.55G/7.89G [03:08<00:08, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.56G/7.89G [03:09<00:07, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.57G/7.89G [03:09<00:08, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.58G/7.89G [03:09<00:07, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.59G/7.89G [03:10<00:07, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  96% 7.60G/7.89G [03:10<00:07, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.61G/7.89G [03:10<00:07, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.62G/7.89G [03:10<00:06, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.63G/7.89G [03:11<00:06, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.64G/7.89G [03:11<00:05, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.65G/7.89G [03:11<00:05, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.67G/7.89G [03:11<00:05, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.68G/7.89G [03:12<00:05, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  97% 7.69G/7.89G [03:12<00:04, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.70G/7.89G [03:12<00:04, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.71G/7.89G [03:12<00:04, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.72G/7.89G [03:12<00:03, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.73G/7.89G [03:13<00:03, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.74G/7.89G [03:13<00:03, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.75G/7.89G [03:13<00:02, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  98% 7.76G/7.89G [03:13<00:02, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.77G/7.89G [03:14<00:02, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.78G/7.89G [03:14<00:02, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.79G/7.89G [03:14<00:01, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.80G/7.89G [03:14<00:02, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.81G/7.89G [03:15<00:02, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.82G/7.89G [03:15<00:01, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.83G/7.89G [03:15<00:01, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin:  99% 7.84G/7.89G [03:16<00:01, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin: 100% 7.85G/7.89G [03:16<00:00, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin: 100% 7.86G/7.89G [03:16<00:00, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin: 100% 7.87G/7.89G [03:16<00:00, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00003-of-00005.bin: 100% 7.89G/7.89G [03:17<00:00, 40.0MB/s]\n",
      "Downloading shards:  60% 3/5 [09:29<06:22, 191.30s/it]\n",
      "pytorch_model-00004-of-00005.bin:   0% 0.00/7.89G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   0% 10.5M/7.89G [00:00<10:00, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   0% 21.0M/7.89G [00:01<05:53, 22.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   0% 31.5M/7.89G [00:01<04:08, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 41.9M/7.89G [00:01<03:07, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 52.4M/7.89G [00:01<02:53, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 62.9M/7.89G [00:01<02:35, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 73.4M/7.89G [00:01<02:40, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 83.9M/7.89G [00:02<02:43, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 94.4M/7.89G [00:02<02:33, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 105M/7.89G [00:02<02:41, 48.1MB/s] \u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   1% 115M/7.89G [00:03<03:56, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 126M/7.89G [00:03<03:38, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 136M/7.89G [00:03<03:24, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 147M/7.89G [00:03<03:13, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 157M/7.89G [00:03<02:52, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 168M/7.89G [00:04<02:51, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 178M/7.89G [00:04<02:36, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   2% 189M/7.89G [00:04<02:45, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 199M/7.89G [00:04<02:45, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 210M/7.89G [00:05<02:58, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 220M/7.89G [00:05<02:55, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 231M/7.89G [00:05<02:39, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 241M/7.89G [00:05<02:41, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 252M/7.89G [00:05<02:28, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 262M/7.89G [00:06<02:35, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   3% 273M/7.89G [00:06<02:38, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 283M/7.89G [00:06<02:40, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 294M/7.89G [00:06<02:31, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 304M/7.89G [00:07<02:36, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 315M/7.89G [00:07<02:34, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 325M/7.89G [00:07<02:29, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 336M/7.89G [00:07<02:34, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   4% 346M/7.89G [00:07<02:30, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 357M/7.89G [00:08<02:39, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 367M/7.89G [00:08<02:42, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 377M/7.89G [00:08<02:31, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 388M/7.89G [00:08<02:32, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 398M/7.89G [00:08<02:21, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 409M/7.89G [00:09<02:55, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 419M/7.89G [00:09<02:51, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   5% 430M/7.89G [00:09<02:34, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 440M/7.89G [00:09<02:48, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 451M/7.89G [00:10<02:34, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 461M/7.89G [00:10<02:35, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 472M/7.89G [00:10<02:23, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 482M/7.89G [00:10<02:28, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 493M/7.89G [00:10<02:31, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   6% 503M/7.89G [00:11<02:46, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 514M/7.89G [00:11<03:12, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 524M/7.89G [00:11<03:02, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 535M/7.89G [00:12<03:01, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 545M/7.89G [00:12<03:51, 31.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 556M/7.89G [00:12<03:16, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 566M/7.89G [00:12<03:05, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 577M/7.89G [00:13<02:56, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   7% 587M/7.89G [00:13<02:37, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 598M/7.89G [00:13<03:09, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 608M/7.89G [00:14<03:12, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 619M/7.89G [00:14<02:49, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 629M/7.89G [00:14<02:52, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 640M/7.89G [00:14<02:48, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 650M/7.89G [00:15<03:02, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   8% 661M/7.89G [00:15<02:54, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 671M/7.89G [00:15<02:49, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 682M/7.89G [00:15<02:38, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 692M/7.89G [00:16<03:05, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 703M/7.89G [00:16<02:57, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 713M/7.89G [00:16<03:04, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 724M/7.89G [00:16<03:08, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 734M/7.89G [00:17<02:58, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:   9% 744M/7.89G [00:17<03:08, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 755M/7.89G [00:17<03:03, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 765M/7.89G [00:17<02:51, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 776M/7.89G [00:18<02:53, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 786M/7.89G [00:18<03:21, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 797M/7.89G [00:18<03:07, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 807M/7.89G [00:19<03:02, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 818M/7.89G [00:19<02:40, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  10% 828M/7.89G [00:19<02:38, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 839M/7.89G [00:19<02:24, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 849M/7.89G [00:19<02:27, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 860M/7.89G [00:20<02:29, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 870M/7.89G [00:20<02:30, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 881M/7.89G [00:20<02:19, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 891M/7.89G [00:20<02:23, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  11% 902M/7.89G [00:20<02:25, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 912M/7.89G [00:21<02:14, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 923M/7.89G [00:21<02:19, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 933M/7.89G [00:21<02:32, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 944M/7.89G [00:21<02:32, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 954M/7.89G [00:21<02:18, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 965M/7.89G [00:22<02:49, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 975M/7.89G [00:22<02:30, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  12% 986M/7.89G [00:22<02:57, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 996M/7.89G [00:23<02:36, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.01G/7.89G [00:23<02:34, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.02G/7.89G [00:23<02:33, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.03G/7.89G [00:23<02:22, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.04G/7.89G [00:23<02:26, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.05G/7.89G [00:24<02:43, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  13% 1.06G/7.89G [00:24<02:31, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.07G/7.89G [00:24<02:26, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.08G/7.89G [00:24<02:26, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.09G/7.89G [00:25<02:18, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.10G/7.89G [00:25<02:21, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.11G/7.89G [00:25<02:28, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.12G/7.89G [00:25<02:15, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.13G/7.89G [00:25<02:20, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  14% 1.14G/7.89G [00:26<02:12, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.15G/7.89G [00:26<02:14, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.16G/7.89G [00:26<02:17, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.17G/7.89G [00:26<02:08, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.18G/7.89G [00:26<02:14, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.20G/7.89G [00:27<02:06, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.21G/7.89G [00:27<02:11, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  15% 1.22G/7.89G [00:27<02:17, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.23G/7.89G [00:27<02:19, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.24G/7.89G [00:27<02:10, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.25G/7.89G [00:28<02:13, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.26G/7.89G [00:28<02:17, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.27G/7.89G [00:28<02:11, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.28G/7.89G [00:28<02:11, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.29G/7.89G [00:28<02:06, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  16% 1.30G/7.89G [00:29<02:16, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.31G/7.89G [00:29<02:11, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.32G/7.89G [00:29<02:16, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.33G/7.89G [00:29<02:06, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.34G/7.89G [00:30<02:10, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.35G/7.89G [00:30<02:14, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.36G/7.89G [00:30<02:04, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  17% 1.37G/7.89G [00:30<02:09, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.38G/7.89G [00:30<02:13, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.39G/7.89G [00:31<02:08, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.41G/7.89G [00:31<02:09, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.42G/7.89G [00:31<02:12, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.43G/7.89G [00:31<02:03, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.44G/7.89G [00:31<02:08, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.45G/7.89G [00:32<02:13, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  18% 1.46G/7.89G [00:32<02:03, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.47G/7.89G [00:32<02:08, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.48G/7.89G [00:32<02:12, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.49G/7.89G [00:32<02:02, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.50G/7.89G [00:33<02:07, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.51G/7.89G [00:33<02:10, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.52G/7.89G [00:33<02:03, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  19% 1.53G/7.89G [00:33<02:06, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.54G/7.89G [00:34<02:08, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.55G/7.89G [00:34<02:00, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.56G/7.89G [00:34<02:14, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.57G/7.89G [00:34<02:26, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.58G/7.89G [00:34<02:12, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.59G/7.89G [00:35<02:13, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.60G/7.89G [00:35<02:14, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  20% 1.61G/7.89G [00:35<02:09, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.63G/7.89G [00:35<02:10, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.64G/7.89G [00:35<02:00, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.65G/7.89G [00:36<02:16, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.66G/7.89G [00:36<02:23, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.67G/7.89G [00:36<02:09, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.68G/7.89G [00:36<02:11, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  21% 1.69G/7.89G [00:37<02:12, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.70G/7.89G [00:37<02:01, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.71G/7.89G [00:37<02:05, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.72G/7.89G [00:37<01:59, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.73G/7.89G [00:37<02:00, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.74G/7.89G [00:38<02:04, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.75G/7.89G [00:38<01:56, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.76G/7.89G [00:38<02:01, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  22% 1.77G/7.89G [00:38<02:04, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.78G/7.89G [00:38<01:56, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.79G/7.89G [00:39<02:00, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.80G/7.89G [00:39<02:03, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.81G/7.89G [00:39<02:00, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.82G/7.89G [00:39<02:14, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.84G/7.89G [00:40<02:11, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  23% 1.85G/7.89G [00:40<02:11, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.86G/7.89G [00:40<02:11, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.87G/7.89G [00:40<02:02, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.88G/7.89G [00:40<02:02, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.89G/7.89G [00:41<02:04, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.90G/7.89G [00:41<01:56, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.91G/7.89G [00:41<01:59, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.92G/7.89G [00:41<02:03, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  24% 1.93G/7.89G [00:41<01:52, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.94G/7.89G [00:42<01:58, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.95G/7.89G [00:42<02:01, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.96G/7.89G [00:42<02:27, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.97G/7.89G [00:43<02:30, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.98G/7.89G [00:43<02:24, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 1.99G/7.89G [00:43<02:19, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  25% 2.00G/7.89G [00:43<02:09, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.01G/7.89G [00:43<02:08, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.02G/7.89G [00:44<02:24, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.03G/7.89G [00:44<02:22, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.04G/7.89G [00:44<02:18, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.06G/7.89G [00:45<02:14, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.07G/7.89G [00:45<02:04, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.08G/7.89G [00:45<02:01, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  26% 2.09G/7.89G [00:45<02:02, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.10G/7.89G [00:45<01:54, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.11G/7.89G [00:46<01:56, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.12G/7.89G [00:46<02:03, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.13G/7.89G [00:46<02:12, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.14G/7.89G [00:46<02:10, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.15G/7.89G [00:46<02:00, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  27% 2.16G/7.89G [00:47<02:13, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.17G/7.89G [00:47<02:11, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.18G/7.89G [00:47<02:07, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.19G/7.89G [00:47<01:57, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.20G/7.89G [00:48<01:59, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.21G/7.89G [00:48<01:59, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.22G/7.89G [00:48<01:51, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.23G/7.89G [00:48<01:53, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  28% 2.24G/7.89G [00:48<01:46, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.25G/7.89G [00:49<01:51, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.26G/7.89G [00:49<01:53, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.28G/7.89G [00:49<01:46, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.29G/7.89G [00:49<01:51, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.30G/7.89G [00:49<01:54, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.31G/7.89G [00:50<01:53, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  29% 2.32G/7.89G [00:50<02:04, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.33G/7.89G [00:50<02:02, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.34G/7.89G [00:50<01:57, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.35G/7.89G [00:51<01:59, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.36G/7.89G [00:51<01:59, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.37G/7.89G [00:51<02:01, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.38G/7.89G [00:51<02:01, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.39G/7.89G [00:52<01:52, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  30% 2.40G/7.89G [00:52<01:52, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.41G/7.89G [00:52<01:46, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.42G/7.89G [00:52<02:08, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.43G/7.89G [00:52<02:05, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.44G/7.89G [00:53<02:03, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.45G/7.89G [00:53<01:52, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.46G/7.89G [00:53<01:53, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.47G/7.89G [00:53<01:54, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  31% 2.49G/7.89G [00:54<01:49, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.50G/7.89G [00:54<01:59, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.51G/7.89G [00:54<01:58, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.52G/7.89G [00:54<02:07, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.53G/7.89G [00:55<02:05, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.54G/7.89G [00:55<02:14, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.55G/7.89G [00:55<02:08, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  32% 2.56G/7.89G [00:55<01:54, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.57G/7.89G [00:56<02:04, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.58G/7.89G [00:56<02:04, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.59G/7.89G [00:56<02:00, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.60G/7.89G [00:56<01:58, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.61G/7.89G [00:56<01:49, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.62G/7.89G [00:57<01:50, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.63G/7.89G [00:57<01:50, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  33% 2.64G/7.89G [00:57<01:43, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.65G/7.89G [00:57<01:45, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.66G/7.89G [00:57<01:47, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.67G/7.89G [00:58<01:40, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.68G/7.89G [00:58<01:43, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.69G/7.89G [00:58<01:37, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.71G/7.89G [00:58<01:42, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  34% 2.72G/7.89G [00:59<01:47, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  35% 2.73G/7.89G [01:00<03:51, 22.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  35% 2.75G/7.89G [01:00<02:20, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  35% 2.78G/7.89G [01:00<01:20, 63.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  35% 2.80G/7.89G [01:00<01:25, 59.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.81G/7.89G [01:00<01:24, 60.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.82G/7.89G [01:01<01:32, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.83G/7.89G [01:01<01:36, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.84G/7.89G [01:01<01:34, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.85G/7.89G [01:01<01:36, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.86G/7.89G [01:01<01:31, 55.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  36% 2.87G/7.89G [01:02<01:57, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.88G/7.89G [01:02<01:46, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.89G/7.89G [01:02<01:47, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.90G/7.89G [01:03<01:53, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.92G/7.89G [01:03<01:53, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.93G/7.89G [01:03<01:51, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.94G/7.89G [01:03<01:41, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.95G/7.89G [01:03<01:46, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  37% 2.96G/7.89G [01:04<01:55, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 2.97G/7.89G [01:04<01:58, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 2.98G/7.89G [01:04<01:54, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 2.99G/7.89G [01:04<01:52, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 3.00G/7.89G [01:05<01:41, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 3.01G/7.89G [01:05<01:42, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 3.02G/7.89G [01:05<01:35, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  38% 3.03G/7.89G [01:05<01:37, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.04G/7.89G [01:06<01:57, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.05G/7.89G [01:06<01:44, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.06G/7.89G [01:06<01:45, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.07G/7.89G [01:06<01:44, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.08G/7.89G [01:06<01:35, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.09G/7.89G [01:07<01:38, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.10G/7.89G [01:07<01:30, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  39% 3.11G/7.89G [01:07<01:38, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.12G/7.89G [01:07<01:40, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.14G/7.89G [01:07<01:35, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.15G/7.89G [01:08<01:34, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.16G/7.89G [01:08<01:36, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.17G/7.89G [01:08<01:29, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.18G/7.89G [01:08<01:54, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  40% 3.19G/7.89G [01:09<01:42, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.20G/7.89G [01:09<01:42, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.21G/7.89G [01:09<01:41, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.22G/7.89G [01:09<01:38, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.23G/7.89G [01:09<01:34, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.24G/7.89G [01:10<01:36, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.25G/7.89G [01:10<01:37, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.26G/7.89G [01:10<01:36, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  41% 3.27G/7.89G [01:10<01:31, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.28G/7.89G [01:10<01:33, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.29G/7.89G [01:11<01:26, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.30G/7.89G [01:11<01:30, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.31G/7.89G [01:11<01:32, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.32G/7.89G [01:11<01:34, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.33G/7.89G [01:12<01:28, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  42% 3.34G/7.89G [01:12<01:32, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.36G/7.89G [01:12<01:32, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.37G/7.89G [01:12<01:27, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.38G/7.89G [01:12<01:30, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.39G/7.89G [01:13<01:23, 53.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.40G/7.89G [01:13<01:27, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.41G/7.89G [01:13<01:29, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.42G/7.89G [01:13<01:24, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  43% 3.43G/7.89G [01:13<01:28, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.44G/7.89G [01:14<01:29, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.45G/7.89G [01:14<01:24, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.46G/7.89G [01:14<01:29, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.47G/7.89G [01:14<01:31, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.48G/7.89G [01:15<01:51, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.49G/7.89G [01:15<01:39, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  44% 3.50G/7.89G [01:15<01:37, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.51G/7.89G [01:15<01:36, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.52G/7.89G [01:15<01:27, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.53G/7.89G [01:16<01:29, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.54G/7.89G [01:16<01:42, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.55G/7.89G [01:16<01:33, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.57G/7.89G [01:16<01:33, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.58G/7.89G [01:17<01:26, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  45% 3.59G/7.89G [01:17<01:27, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.60G/7.89G [01:17<01:29, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.61G/7.89G [01:17<01:22, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.62G/7.89G [01:17<01:25, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.63G/7.89G [01:18<01:27, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.64G/7.89G [01:18<01:41, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.65G/7.89G [01:19<02:22, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  46% 3.66G/7.89G [01:19<02:00, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.67G/7.89G [01:19<01:51, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.68G/7.89G [01:19<01:57, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.69G/7.89G [01:19<01:41, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.70G/7.89G [01:20<01:44, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.71G/7.89G [01:20<01:40, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.72G/7.89G [01:20<01:31, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.73G/7.89G [01:20<01:29, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  47% 3.74G/7.89G [01:20<01:21, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.75G/7.89G [01:21<01:25, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.76G/7.89G [01:21<01:26, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.77G/7.89G [01:21<01:20, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.79G/7.89G [01:21<01:22, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.80G/7.89G [01:21<01:17, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.81G/7.89G [01:22<01:20, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  48% 3.82G/7.89G [01:22<01:22, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.83G/7.89G [01:22<01:16, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.84G/7.89G [01:22<01:19, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.85G/7.89G [01:23<01:22, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.86G/7.89G [01:23<01:16, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.87G/7.89G [01:23<01:19, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.88G/7.89G [01:23<01:21, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.89G/7.89G [01:23<01:27, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  49% 3.90G/7.89G [01:24<01:26, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.91G/7.89G [01:24<01:42, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.92G/7.89G [01:24<01:40, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.93G/7.89G [01:25<01:35, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.94G/7.89G [01:25<01:33, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.95G/7.89G [01:25<01:24, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.96G/7.89G [01:25<01:23, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  50% 3.97G/7.89G [01:25<01:23, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 3.98G/7.89G [01:26<01:24, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.00G/7.89G [01:26<01:17, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.01G/7.89G [01:26<01:20, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.02G/7.89G [01:26<01:21, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.03G/7.89G [01:26<01:15, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.04G/7.89G [01:27<01:18, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.05G/7.89G [01:27<01:18, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  51% 4.06G/7.89G [01:27<01:13, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.07G/7.89G [01:27<01:26, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.08G/7.89G [01:28<01:25, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.09G/7.89G [01:28<01:35, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.10G/7.89G [01:28<01:32, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.11G/7.89G [01:28<01:25, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.12G/7.89G [01:29<01:24, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.13G/7.89G [01:29<01:24, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  52% 4.14G/7.89G [01:29<01:22, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.15G/7.89G [01:30<01:54, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.16G/7.89G [01:30<02:23, 25.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.17G/7.89G [01:30<02:01, 30.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.18G/7.89G [01:31<02:01, 30.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.19G/7.89G [01:31<01:59, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.20G/7.89G [01:31<01:47, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  53% 4.22G/7.89G [01:31<01:39, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.23G/7.89G [01:32<01:32, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.24G/7.89G [01:32<01:27, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.25G/7.89G [01:32<01:18, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.26G/7.89G [01:32<01:18, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.27G/7.89G [01:33<01:17, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.28G/7.89G [01:33<01:11, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.29G/7.89G [01:33<01:13, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  54% 4.30G/7.89G [01:33<01:14, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.31G/7.89G [01:33<01:09, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.32G/7.89G [01:34<01:11, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.33G/7.89G [01:34<01:06, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.34G/7.89G [01:34<01:09, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.35G/7.89G [01:34<01:29, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.36G/7.89G [01:35<01:38, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  55% 4.37G/7.89G [01:35<01:48, 32.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.38G/7.89G [01:35<01:31, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.39G/7.89G [01:36<01:26, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.40G/7.89G [01:36<01:23, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.41G/7.89G [01:36<01:15, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.42G/7.89G [01:36<01:14, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.44G/7.89G [01:36<01:22, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.45G/7.89G [01:37<01:20, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  56% 4.46G/7.89G [01:37<01:18, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.47G/7.89G [01:37<01:10, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.48G/7.89G [01:37<01:11, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.49G/7.89G [01:37<01:05, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.50G/7.89G [01:38<01:08, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.51G/7.89G [01:38<01:10, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.52G/7.89G [01:38<01:10, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  57% 4.53G/7.89G [01:38<01:04, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.54G/7.89G [01:39<01:07, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.55G/7.89G [01:39<01:08, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.56G/7.89G [01:39<01:08, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.57G/7.89G [01:39<01:04, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.58G/7.89G [01:40<01:37, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.59G/7.89G [01:40<01:36, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.60G/7.89G [01:40<01:21, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  58% 4.61G/7.89G [01:40<01:24, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.62G/7.89G [01:41<01:28, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.63G/7.89G [01:41<01:18, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.65G/7.89G [01:41<01:19, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.66G/7.89G [01:41<01:15, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.67G/7.89G [01:42<01:45, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.68G/7.89G [01:42<01:39, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  59% 4.69G/7.89G [01:42<01:24, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.70G/7.89G [01:43<01:19, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.71G/7.89G [01:43<01:13, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.72G/7.89G [01:43<01:08, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.73G/7.89G [01:43<01:08, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.74G/7.89G [01:43<01:02, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.75G/7.89G [01:44<01:04, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.76G/7.89G [01:44<01:05, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  60% 4.77G/7.89G [01:44<01:01, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.78G/7.89G [01:44<01:01, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.79G/7.89G [01:44<00:58, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.80G/7.89G [01:45<00:59, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.81G/7.89G [01:45<01:01, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.82G/7.89G [01:45<00:58, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.83G/7.89G [01:45<01:00, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  61% 4.84G/7.89G [01:46<01:01, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.85G/7.89G [01:46<00:57, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.87G/7.89G [01:46<01:11, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.88G/7.89G [01:46<01:03, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.89G/7.89G [01:47<01:11, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.90G/7.89G [01:47<01:09, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.91G/7.89G [01:47<01:11, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.92G/7.89G [01:47<01:00, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  62% 4.93G/7.89G [01:47<00:56, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.94G/7.89G [01:48<01:06, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.95G/7.89G [01:48<01:06, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.96G/7.89G [01:48<01:03, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.97G/7.89G [01:48<00:59, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.98G/7.89G [01:49<01:00, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 4.99G/7.89G [01:49<00:58, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  63% 5.00G/7.89G [01:49<00:57, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.01G/7.89G [01:49<00:58, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.02G/7.89G [01:49<00:56, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.03G/7.89G [01:50<00:55, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.04G/7.89G [01:50<00:57, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.05G/7.89G [01:50<00:55, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.06G/7.89G [01:50<00:58, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.08G/7.89G [01:50<00:53, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  64% 5.09G/7.89G [01:51<00:56, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.10G/7.89G [01:51<00:57, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.11G/7.89G [01:51<01:01, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.12G/7.89G [01:51<00:52, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.13G/7.89G [01:51<00:54, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.14G/7.89G [01:52<00:50, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.15G/7.89G [01:52<00:52, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  65% 5.16G/7.89G [01:52<00:50, 54.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.17G/7.89G [01:52<00:52, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.18G/7.89G [01:52<00:54, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.19G/7.89G [01:53<00:51, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.20G/7.89G [01:53<00:53, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.21G/7.89G [01:53<00:54, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.22G/7.89G [01:53<01:00, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.23G/7.89G [01:53<00:51, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  66% 5.24G/7.89G [01:54<00:52, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.25G/7.89G [01:54<00:56, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.26G/7.89G [01:54<00:51, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.27G/7.89G [01:54<00:58, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.28G/7.89G [01:55<01:08, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.30G/7.89G [01:55<01:16, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  67% 5.32G/7.89G [01:55<00:54, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.33G/7.89G [01:56<00:50, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.34G/7.89G [01:56<01:07, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.35G/7.89G [01:56<01:10, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.36G/7.89G [01:57<01:06, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.37G/7.89G [01:57<01:02, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.38G/7.89G [01:57<00:55, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.39G/7.89G [01:57<00:55, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  68% 5.40G/7.89G [01:58<01:05, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.41G/7.89G [01:58<01:00, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.42G/7.89G [01:58<00:57, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.43G/7.89G [01:58<00:56, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.44G/7.89G [01:59<01:00, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.45G/7.89G [01:59<00:58, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.46G/7.89G [01:59<01:03, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  69% 5.47G/7.89G [01:59<01:00, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.48G/7.89G [02:00<00:57, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.49G/7.89G [02:00<00:51, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.51G/7.89G [02:00<00:51, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.52G/7.89G [02:00<00:46, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.53G/7.89G [02:01<00:54, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.54G/7.89G [02:01<00:53, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.55G/7.89G [02:01<00:52, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  70% 5.56G/7.89G [02:01<00:53, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.57G/7.89G [02:01<00:48, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.58G/7.89G [02:02<00:51, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.59G/7.89G [02:02<00:51, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.60G/7.89G [02:02<00:50, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.61G/7.89G [02:02<00:49, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.62G/7.89G [02:03<00:50, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.63G/7.89G [02:03<00:53, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  71% 5.64G/7.89G [02:03<00:56, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.65G/7.89G [02:03<00:50, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.66G/7.89G [02:04<00:49, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.67G/7.89G [02:04<00:48, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.68G/7.89G [02:04<00:51, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.69G/7.89G [02:04<00:43, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.70G/7.89G [02:05<00:51, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  72% 5.71G/7.89G [02:05<00:45, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.73G/7.89G [02:05<00:45, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.74G/7.89G [02:05<00:41, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.75G/7.89G [02:05<00:43, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.76G/7.89G [02:06<00:44, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.77G/7.89G [02:06<00:40, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.78G/7.89G [02:06<00:42, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.79G/7.89G [02:06<00:39, 53.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  73% 5.80G/7.89G [02:06<00:45, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.81G/7.89G [02:07<00:45, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.82G/7.89G [02:07<00:41, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.83G/7.89G [02:07<00:42, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.84G/7.89G [02:07<00:44, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.85G/7.89G [02:07<00:41, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.86G/7.89G [02:08<00:54, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  74% 5.87G/7.89G [02:08<00:55, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.88G/7.89G [02:08<00:49, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.89G/7.89G [02:09<00:48, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.90G/7.89G [02:09<00:46, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.91G/7.89G [02:09<00:49, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.92G/7.89G [02:10<00:58, 33.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.93G/7.89G [02:10<00:53, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.95G/7.89G [02:10<00:55, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  75% 5.96G/7.89G [02:10<00:48, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 5.97G/7.89G [02:11<00:47, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 5.98G/7.89G [02:11<00:45, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 5.99G/7.89G [02:11<00:42, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 6.00G/7.89G [02:11<00:42, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 6.01G/7.89G [02:11<00:41, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 6.02G/7.89G [02:12<00:38, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  76% 6.03G/7.89G [02:12<00:38, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.04G/7.89G [02:12<00:36, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.05G/7.89G [02:12<00:37, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.06G/7.89G [02:12<00:37, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.07G/7.89G [02:13<00:35, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.08G/7.89G [02:13<00:36, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.09G/7.89G [02:13<00:37, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.10G/7.89G [02:13<00:34, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  77% 6.11G/7.89G [02:14<00:35, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.12G/7.89G [02:14<00:33, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.13G/7.89G [02:14<00:34, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.14G/7.89G [02:14<00:35, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.16G/7.89G [02:14<00:33, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.17G/7.89G [02:15<00:34, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.18G/7.89G [02:15<00:35, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  78% 6.19G/7.89G [02:15<00:33, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.20G/7.89G [02:15<00:47, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.21G/7.89G [02:16<01:02, 26.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.22G/7.89G [02:16<00:56, 29.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.23G/7.89G [02:17<00:58, 28.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.24G/7.89G [02:17<00:52, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.25G/7.89G [02:17<00:46, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.26G/7.89G [02:17<00:40, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  79% 6.27G/7.89G [02:18<00:38, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.28G/7.89G [02:18<00:37, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.29G/7.89G [02:18<00:39, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.30G/7.89G [02:18<00:38, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.31G/7.89G [02:19<00:35, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.32G/7.89G [02:19<00:33, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.33G/7.89G [02:19<00:31, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  80% 6.34G/7.89G [02:19<00:32, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.35G/7.89G [02:20<00:40, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.36G/7.89G [02:20<00:36, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.38G/7.89G [02:20<00:34, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.39G/7.89G [02:20<00:34, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.40G/7.89G [02:20<00:33, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.41G/7.89G [02:21<00:31, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.42G/7.89G [02:21<00:30, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  81% 6.43G/7.89G [02:21<00:28, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.44G/7.89G [02:21<00:28, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.45G/7.89G [02:21<00:29, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.46G/7.89G [02:22<00:27, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.47G/7.89G [02:22<00:28, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.48G/7.89G [02:22<00:28, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.49G/7.89G [02:22<00:26, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  82% 6.50G/7.89G [02:22<00:27, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.51G/7.89G [02:23<00:25, 54.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.52G/7.89G [02:23<00:26, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.53G/7.89G [02:23<00:28, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.54G/7.89G [02:23<00:25, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.55G/7.89G [02:24<00:28, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.56G/7.89G [02:24<00:28, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.57G/7.89G [02:24<00:25, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  83% 6.59G/7.89G [02:24<00:26, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.60G/7.89G [02:24<00:24, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.61G/7.89G [02:25<00:25, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.62G/7.89G [02:25<00:38, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.63G/7.89G [02:25<00:38, 32.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.64G/7.89G [02:26<00:35, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.65G/7.89G [02:26<00:35, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  84% 6.66G/7.89G [02:26<00:29, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.67G/7.89G [02:26<00:28, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.68G/7.89G [02:27<00:29, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.69G/7.89G [02:27<00:32, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.70G/7.89G [02:27<00:29, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.71G/7.89G [02:28<00:32, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.72G/7.89G [02:28<00:30, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.73G/7.89G [02:28<00:26, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  85% 6.74G/7.89G [02:28<00:26, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.75G/7.89G [02:28<00:26, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.76G/7.89G [02:29<00:26, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.77G/7.89G [02:29<00:24, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.78G/7.89G [02:29<00:29, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.79G/7.89G [02:30<00:26, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.81G/7.89G [02:30<00:24, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  86% 6.82G/7.89G [02:30<00:24, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.83G/7.89G [02:30<00:23, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.84G/7.89G [02:30<00:23, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.85G/7.89G [02:31<00:21, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.86G/7.89G [02:31<00:21, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.87G/7.89G [02:31<00:21, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.88G/7.89G [02:31<00:21, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.89G/7.89G [02:31<00:19, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  87% 6.90G/7.89G [02:32<00:20, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.91G/7.89G [02:32<00:19, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.92G/7.89G [02:32<00:20, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.93G/7.89G [02:32<00:18, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.94G/7.89G [02:32<00:18, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.95G/7.89G [02:33<00:19, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.96G/7.89G [02:33<00:18, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  88% 6.97G/7.89G [02:33<00:17, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 6.98G/7.89G [02:33<00:17, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 6.99G/7.89G [02:34<00:17, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.00G/7.89G [02:34<00:17, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.01G/7.89G [02:34<00:16, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.03G/7.89G [02:34<00:16, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.04G/7.89G [02:34<00:17, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.05G/7.89G [02:35<00:20, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  89% 7.06G/7.89G [02:35<00:19, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.07G/7.89G [02:35<00:19, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.08G/7.89G [02:35<00:17, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.09G/7.89G [02:36<00:17, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.10G/7.89G [02:36<00:15, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.11G/7.89G [02:36<00:19, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.12G/7.89G [02:36<00:16, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  90% 7.13G/7.89G [02:37<00:16, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.14G/7.89G [02:37<00:17, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.15G/7.89G [02:37<00:15, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.16G/7.89G [02:37<00:15, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.17G/7.89G [02:37<00:15, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.18G/7.89G [02:38<00:15, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.19G/7.89G [02:38<00:13, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.20G/7.89G [02:38<00:13, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  91% 7.21G/7.89G [02:38<00:12, 53.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.22G/7.89G [02:38<00:13, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.24G/7.89G [02:39<00:13, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.25G/7.89G [02:39<00:12, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.26G/7.89G [02:39<00:13, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.27G/7.89G [02:39<00:15, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.28G/7.89G [02:40<00:14, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.29G/7.89G [02:40<00:12, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  92% 7.30G/7.89G [02:40<00:12, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.31G/7.89G [02:40<00:12, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.32G/7.89G [02:40<00:11, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.33G/7.89G [02:41<00:11, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.34G/7.89G [02:41<00:10, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.35G/7.89G [02:41<00:10, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.36G/7.89G [02:41<00:10, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  93% 7.37G/7.89G [02:42<00:10, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.38G/7.89G [02:42<00:09, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.39G/7.89G [02:42<00:09, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.40G/7.89G [02:42<00:09, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.41G/7.89G [02:42<00:09, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.42G/7.89G [02:43<00:09, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.43G/7.89G [02:43<00:09, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.44G/7.89G [02:43<00:08, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  94% 7.46G/7.89G [02:43<00:08, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.47G/7.89G [02:43<00:08, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.48G/7.89G [02:44<00:10, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.49G/7.89G [02:44<00:08, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.50G/7.89G [02:44<00:09, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.51G/7.89G [02:45<00:09, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.52G/7.89G [02:45<00:08, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  95% 7.53G/7.89G [02:45<00:07, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.54G/7.89G [02:45<00:07, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.55G/7.89G [02:45<00:06, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.56G/7.89G [02:46<00:06, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.57G/7.89G [02:46<00:06, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.58G/7.89G [02:46<00:06, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.59G/7.89G [02:46<00:05, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.60G/7.89G [02:46<00:05, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  96% 7.61G/7.89G [02:47<00:05, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.62G/7.89G [02:47<00:05, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.63G/7.89G [02:47<00:04, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.64G/7.89G [02:47<00:04, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.65G/7.89G [02:47<00:05, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.67G/7.89G [02:48<00:05, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.68G/7.89G [02:48<00:04, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  97% 7.69G/7.89G [02:48<00:05, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.70G/7.89G [02:49<00:07, 26.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.71G/7.89G [02:49<00:05, 31.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.72G/7.89G [02:49<00:04, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.73G/7.89G [02:50<00:04, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.74G/7.89G [02:50<00:03, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.75G/7.89G [02:50<00:03, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.76G/7.89G [02:50<00:02, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  98% 7.77G/7.89G [02:50<00:02, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.78G/7.89G [02:51<00:02, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.79G/7.89G [02:51<00:01, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.80G/7.89G [02:51<00:02, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.81G/7.89G [02:51<00:02, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.82G/7.89G [02:52<00:01, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.83G/7.89G [02:52<00:01, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin:  99% 7.84G/7.89G [02:52<00:00, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin: 100% 7.85G/7.89G [02:52<00:00, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin: 100% 7.86G/7.89G [02:52<00:00, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin: 100% 7.87G/7.89G [02:53<00:00, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin: 100% 7.89G/7.89G [02:53<00:00, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00004-of-00005.bin: 100% 7.89G/7.89G [02:53<00:00, 45.5MB/s]\n",
      "Downloading shards:  80% 4/5 [12:23<03:04, 184.54s/it]\n",
      "pytorch_model-00005-of-00005.bin:   0% 0.00/1.55G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   1% 10.5M/1.55G [00:00<01:36, 16.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   1% 21.0M/1.55G [00:00<00:54, 28.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   2% 31.5M/1.55G [00:01<00:42, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   3% 41.9M/1.55G [00:01<00:37, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   3% 52.4M/1.55G [00:01<00:31, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   4% 62.9M/1.55G [00:01<00:31, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   5% 73.4M/1.55G [00:01<00:28, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   5% 83.9M/1.55G [00:01<00:28, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   6% 94.4M/1.55G [00:02<00:29, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   7% 105M/1.55G [00:02<00:26, 54.5MB/s] \u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   7% 115M/1.55G [00:02<00:27, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   8% 126M/1.55G [00:02<00:27, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   9% 136M/1.55G [00:03<00:29, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:   9% 147M/1.55G [00:03<00:27, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  10% 157M/1.55G [00:03<00:27, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  11% 168M/1.55G [00:03<00:28, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  11% 178M/1.55G [00:03<00:26, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  12% 189M/1.55G [00:04<00:26, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  13% 199M/1.55G [00:04<00:35, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  14% 210M/1.55G [00:04<00:39, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  14% 220M/1.55G [00:05<00:35, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  15% 231M/1.55G [00:05<00:33, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  16% 241M/1.55G [00:05<00:35, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  16% 252M/1.55G [00:05<00:36, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  17% 262M/1.55G [00:06<00:34, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  18% 273M/1.55G [00:06<00:31, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  18% 283M/1.55G [00:06<00:27, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  19% 294M/1.55G [00:06<00:27, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  20% 304M/1.55G [00:07<00:26, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  20% 315M/1.55G [00:07<00:24, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  21% 325M/1.55G [00:07<00:24, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  22% 336M/1.55G [00:07<00:24, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  22% 346M/1.55G [00:07<00:29, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  23% 357M/1.55G [00:08<00:32, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  24% 367M/1.55G [00:08<00:27, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  24% 377M/1.55G [00:08<00:27, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  25% 388M/1.55G [00:08<00:27, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  26% 398M/1.55G [00:09<00:24, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  26% 409M/1.55G [00:09<00:23, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  27% 419M/1.55G [00:09<00:23, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  28% 430M/1.55G [00:09<00:23, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  28% 440M/1.55G [00:10<00:26, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  29% 451M/1.55G [00:10<00:23, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  30% 461M/1.55G [00:10<00:23, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  30% 472M/1.55G [00:10<00:22, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  31% 482M/1.55G [00:10<00:21, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  32% 493M/1.55G [00:11<00:21, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  32% 503M/1.55G [00:11<00:19, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  33% 514M/1.55G [00:11<00:27, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  34% 524M/1.55G [00:11<00:25, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  34% 535M/1.55G [00:12<00:24, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  35% 545M/1.55G [00:12<00:27, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  36% 556M/1.55G [00:12<00:25, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  36% 566M/1.55G [00:12<00:24, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  37% 577M/1.55G [00:13<00:26, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  38% 587M/1.55G [00:13<00:22, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  39% 598M/1.55G [00:13<00:21, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  39% 608M/1.55G [00:14<00:25, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  40% 619M/1.55G [00:14<00:22, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  41% 629M/1.55G [00:14<00:24, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  41% 640M/1.55G [00:14<00:20, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  42% 650M/1.55G [00:15<00:20, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  43% 661M/1.55G [00:15<00:23, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  43% 671M/1.55G [00:15<00:20, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  44% 682M/1.55G [00:15<00:19, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  45% 692M/1.55G [00:15<00:19, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  45% 703M/1.55G [00:16<00:18, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  46% 713M/1.55G [00:16<00:22, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  47% 724M/1.55G [00:16<00:22, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  47% 734M/1.55G [00:17<00:20, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  48% 744M/1.55G [00:17<00:19, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  49% 755M/1.55G [00:17<00:20, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  49% 765M/1.55G [00:17<00:19, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  50% 776M/1.55G [00:18<00:19, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  51% 786M/1.55G [00:18<00:17, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  51% 797M/1.55G [00:18<00:16, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  52% 807M/1.55G [00:18<00:14, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  53% 818M/1.55G [00:18<00:14, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  53% 828M/1.55G [00:19<00:14, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  54% 839M/1.55G [00:19<00:14, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  55% 849M/1.55G [00:19<00:13, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  55% 860M/1.55G [00:19<00:17, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  56% 870M/1.55G [00:20<00:17, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  57% 881M/1.55G [00:20<00:16, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  57% 891M/1.55G [00:20<00:14, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  58% 902M/1.55G [00:20<00:16, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  59% 912M/1.55G [00:21<00:16, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  59% 923M/1.55G [00:21<00:14, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  60% 933M/1.55G [00:21<00:14, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  61% 944M/1.55G [00:21<00:13, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  61% 954M/1.55G [00:22<00:12, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  62% 965M/1.55G [00:22<00:11, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  63% 975M/1.55G [00:22<00:11, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  64% 986M/1.55G [00:22<00:10, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  64% 996M/1.55G [00:22<00:11, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  65% 1.01G/1.55G [00:23<00:11, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  66% 1.02G/1.55G [00:23<00:10, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  66% 1.03G/1.55G [00:23<00:10, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  67% 1.04G/1.55G [00:23<00:09, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  68% 1.05G/1.55G [00:23<00:09, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  68% 1.06G/1.55G [00:24<00:09, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  69% 1.07G/1.55G [00:24<00:08, 54.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  70% 1.08G/1.55G [00:24<00:08, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  70% 1.09G/1.55G [00:24<00:08, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  71% 1.10G/1.55G [00:24<00:08, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  72% 1.11G/1.55G [00:25<00:08, 53.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  72% 1.12G/1.55G [00:25<00:07, 56.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  73% 1.13G/1.55G [00:25<00:07, 53.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  74% 1.14G/1.55G [00:25<00:07, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  74% 1.15G/1.55G [00:26<00:10, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  75% 1.16G/1.55G [00:26<00:09, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  76% 1.17G/1.55G [00:26<00:08, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  76% 1.18G/1.55G [00:26<00:08, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  77% 1.20G/1.55G [00:26<00:07, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  78% 1.21G/1.55G [00:27<00:08, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  78% 1.22G/1.55G [00:27<00:07, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  79% 1.23G/1.55G [00:27<00:06, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  80% 1.24G/1.55G [00:27<00:06, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  80% 1.25G/1.55G [00:28<00:05, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  81% 1.26G/1.55G [00:28<00:05, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  82% 1.27G/1.55G [00:28<00:05, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  82% 1.28G/1.55G [00:28<00:05, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  83% 1.29G/1.55G [00:29<00:06, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  84% 1.31G/1.55G [00:29<00:04, 53.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  85% 1.32G/1.55G [00:29<00:04, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  86% 1.33G/1.55G [00:29<00:04, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  86% 1.34G/1.55G [00:30<00:04, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  87% 1.35G/1.55G [00:30<00:05, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  88% 1.36G/1.55G [00:30<00:05, 33.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  89% 1.37G/1.55G [00:31<00:04, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  89% 1.38G/1.55G [00:31<00:05, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  90% 1.39G/1.55G [00:31<00:04, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  91% 1.41G/1.55G [00:31<00:03, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  91% 1.42G/1.55G [00:32<00:03, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  92% 1.43G/1.55G [00:32<00:02, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  93% 1.44G/1.55G [00:32<00:02, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  93% 1.45G/1.55G [00:32<00:02, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  94% 1.46G/1.55G [00:33<00:02, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  95% 1.47G/1.55G [00:33<00:02, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  95% 1.48G/1.55G [00:33<00:01, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  96% 1.49G/1.55G [00:34<00:01, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  97% 1.50G/1.55G [00:34<00:01, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  97% 1.51G/1.55G [00:34<00:01, 28.7MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  98% 1.52G/1.55G [00:35<00:00, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  99% 1.53G/1.55G [00:35<00:00, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin:  99% 1.54G/1.55G [00:35<00:00, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00005-of-00005.bin: 100% 1.55G/1.55G [00:35<00:00, 43.4MB/s]\n",
      "Downloading shards: 100% 5/5 [13:00<00:00, 156.06s/it]\n",
      "Loading checkpoint shards: 100% 5/5 [00:00<00:00,  6.48it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-16b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:16<01:02,  6.57it/s]04/30/2024 14:31:59 - WARNING - __main__ - epoch 0 step 102 loss 0.35199\n",
      "[[0.06040495]\n",
      " [0.04578882]\n",
      " [0.05590908]\n",
      " ...\n",
      " [0.07298056]\n",
      " [0.06047671]\n",
      " [0.0917248 ]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 14:32:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:32:10 - INFO - __main__ -   auc_score = 0.686\n",
      "04/30/2024 14:32:10 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 14:32:10 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 14:32:10 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [00:43<00:46,  6.58it/s]04/30/2024 14:32:26 - WARNING - __main__ - epoch 0 step 204 loss 0.27684\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.0751413 ]\n",
      " [0.02621211]\n",
      " [0.03687505]\n",
      " ...\n",
      " [0.09177054]\n",
      " [0.0838027 ]\n",
      " [0.13692868]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 14:32:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:32:37 - INFO - __main__ -   auc_score = 0.7683\n",
      "04/30/2024 14:32:37 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 14:32:37 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 14:32:37 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [01:09<00:31,  6.60it/s]04/30/2024 14:32:52 - WARNING - __main__ - epoch 0 step 306 loss 0.27446\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.11083073]\n",
      " [0.01972249]\n",
      " [0.04691996]\n",
      " ...\n",
      " [0.18233034]\n",
      " [0.14482549]\n",
      " [0.20469254]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 14:33:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:33:03 - INFO - __main__ -   auc_score = 0.803\n",
      "04/30/2024 14:33:03 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 14:33:03 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 14:33:03 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [01:36<00:15,  6.60it/s]04/30/2024 14:33:19 - WARNING - __main__ - epoch 0 step 408 loss 0.26863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.1223838 ]\n",
      " [0.01668312]\n",
      " [0.03027844]\n",
      " ...\n",
      " [0.15612301]\n",
      " [0.13809401]\n",
      " [0.22897488]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 14:33:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:33:30 - INFO - __main__ -   auc_score = 0.8093\n",
      "04/30/2024 14:33:30 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 14:33:30 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 14:33:30 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [02:02<00:00,  6.57it/s]04/30/2024 14:33:45 - WARNING - __main__ - epoch 0 step 510 loss 0.24253\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.19398765]\n",
      " [0.02100381]\n",
      " [0.03173939]\n",
      " ...\n",
      " [0.1945405 ]\n",
      " [0.15113406]\n",
      " [0.27832004]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/30/2024 14:33:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:33:56 - INFO - __main__ -   auc_score = 0.8181\n",
      "04/30/2024 14:33:56 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/30/2024 14:33:56 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/30/2024 14:33:56 - INFO - __main__ -   eval_recall = 0.0\n",
      "100% 512/512 [02:13<00:00,  3.82it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 14:34:12 - WARNING - __main__ - epoch 1 step 102 loss 0.25302\n",
      "[[0.41033837]\n",
      " [0.02892501]\n",
      " [0.03630851]\n",
      " ...\n",
      " [0.3164949 ]\n",
      " [0.30857387]\n",
      " [0.44642624]]\n",
      "04/30/2024 14:34:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:34:23 - INFO - __main__ -   auc_score = 0.8249\n",
      "04/30/2024 14:34:23 - INFO - __main__ -   eval_f1 = 0.0814\n",
      "04/30/2024 14:34:23 - INFO - __main__ -   eval_precision = 0.4286\n",
      "04/30/2024 14:34:23 - INFO - __main__ -   eval_recall = 0.045\n",
      " 40% 203/512 [00:42<00:46,  6.58it/s]04/30/2024 14:34:39 - WARNING - __main__ - epoch 1 step 204 loss 0.23141\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.35146987]\n",
      " [0.02704509]\n",
      " [0.03473947]\n",
      " ...\n",
      " [0.25565085]\n",
      " [0.25006697]\n",
      " [0.3582534 ]]\n",
      "04/30/2024 14:34:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:34:50 - INFO - __main__ -   auc_score = 0.8317\n",
      "04/30/2024 14:34:50 - INFO - __main__ -   eval_f1 = 0.0492\n",
      "04/30/2024 14:34:50 - INFO - __main__ -   eval_precision = 0.5714\n",
      "04/30/2024 14:34:50 - INFO - __main__ -   eval_recall = 0.0257\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 14:35:05 - WARNING - __main__ - epoch 1 step 306 loss 0.24598\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.37643254]\n",
      " [0.0456341 ]\n",
      " [0.04365694]\n",
      " ...\n",
      " [0.3314234 ]\n",
      " [0.24533947]\n",
      " [0.33071795]]\n",
      "04/30/2024 14:35:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:35:16 - INFO - __main__ -   auc_score = 0.8366\n",
      "04/30/2024 14:35:16 - INFO - __main__ -   eval_f1 = 0.0211\n",
      "04/30/2024 14:35:16 - INFO - __main__ -   eval_precision = 0.625\n",
      "04/30/2024 14:35:16 - INFO - __main__ -   eval_recall = 0.0107\n",
      " 79% 407/512 [01:35<00:15,  6.60it/s]04/30/2024 14:35:32 - WARNING - __main__ - epoch 1 step 408 loss 0.23346\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.42522046]\n",
      " [0.04222975]\n",
      " [0.04565831]\n",
      " ...\n",
      " [0.45076516]\n",
      " [0.28543815]\n",
      " [0.3463181 ]]\n",
      "04/30/2024 14:35:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:35:43 - INFO - __main__ -   auc_score = 0.8403\n",
      "04/30/2024 14:35:43 - INFO - __main__ -   eval_f1 = 0.1429\n",
      "04/30/2024 14:35:43 - INFO - __main__ -   eval_precision = 0.5846\n",
      "04/30/2024 14:35:43 - INFO - __main__ -   eval_recall = 0.0814\n",
      " 99% 509/512 [02:02<00:00,  6.59it/s]04/30/2024 14:35:59 - WARNING - __main__ - epoch 1 step 510 loss 0.22874\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.4220674 ]\n",
      " [0.03871477]\n",
      " [0.04544458]\n",
      " ...\n",
      " [0.401852  ]\n",
      " [0.22014034]\n",
      " [0.29785314]]\n",
      "04/30/2024 14:36:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:36:10 - INFO - __main__ -   auc_score = 0.8445\n",
      "04/30/2024 14:36:10 - INFO - __main__ -   eval_f1 = 0.0792\n",
      "04/30/2024 14:36:10 - INFO - __main__ -   eval_precision = 0.5263\n",
      "04/30/2024 14:36:10 - INFO - __main__ -   eval_recall = 0.0428\n",
      "100% 512/512 [02:14<00:00,  3.82it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.61it/s]04/30/2024 14:36:26 - WARNING - __main__ - epoch 2 step 102 loss 0.2327\n",
      "[[0.641461  ]\n",
      " [0.10609908]\n",
      " [0.11678312]\n",
      " ...\n",
      " [0.61704504]\n",
      " [0.46618548]\n",
      " [0.5082717 ]]\n",
      "04/30/2024 14:36:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:36:37 - INFO - __main__ -   auc_score = 0.8478\n",
      "04/30/2024 14:36:37 - INFO - __main__ -   eval_f1 = 0.2908\n",
      "04/30/2024 14:36:37 - INFO - __main__ -   eval_precision = 0.4046\n",
      "04/30/2024 14:36:37 - INFO - __main__ -   eval_recall = 0.227\n",
      " 40% 203/512 [00:42<00:46,  6.59it/s]04/30/2024 14:36:53 - WARNING - __main__ - epoch 2 step 204 loss 0.22564\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.3768074 ]\n",
      " [0.0299842 ]\n",
      " [0.02550898]\n",
      " ...\n",
      " [0.29739898]\n",
      " [0.15813735]\n",
      " [0.2411269 ]]\n",
      "04/30/2024 14:37:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:37:04 - INFO - __main__ -   auc_score = 0.8451\n",
      "04/30/2024 14:37:04 - INFO - __main__ -   eval_f1 = 0.0374\n",
      "04/30/2024 14:37:04 - INFO - __main__ -   eval_precision = 0.6429\n",
      "04/30/2024 14:37:04 - INFO - __main__ -   eval_recall = 0.0193\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 14:37:19 - WARNING - __main__ - epoch 2 step 306 loss 0.21909\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.59063363]\n",
      " [0.05792559]\n",
      " [0.05457103]\n",
      " ...\n",
      " [0.44591546]\n",
      " [0.3050633 ]\n",
      " [0.37924576]]\n",
      "04/30/2024 14:37:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:37:30 - INFO - __main__ -   auc_score = 0.8493\n",
      "04/30/2024 14:37:30 - INFO - __main__ -   eval_f1 = 0.1735\n",
      "04/30/2024 14:37:30 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/30/2024 14:37:30 - INFO - __main__ -   eval_recall = 0.1049\n",
      " 79% 407/512 [01:35<00:15,  6.60it/s]04/30/2024 14:37:46 - WARNING - __main__ - epoch 2 step 408 loss 0.21771\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6569363 ]\n",
      " [0.07378933]\n",
      " [0.04891599]\n",
      " ...\n",
      " [0.45284963]\n",
      " [0.30442038]\n",
      " [0.45068428]]\n",
      "04/30/2024 14:37:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:37:57 - INFO - __main__ -   auc_score = 0.8509\n",
      "04/30/2024 14:37:57 - INFO - __main__ -   eval_f1 = 0.19\n",
      "04/30/2024 14:37:57 - INFO - __main__ -   eval_precision = 0.4911\n",
      "04/30/2024 14:37:57 - INFO - __main__ -   eval_recall = 0.1178\n",
      " 99% 509/512 [02:01<00:00,  6.54it/s]04/30/2024 14:38:12 - WARNING - __main__ - epoch 2 step 510 loss 0.23224\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7056758 ]\n",
      " [0.14965424]\n",
      " [0.0961052 ]\n",
      " ...\n",
      " [0.5558212 ]\n",
      " [0.36200503]\n",
      " [0.48969987]]\n",
      "04/30/2024 14:38:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:38:23 - INFO - __main__ -   auc_score = 0.854\n",
      "04/30/2024 14:38:23 - INFO - __main__ -   eval_f1 = 0.2655\n",
      "04/30/2024 14:38:23 - INFO - __main__ -   eval_precision = 0.449\n",
      "04/30/2024 14:38:23 - INFO - __main__ -   eval_recall = 0.1884\n",
      "100% 512/512 [02:13<00:00,  3.84it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.58it/s]04/30/2024 14:38:39 - WARNING - __main__ - epoch 3 step 102 loss 0.21653\n",
      "[[0.49669656]\n",
      " [0.06859889]\n",
      " [0.03898284]\n",
      " ...\n",
      " [0.35762566]\n",
      " [0.17746471]\n",
      " [0.27077937]]\n",
      "04/30/2024 14:38:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:38:50 - INFO - __main__ -   auc_score = 0.8545\n",
      "04/30/2024 14:38:50 - INFO - __main__ -   eval_f1 = 0.1399\n",
      "04/30/2024 14:38:50 - INFO - __main__ -   eval_precision = 0.5968\n",
      "04/30/2024 14:38:50 - INFO - __main__ -   eval_recall = 0.0792\n",
      " 40% 203/512 [00:41<00:47,  6.54it/s]04/30/2024 14:39:05 - WARNING - __main__ - epoch 3 step 204 loss 0.21537\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.74878293]\n",
      " [0.14671366]\n",
      " [0.07756273]\n",
      " ...\n",
      " [0.6424492 ]\n",
      " [0.44639185]\n",
      " [0.6679143 ]]\n",
      "04/30/2024 14:39:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:39:16 - INFO - __main__ -   auc_score = 0.8559\n",
      "04/30/2024 14:39:16 - INFO - __main__ -   eval_f1 = 0.3293\n",
      "04/30/2024 14:39:16 - INFO - __main__ -   eval_precision = 0.4336\n",
      "04/30/2024 14:39:16 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 60% 305/512 [01:09<00:31,  6.59it/s]04/30/2024 14:39:33 - WARNING - __main__ - epoch 3 step 306 loss 0.21928\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5649238 ]\n",
      " [0.05028382]\n",
      " [0.04049704]\n",
      " ...\n",
      " [0.39350748]\n",
      " [0.22021158]\n",
      " [0.4181013 ]]\n",
      "04/30/2024 14:39:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:39:44 - INFO - __main__ -   auc_score = 0.8569\n",
      "04/30/2024 14:39:44 - INFO - __main__ -   eval_f1 = 0.1648\n",
      "04/30/2024 14:39:44 - INFO - __main__ -   eval_precision = 0.5696\n",
      "04/30/2024 14:39:44 - INFO - __main__ -   eval_recall = 0.0964\n",
      " 79% 407/512 [01:35<00:15,  6.58it/s]04/30/2024 14:39:59 - WARNING - __main__ - epoch 3 step 408 loss 0.21779\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.67813206]\n",
      " [0.09587911]\n",
      " [0.04621715]\n",
      " ...\n",
      " [0.41183808]\n",
      " [0.30283666]\n",
      " [0.5573341 ]]\n",
      "04/30/2024 14:40:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:40:10 - INFO - __main__ -   auc_score = 0.8568\n",
      "04/30/2024 14:40:10 - INFO - __main__ -   eval_f1 = 0.2044\n",
      "04/30/2024 14:40:10 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/30/2024 14:40:10 - INFO - __main__ -   eval_recall = 0.1285\n",
      " 99% 509/512 [02:01<00:00,  6.61it/s]04/30/2024 14:40:26 - WARNING - __main__ - epoch 3 step 510 loss 0.21977\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.51386184]\n",
      " [0.1071135 ]\n",
      " [0.06680859]\n",
      " ...\n",
      " [0.3784272 ]\n",
      " [0.23788291]\n",
      " [0.48233664]]\n",
      "04/30/2024 14:40:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:40:37 - INFO - __main__ -   auc_score = 0.8604\n",
      "04/30/2024 14:40:37 - INFO - __main__ -   eval_f1 = 0.163\n",
      "04/30/2024 14:40:37 - INFO - __main__ -   eval_precision = 0.5294\n",
      "04/30/2024 14:40:37 - INFO - __main__ -   eval_recall = 0.0964\n",
      "100% 512/512 [02:13<00:00,  3.84it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.57it/s]04/30/2024 14:40:52 - WARNING - __main__ - epoch 4 step 102 loss 0.20019\n",
      "[[0.64066064]\n",
      " [0.12330893]\n",
      " [0.07525326]\n",
      " ...\n",
      " [0.4833213 ]\n",
      " [0.26738775]\n",
      " [0.5838377 ]]\n",
      "04/30/2024 14:41:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:41:03 - INFO - __main__ -   auc_score = 0.8604\n",
      "04/30/2024 14:41:03 - INFO - __main__ -   eval_f1 = 0.3228\n",
      "04/30/2024 14:41:03 - INFO - __main__ -   eval_precision = 0.4934\n",
      "04/30/2024 14:41:03 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 40% 203/512 [00:41<00:46,  6.59it/s]04/30/2024 14:41:19 - WARNING - __main__ - epoch 4 step 204 loss 0.21075\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.67159605]\n",
      " [0.12474709]\n",
      " [0.07126471]\n",
      " ...\n",
      " [0.45184815]\n",
      " [0.30254057]\n",
      " [0.56104285]]\n",
      "04/30/2024 14:41:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:41:30 - INFO - __main__ -   auc_score = 0.8575\n",
      "04/30/2024 14:41:30 - INFO - __main__ -   eval_f1 = 0.2469\n",
      "04/30/2024 14:41:30 - INFO - __main__ -   eval_precision = 0.4566\n",
      "04/30/2024 14:41:30 - INFO - __main__ -   eval_recall = 0.1692\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 14:41:45 - WARNING - __main__ - epoch 4 step 306 loss 0.21357\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65445125]\n",
      " [0.09871891]\n",
      " [0.06896857]\n",
      " ...\n",
      " [0.49616876]\n",
      " [0.31247175]\n",
      " [0.5325445 ]]\n",
      "04/30/2024 14:41:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:41:56 - INFO - __main__ -   auc_score = 0.8579\n",
      "04/30/2024 14:41:56 - INFO - __main__ -   eval_f1 = 0.2823\n",
      "04/30/2024 14:41:56 - INFO - __main__ -   eval_precision = 0.4724\n",
      "04/30/2024 14:41:56 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 79% 407/512 [01:34<00:15,  6.60it/s]04/30/2024 14:42:11 - WARNING - __main__ - epoch 4 step 408 loss 0.20757\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7121716 ]\n",
      " [0.15355626]\n",
      " [0.07777246]\n",
      " ...\n",
      " [0.5975553 ]\n",
      " [0.32755628]\n",
      " [0.613417  ]]\n",
      "04/30/2024 14:42:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:42:22 - INFO - __main__ -   auc_score = 0.859\n",
      "04/30/2024 14:42:22 - INFO - __main__ -   eval_f1 = 0.3073\n",
      "04/30/2024 14:42:22 - INFO - __main__ -   eval_precision = 0.4418\n",
      "04/30/2024 14:42:22 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 99% 509/512 [02:00<00:00,  6.61it/s]04/30/2024 14:42:38 - WARNING - __main__ - epoch 4 step 510 loss 0.21071\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.70008916]\n",
      " [0.14786509]\n",
      " [0.0725501 ]\n",
      " ...\n",
      " [0.6273507 ]\n",
      " [0.34114206]\n",
      " [0.60898715]]\n",
      "04/30/2024 14:42:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:42:49 - INFO - __main__ -   auc_score = 0.8607\n",
      "04/30/2024 14:42:49 - INFO - __main__ -   eval_f1 = 0.3035\n",
      "04/30/2024 14:42:49 - INFO - __main__ -   eval_precision = 0.4496\n",
      "04/30/2024 14:42:49 - INFO - __main__ -   eval_recall = 0.2291\n",
      "100% 512/512 [02:12<00:00,  3.87it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 14:43:05 - WARNING - __main__ - epoch 5 step 102 loss 0.20551\n",
      "[[0.77113426]\n",
      " [0.23302224]\n",
      " [0.09944699]\n",
      " ...\n",
      " [0.66249675]\n",
      " [0.4918316 ]\n",
      " [0.69075286]]\n",
      "04/30/2024 14:43:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:43:16 - INFO - __main__ -   auc_score = 0.8614\n",
      "04/30/2024 14:43:16 - INFO - __main__ -   eval_f1 = 0.3755\n",
      "04/30/2024 14:43:16 - INFO - __main__ -   eval_precision = 0.4397\n",
      "04/30/2024 14:43:16 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 40% 203/512 [00:42<00:46,  6.59it/s]04/30/2024 14:43:32 - WARNING - __main__ - epoch 5 step 204 loss 0.20292\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7787229 ]\n",
      " [0.23131922]\n",
      " [0.10518584]\n",
      " ...\n",
      " [0.6817924 ]\n",
      " [0.38097507]\n",
      " [0.6118443 ]]\n",
      "04/30/2024 14:43:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:43:43 - INFO - __main__ -   auc_score = 0.8612\n",
      "04/30/2024 14:43:43 - INFO - __main__ -   eval_f1 = 0.3516\n",
      "04/30/2024 14:43:43 - INFO - __main__ -   eval_precision = 0.4485\n",
      "04/30/2024 14:43:43 - INFO - __main__ -   eval_recall = 0.2891\n",
      " 60% 305/512 [01:09<00:31,  6.59it/s]04/30/2024 14:43:58 - WARNING - __main__ - epoch 5 step 306 loss 0.19381\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8035992 ]\n",
      " [0.1752802 ]\n",
      " [0.09115095]\n",
      " ...\n",
      " [0.6729393 ]\n",
      " [0.38614964]\n",
      " [0.630462  ]]\n",
      "04/30/2024 14:44:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:44:09 - INFO - __main__ -   auc_score = 0.8591\n",
      "04/30/2024 14:44:09 - INFO - __main__ -   eval_f1 = 0.3578\n",
      "04/30/2024 14:44:09 - INFO - __main__ -   eval_precision = 0.4484\n",
      "04/30/2024 14:44:09 - INFO - __main__ -   eval_recall = 0.2976\n",
      " 79% 407/512 [01:35<00:15,  6.59it/s]04/30/2024 14:44:25 - WARNING - __main__ - epoch 5 step 408 loss 0.20673\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7917063 ]\n",
      " [0.1942647 ]\n",
      " [0.09177636]\n",
      " ...\n",
      " [0.69647735]\n",
      " [0.26818737]\n",
      " [0.53541106]]\n",
      "04/30/2024 14:44:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:44:36 - INFO - __main__ -   auc_score = 0.8614\n",
      "04/30/2024 14:44:36 - INFO - __main__ -   eval_f1 = 0.3724\n",
      "04/30/2024 14:44:36 - INFO - __main__ -   eval_precision = 0.4606\n",
      "04/30/2024 14:44:36 - INFO - __main__ -   eval_recall = 0.3126\n",
      " 99% 509/512 [02:01<00:00,  6.59it/s]04/30/2024 14:44:51 - WARNING - __main__ - epoch 5 step 510 loss 0.21337\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6741122 ]\n",
      " [0.15902321]\n",
      " [0.05962575]\n",
      " ...\n",
      " [0.53581333]\n",
      " [0.1862265 ]\n",
      " [0.47835368]]\n",
      "04/30/2024 14:45:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:45:02 - INFO - __main__ -   auc_score = 0.8593\n",
      "04/30/2024 14:45:02 - INFO - __main__ -   eval_f1 = 0.2671\n",
      "04/30/2024 14:45:02 - INFO - __main__ -   eval_precision = 0.4583\n",
      "04/30/2024 14:45:02 - INFO - __main__ -   eval_recall = 0.1884\n",
      "100% 512/512 [02:13<00:00,  3.84it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 14:45:18 - WARNING - __main__ - epoch 6 step 102 loss 0.18899\n",
      "[[0.7838152 ]\n",
      " [0.21007363]\n",
      " [0.07794067]\n",
      " ...\n",
      " [0.6788772 ]\n",
      " [0.2658753 ]\n",
      " [0.4995289 ]]\n",
      "04/30/2024 14:45:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:45:29 - INFO - __main__ -   auc_score = 0.8578\n",
      "04/30/2024 14:45:29 - INFO - __main__ -   eval_f1 = 0.3726\n",
      "04/30/2024 14:45:29 - INFO - __main__ -   eval_precision = 0.4706\n",
      "04/30/2024 14:45:29 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [00:41<00:46,  6.60it/s]04/30/2024 14:45:44 - WARNING - __main__ - epoch 6 step 204 loss 0.20093\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.8190924 ]\n",
      " [0.26316476]\n",
      " [0.09164726]\n",
      " ...\n",
      " [0.72379494]\n",
      " [0.40918761]\n",
      " [0.646159  ]]\n",
      "04/30/2024 14:45:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:45:55 - INFO - __main__ -   auc_score = 0.8572\n",
      "04/30/2024 14:45:55 - INFO - __main__ -   eval_f1 = 0.4052\n",
      "04/30/2024 14:45:55 - INFO - __main__ -   eval_precision = 0.447\n",
      "04/30/2024 14:45:55 - INFO - __main__ -   eval_recall = 0.3704\n",
      " 60% 305/512 [01:08<00:31,  6.60it/s]04/30/2024 14:46:11 - WARNING - __main__ - epoch 6 step 306 loss 0.19819\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7971174 ]\n",
      " [0.24918373]\n",
      " [0.11104348]\n",
      " ...\n",
      " [0.72041774]\n",
      " [0.46607333]\n",
      " [0.7172074 ]]\n",
      "04/30/2024 14:46:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:46:23 - INFO - __main__ -   auc_score = 0.8584\n",
      "04/30/2024 14:46:23 - INFO - __main__ -   eval_f1 = 0.3963\n",
      "04/30/2024 14:46:23 - INFO - __main__ -   eval_precision = 0.4318\n",
      "04/30/2024 14:46:23 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 79% 407/512 [01:35<00:15,  6.59it/s]04/30/2024 14:46:38 - WARNING - __main__ - epoch 6 step 408 loss 0.20321\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.64780915]\n",
      " [0.12204833]\n",
      " [0.07601956]\n",
      " ...\n",
      " [0.57379293]\n",
      " [0.2382807 ]\n",
      " [0.6072788 ]]\n",
      "04/30/2024 14:46:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:46:49 - INFO - __main__ -   auc_score = 0.8584\n",
      "04/30/2024 14:46:49 - INFO - __main__ -   eval_f1 = 0.3099\n",
      "04/30/2024 14:46:49 - INFO - __main__ -   eval_precision = 0.4527\n",
      "04/30/2024 14:46:49 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 99% 509/512 [02:01<00:00,  6.53it/s]04/30/2024 14:47:04 - WARNING - __main__ - epoch 6 step 510 loss 0.193\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7758441 ]\n",
      " [0.19657956]\n",
      " [0.09512592]\n",
      " ...\n",
      " [0.71789545]\n",
      " [0.36909175]\n",
      " [0.68611866]]\n",
      "04/30/2024 14:47:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:47:15 - INFO - __main__ -   auc_score = 0.86\n",
      "04/30/2024 14:47:15 - INFO - __main__ -   eval_f1 = 0.4\n",
      "04/30/2024 14:47:15 - INFO - __main__ -   eval_precision = 0.4347\n",
      "04/30/2024 14:47:15 - INFO - __main__ -   eval_recall = 0.3704\n",
      "100% 512/512 [02:13<00:00,  3.84it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.56it/s]04/30/2024 14:47:31 - WARNING - __main__ - epoch 7 step 102 loss 0.20471\n",
      "[[0.61254233]\n",
      " [0.11412687]\n",
      " [0.07301426]\n",
      " ...\n",
      " [0.5216009 ]\n",
      " [0.2793199 ]\n",
      " [0.50064147]]\n",
      "04/30/2024 14:47:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:47:42 - INFO - __main__ -   auc_score = 0.8573\n",
      "04/30/2024 14:47:42 - INFO - __main__ -   eval_f1 = 0.3126\n",
      "04/30/2024 14:47:42 - INFO - __main__ -   eval_precision = 0.4414\n",
      "04/30/2024 14:47:42 - INFO - __main__ -   eval_recall = 0.242\n",
      " 40% 203/512 [00:41<00:46,  6.59it/s]04/30/2024 14:47:58 - WARNING - __main__ - epoch 7 step 204 loss 0.18128\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.47668126]\n",
      " [0.06816504]\n",
      " [0.06314088]\n",
      " ...\n",
      " [0.5399346 ]\n",
      " [0.19207798]\n",
      " [0.40963545]]\n",
      "04/30/2024 14:48:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:48:09 - INFO - __main__ -   auc_score = 0.8567\n",
      "04/30/2024 14:48:09 - INFO - __main__ -   eval_f1 = 0.2886\n",
      "04/30/2024 14:48:09 - INFO - __main__ -   eval_precision = 0.4521\n",
      "04/30/2024 14:48:09 - INFO - __main__ -   eval_recall = 0.212\n",
      " 60% 305/512 [01:08<00:31,  6.58it/s]04/30/2024 14:48:24 - WARNING - __main__ - epoch 7 step 306 loss 0.19326\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.69811034]\n",
      " [0.12990521]\n",
      " [0.07522012]\n",
      " ...\n",
      " [0.60509956]\n",
      " [0.27470782]\n",
      " [0.58772033]]\n",
      "04/30/2024 14:48:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:48:35 - INFO - __main__ -   auc_score = 0.8583\n",
      "04/30/2024 14:48:35 - INFO - __main__ -   eval_f1 = 0.3453\n",
      "04/30/2024 14:48:35 - INFO - __main__ -   eval_precision = 0.4545\n",
      "04/30/2024 14:48:35 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 79% 407/512 [01:34<00:15,  6.60it/s]04/30/2024 14:48:50 - WARNING - __main__ - epoch 7 step 408 loss 0.20198\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.71428156]\n",
      " [0.18695067]\n",
      " [0.07542992]\n",
      " ...\n",
      " [0.59714967]\n",
      " [0.3344868 ]\n",
      " [0.63081855]]\n",
      "04/30/2024 14:49:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:49:01 - INFO - __main__ -   auc_score = 0.8581\n",
      "04/30/2024 14:49:01 - INFO - __main__ -   eval_f1 = 0.3724\n",
      "04/30/2024 14:49:01 - INFO - __main__ -   eval_precision = 0.439\n",
      "04/30/2024 14:49:01 - INFO - __main__ -   eval_recall = 0.3233\n",
      " 99% 509/512 [02:00<00:00,  6.62it/s]04/30/2024 14:49:17 - WARNING - __main__ - epoch 7 step 510 loss 0.18414\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.66934216]\n",
      " [0.14058702]\n",
      " [0.06994851]\n",
      " ...\n",
      " [0.5938263 ]\n",
      " [0.28848234]\n",
      " [0.5634154 ]]\n",
      "04/30/2024 14:49:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:49:28 - INFO - __main__ -   auc_score = 0.8577\n",
      "04/30/2024 14:49:28 - INFO - __main__ -   eval_f1 = 0.3451\n",
      "04/30/2024 14:49:28 - INFO - __main__ -   eval_precision = 0.443\n",
      "04/30/2024 14:49:28 - INFO - __main__ -   eval_recall = 0.2827\n",
      "100% 512/512 [02:12<00:00,  3.87it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.55it/s]04/30/2024 14:49:43 - WARNING - __main__ - epoch 8 step 102 loss 0.18226\n",
      "[[0.7184298 ]\n",
      " [0.15616828]\n",
      " [0.07810762]\n",
      " ...\n",
      " [0.6371668 ]\n",
      " [0.37832677]\n",
      " [0.57438135]]\n",
      "04/30/2024 14:49:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:49:54 - INFO - __main__ -   auc_score = 0.8584\n",
      "04/30/2024 14:49:54 - INFO - __main__ -   eval_f1 = 0.3873\n",
      "04/30/2024 14:49:54 - INFO - __main__ -   eval_precision = 0.4492\n",
      "04/30/2024 14:49:54 - INFO - __main__ -   eval_recall = 0.3405\n",
      " 40% 203/512 [00:41<00:47,  6.52it/s]04/30/2024 14:50:10 - WARNING - __main__ - epoch 8 step 204 loss 0.19364\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.72526973]\n",
      " [0.16155314]\n",
      " [0.07273002]\n",
      " ...\n",
      " [0.6275103 ]\n",
      " [0.42475522]\n",
      " [0.57985926]]\n",
      "04/30/2024 14:50:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:50:21 - INFO - __main__ -   auc_score = 0.8585\n",
      "04/30/2024 14:50:21 - INFO - __main__ -   eval_f1 = 0.3759\n",
      "04/30/2024 14:50:21 - INFO - __main__ -   eval_precision = 0.4409\n",
      "04/30/2024 14:50:21 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 14:50:36 - WARNING - __main__ - epoch 8 step 306 loss 0.19535\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.7107865 ]\n",
      " [0.14084756]\n",
      " [0.07128871]\n",
      " ...\n",
      " [0.57923764]\n",
      " [0.37740323]\n",
      " [0.5453727 ]]\n",
      "04/30/2024 14:50:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:50:47 - INFO - __main__ -   auc_score = 0.8583\n",
      "04/30/2024 14:50:47 - INFO - __main__ -   eval_f1 = 0.3602\n",
      "04/30/2024 14:50:47 - INFO - __main__ -   eval_precision = 0.4462\n",
      "04/30/2024 14:50:47 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 79% 407/512 [01:34<00:15,  6.60it/s]04/30/2024 14:51:03 - WARNING - __main__ - epoch 8 step 408 loss 0.19173\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6660932 ]\n",
      " [0.12514919]\n",
      " [0.07675765]\n",
      " ...\n",
      " [0.49235865]\n",
      " [0.34923092]\n",
      " [0.5270424 ]]\n",
      "04/30/2024 14:51:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:51:14 - INFO - __main__ -   auc_score = 0.8572\n",
      "04/30/2024 14:51:14 - INFO - __main__ -   eval_f1 = 0.3364\n",
      "04/30/2024 14:51:14 - INFO - __main__ -   eval_precision = 0.43\n",
      "04/30/2024 14:51:14 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 99% 509/512 [02:00<00:00,  6.59it/s]04/30/2024 14:51:29 - WARNING - __main__ - epoch 8 step 510 loss 0.18334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.68704623]\n",
      " [0.13401908]\n",
      " [0.08477391]\n",
      " ...\n",
      " [0.5462659 ]\n",
      " [0.39314532]\n",
      " [0.5684283 ]]\n",
      "04/30/2024 14:51:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:51:40 - INFO - __main__ -   auc_score = 0.8568\n",
      "04/30/2024 14:51:40 - INFO - __main__ -   eval_f1 = 0.3829\n",
      "04/30/2024 14:51:40 - INFO - __main__ -   eval_precision = 0.4448\n",
      "04/30/2024 14:51:40 - INFO - __main__ -   eval_recall = 0.3362\n",
      "100% 512/512 [02:12<00:00,  3.87it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 101/512 [00:15<01:02,  6.60it/s]04/30/2024 14:51:56 - WARNING - __main__ - epoch 9 step 102 loss 0.19119\n",
      "[[0.68591493]\n",
      " [0.11725594]\n",
      " [0.07995543]\n",
      " ...\n",
      " [0.503069  ]\n",
      " [0.38608465]\n",
      " [0.56264937]]\n",
      "04/30/2024 14:52:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:52:07 - INFO - __main__ -   auc_score = 0.8564\n",
      "04/30/2024 14:52:07 - INFO - __main__ -   eval_f1 = 0.3537\n",
      "04/30/2024 14:52:07 - INFO - __main__ -   eval_precision = 0.4357\n",
      "04/30/2024 14:52:07 - INFO - __main__ -   eval_recall = 0.2976\n",
      " 40% 203/512 [00:41<00:46,  6.59it/s]04/30/2024 14:52:22 - WARNING - __main__ - epoch 9 step 204 loss 0.18716\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.62547624]\n",
      " [0.08938776]\n",
      " [0.07304765]\n",
      " ...\n",
      " [0.48768085]\n",
      " [0.36746925]\n",
      " [0.5489783 ]]\n",
      "04/30/2024 14:52:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:52:33 - INFO - __main__ -   auc_score = 0.8559\n",
      "04/30/2024 14:52:33 - INFO - __main__ -   eval_f1 = 0.3493\n",
      "04/30/2024 14:52:33 - INFO - __main__ -   eval_precision = 0.4412\n",
      "04/30/2024 14:52:33 - INFO - __main__ -   eval_recall = 0.2891\n",
      " 60% 305/512 [01:08<00:31,  6.59it/s]04/30/2024 14:52:48 - WARNING - __main__ - epoch 9 step 306 loss 0.18808\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6614569 ]\n",
      " [0.10817697]\n",
      " [0.08244435]\n",
      " ...\n",
      " [0.5468772 ]\n",
      " [0.3947925 ]\n",
      " [0.5761033 ]]\n",
      "04/30/2024 14:52:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:52:59 - INFO - __main__ -   auc_score = 0.8558\n",
      "04/30/2024 14:52:59 - INFO - __main__ -   eval_f1 = 0.362\n",
      "04/30/2024 14:52:59 - INFO - __main__ -   eval_precision = 0.4341\n",
      "04/30/2024 14:52:59 - INFO - __main__ -   eval_recall = 0.3105\n",
      " 79% 407/512 [01:34<00:15,  6.62it/s]04/30/2024 14:53:15 - WARNING - __main__ - epoch 9 step 408 loss 0.19065\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.66459024]\n",
      " [0.11336398]\n",
      " [0.08251609]\n",
      " ...\n",
      " [0.54311067]\n",
      " [0.3863219 ]\n",
      " [0.5548233 ]]\n",
      "04/30/2024 14:53:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:53:26 - INFO - __main__ -   auc_score = 0.856\n",
      "04/30/2024 14:53:26 - INFO - __main__ -   eval_f1 = 0.3597\n",
      "04/30/2024 14:53:26 - INFO - __main__ -   eval_precision = 0.436\n",
      "04/30/2024 14:53:26 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 99% 509/512 [02:00<00:00,  6.59it/s]04/30/2024 14:53:41 - WARNING - __main__ - epoch 9 step 510 loss 0.17208\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6402562 ]\n",
      " [0.10449107]\n",
      " [0.07824163]\n",
      " ...\n",
      " [0.51135963]\n",
      " [0.35885286]\n",
      " [0.5302474 ]]\n",
      "04/30/2024 14:53:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/30/2024 14:53:52 - INFO - __main__ -   auc_score = 0.8557\n",
      "04/30/2024 14:53:52 - INFO - __main__ -   eval_f1 = 0.3441\n",
      "04/30/2024 14:53:52 - INFO - __main__ -   eval_precision = 0.4346\n",
      "04/30/2024 14:53:52 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [02:12<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-16b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-16b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5viRgVwCyceg",
    "outputId": "d6ec745d-43e5-4f9b-e945-34056454f53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using a model of type codet5p to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100% 5/5 [00:00<00:00,  6.20it/s]\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5p-16b and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "trainable params: 2,359,296 || all params: 72,169,472 || trainable%: 3.269105252702971\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/30/2024 16:16:22 - INFO - __main__ - ***** Test results *****\n",
      "04/30/2024 16:16:22 - INFO - __main__ -   auc_score = 0.8323\n",
      "04/30/2024 16:16:22 - INFO - __main__ -   test_f1 = 0.3506\n",
      "04/30/2024 16:16:22 - INFO - __main__ -   test_precision = 0.3973\n",
      "04/30/2024 16:16:22 - INFO - __main__ -   test_recall = 0.3137\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-16b/single/checkpoints \\\n",
    "   --pretrained_model codet5p-16b \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --hidden_size 512 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpAOQvRELToW"
   },
   "source": [
    "### Learning rate optimization for the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_p4mUZbXRuw"
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCkAoHe9wmj8"
   },
   "source": [
    "#### LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7CJEI04K2tA",
    "outputId": "1cb007cf-51e1-4f55-d4ae-768b1bacea68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:35,  1.14s/it]04/27/2024 01:51:28 - WARNING - __main__ - epoch 0 step 204 loss 0.31294\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 01:53:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 01:53:34 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 01:53:34 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 01:53:34 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 01:55:40 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 01:55:40 - INFO - __main__ -   auc_score = 0.5752\n",
      "04/27/2024 01:55:40 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 01:55:40 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 01:55:40 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 407/1024 [11:55<11:43,  1.14s/it]04/27/2024 01:59:31 - WARNING - __main__ - epoch 0 step 408 loss 0.31276\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:01:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:01:37 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 02:01:37 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 02:01:37 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:03:43 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:03:43 - INFO - __main__ -   auc_score = 0.659\n",
      "04/27/2024 02:03:43 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 02:03:43 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 02:03:43 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 611/1024 [19:59<07:51,  1.14s/it]04/27/2024 02:07:35 - WARNING - __main__ - epoch 0 step 612 loss 0.28573\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:09:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:09:41 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 02:09:41 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 02:09:41 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:11:47 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:11:47 - INFO - __main__ -   auc_score = 0.7806\n",
      "04/27/2024 02:11:47 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 02:11:47 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 02:11:47 - INFO - __main__ -   test_recall = 0.0\n",
      " 80% 815/1024 [28:02<03:58,  1.14s/it]04/27/2024 02:15:39 - WARNING - __main__ - epoch 0 step 816 loss 0.2703\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:17:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:17:45 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 02:17:45 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 02:17:45 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:19:50 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:19:50 - INFO - __main__ -   auc_score = 0.818\n",
      "04/27/2024 02:19:50 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 02:19:50 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 02:19:50 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 1019/1024 [36:05<00:05,  1.14s/it]04/27/2024 02:23:42 - WARNING - __main__ - epoch 0 step 1020 loss 0.26144\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:25:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:25:48 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 02:25:48 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 02:25:48 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:27:53 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:27:53 - INFO - __main__ -   auc_score = 0.8193\n",
      "04/27/2024 02:27:53 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 02:27:53 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 02:27:53 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 1024/1024 [40:21<00:00,  2.36s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/27/2024 02:31:49 - WARNING - __main__ - epoch 1 step 204 loss 0.24125\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:33:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:33:55 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 02:33:55 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 02:33:55 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 02:36:01 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:36:01 - INFO - __main__ -   auc_score = 0.7969\n",
      "04/27/2024 02:36:01 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 02:36:01 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 02:36:01 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 407/1024 [11:54<11:43,  1.14s/it]04/27/2024 02:39:52 - WARNING - __main__ - epoch 1 step 408 loss 0.23686\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 02:41:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:41:58 - INFO - __main__ -   eval_f1 = 0.0294\n",
      "04/27/2024 02:41:58 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/27/2024 02:41:58 - INFO - __main__ -   eval_recall = 0.015\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 02:44:16 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:44:16 - INFO - __main__ -   auc_score = 0.7876\n",
      "04/27/2024 02:44:16 - INFO - __main__ -   test_f1 = 0.0125\n",
      "04/27/2024 02:44:16 - INFO - __main__ -   test_precision = 0.5\n",
      "04/27/2024 02:44:16 - INFO - __main__ -   test_recall = 0.0063\n",
      " 60% 611/1024 [20:10<07:51,  1.14s/it]04/27/2024 02:48:08 - WARNING - __main__ - epoch 1 step 612 loss 0.23185\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 02:50:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:50:14 - INFO - __main__ -   eval_f1 = 0.0559\n",
      "04/27/2024 02:50:14 - INFO - __main__ -   eval_precision = 0.4118\n",
      "04/27/2024 02:50:14 - INFO - __main__ -   eval_recall = 0.03\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 02:52:38 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 02:52:38 - INFO - __main__ -   auc_score = 0.8167\n",
      "04/27/2024 02:52:38 - INFO - __main__ -   test_f1 = 0.0429\n",
      "04/27/2024 02:52:38 - INFO - __main__ -   test_precision = 0.2895\n",
      "04/27/2024 02:52:38 - INFO - __main__ -   test_recall = 0.0232\n",
      " 80% 815/1024 [28:32<03:58,  1.14s/it]04/27/2024 02:56:30 - WARNING - __main__ - epoch 1 step 816 loss 0.24292\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 02:58:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 02:58:36 - INFO - __main__ -   eval_f1 = 0.1611\n",
      "04/27/2024 02:58:36 - INFO - __main__ -   eval_precision = 0.4423\n",
      "04/27/2024 02:58:36 - INFO - __main__ -   eval_recall = 0.0985\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:01:01 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:01:01 - INFO - __main__ -   auc_score = 0.8184\n",
      "04/27/2024 03:01:01 - INFO - __main__ -   test_f1 = 0.1484\n",
      "04/27/2024 03:01:01 - INFO - __main__ -   test_precision = 0.3729\n",
      "04/27/2024 03:01:01 - INFO - __main__ -   test_recall = 0.0926\n",
      "100% 1019/1024 [36:55<00:05,  1.14s/it]04/27/2024 03:04:53 - WARNING - __main__ - epoch 1 step 1020 loss 0.23368\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:06:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:06:59 - INFO - __main__ -   eval_f1 = 0.0252\n",
      "04/27/2024 03:06:59 - INFO - __main__ -   eval_precision = 0.6\n",
      "04/27/2024 03:06:59 - INFO - __main__ -   eval_recall = 0.0128\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:09:05 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:09:05 - INFO - __main__ -   auc_score = 0.8317\n",
      "04/27/2024 03:09:05 - INFO - __main__ -   test_f1 = 0.0083\n",
      "04/27/2024 03:09:05 - INFO - __main__ -   test_precision = 0.3333\n",
      "04/27/2024 03:09:05 - INFO - __main__ -   test_recall = 0.0042\n",
      "100% 1024/1024 [41:11<00:00,  2.41s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/27/2024 03:13:01 - WARNING - __main__ - epoch 2 step 204 loss 0.20543\n",
      "04/27/2024 03:15:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:15:08 - INFO - __main__ -   eval_f1 = 0.0835\n",
      "04/27/2024 03:15:08 - INFO - __main__ -   eval_precision = 0.3667\n",
      "04/27/2024 03:15:08 - INFO - __main__ -   eval_recall = 0.0471\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:17:14 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:17:14 - INFO - __main__ -   auc_score = 0.8194\n",
      "04/27/2024 03:17:14 - INFO - __main__ -   test_f1 = 0.0956\n",
      "04/27/2024 03:17:14 - INFO - __main__ -   test_precision = 0.3768\n",
      "04/27/2024 03:17:14 - INFO - __main__ -   test_recall = 0.0547\n",
      " 40% 407/1024 [11:56<11:44,  1.14s/it]04/27/2024 03:21:06 - WARNING - __main__ - epoch 2 step 408 loss 0.20106\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:23:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:23:12 - INFO - __main__ -   eval_f1 = 0.2054\n",
      "04/27/2024 03:23:12 - INFO - __main__ -   eval_precision = 0.3916\n",
      "04/27/2024 03:23:12 - INFO - __main__ -   eval_recall = 0.1392\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:25:36 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:25:36 - INFO - __main__ -   auc_score = 0.8199\n",
      "04/27/2024 03:25:36 - INFO - __main__ -   test_f1 = 0.1526\n",
      "04/27/2024 03:25:36 - INFO - __main__ -   test_precision = 0.3117\n",
      "04/27/2024 03:25:36 - INFO - __main__ -   test_recall = 0.1011\n",
      " 60% 611/1024 [20:19<07:52,  1.14s/it]04/27/2024 03:29:29 - WARNING - __main__ - epoch 2 step 612 loss 0.21189\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:31:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:31:35 - INFO - __main__ -   eval_f1 = 0.0169\n",
      "04/27/2024 03:31:35 - INFO - __main__ -   eval_precision = 0.8\n",
      "04/27/2024 03:31:35 - INFO - __main__ -   eval_recall = 0.0086\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:33:41 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:33:41 - INFO - __main__ -   auc_score = 0.8185\n",
      "04/27/2024 03:33:41 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 03:33:41 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 03:33:41 - INFO - __main__ -   test_recall = 0.0\n",
      " 80% 815/1024 [28:24<03:58,  1.14s/it]04/27/2024 03:37:33 - WARNING - __main__ - epoch 2 step 816 loss 0.20934\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:39:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:39:40 - INFO - __main__ -   eval_f1 = 0.0744\n",
      "04/27/2024 03:39:40 - INFO - __main__ -   eval_precision = 0.4318\n",
      "04/27/2024 03:39:40 - INFO - __main__ -   eval_recall = 0.0407\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:41:46 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:41:46 - INFO - __main__ -   auc_score = 0.819\n",
      "04/27/2024 03:41:46 - INFO - __main__ -   test_f1 = 0.0724\n",
      "04/27/2024 03:41:46 - INFO - __main__ -   test_precision = 0.38\n",
      "04/27/2024 03:41:46 - INFO - __main__ -   test_recall = 0.04\n",
      "100% 1019/1024 [36:29<00:05,  1.14s/it]04/27/2024 03:45:38 - WARNING - __main__ - epoch 2 step 1020 loss 0.19148\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:47:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:47:45 - INFO - __main__ -   eval_f1 = 0.2472\n",
      "04/27/2024 03:47:45 - INFO - __main__ -   eval_precision = 0.3518\n",
      "04/27/2024 03:47:45 - INFO - __main__ -   eval_recall = 0.1906\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:50:09 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:50:09 - INFO - __main__ -   auc_score = 0.8101\n",
      "04/27/2024 03:50:09 - INFO - __main__ -   test_f1 = 0.2405\n",
      "04/27/2024 03:50:09 - INFO - __main__ -   test_precision = 0.3358\n",
      "04/27/2024 03:50:09 - INFO - __main__ -   test_recall = 0.1874\n",
      "100% 1024/1024 [41:04<00:00,  2.41s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:38,  1.14s/it]04/27/2024 03:54:06 - WARNING - __main__ - epoch 3 step 204 loss 0.17289\n",
      "04/27/2024 03:56:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 03:56:12 - INFO - __main__ -   eval_f1 = 0.1045\n",
      "04/27/2024 03:56:12 - INFO - __main__ -   eval_precision = 0.4058\n",
      "04/27/2024 03:56:12 - INFO - __main__ -   eval_recall = 0.06\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 03:58:18 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 03:58:18 - INFO - __main__ -   auc_score = 0.8109\n",
      "04/27/2024 03:58:18 - INFO - __main__ -   test_f1 = 0.1135\n",
      "04/27/2024 03:58:18 - INFO - __main__ -   test_precision = 0.3596\n",
      "04/27/2024 03:58:18 - INFO - __main__ -   test_recall = 0.0674\n",
      " 40% 407/1024 [11:57<11:45,  1.14s/it]04/27/2024 04:02:11 - WARNING - __main__ - epoch 3 step 408 loss 0.17387\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:04:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:04:17 - INFO - __main__ -   eval_f1 = 0.1536\n",
      "04/27/2024 04:04:17 - INFO - __main__ -   eval_precision = 0.3485\n",
      "04/27/2024 04:04:17 - INFO - __main__ -   eval_recall = 0.0985\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:06:23 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:06:23 - INFO - __main__ -   auc_score = 0.8061\n",
      "04/27/2024 04:06:23 - INFO - __main__ -   test_f1 = 0.1691\n",
      "04/27/2024 04:06:23 - INFO - __main__ -   test_precision = 0.3487\n",
      "04/27/2024 04:06:23 - INFO - __main__ -   test_recall = 0.1116\n",
      " 60% 611/1024 [20:02<07:52,  1.14s/it]04/27/2024 04:10:16 - WARNING - __main__ - epoch 3 step 612 loss 0.1702\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:12:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:12:22 - INFO - __main__ -   eval_f1 = 0.2968\n",
      "04/27/2024 04:12:22 - INFO - __main__ -   eval_precision = 0.3178\n",
      "04/27/2024 04:12:22 - INFO - __main__ -   eval_recall = 0.2784\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:14:48 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:14:48 - INFO - __main__ -   auc_score = 0.8111\n",
      "04/27/2024 04:14:48 - INFO - __main__ -   test_f1 = 0.295\n",
      "04/27/2024 04:14:48 - INFO - __main__ -   test_precision = 0.3043\n",
      "04/27/2024 04:14:48 - INFO - __main__ -   test_recall = 0.2863\n",
      " 80% 815/1024 [28:26<03:58,  1.14s/it]04/27/2024 04:18:40 - WARNING - __main__ - epoch 3 step 816 loss 0.16877\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:20:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:20:46 - INFO - __main__ -   eval_f1 = 0.2629\n",
      "04/27/2024 04:20:46 - INFO - __main__ -   eval_precision = 0.3462\n",
      "04/27/2024 04:20:46 - INFO - __main__ -   eval_recall = 0.212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:22:53 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:22:53 - INFO - __main__ -   auc_score = 0.8048\n",
      "04/27/2024 04:22:53 - INFO - __main__ -   test_f1 = 0.2383\n",
      "04/27/2024 04:22:53 - INFO - __main__ -   test_precision = 0.2994\n",
      "04/27/2024 04:22:53 - INFO - __main__ -   test_recall = 0.1979\n",
      "100% 1019/1024 [36:31<00:05,  1.14s/it]04/27/2024 04:26:45 - WARNING - __main__ - epoch 3 step 1020 loss 0.18857\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:28:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:28:51 - INFO - __main__ -   eval_f1 = 0.2413\n",
      "04/27/2024 04:28:51 - INFO - __main__ -   eval_precision = 0.3425\n",
      "04/27/2024 04:28:51 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:30:57 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:30:57 - INFO - __main__ -   auc_score = 0.8081\n",
      "04/27/2024 04:30:57 - INFO - __main__ -   test_f1 = 0.2314\n",
      "04/27/2024 04:30:57 - INFO - __main__ -   test_precision = 0.3141\n",
      "04/27/2024 04:30:57 - INFO - __main__ -   test_recall = 0.1832\n",
      "100% 1024/1024 [40:48<00:00,  2.39s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:37,  1.14s/it]04/27/2024 04:34:54 - WARNING - __main__ - epoch 4 step 204 loss 0.13762\n",
      "04/27/2024 04:37:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:37:00 - INFO - __main__ -   eval_f1 = 0.1541\n",
      "04/27/2024 04:37:00 - INFO - __main__ -   eval_precision = 0.4231\n",
      "04/27/2024 04:37:00 - INFO - __main__ -   eval_recall = 0.0942\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:39:06 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:39:06 - INFO - __main__ -   auc_score = 0.8012\n",
      "04/27/2024 04:39:06 - INFO - __main__ -   test_f1 = 0.1293\n",
      "04/27/2024 04:39:06 - INFO - __main__ -   test_precision = 0.3363\n",
      "04/27/2024 04:39:06 - INFO - __main__ -   test_recall = 0.08\n",
      " 40% 407/1024 [11:56<11:45,  1.14s/it]04/27/2024 04:42:58 - WARNING - __main__ - epoch 4 step 408 loss 0.15314\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:45:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:45:05 - INFO - __main__ -   eval_f1 = 0.1582\n",
      "04/27/2024 04:45:05 - INFO - __main__ -   eval_precision = 0.3701\n",
      "04/27/2024 04:45:05 - INFO - __main__ -   eval_recall = 0.1006\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:47:11 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:47:11 - INFO - __main__ -   auc_score = 0.8069\n",
      "04/27/2024 04:47:11 - INFO - __main__ -   test_f1 = 0.127\n",
      "04/27/2024 04:47:11 - INFO - __main__ -   test_precision = 0.2806\n",
      "04/27/2024 04:47:11 - INFO - __main__ -   test_recall = 0.0821\n",
      " 60% 611/1024 [20:01<07:52,  1.14s/it]04/27/2024 04:51:03 - WARNING - __main__ - epoch 4 step 612 loss 0.16088\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:53:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 04:53:10 - INFO - __main__ -   eval_f1 = 0.2412\n",
      "04/27/2024 04:53:10 - INFO - __main__ -   eval_precision = 0.3496\n",
      "04/27/2024 04:53:10 - INFO - __main__ -   eval_recall = 0.1842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 04:55:16 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 04:55:16 - INFO - __main__ -   auc_score = 0.811\n",
      "04/27/2024 04:55:16 - INFO - __main__ -   test_f1 = 0.1994\n",
      "04/27/2024 04:55:16 - INFO - __main__ -   test_precision = 0.2915\n",
      "04/27/2024 04:55:16 - INFO - __main__ -   test_recall = 0.1516\n",
      " 80% 815/1024 [28:06<03:58,  1.14s/it]04/27/2024 04:59:08 - WARNING - __main__ - epoch 4 step 816 loss 0.15532\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:01:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:01:14 - INFO - __main__ -   eval_f1 = 0.169\n",
      "04/27/2024 05:01:14 - INFO - __main__ -   eval_precision = 0.4336\n",
      "04/27/2024 05:01:14 - INFO - __main__ -   eval_recall = 0.1049\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:03:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:03:20 - INFO - __main__ -   auc_score = 0.7974\n",
      "04/27/2024 05:03:20 - INFO - __main__ -   test_f1 = 0.114\n",
      "04/27/2024 05:03:20 - INFO - __main__ -   test_precision = 0.3173\n",
      "04/27/2024 05:03:20 - INFO - __main__ -   test_recall = 0.0695\n",
      "100% 1019/1024 [36:10<00:05,  1.14s/it]04/27/2024 05:07:12 - WARNING - __main__ - epoch 4 step 1020 loss 0.16318\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:09:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:09:19 - INFO - __main__ -   eval_f1 = 0.2698\n",
      "04/27/2024 05:09:19 - INFO - __main__ -   eval_precision = 0.3016\n",
      "04/27/2024 05:09:19 - INFO - __main__ -   eval_recall = 0.2441\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:11:25 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:11:25 - INFO - __main__ -   auc_score = 0.8049\n",
      "04/27/2024 05:11:25 - INFO - __main__ -   test_f1 = 0.2649\n",
      "04/27/2024 05:11:25 - INFO - __main__ -   test_precision = 0.2989\n",
      "04/27/2024 05:11:25 - INFO - __main__ -   test_recall = 0.2379\n",
      "100% 1024/1024 [40:27<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/27/2024 05:15:20 - WARNING - __main__ - epoch 5 step 204 loss 0.1333\n",
      "04/27/2024 05:17:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:17:27 - INFO - __main__ -   eval_f1 = 0.2807\n",
      "04/27/2024 05:17:27 - INFO - __main__ -   eval_precision = 0.3343\n",
      "04/27/2024 05:17:27 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:19:33 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:19:33 - INFO - __main__ -   auc_score = 0.8076\n",
      "04/27/2024 05:19:33 - INFO - __main__ -   test_f1 = 0.2543\n",
      "04/27/2024 05:19:33 - INFO - __main__ -   test_precision = 0.3075\n",
      "04/27/2024 05:19:33 - INFO - __main__ -   test_recall = 0.2168\n",
      " 40% 407/1024 [11:56<11:43,  1.14s/it]04/27/2024 05:23:25 - WARNING - __main__ - epoch 5 step 408 loss 0.15086\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:25:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:25:31 - INFO - __main__ -   eval_f1 = 0.2326\n",
      "04/27/2024 05:25:31 - INFO - __main__ -   eval_precision = 0.3949\n",
      "04/27/2024 05:25:31 - INFO - __main__ -   eval_recall = 0.1649\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:27:37 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:27:37 - INFO - __main__ -   auc_score = 0.808\n",
      "04/27/2024 05:27:37 - INFO - __main__ -   test_f1 = 0.177\n",
      "04/27/2024 05:27:37 - INFO - __main__ -   test_precision = 0.2956\n",
      "04/27/2024 05:27:37 - INFO - __main__ -   test_recall = 0.1263\n",
      " 60% 611/1024 [20:00<07:51,  1.14s/it]04/27/2024 05:31:29 - WARNING - __main__ - epoch 5 step 612 loss 0.11851\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:33:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:33:35 - INFO - __main__ -   eval_f1 = 0.2705\n",
      "04/27/2024 05:33:35 - INFO - __main__ -   eval_precision = 0.3736\n",
      "04/27/2024 05:33:35 - INFO - __main__ -   eval_recall = 0.212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:35:41 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:35:41 - INFO - __main__ -   auc_score = 0.8082\n",
      "04/27/2024 05:35:41 - INFO - __main__ -   test_f1 = 0.234\n",
      "04/27/2024 05:35:41 - INFO - __main__ -   test_precision = 0.3308\n",
      "04/27/2024 05:35:41 - INFO - __main__ -   test_recall = 0.1811\n",
      " 80% 815/1024 [28:04<03:58,  1.14s/it]04/27/2024 05:39:33 - WARNING - __main__ - epoch 5 step 816 loss 0.13198\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:41:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:41:40 - INFO - __main__ -   eval_f1 = 0.2544\n",
      "04/27/2024 05:41:40 - INFO - __main__ -   eval_precision = 0.3523\n",
      "04/27/2024 05:41:40 - INFO - __main__ -   eval_recall = 0.1991\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:43:45 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:43:45 - INFO - __main__ -   auc_score = 0.8034\n",
      "04/27/2024 05:43:45 - INFO - __main__ -   test_f1 = 0.2268\n",
      "04/27/2024 05:43:45 - INFO - __main__ -   test_precision = 0.323\n",
      "04/27/2024 05:43:45 - INFO - __main__ -   test_recall = 0.1747\n",
      "100% 1019/1024 [36:08<00:05,  1.14s/it]04/27/2024 05:47:37 - WARNING - __main__ - epoch 5 step 1020 loss 0.14044\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:49:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:49:43 - INFO - __main__ -   eval_f1 = 0.2226\n",
      "04/27/2024 05:49:43 - INFO - __main__ -   eval_precision = 0.4\n",
      "04/27/2024 05:49:43 - INFO - __main__ -   eval_recall = 0.1542\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:51:49 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:51:49 - INFO - __main__ -   auc_score = 0.8077\n",
      "04/27/2024 05:51:49 - INFO - __main__ -   test_f1 = 0.1738\n",
      "04/27/2024 05:51:49 - INFO - __main__ -   test_precision = 0.3149\n",
      "04/27/2024 05:51:49 - INFO - __main__ -   test_recall = 0.12\n",
      "100% 1024/1024 [40:24<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/27/2024 05:55:45 - WARNING - __main__ - epoch 6 step 204 loss 0.11736\n",
      "04/27/2024 05:57:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 05:57:51 - INFO - __main__ -   eval_f1 = 0.2444\n",
      "04/27/2024 05:57:51 - INFO - __main__ -   eval_precision = 0.3478\n",
      "04/27/2024 05:57:51 - INFO - __main__ -   eval_recall = 0.1884\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 05:59:57 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 05:59:57 - INFO - __main__ -   auc_score = 0.8014\n",
      "04/27/2024 05:59:57 - INFO - __main__ -   test_f1 = 0.2017\n",
      "04/27/2024 05:59:57 - INFO - __main__ -   test_precision = 0.2932\n",
      "04/27/2024 05:59:57 - INFO - __main__ -   test_recall = 0.1537\n",
      " 40% 407/1024 [11:55<11:43,  1.14s/it]04/27/2024 06:03:49 - WARNING - __main__ - epoch 6 step 408 loss 0.10508\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:05:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:05:55 - INFO - __main__ -   eval_f1 = 0.2437\n",
      "04/27/2024 06:05:55 - INFO - __main__ -   eval_precision = 0.3194\n",
      "04/27/2024 06:05:55 - INFO - __main__ -   eval_recall = 0.197\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:08:00 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:08:00 - INFO - __main__ -   auc_score = 0.8036\n",
      "04/27/2024 06:08:00 - INFO - __main__ -   test_f1 = 0.2169\n",
      "04/27/2024 06:08:00 - INFO - __main__ -   test_precision = 0.2918\n",
      "04/27/2024 06:08:00 - INFO - __main__ -   test_recall = 0.1726\n",
      " 60% 611/1024 [19:59<07:50,  1.14s/it]04/27/2024 06:11:53 - WARNING - __main__ - epoch 6 step 612 loss 0.10663\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:13:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:13:59 - INFO - __main__ -   eval_f1 = 0.2245\n",
      "04/27/2024 06:13:59 - INFO - __main__ -   eval_precision = 0.3421\n",
      "04/27/2024 06:13:59 - INFO - __main__ -   eval_recall = 0.167\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:16:04 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:16:04 - INFO - __main__ -   auc_score = 0.8002\n",
      "04/27/2024 06:16:04 - INFO - __main__ -   test_f1 = 0.1742\n",
      "04/27/2024 06:16:04 - INFO - __main__ -   test_precision = 0.2804\n",
      "04/27/2024 06:16:04 - INFO - __main__ -   test_recall = 0.1263\n",
      " 80% 815/1024 [28:02<03:58,  1.14s/it]04/27/2024 06:19:56 - WARNING - __main__ - epoch 6 step 816 loss 0.10737\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:22:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:22:02 - INFO - __main__ -   eval_f1 = 0.2593\n",
      "04/27/2024 06:22:02 - INFO - __main__ -   eval_precision = 0.3391\n",
      "04/27/2024 06:22:02 - INFO - __main__ -   eval_recall = 0.2099\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:24:08 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:24:08 - INFO - __main__ -   auc_score = 0.8027\n",
      "04/27/2024 06:24:08 - INFO - __main__ -   test_f1 = 0.2101\n",
      "04/27/2024 06:24:08 - INFO - __main__ -   test_precision = 0.2852\n",
      "04/27/2024 06:24:08 - INFO - __main__ -   test_recall = 0.1663\n",
      "100% 1019/1024 [36:06<00:05,  1.14s/it]04/27/2024 06:28:00 - WARNING - __main__ - epoch 6 step 1020 loss 0.11932\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:30:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:30:06 - INFO - __main__ -   eval_f1 = 0.2399\n",
      "04/27/2024 06:30:06 - INFO - __main__ -   eval_precision = 0.344\n",
      "04/27/2024 06:30:06 - INFO - __main__ -   eval_recall = 0.1842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:32:12 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:32:12 - INFO - __main__ -   auc_score = 0.8016\n",
      "04/27/2024 06:32:12 - INFO - __main__ -   test_f1 = 0.1676\n",
      "04/27/2024 06:32:12 - INFO - __main__ -   test_precision = 0.249\n",
      "04/27/2024 06:32:12 - INFO - __main__ -   test_recall = 0.1263\n",
      "100% 1024/1024 [40:22<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/27/2024 06:36:08 - WARNING - __main__ - epoch 7 step 204 loss 0.09298\n",
      "04/27/2024 06:38:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:38:14 - INFO - __main__ -   eval_f1 = 0.239\n",
      "04/27/2024 06:38:14 - INFO - __main__ -   eval_precision = 0.3333\n",
      "04/27/2024 06:38:14 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:40:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:40:20 - INFO - __main__ -   auc_score = 0.7996\n",
      "04/27/2024 06:40:20 - INFO - __main__ -   test_f1 = 0.1806\n",
      "04/27/2024 06:40:20 - INFO - __main__ -   test_precision = 0.2653\n",
      "04/27/2024 06:40:20 - INFO - __main__ -   test_recall = 0.1368\n",
      " 40% 407/1024 [11:55<11:44,  1.14s/it]04/27/2024 06:44:12 - WARNING - __main__ - epoch 7 step 408 loss 0.09411\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:46:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:46:18 - INFO - __main__ -   eval_f1 = 0.2419\n",
      "04/27/2024 06:46:18 - INFO - __main__ -   eval_precision = 0.3079\n",
      "04/27/2024 06:46:18 - INFO - __main__ -   eval_recall = 0.1991\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:48:24 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:48:24 - INFO - __main__ -   auc_score = 0.8024\n",
      "04/27/2024 06:48:24 - INFO - __main__ -   test_f1 = 0.2013\n",
      "04/27/2024 06:48:24 - INFO - __main__ -   test_precision = 0.2655\n",
      "04/27/2024 06:48:24 - INFO - __main__ -   test_recall = 0.1621\n",
      " 60% 611/1024 [20:00<07:51,  1.14s/it]04/27/2024 06:52:17 - WARNING - __main__ - epoch 7 step 612 loss 0.0798\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:54:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 06:54:23 - INFO - __main__ -   eval_f1 = 0.22\n",
      "04/27/2024 06:54:23 - INFO - __main__ -   eval_precision = 0.3393\n",
      "04/27/2024 06:54:23 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 06:56:29 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 06:56:29 - INFO - __main__ -   auc_score = 0.8033\n",
      "04/27/2024 06:56:29 - INFO - __main__ -   test_f1 = 0.1785\n",
      "04/27/2024 06:56:29 - INFO - __main__ -   test_precision = 0.2727\n",
      "04/27/2024 06:56:29 - INFO - __main__ -   test_recall = 0.1326\n",
      " 80% 815/1024 [28:04<03:58,  1.14s/it]04/27/2024 07:00:21 - WARNING - __main__ - epoch 7 step 816 loss 0.09178\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:02:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:02:28 - INFO - __main__ -   eval_f1 = 0.23\n",
      "04/27/2024 07:02:28 - INFO - __main__ -   eval_precision = 0.3125\n",
      "04/27/2024 07:02:28 - INFO - __main__ -   eval_recall = 0.182\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:04:33 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:04:33 - INFO - __main__ -   auc_score = 0.8018\n",
      "04/27/2024 07:04:33 - INFO - __main__ -   test_f1 = 0.1943\n",
      "04/27/2024 07:04:33 - INFO - __main__ -   test_precision = 0.2707\n",
      "04/27/2024 07:04:33 - INFO - __main__ -   test_recall = 0.1516\n",
      "100% 1019/1024 [36:09<00:05,  1.14s/it]04/27/2024 07:08:25 - WARNING - __main__ - epoch 7 step 1020 loss 0.09327\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:10:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:10:32 - INFO - __main__ -   eval_f1 = 0.2155\n",
      "04/27/2024 07:10:32 - INFO - __main__ -   eval_precision = 0.3035\n",
      "04/27/2024 07:10:32 - INFO - __main__ -   eval_recall = 0.167\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:12:38 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:12:38 - INFO - __main__ -   auc_score = 0.7978\n",
      "04/27/2024 07:12:38 - INFO - __main__ -   test_f1 = 0.1719\n",
      "04/27/2024 07:12:38 - INFO - __main__ -   test_precision = 0.2442\n",
      "04/27/2024 07:12:38 - INFO - __main__ -   test_recall = 0.1326\n",
      "100% 1024/1024 [40:25<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:37,  1.14s/it]04/27/2024 07:16:34 - WARNING - __main__ - epoch 8 step 204 loss 0.07091\n",
      "04/27/2024 07:18:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:18:40 - INFO - __main__ -   eval_f1 = 0.2304\n",
      "04/27/2024 07:18:40 - INFO - __main__ -   eval_precision = 0.2963\n",
      "04/27/2024 07:18:40 - INFO - __main__ -   eval_recall = 0.1884\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:21:02 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:21:02 - INFO - __main__ -   auc_score = 0.7983\n",
      "04/27/2024 07:21:02 - INFO - __main__ -   test_f1 = 0.207\n",
      "04/27/2024 07:21:02 - INFO - __main__ -   test_precision = 0.2685\n",
      "04/27/2024 07:21:02 - INFO - __main__ -   test_recall = 0.1684\n",
      " 40% 407/1024 [12:12<11:44,  1.14s/it]04/27/2024 07:24:54 - WARNING - __main__ - epoch 8 step 408 loss 0.06631\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:27:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:27:01 - INFO - __main__ -   eval_f1 = 0.2234\n",
      "04/27/2024 07:27:01 - INFO - __main__ -   eval_precision = 0.3007\n",
      "04/27/2024 07:27:01 - INFO - __main__ -   eval_recall = 0.1777\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:29:20 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:29:20 - INFO - __main__ -   auc_score = 0.7972\n",
      "04/27/2024 07:29:20 - INFO - __main__ -   test_f1 = 0.2108\n",
      "04/27/2024 07:29:20 - INFO - __main__ -   test_precision = 0.2817\n",
      "04/27/2024 07:29:20 - INFO - __main__ -   test_recall = 0.1684\n",
      " 60% 611/1024 [20:30<07:51,  1.14s/it]04/27/2024 07:33:12 - WARNING - __main__ - epoch 8 step 612 loss 0.07804\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:35:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:35:19 - INFO - __main__ -   eval_f1 = 0.2183\n",
      "04/27/2024 07:35:19 - INFO - __main__ -   eval_precision = 0.3008\n",
      "04/27/2024 07:35:19 - INFO - __main__ -   eval_recall = 0.1713\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:37:39 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:37:39 - INFO - __main__ -   auc_score = 0.7964\n",
      "04/27/2024 07:37:39 - INFO - __main__ -   test_f1 = 0.1951\n",
      "04/27/2024 07:37:39 - INFO - __main__ -   test_precision = 0.2738\n",
      "04/27/2024 07:37:39 - INFO - __main__ -   test_recall = 0.1516\n",
      " 80% 815/1024 [28:49<03:58,  1.14s/it]04/27/2024 07:41:31 - WARNING - __main__ - epoch 8 step 816 loss 0.07398\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:43:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 07:43:37 - INFO - __main__ -   eval_f1 = 0.2269\n",
      "04/27/2024 07:43:37 - INFO - __main__ -   eval_precision = 0.2955\n",
      "04/27/2024 07:43:37 - INFO - __main__ -   eval_recall = 0.1842\n",
      "04/27/2024 07:43:54 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 80% 815/1024 [31:12<08:00,  2.30s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-3 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwR7Evs5L_nL",
    "outputId": "39bbdbef-baee-41aa-a630-225efc94499f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/27/2024 07:55:54 - INFO - __main__ - Successfully load epoch 3's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 07:58:01 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 07:58:01 - INFO - __main__ -   auc_score = 0.8128\n",
      "04/27/2024 07:58:01 - INFO - __main__ -   test_f1 = 0.2969\n",
      "04/27/2024 07:58:01 - INFO - __main__ -   test_precision = 0.3058\n",
      "04/27/2024 07:58:01 - INFO - __main__ -   test_recall = 0.2884\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-3 --epochs 10 --batch_size 16 --hidden_size 1024 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skkk2YvJwucF"
   },
   "source": [
    "#### LR = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThPIGWGFNNhN"
   },
   "source": [
    "**Command for lr = 5e-4 (run on Apuana):**\n",
    "\n",
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 5e-4 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG0zPhYDz-Fo"
   },
   "source": [
    "04/30/2024 13:23:18 - INFO - __main__ - Successfully load epoch 4's model\n",
    "checkpoint\n",
    "04/30/2024 13:25:54 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "04/30/2024 13:25:54 - INFO - __main__ -   auc_score = 0.7842\n",
    "\n",
    "04/30/2024 13:25:54 - INFO - __main__ -   test_f1 = 0.2748\n",
    "\n",
    "04/30/2024 13:25:54 - INFO - __main__ -   test_precision = 0.3043\n",
    "\n",
    "04/30/2024 13:25:54 - INFO - __main__ -   test_recall = 0.2505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPr7dowtw2-Z"
   },
   "source": [
    "#### LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWtCaXYQNkTo",
    "outputId": "fe0d18b1-d853-415b-cb95-a81afee91a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "config.json: 100% 770/770 [00:00<00:00, 3.84MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 8.70MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 1.52MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 64.1MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 11.9kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 48.1MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:03<00:00, 468MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:53<15:35,  1.14s/it]04/27/2024 18:15:51 - WARNING - __main__ - epoch 0 step 204 loss 0.29438\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:17:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:17:58 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 18:17:58 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 18:17:58 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:20:04 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 18:20:04 - INFO - __main__ -   auc_score = 0.6975\n",
      "04/27/2024 18:20:04 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 18:20:04 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 18:20:04 - INFO - __main__ -   test_recall = 0.0\n",
      " 40% 407/1024 [11:57<11:44,  1.14s/it]04/27/2024 18:23:56 - WARNING - __main__ - epoch 0 step 408 loss 0.25301\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:26:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:26:02 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 18:26:02 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 18:26:02 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:28:08 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 18:28:08 - INFO - __main__ -   auc_score = 0.835\n",
      "04/27/2024 18:28:08 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 18:28:08 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 18:28:08 - INFO - __main__ -   test_recall = 0.0\n",
      " 60% 611/1024 [20:01<07:51,  1.14s/it]04/27/2024 18:32:00 - WARNING - __main__ - epoch 0 step 612 loss 0.23354\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:34:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:34:06 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 18:34:06 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 18:34:06 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 18:36:12 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 18:36:12 - INFO - __main__ -   auc_score = 0.8486\n",
      "04/27/2024 18:36:12 - INFO - __main__ -   test_f1 = 0.0126\n",
      "04/27/2024 18:36:12 - INFO - __main__ -   test_precision = 1.0\n",
      "04/27/2024 18:36:12 - INFO - __main__ -   test_recall = 0.0063\n",
      " 80% 815/1024 [28:06<03:58,  1.14s/it]04/27/2024 18:40:04 - WARNING - __main__ - epoch 0 step 816 loss 0.2223\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 18:42:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:42:10 - INFO - __main__ -   eval_f1 = 0.0043\n",
      "04/27/2024 18:42:10 - INFO - __main__ -   eval_precision = 1.0\n",
      "04/27/2024 18:42:10 - INFO - __main__ -   eval_recall = 0.0021\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 18:44:29 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 18:44:29 - INFO - __main__ -   auc_score = 0.857\n",
      "04/27/2024 18:44:29 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 18:44:29 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 18:44:29 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 1019/1024 [36:22<00:05,  1.14s/it]04/27/2024 18:48:21 - WARNING - __main__ - epoch 0 step 1020 loss 0.23173\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:50:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:50:27 - INFO - __main__ -   eval_f1 = 0.0\n",
      "04/27/2024 18:50:27 - INFO - __main__ -   eval_precision = 0.0\n",
      "04/27/2024 18:50:27 - INFO - __main__ -   eval_recall = 0.0\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "04/27/2024 18:52:33 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 18:52:33 - INFO - __main__ -   auc_score = 0.846\n",
      "04/27/2024 18:52:33 - INFO - __main__ -   test_f1 = 0.0\n",
      "04/27/2024 18:52:33 - INFO - __main__ -   test_precision = 0.0\n",
      "04/27/2024 18:52:33 - INFO - __main__ -   test_recall = 0.0\n",
      "100% 1024/1024 [40:38<00:00,  2.38s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/27/2024 18:56:29 - WARNING - __main__ - epoch 1 step 204 loss 0.19807\n",
      "04/27/2024 18:58:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 18:58:35 - INFO - __main__ -   eval_f1 = 0.298\n",
      "04/27/2024 18:58:35 - INFO - __main__ -   eval_precision = 0.6569\n",
      "04/27/2024 18:58:35 - INFO - __main__ -   eval_recall = 0.1927\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:01:00 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:01:00 - INFO - __main__ -   auc_score = 0.851\n",
      "04/27/2024 19:01:00 - INFO - __main__ -   test_f1 = 0.227\n",
      "04/27/2024 19:01:00 - INFO - __main__ -   test_precision = 0.5188\n",
      "04/27/2024 19:01:00 - INFO - __main__ -   test_recall = 0.1453\n",
      " 40% 407/1024 [12:14<11:43,  1.14s/it]04/27/2024 19:04:52 - WARNING - __main__ - epoch 1 step 408 loss 0.19592\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:06:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:06:58 - INFO - __main__ -   eval_f1 = 0.0565\n",
      "04/27/2024 19:06:58 - INFO - __main__ -   eval_precision = 0.4828\n",
      "04/27/2024 19:06:58 - INFO - __main__ -   eval_recall = 0.03\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:09:04 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:09:04 - INFO - __main__ -   auc_score = 0.8404\n",
      "04/27/2024 19:09:04 - INFO - __main__ -   test_f1 = 0.0485\n",
      "04/27/2024 19:09:04 - INFO - __main__ -   test_precision = 0.6\n",
      "04/27/2024 19:09:04 - INFO - __main__ -   test_recall = 0.0253\n",
      " 60% 611/1024 [20:18<07:51,  1.14s/it]04/27/2024 19:12:56 - WARNING - __main__ - epoch 1 step 612 loss 0.20007\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:15:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:15:02 - INFO - __main__ -   eval_f1 = 0.2389\n",
      "04/27/2024 19:15:02 - INFO - __main__ -   eval_precision = 0.4194\n",
      "04/27/2024 19:15:02 - INFO - __main__ -   eval_recall = 0.167\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:17:08 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:17:08 - INFO - __main__ -   auc_score = 0.8408\n",
      "04/27/2024 19:17:08 - INFO - __main__ -   test_f1 = 0.2453\n",
      "04/27/2024 19:17:08 - INFO - __main__ -   test_precision = 0.4\n",
      "04/27/2024 19:17:08 - INFO - __main__ -   test_recall = 0.1768\n",
      " 80% 815/1024 [28:22<03:58,  1.14s/it]04/27/2024 19:21:00 - WARNING - __main__ - epoch 1 step 816 loss 0.20643\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:23:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:23:06 - INFO - __main__ -   eval_f1 = 0.2264\n",
      "04/27/2024 19:23:06 - INFO - __main__ -   eval_precision = 0.536\n",
      "04/27/2024 19:23:06 - INFO - __main__ -   eval_recall = 0.1435\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:25:12 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:25:12 - INFO - __main__ -   auc_score = 0.8546\n",
      "04/27/2024 19:25:12 - INFO - __main__ -   test_f1 = 0.2328\n",
      "04/27/2024 19:25:12 - INFO - __main__ -   test_precision = 0.5259\n",
      "04/27/2024 19:25:12 - INFO - __main__ -   test_recall = 0.1495\n",
      "100% 1019/1024 [36:26<00:05,  1.14s/it]04/27/2024 19:29:04 - WARNING - __main__ - epoch 1 step 1020 loss 0.20125\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:31:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:31:10 - INFO - __main__ -   eval_f1 = 0.2083\n",
      "04/27/2024 19:31:10 - INFO - __main__ -   eval_precision = 0.4565\n",
      "04/27/2024 19:31:10 - INFO - __main__ -   eval_recall = 0.1349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:33:16 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:33:16 - INFO - __main__ -   auc_score = 0.8385\n",
      "04/27/2024 19:33:16 - INFO - __main__ -   test_f1 = 0.2433\n",
      "04/27/2024 19:33:16 - INFO - __main__ -   test_precision = 0.4873\n",
      "04/27/2024 19:33:16 - INFO - __main__ -   test_recall = 0.1621\n",
      "100% 1024/1024 [40:43<00:00,  2.39s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/27/2024 19:37:12 - WARNING - __main__ - epoch 2 step 204 loss 0.15703\n",
      "04/27/2024 19:39:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:39:18 - INFO - __main__ -   eval_f1 = 0.2355\n",
      "04/27/2024 19:39:18 - INFO - __main__ -   eval_precision = 0.4412\n",
      "04/27/2024 19:39:18 - INFO - __main__ -   eval_recall = 0.1606\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:41:24 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:41:24 - INFO - __main__ -   auc_score = 0.8296\n",
      "04/27/2024 19:41:24 - INFO - __main__ -   test_f1 = 0.247\n",
      "04/27/2024 19:41:24 - INFO - __main__ -   test_precision = 0.4339\n",
      "04/27/2024 19:41:24 - INFO - __main__ -   test_recall = 0.1726\n",
      " 40% 407/1024 [11:55<11:42,  1.14s/it]04/27/2024 19:45:16 - WARNING - __main__ - epoch 2 step 408 loss 0.13943\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:47:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:47:22 - INFO - __main__ -   eval_f1 = 0.3799\n",
      "04/27/2024 19:47:22 - INFO - __main__ -   eval_precision = 0.3875\n",
      "04/27/2024 19:47:22 - INFO - __main__ -   eval_recall = 0.3726\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:49:43 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:49:43 - INFO - __main__ -   auc_score = 0.8368\n",
      "04/27/2024 19:49:43 - INFO - __main__ -   test_f1 = 0.3661\n",
      "04/27/2024 19:49:43 - INFO - __main__ -   test_precision = 0.3406\n",
      "04/27/2024 19:49:43 - INFO - __main__ -   test_recall = 0.3958\n",
      " 60% 611/1024 [20:14<07:50,  1.14s/it]04/27/2024 19:53:35 - WARNING - __main__ - epoch 2 step 612 loss 0.1497\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:55:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 19:55:41 - INFO - __main__ -   eval_f1 = 0.2476\n",
      "04/27/2024 19:55:41 - INFO - __main__ -   eval_precision = 0.517\n",
      "04/27/2024 19:55:41 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 19:57:47 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 19:57:47 - INFO - __main__ -   auc_score = 0.8258\n",
      "04/27/2024 19:57:47 - INFO - __main__ -   test_f1 = 0.2427\n",
      "04/27/2024 19:57:47 - INFO - __main__ -   test_precision = 0.4489\n",
      "04/27/2024 19:57:47 - INFO - __main__ -   test_recall = 0.1663\n",
      " 80% 815/1024 [28:17<03:58,  1.14s/it]04/27/2024 20:01:38 - WARNING - __main__ - epoch 2 step 816 loss 0.15909\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:03:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:03:44 - INFO - __main__ -   eval_f1 = 0.3038\n",
      "04/27/2024 20:03:44 - INFO - __main__ -   eval_precision = 0.4882\n",
      "04/27/2024 20:03:44 - INFO - __main__ -   eval_recall = 0.2206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:05:50 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:05:50 - INFO - __main__ -   auc_score = 0.8473\n",
      "04/27/2024 20:05:50 - INFO - __main__ -   test_f1 = 0.2825\n",
      "04/27/2024 20:05:50 - INFO - __main__ -   test_precision = 0.413\n",
      "04/27/2024 20:05:50 - INFO - __main__ -   test_recall = 0.2147\n",
      "100% 1019/1024 [36:21<00:05,  1.14s/it]04/27/2024 20:09:42 - WARNING - __main__ - epoch 2 step 1020 loss 0.13755\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:11:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:11:48 - INFO - __main__ -   eval_f1 = 0.3799\n",
      "04/27/2024 20:11:48 - INFO - __main__ -   eval_precision = 0.3787\n",
      "04/27/2024 20:11:48 - INFO - __main__ -   eval_recall = 0.3812\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:14:14 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:14:14 - INFO - __main__ -   auc_score = 0.8288\n",
      "04/27/2024 20:14:14 - INFO - __main__ -   test_f1 = 0.3333\n",
      "04/27/2024 20:14:14 - INFO - __main__ -   test_precision = 0.3119\n",
      "04/27/2024 20:14:14 - INFO - __main__ -   test_recall = 0.3579\n",
      "100% 1024/1024 [40:57<00:00,  2.40s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/27/2024 20:18:09 - WARNING - __main__ - epoch 3 step 204 loss 0.07896\n",
      "04/27/2024 20:20:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:20:15 - INFO - __main__ -   eval_f1 = 0.2605\n",
      "04/27/2024 20:20:15 - INFO - __main__ -   eval_precision = 0.5226\n",
      "04/27/2024 20:20:15 - INFO - __main__ -   eval_recall = 0.1734\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:22:21 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:22:21 - INFO - __main__ -   auc_score = 0.8282\n",
      "04/27/2024 20:22:21 - INFO - __main__ -   test_f1 = 0.2302\n",
      "04/27/2024 20:22:21 - INFO - __main__ -   test_precision = 0.3969\n",
      "04/27/2024 20:22:21 - INFO - __main__ -   test_recall = 0.1621\n",
      " 40% 407/1024 [11:55<11:44,  1.14s/it]04/27/2024 20:26:13 - WARNING - __main__ - epoch 3 step 408 loss 0.08816\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:28:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:28:20 - INFO - __main__ -   eval_f1 = 0.1926\n",
      "04/27/2024 20:28:20 - INFO - __main__ -   eval_precision = 0.5288\n",
      "04/27/2024 20:28:20 - INFO - __main__ -   eval_recall = 0.1178\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:30:25 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:30:25 - INFO - __main__ -   auc_score = 0.8086\n",
      "04/27/2024 20:30:25 - INFO - __main__ -   test_f1 = 0.1648\n",
      "04/27/2024 20:30:25 - INFO - __main__ -   test_precision = 0.3542\n",
      "04/27/2024 20:30:25 - INFO - __main__ -   test_recall = 0.1074\n",
      " 60% 611/1024 [19:59<07:50,  1.14s/it]04/27/2024 20:34:17 - WARNING - __main__ - epoch 3 step 612 loss 0.09943\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:36:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:36:23 - INFO - __main__ -   eval_f1 = 0.3574\n",
      "04/27/2024 20:36:23 - INFO - __main__ -   eval_precision = 0.4171\n",
      "04/27/2024 20:36:23 - INFO - __main__ -   eval_recall = 0.3126\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:38:29 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:38:29 - INFO - __main__ -   auc_score = 0.829\n",
      "04/27/2024 20:38:29 - INFO - __main__ -   test_f1 = 0.3283\n",
      "04/27/2024 20:38:29 - INFO - __main__ -   test_precision = 0.3672\n",
      "04/27/2024 20:38:29 - INFO - __main__ -   test_recall = 0.2968\n",
      " 80% 815/1024 [28:02<03:58,  1.14s/it]04/27/2024 20:42:21 - WARNING - __main__ - epoch 3 step 816 loss 0.09019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:44:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:44:27 - INFO - __main__ -   eval_f1 = 0.3319\n",
      "04/27/2024 20:44:27 - INFO - __main__ -   eval_precision = 0.3432\n",
      "04/27/2024 20:44:27 - INFO - __main__ -   eval_recall = 0.3212\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:46:32 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:46:32 - INFO - __main__ -   auc_score = 0.8158\n",
      "04/27/2024 20:46:32 - INFO - __main__ -   test_f1 = 0.3152\n",
      "04/27/2024 20:46:32 - INFO - __main__ -   test_precision = 0.319\n",
      "04/27/2024 20:46:32 - INFO - __main__ -   test_recall = 0.3116\n",
      "100% 1019/1024 [36:06<00:05,  1.14s/it]04/27/2024 20:50:25 - WARNING - __main__ - epoch 3 step 1020 loss 0.09898\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:52:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 20:52:31 - INFO - __main__ -   eval_f1 = 0.2557\n",
      "04/27/2024 20:52:31 - INFO - __main__ -   eval_precision = 0.3797\n",
      "04/27/2024 20:52:31 - INFO - __main__ -   eval_recall = 0.1927\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 20:54:37 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 20:54:37 - INFO - __main__ -   auc_score = 0.8324\n",
      "04/27/2024 20:54:37 - INFO - __main__ -   test_f1 = 0.2449\n",
      "04/27/2024 20:54:37 - INFO - __main__ -   test_precision = 0.3462\n",
      "04/27/2024 20:54:37 - INFO - __main__ -   test_recall = 0.1895\n",
      "100% 1024/1024 [40:23<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/27/2024 20:58:33 - WARNING - __main__ - epoch 4 step 204 loss 0.04995\n",
      "04/27/2024 21:00:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:00:39 - INFO - __main__ -   eval_f1 = 0.3007\n",
      "04/27/2024 21:00:39 - INFO - __main__ -   eval_precision = 0.4454\n",
      "04/27/2024 21:00:39 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:02:45 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:02:45 - INFO - __main__ -   auc_score = 0.8241\n",
      "04/27/2024 21:02:45 - INFO - __main__ -   test_f1 = 0.2541\n",
      "04/27/2024 21:02:45 - INFO - __main__ -   test_precision = 0.3619\n",
      "04/27/2024 21:02:45 - INFO - __main__ -   test_recall = 0.1958\n",
      " 40% 407/1024 [11:56<11:43,  1.14s/it]04/27/2024 21:06:37 - WARNING - __main__ - epoch 4 step 408 loss 0.05115\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:08:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:08:43 - INFO - __main__ -   eval_f1 = 0.261\n",
      "04/27/2024 21:08:43 - INFO - __main__ -   eval_precision = 0.4479\n",
      "04/27/2024 21:08:43 - INFO - __main__ -   eval_recall = 0.1842\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:10:49 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:10:49 - INFO - __main__ -   auc_score = 0.8222\n",
      "04/27/2024 21:10:49 - INFO - __main__ -   test_f1 = 0.2203\n",
      "04/27/2024 21:10:49 - INFO - __main__ -   test_precision = 0.3641\n",
      "04/27/2024 21:10:49 - INFO - __main__ -   test_recall = 0.1579\n",
      " 60% 611/1024 [20:00<07:51,  1.14s/it]04/27/2024 21:14:41 - WARNING - __main__ - epoch 4 step 612 loss 0.04249\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:16:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:16:47 - INFO - __main__ -   eval_f1 = 0.2386\n",
      "04/27/2024 21:16:47 - INFO - __main__ -   eval_precision = 0.4471\n",
      "04/27/2024 21:16:47 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:18:53 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:18:53 - INFO - __main__ -   auc_score = 0.8265\n",
      "04/27/2024 21:18:53 - INFO - __main__ -   test_f1 = 0.2242\n",
      "04/27/2024 21:18:53 - INFO - __main__ -   test_precision = 0.4\n",
      "04/27/2024 21:18:53 - INFO - __main__ -   test_recall = 0.1558\n",
      " 80% 815/1024 [28:03<03:58,  1.14s/it]04/27/2024 21:22:45 - WARNING - __main__ - epoch 4 step 816 loss 0.0514\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:24:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:24:51 - INFO - __main__ -   eval_f1 = 0.2659\n",
      "04/27/2024 21:24:51 - INFO - __main__ -   eval_precision = 0.4089\n",
      "04/27/2024 21:24:51 - INFO - __main__ -   eval_recall = 0.197\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:26:56 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:26:56 - INFO - __main__ -   auc_score = 0.8153\n",
      "04/27/2024 21:26:56 - INFO - __main__ -   test_f1 = 0.2721\n",
      "04/27/2024 21:26:56 - INFO - __main__ -   test_precision = 0.3846\n",
      "04/27/2024 21:26:56 - INFO - __main__ -   test_recall = 0.2105\n",
      "100% 1019/1024 [36:07<00:05,  1.14s/it]04/27/2024 21:30:48 - WARNING - __main__ - epoch 4 step 1020 loss 0.06411\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:32:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:32:54 - INFO - __main__ -   eval_f1 = 0.2994\n",
      "04/27/2024 21:32:54 - INFO - __main__ -   eval_precision = 0.3766\n",
      "04/27/2024 21:32:54 - INFO - __main__ -   eval_recall = 0.2484\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:35:00 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:35:00 - INFO - __main__ -   auc_score = 0.8144\n",
      "04/27/2024 21:35:00 - INFO - __main__ -   test_f1 = 0.2559\n",
      "04/27/2024 21:35:00 - INFO - __main__ -   test_precision = 0.3121\n",
      "04/27/2024 21:35:00 - INFO - __main__ -   test_recall = 0.2168\n",
      "100% 1024/1024 [40:23<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/27/2024 21:38:56 - WARNING - __main__ - epoch 5 step 204 loss 0.02465\n",
      "04/27/2024 21:41:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:41:03 - INFO - __main__ -   eval_f1 = 0.2744\n",
      "04/27/2024 21:41:03 - INFO - __main__ -   eval_precision = 0.4042\n",
      "04/27/2024 21:41:03 - INFO - __main__ -   eval_recall = 0.2077\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:43:09 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:43:09 - INFO - __main__ -   auc_score = 0.7004\n",
      "04/27/2024 21:43:09 - INFO - __main__ -   test_f1 = 0.2634\n",
      "04/27/2024 21:43:09 - INFO - __main__ -   test_precision = 0.3643\n",
      "04/27/2024 21:43:09 - INFO - __main__ -   test_recall = 0.2063\n",
      " 40% 407/1024 [11:56<11:44,  1.14s/it]04/27/2024 21:47:01 - WARNING - __main__ - epoch 5 step 408 loss 0.02391\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:49:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:49:07 - INFO - __main__ -   eval_f1 = 0.2525\n",
      "04/27/2024 21:49:07 - INFO - __main__ -   eval_precision = 0.3919\n",
      "04/27/2024 21:49:07 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:51:12 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:51:12 - INFO - __main__ -   auc_score = 0.7991\n",
      "04/27/2024 21:51:12 - INFO - __main__ -   test_f1 = 0.2411\n",
      "04/27/2024 21:51:12 - INFO - __main__ -   test_precision = 0.3696\n",
      "04/27/2024 21:51:12 - INFO - __main__ -   test_recall = 0.1789\n",
      " 60% 611/1024 [19:59<07:50,  1.14s/it]04/27/2024 21:55:04 - WARNING - __main__ - epoch 5 step 612 loss 0.03086\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:57:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 21:57:10 - INFO - __main__ -   eval_f1 = 0.3021\n",
      "04/27/2024 21:57:10 - INFO - __main__ -   eval_precision = 0.3503\n",
      "04/27/2024 21:57:10 - INFO - __main__ -   eval_recall = 0.2655\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 21:59:16 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 21:59:16 - INFO - __main__ -   auc_score = 0.8095\n",
      "04/27/2024 21:59:16 - INFO - __main__ -   test_f1 = 0.2744\n",
      "04/27/2024 21:59:16 - INFO - __main__ -   test_precision = 0.3065\n",
      "04/27/2024 21:59:16 - INFO - __main__ -   test_recall = 0.2484\n",
      " 80% 815/1024 [28:03<03:58,  1.14s/it]04/27/2024 22:03:07 - WARNING - __main__ - epoch 5 step 816 loss 0.03329\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:05:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:05:13 - INFO - __main__ -   eval_f1 = 0.3137\n",
      "04/27/2024 22:05:13 - INFO - __main__ -   eval_precision = 0.4027\n",
      "04/27/2024 22:05:13 - INFO - __main__ -   eval_recall = 0.257\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:07:19 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:07:19 - INFO - __main__ -   auc_score = 0.8151\n",
      "04/27/2024 22:07:19 - INFO - __main__ -   test_f1 = 0.2804\n",
      "04/27/2024 22:07:19 - INFO - __main__ -   test_precision = 0.3373\n",
      "04/27/2024 22:07:19 - INFO - __main__ -   test_recall = 0.24\n",
      "100% 1019/1024 [36:06<00:05,  1.14s/it]04/27/2024 22:11:11 - WARNING - __main__ - epoch 5 step 1020 loss 0.03086\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:13:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:13:17 - INFO - __main__ -   eval_f1 = 0.3158\n",
      "04/27/2024 22:13:17 - INFO - __main__ -   eval_precision = 0.427\n",
      "04/27/2024 22:13:17 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:15:23 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:15:23 - INFO - __main__ -   auc_score = 0.8264\n",
      "04/27/2024 22:15:23 - INFO - __main__ -   test_f1 = 0.2774\n",
      "04/27/2024 22:15:23 - INFO - __main__ -   test_precision = 0.3505\n",
      "04/27/2024 22:15:23 - INFO - __main__ -   test_recall = 0.2295\n",
      "100% 1024/1024 [40:22<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/27/2024 22:19:19 - WARNING - __main__ - epoch 6 step 204 loss 0.01673\n",
      "04/27/2024 22:21:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:21:25 - INFO - __main__ -   eval_f1 = 0.3058\n",
      "04/27/2024 22:21:25 - INFO - __main__ -   eval_precision = 0.4286\n",
      "04/27/2024 22:21:25 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:23:30 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:23:30 - INFO - __main__ -   auc_score = 0.8157\n",
      "04/27/2024 22:23:30 - INFO - __main__ -   test_f1 = 0.2565\n",
      "04/27/2024 22:23:30 - INFO - __main__ -   test_precision = 0.3391\n",
      "04/27/2024 22:23:30 - INFO - __main__ -   test_recall = 0.2063\n",
      " 40% 407/1024 [11:54<11:42,  1.14s/it]04/27/2024 22:27:22 - WARNING - __main__ - epoch 6 step 408 loss 0.01028\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:29:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:29:28 - INFO - __main__ -   eval_f1 = 0.2902\n",
      "04/27/2024 22:29:28 - INFO - __main__ -   eval_precision = 0.4322\n",
      "04/27/2024 22:29:28 - INFO - __main__ -   eval_recall = 0.2184\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:31:34 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:31:34 - INFO - __main__ -   auc_score = 0.8133\n",
      "04/27/2024 22:31:34 - INFO - __main__ -   test_f1 = 0.2338\n",
      "04/27/2024 22:31:34 - INFO - __main__ -   test_precision = 0.3373\n",
      "04/27/2024 22:31:34 - INFO - __main__ -   test_recall = 0.1789\n",
      " 60% 611/1024 [19:58<07:51,  1.14s/it]04/27/2024 22:35:26 - WARNING - __main__ - epoch 6 step 612 loss 0.01758\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:37:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:37:32 - INFO - __main__ -   eval_f1 = 0.2869\n",
      "04/27/2024 22:37:32 - INFO - __main__ -   eval_precision = 0.3962\n",
      "04/27/2024 22:37:32 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:39:38 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:39:38 - INFO - __main__ -   auc_score = 0.7278\n",
      "04/27/2024 22:39:38 - INFO - __main__ -   test_f1 = 0.228\n",
      "04/27/2024 22:39:38 - INFO - __main__ -   test_precision = 0.2963\n",
      "04/27/2024 22:39:38 - INFO - __main__ -   test_recall = 0.1853\n",
      " 80% 815/1024 [28:02<03:58,  1.14s/it]04/27/2024 22:43:30 - WARNING - __main__ - epoch 6 step 816 loss 0.01342\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:45:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:45:36 - INFO - __main__ -   eval_f1 = 0.3079\n",
      "04/27/2024 22:45:36 - INFO - __main__ -   eval_precision = 0.4232\n",
      "04/27/2024 22:45:36 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:47:42 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:47:42 - INFO - __main__ -   auc_score = 0.7889\n",
      "04/27/2024 22:47:42 - INFO - __main__ -   test_f1 = 0.2451\n",
      "04/27/2024 22:47:42 - INFO - __main__ -   test_precision = 0.3275\n",
      "04/27/2024 22:47:42 - INFO - __main__ -   test_recall = 0.1958\n",
      "100% 1019/1024 [36:06<00:05,  1.14s/it]04/27/2024 22:51:34 - WARNING - __main__ - epoch 6 step 1020 loss 0.01776\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:53:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 22:53:40 - INFO - __main__ -   eval_f1 = 0.2936\n",
      "04/27/2024 22:53:40 - INFO - __main__ -   eval_precision = 0.3545\n",
      "04/27/2024 22:53:40 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 22:55:45 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 22:55:45 - INFO - __main__ -   auc_score = 0.7947\n",
      "04/27/2024 22:55:45 - INFO - __main__ -   test_f1 = 0.284\n",
      "04/27/2024 22:55:45 - INFO - __main__ -   test_precision = 0.3243\n",
      "04/27/2024 22:55:45 - INFO - __main__ -   test_recall = 0.2526\n",
      "100% 1024/1024 [40:22<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/27/2024 22:59:42 - WARNING - __main__ - epoch 7 step 204 loss 0.0056\n",
      "04/27/2024 23:01:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:01:47 - INFO - __main__ -   eval_f1 = 0.2931\n",
      "04/27/2024 23:01:47 - INFO - __main__ -   eval_precision = 0.3717\n",
      "04/27/2024 23:01:47 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:03:53 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 23:03:53 - INFO - __main__ -   auc_score = 0.7906\n",
      "04/27/2024 23:03:53 - INFO - __main__ -   test_f1 = 0.2635\n",
      "04/27/2024 23:03:53 - INFO - __main__ -   test_precision = 0.3175\n",
      "04/27/2024 23:03:53 - INFO - __main__ -   test_recall = 0.2253\n",
      " 40% 407/1024 [11:55<11:43,  1.14s/it]04/27/2024 23:07:45 - WARNING - __main__ - epoch 7 step 408 loss 0.01247\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:09:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:09:51 - INFO - __main__ -   eval_f1 = 0.2834\n",
      "04/27/2024 23:09:51 - INFO - __main__ -   eval_precision = 0.3832\n",
      "04/27/2024 23:09:51 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:11:57 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 23:11:57 - INFO - __main__ -   auc_score = 0.7353\n",
      "04/27/2024 23:11:57 - INFO - __main__ -   test_f1 = 0.2407\n",
      "04/27/2024 23:11:57 - INFO - __main__ -   test_precision = 0.3072\n",
      "04/27/2024 23:11:57 - INFO - __main__ -   test_recall = 0.1979\n",
      " 60% 611/1024 [19:58<07:50,  1.14s/it]04/27/2024 23:15:49 - WARNING - __main__ - epoch 7 step 612 loss 0.00879\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:17:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:17:55 - INFO - __main__ -   eval_f1 = 0.2945\n",
      "04/27/2024 23:17:55 - INFO - __main__ -   eval_precision = 0.4268\n",
      "04/27/2024 23:17:55 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:20:01 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 23:20:01 - INFO - __main__ -   auc_score = 0.7576\n",
      "04/27/2024 23:20:01 - INFO - __main__ -   test_f1 = 0.245\n",
      "04/27/2024 23:20:01 - INFO - __main__ -   test_precision = 0.3333\n",
      "04/27/2024 23:20:01 - INFO - __main__ -   test_recall = 0.1937\n",
      " 80% 815/1024 [28:02<03:58,  1.14s/it]04/27/2024 23:23:53 - WARNING - __main__ - epoch 7 step 816 loss 0.01051\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:25:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:25:59 - INFO - __main__ -   eval_f1 = 0.3143\n",
      "04/27/2024 23:25:59 - INFO - __main__ -   eval_precision = 0.3993\n",
      "04/27/2024 23:25:59 - INFO - __main__ -   eval_recall = 0.2591\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:28:04 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 23:28:04 - INFO - __main__ -   auc_score = 0.7537\n",
      "04/27/2024 23:28:04 - INFO - __main__ -   test_f1 = 0.2678\n",
      "04/27/2024 23:28:04 - INFO - __main__ -   test_precision = 0.3215\n",
      "04/27/2024 23:28:04 - INFO - __main__ -   test_recall = 0.2295\n",
      "100% 1019/1024 [36:06<00:05,  1.14s/it]04/27/2024 23:31:56 - WARNING - __main__ - epoch 7 step 1020 loss 0.0064\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:34:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:34:02 - INFO - __main__ -   eval_f1 = 0.273\n",
      "04/27/2024 23:34:02 - INFO - __main__ -   eval_precision = 0.4148\n",
      "04/27/2024 23:34:02 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/27/2024 23:36:08 - INFO - __main__ - ***** Test results *****\n",
      "04/27/2024 23:36:08 - INFO - __main__ -   auc_score = 0.7658\n",
      "04/27/2024 23:36:08 - INFO - __main__ -   test_f1 = 0.2538\n",
      "04/27/2024 23:36:08 - INFO - __main__ -   test_precision = 0.3605\n",
      "04/27/2024 23:36:08 - INFO - __main__ -   test_recall = 0.1958\n",
      "100% 1024/1024 [40:22<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/27/2024 23:40:04 - WARNING - __main__ - epoch 8 step 204 loss 0.00874\n",
      "04/27/2024 23:42:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/27/2024 23:42:10 - INFO - __main__ -   eval_f1 = 0.2399\n",
      "04/27/2024 23:42:10 - INFO - __main__ -   eval_precision = 0.4933\n",
      "04/27/2024 23:42:10 - INFO - __main__ -   eval_recall = 0.1585\n",
      "04/27/2024 23:42:25 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 203/1024 [06:13<25:09,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-4 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8H0ME5DvmQj",
    "outputId": "5cc731db-132d-4493-c099-e887f688d1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/28/2024 00:14:53 - INFO - __main__ - Successfully load epoch 2's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 00:16:59 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 00:16:59 - INFO - __main__ -   auc_score = 0.8275\n",
      "04/28/2024 00:16:59 - INFO - __main__ -   test_f1 = 0.3369\n",
      "04/28/2024 00:16:59 - INFO - __main__ -   test_precision = 0.3118\n",
      "04/28/2024 00:16:59 - INFO - __main__ -   test_recall = 0.3663\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-4 --epochs 10 --batch_size 16 --hidden_size 1024 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GZSfSn98WGU"
   },
   "source": [
    "#### LR = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyrRQxVqDSHD",
    "outputId": "8c389d40-8dc5-42bc-9396-240e7e09f599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "config.json: 100% 770/770 [00:00<00:00, 3.80MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 7.80MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 2.86MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 411kB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 12.2kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 41.3MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:06<00:00, 212MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:53<15:39,  1.14s/it]04/28/2024 13:53:53 - WARNING - __main__ - epoch 0 step 204 loss 0.26303\n",
      "04/28/2024 13:55:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 13:55:59 - INFO - __main__ -   eval_f1 = 0.1553\n",
      "04/28/2024 13:55:59 - INFO - __main__ -   eval_precision = 0.6721\n",
      "04/28/2024 13:55:59 - INFO - __main__ -   eval_recall = 0.0878\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 13:58:18 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 13:58:18 - INFO - __main__ -   auc_score = 0.8494\n",
      "04/28/2024 13:58:18 - INFO - __main__ -   test_f1 = 0.1285\n",
      "04/28/2024 13:58:18 - INFO - __main__ -   test_precision = 0.6296\n",
      "04/28/2024 13:58:18 - INFO - __main__ -   test_recall = 0.0716\n",
      " 40% 407/1024 [12:11<11:45,  1.14s/it]04/28/2024 14:02:11 - WARNING - __main__ - epoch 0 step 408 loss 0.23827\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:04:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:04:18 - INFO - __main__ -   eval_f1 = 0.0878\n",
      "04/28/2024 14:04:18 - INFO - __main__ -   eval_precision = 0.6471\n",
      "04/28/2024 14:04:18 - INFO - __main__ -   eval_recall = 0.0471\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:06:24 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:06:24 - INFO - __main__ -   auc_score = 0.8344\n",
      "04/28/2024 14:06:24 - INFO - __main__ -   test_f1 = 0.0645\n",
      "04/28/2024 14:06:24 - INFO - __main__ -   test_precision = 0.7619\n",
      "04/28/2024 14:06:24 - INFO - __main__ -   test_recall = 0.0337\n",
      " 60% 611/1024 [20:17<07:52,  1.14s/it]04/28/2024 14:10:16 - WARNING - __main__ - epoch 0 step 612 loss 0.22012\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:12:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:12:23 - INFO - __main__ -   eval_f1 = 0.1044\n",
      "04/28/2024 14:12:23 - INFO - __main__ -   eval_precision = 0.8387\n",
      "04/28/2024 14:12:23 - INFO - __main__ -   eval_recall = 0.0557\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:14:29 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:14:29 - INFO - __main__ -   auc_score = 0.8581\n",
      "04/28/2024 14:14:29 - INFO - __main__ -   test_f1 = 0.0765\n",
      "04/28/2024 14:14:29 - INFO - __main__ -   test_precision = 0.8636\n",
      "04/28/2024 14:14:29 - INFO - __main__ -   test_recall = 0.04\n",
      " 80% 815/1024 [28:22<03:59,  1.14s/it]04/28/2024 14:18:22 - WARNING - __main__ - epoch 0 step 816 loss 0.20888\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:20:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:20:28 - INFO - __main__ -   eval_f1 = 0.373\n",
      "04/28/2024 14:20:28 - INFO - __main__ -   eval_precision = 0.5935\n",
      "04/28/2024 14:20:28 - INFO - __main__ -   eval_recall = 0.2719\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:22:51 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:22:51 - INFO - __main__ -   auc_score = 0.8663\n",
      "04/28/2024 14:22:51 - INFO - __main__ -   test_f1 = 0.3347\n",
      "04/28/2024 14:22:51 - INFO - __main__ -   test_precision = 0.4959\n",
      "04/28/2024 14:22:51 - INFO - __main__ -   test_recall = 0.2526\n",
      "100% 1019/1024 [36:44<00:05,  1.14s/it]04/28/2024 14:26:44 - WARNING - __main__ - epoch 0 step 1020 loss 0.21888\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:28:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:28:50 - INFO - __main__ -   eval_f1 = 0.4037\n",
      "04/28/2024 14:28:50 - INFO - __main__ -   eval_precision = 0.5203\n",
      "04/28/2024 14:28:50 - INFO - __main__ -   eval_recall = 0.3298\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:31:15 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:31:15 - INFO - __main__ -   auc_score = 0.8625\n",
      "04/28/2024 14:31:15 - INFO - __main__ -   test_f1 = 0.381\n",
      "04/28/2024 14:31:15 - INFO - __main__ -   test_precision = 0.4901\n",
      "04/28/2024 14:31:15 - INFO - __main__ -   test_recall = 0.3116\n",
      "100% 1024/1024 [41:20<00:00,  2.42s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]04/28/2024 14:35:12 - WARNING - __main__ - epoch 1 step 204 loss 0.161\n",
      "04/28/2024 14:37:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:37:18 - INFO - __main__ -   eval_f1 = 0.3676\n",
      "04/28/2024 14:37:18 - INFO - __main__ -   eval_precision = 0.5869\n",
      "04/28/2024 14:37:18 - INFO - __main__ -   eval_recall = 0.2677\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:39:25 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:39:25 - INFO - __main__ -   auc_score = 0.858\n",
      "04/28/2024 14:39:25 - INFO - __main__ -   test_f1 = 0.3333\n",
      "04/28/2024 14:39:25 - INFO - __main__ -   test_precision = 0.4979\n",
      "04/28/2024 14:39:25 - INFO - __main__ -   test_recall = 0.2505\n",
      " 40% 407/1024 [11:58<11:46,  1.14s/it]04/28/2024 14:43:17 - WARNING - __main__ - epoch 1 step 408 loss 0.16764\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:45:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:45:24 - INFO - __main__ -   eval_f1 = 0.3139\n",
      "04/28/2024 14:45:24 - INFO - __main__ -   eval_precision = 0.5198\n",
      "04/28/2024 14:45:24 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:47:30 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:47:30 - INFO - __main__ -   auc_score = 0.8588\n",
      "04/28/2024 14:47:30 - INFO - __main__ -   test_f1 = 0.3357\n",
      "04/28/2024 14:47:30 - INFO - __main__ -   test_precision = 0.527\n",
      "04/28/2024 14:47:30 - INFO - __main__ -   test_recall = 0.2463\n",
      " 60% 611/1024 [20:03<07:52,  1.14s/it]04/28/2024 14:51:23 - WARNING - __main__ - epoch 1 step 612 loss 0.16709\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:53:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 14:53:29 - INFO - __main__ -   eval_f1 = 0.3146\n",
      "04/28/2024 14:53:29 - INFO - __main__ -   eval_precision = 0.4823\n",
      "04/28/2024 14:53:29 - INFO - __main__ -   eval_recall = 0.2334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 14:55:35 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 14:55:35 - INFO - __main__ -   auc_score = 0.8564\n",
      "04/28/2024 14:55:35 - INFO - __main__ -   test_f1 = 0.3267\n",
      "04/28/2024 14:55:35 - INFO - __main__ -   test_precision = 0.4424\n",
      "04/28/2024 14:55:35 - INFO - __main__ -   test_recall = 0.2589\n",
      " 80% 815/1024 [28:08<03:59,  1.14s/it]04/28/2024 14:59:28 - WARNING - __main__ - epoch 1 step 816 loss 0.17911\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:01:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:01:35 - INFO - __main__ -   eval_f1 = 0.3394\n",
      "04/28/2024 15:01:35 - INFO - __main__ -   eval_precision = 0.4919\n",
      "04/28/2024 15:01:35 - INFO - __main__ -   eval_recall = 0.2591\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:03:41 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:03:41 - INFO - __main__ -   auc_score = 0.8662\n",
      "04/28/2024 15:03:41 - INFO - __main__ -   test_f1 = 0.3265\n",
      "04/28/2024 15:03:41 - INFO - __main__ -   test_precision = 0.4685\n",
      "04/28/2024 15:03:41 - INFO - __main__ -   test_recall = 0.2505\n",
      "100% 1019/1024 [36:14<00:05,  1.14s/it]04/28/2024 15:07:34 - WARNING - __main__ - epoch 1 step 1020 loss 0.16093\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:09:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:09:40 - INFO - __main__ -   eval_f1 = 0.3079\n",
      "04/28/2024 15:09:40 - INFO - __main__ -   eval_precision = 0.5099\n",
      "04/28/2024 15:09:40 - INFO - __main__ -   eval_recall = 0.2206\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:11:46 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:11:46 - INFO - __main__ -   auc_score = 0.8541\n",
      "04/28/2024 15:11:46 - INFO - __main__ -   test_f1 = 0.3314\n",
      "04/28/2024 15:11:46 - INFO - __main__ -   test_precision = 0.5065\n",
      "04/28/2024 15:11:46 - INFO - __main__ -   test_recall = 0.2463\n",
      "100% 1024/1024 [40:31<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]04/28/2024 15:15:43 - WARNING - __main__ - epoch 2 step 204 loss 0.08543\n",
      "04/28/2024 15:17:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:17:50 - INFO - __main__ -   eval_f1 = 0.3132\n",
      "04/28/2024 15:17:50 - INFO - __main__ -   eval_precision = 0.4368\n",
      "04/28/2024 15:17:50 - INFO - __main__ -   eval_recall = 0.2441\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:19:56 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:19:56 - INFO - __main__ -   auc_score = 0.8474\n",
      "04/28/2024 15:19:56 - INFO - __main__ -   test_f1 = 0.3449\n",
      "04/28/2024 15:19:56 - INFO - __main__ -   test_precision = 0.4199\n",
      "04/28/2024 15:19:56 - INFO - __main__ -   test_recall = 0.2926\n",
      " 40% 407/1024 [11:58<11:46,  1.14s/it]04/28/2024 15:23:48 - WARNING - __main__ - epoch 2 step 408 loss 0.08145\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:25:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:25:55 - INFO - __main__ -   eval_f1 = 0.367\n",
      "04/28/2024 15:25:55 - INFO - __main__ -   eval_precision = 0.3951\n",
      "04/28/2024 15:25:55 - INFO - __main__ -   eval_recall = 0.3426\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:28:01 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:28:01 - INFO - __main__ -   auc_score = 0.8429\n",
      "04/28/2024 15:28:01 - INFO - __main__ -   test_f1 = 0.3707\n",
      "04/28/2024 15:28:01 - INFO - __main__ -   test_precision = 0.392\n",
      "04/28/2024 15:28:01 - INFO - __main__ -   test_recall = 0.3516\n",
      " 60% 611/1024 [20:03<07:52,  1.14s/it]04/28/2024 15:31:54 - WARNING - __main__ - epoch 2 step 612 loss 0.08149\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:34:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:34:00 - INFO - __main__ -   eval_f1 = 0.2932\n",
      "04/28/2024 15:34:00 - INFO - __main__ -   eval_precision = 0.5249\n",
      "04/28/2024 15:34:00 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:36:07 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:36:07 - INFO - __main__ -   auc_score = 0.8315\n",
      "04/28/2024 15:36:07 - INFO - __main__ -   test_f1 = 0.2683\n",
      "04/28/2024 15:36:07 - INFO - __main__ -   test_precision = 0.4592\n",
      "04/28/2024 15:36:07 - INFO - __main__ -   test_recall = 0.1895\n",
      " 80% 815/1024 [28:08<03:59,  1.14s/it]04/28/2024 15:39:59 - WARNING - __main__ - epoch 2 step 816 loss 0.08628\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:42:06 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:42:06 - INFO - __main__ -   eval_f1 = 0.3379\n",
      "04/28/2024 15:42:06 - INFO - __main__ -   eval_precision = 0.4644\n",
      "04/28/2024 15:42:06 - INFO - __main__ -   eval_recall = 0.2655\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:44:12 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:44:12 - INFO - __main__ -   auc_score = 0.8496\n",
      "04/28/2024 15:44:12 - INFO - __main__ -   test_f1 = 0.3226\n",
      "04/28/2024 15:44:12 - INFO - __main__ -   test_precision = 0.4167\n",
      "04/28/2024 15:44:12 - INFO - __main__ -   test_recall = 0.2632\n",
      "100% 1019/1024 [36:14<00:05,  1.14s/it]04/28/2024 15:48:05 - WARNING - __main__ - epoch 2 step 1020 loss 0.08391\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:50:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:50:11 - INFO - __main__ -   eval_f1 = 0.3401\n",
      "04/28/2024 15:50:11 - INFO - __main__ -   eval_precision = 0.5294\n",
      "04/28/2024 15:50:11 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 15:52:18 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 15:52:18 - INFO - __main__ -   auc_score = 0.8472\n",
      "04/28/2024 15:52:18 - INFO - __main__ -   test_f1 = 0.319\n",
      "04/28/2024 15:52:18 - INFO - __main__ -   test_precision = 0.4391\n",
      "04/28/2024 15:52:18 - INFO - __main__ -   test_recall = 0.2505\n",
      "100% 1024/1024 [40:31<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:37,  1.14s/it]04/28/2024 15:56:14 - WARNING - __main__ - epoch 3 step 204 loss 0.02931\n",
      "04/28/2024 15:58:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 15:58:21 - INFO - __main__ -   eval_f1 = 0.2698\n",
      "04/28/2024 15:58:21 - INFO - __main__ -   eval_precision = 0.5215\n",
      "04/28/2024 15:58:21 - INFO - __main__ -   eval_recall = 0.182\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:00:27 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:00:27 - INFO - __main__ -   auc_score = 0.8244\n",
      "04/28/2024 16:00:27 - INFO - __main__ -   test_f1 = 0.2791\n",
      "04/28/2024 16:00:27 - INFO - __main__ -   test_precision = 0.4507\n",
      "04/28/2024 16:00:27 - INFO - __main__ -   test_recall = 0.2021\n",
      " 40% 407/1024 [11:57<11:45,  1.14s/it]04/28/2024 16:04:20 - WARNING - __main__ - epoch 3 step 408 loss 0.02897\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:06:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:06:26 - INFO - __main__ -   eval_f1 = 0.304\n",
      "04/28/2024 16:06:26 - INFO - __main__ -   eval_precision = 0.4515\n",
      "04/28/2024 16:06:26 - INFO - __main__ -   eval_recall = 0.2291\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:08:32 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:08:32 - INFO - __main__ -   auc_score = 0.8314\n",
      "04/28/2024 16:08:32 - INFO - __main__ -   test_f1 = 0.3221\n",
      "04/28/2024 16:08:32 - INFO - __main__ -   test_precision = 0.4203\n",
      "04/28/2024 16:08:32 - INFO - __main__ -   test_recall = 0.2611\n",
      " 60% 611/1024 [20:03<07:52,  1.14s/it]04/28/2024 16:12:25 - WARNING - __main__ - epoch 3 step 612 loss 0.03569\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:14:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:14:32 - INFO - __main__ -   eval_f1 = 0.3343\n",
      "04/28/2024 16:14:32 - INFO - __main__ -   eval_precision = 0.5021\n",
      "04/28/2024 16:14:32 - INFO - __main__ -   eval_recall = 0.2505\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:16:38 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:16:38 - INFO - __main__ -   auc_score = 0.8258\n",
      "04/28/2024 16:16:38 - INFO - __main__ -   test_f1 = 0.3347\n",
      "04/28/2024 16:16:38 - INFO - __main__ -   test_precision = 0.4731\n",
      "04/28/2024 16:16:38 - INFO - __main__ -   test_recall = 0.2589\n",
      " 80% 815/1024 [28:08<03:59,  1.14s/it]04/28/2024 16:20:31 - WARNING - __main__ - epoch 3 step 816 loss 0.04116\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:22:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:22:37 - INFO - __main__ -   eval_f1 = 0.3356\n",
      "04/28/2024 16:22:37 - INFO - __main__ -   eval_precision = 0.4624\n",
      "04/28/2024 16:22:37 - INFO - __main__ -   eval_recall = 0.2634\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:24:43 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:24:43 - INFO - __main__ -   auc_score = 0.8405\n",
      "04/28/2024 16:24:43 - INFO - __main__ -   test_f1 = 0.3316\n",
      "04/28/2024 16:24:43 - INFO - __main__ -   test_precision = 0.4421\n",
      "04/28/2024 16:24:43 - INFO - __main__ -   test_recall = 0.2653\n",
      "100% 1019/1024 [36:14<00:05,  1.14s/it]04/28/2024 16:28:36 - WARNING - __main__ - epoch 3 step 1020 loss 0.03454\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:30:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:30:43 - INFO - __main__ -   eval_f1 = 0.23\n",
      "04/28/2024 16:30:43 - INFO - __main__ -   eval_precision = 0.5188\n",
      "04/28/2024 16:30:43 - INFO - __main__ -   eval_recall = 0.1478\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:32:49 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:32:49 - INFO - __main__ -   auc_score = 0.8338\n",
      "04/28/2024 16:32:49 - INFO - __main__ -   test_f1 = 0.2265\n",
      "04/28/2024 16:32:49 - INFO - __main__ -   test_precision = 0.4895\n",
      "04/28/2024 16:32:49 - INFO - __main__ -   test_recall = 0.1474\n",
      "100% 1024/1024 [40:31<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]04/28/2024 16:36:46 - WARNING - __main__ - epoch 4 step 204 loss 0.00764\n",
      "04/28/2024 16:38:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:38:52 - INFO - __main__ -   eval_f1 = 0.2133\n",
      "04/28/2024 16:38:52 - INFO - __main__ -   eval_precision = 0.581\n",
      "04/28/2024 16:38:52 - INFO - __main__ -   eval_recall = 0.1306\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:40:58 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:40:58 - INFO - __main__ -   auc_score = 0.8035\n",
      "04/28/2024 16:40:58 - INFO - __main__ -   test_f1 = 0.2222\n",
      "04/28/2024 16:40:58 - INFO - __main__ -   test_precision = 0.5234\n",
      "04/28/2024 16:40:58 - INFO - __main__ -   test_recall = 0.1411\n",
      " 40% 407/1024 [11:57<11:46,  1.14s/it]04/28/2024 16:44:51 - WARNING - __main__ - epoch 4 step 408 loss 0.01564\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:46:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:46:58 - INFO - __main__ -   eval_f1 = 0.3118\n",
      "04/28/2024 16:46:58 - INFO - __main__ -   eval_precision = 0.52\n",
      "04/28/2024 16:46:58 - INFO - __main__ -   eval_recall = 0.2227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:49:04 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:49:04 - INFO - __main__ -   auc_score = 0.8245\n",
      "04/28/2024 16:49:04 - INFO - __main__ -   test_f1 = 0.3059\n",
      "04/28/2024 16:49:04 - INFO - __main__ -   test_precision = 0.4862\n",
      "04/28/2024 16:49:04 - INFO - __main__ -   test_recall = 0.2232\n",
      " 60% 611/1024 [20:03<07:51,  1.14s/it]04/28/2024 16:52:56 - WARNING - __main__ - epoch 4 step 612 loss 0.0145\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:55:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 16:55:03 - INFO - __main__ -   eval_f1 = 0.3761\n",
      "04/28/2024 16:55:03 - INFO - __main__ -   eval_precision = 0.477\n",
      "04/28/2024 16:55:03 - INFO - __main__ -   eval_recall = 0.3105\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 16:57:09 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 16:57:09 - INFO - __main__ -   auc_score = 0.8348\n",
      "04/28/2024 16:57:09 - INFO - __main__ -   test_f1 = 0.3603\n",
      "04/28/2024 16:57:09 - INFO - __main__ -   test_precision = 0.4311\n",
      "04/28/2024 16:57:09 - INFO - __main__ -   test_recall = 0.3095\n",
      " 80% 815/1024 [28:08<03:59,  1.14s/it]04/28/2024 17:01:02 - WARNING - __main__ - epoch 4 step 816 loss 0.01813\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:03:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:03:08 - INFO - __main__ -   eval_f1 = 0.2749\n",
      "04/28/2024 17:03:08 - INFO - __main__ -   eval_precision = 0.5241\n",
      "04/28/2024 17:03:08 - INFO - __main__ -   eval_recall = 0.1863\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:05:15 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:05:15 - INFO - __main__ -   auc_score = 0.8396\n",
      "04/28/2024 17:05:15 - INFO - __main__ -   test_f1 = 0.3207\n",
      "04/28/2024 17:05:15 - INFO - __main__ -   test_precision = 0.5213\n",
      "04/28/2024 17:05:15 - INFO - __main__ -   test_recall = 0.2316\n",
      "100% 1019/1024 [36:14<00:05,  1.14s/it]04/28/2024 17:09:07 - WARNING - __main__ - epoch 4 step 1020 loss 0.0153\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:11:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:11:14 - INFO - __main__ -   eval_f1 = 0.2301\n",
      "04/28/2024 17:11:14 - INFO - __main__ -   eval_precision = 0.4733\n",
      "04/28/2024 17:11:14 - INFO - __main__ -   eval_recall = 0.152\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:13:20 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:13:20 - INFO - __main__ -   auc_score = 0.8194\n",
      "04/28/2024 17:13:20 - INFO - __main__ -   test_f1 = 0.2741\n",
      "04/28/2024 17:13:20 - INFO - __main__ -   test_precision = 0.4815\n",
      "04/28/2024 17:13:20 - INFO - __main__ -   test_recall = 0.1916\n",
      "100% 1024/1024 [40:30<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:36,  1.14s/it]04/28/2024 17:17:16 - WARNING - __main__ - epoch 5 step 204 loss 0.00463\n",
      "04/28/2024 17:19:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:19:23 - INFO - __main__ -   eval_f1 = 0.3097\n",
      "04/28/2024 17:19:23 - INFO - __main__ -   eval_precision = 0.4599\n",
      "04/28/2024 17:19:23 - INFO - __main__ -   eval_recall = 0.2334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:21:29 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:21:29 - INFO - __main__ -   auc_score = 0.8175\n",
      "04/28/2024 17:21:29 - INFO - __main__ -   test_f1 = 0.3417\n",
      "04/28/2024 17:21:29 - INFO - __main__ -   test_precision = 0.4607\n",
      "04/28/2024 17:21:29 - INFO - __main__ -   test_recall = 0.2716\n",
      " 40% 407/1024 [11:57<11:45,  1.14s/it]04/28/2024 17:25:21 - WARNING - __main__ - epoch 5 step 408 loss 0.00348\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:27:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:27:28 - INFO - __main__ -   eval_f1 = 0.2533\n",
      "04/28/2024 17:27:28 - INFO - __main__ -   eval_precision = 0.5714\n",
      "04/28/2024 17:27:28 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:29:34 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:29:34 - INFO - __main__ -   auc_score = 0.7991\n",
      "04/28/2024 17:29:34 - INFO - __main__ -   test_f1 = 0.2441\n",
      "04/28/2024 17:29:34 - INFO - __main__ -   test_precision = 0.4936\n",
      "04/28/2024 17:29:34 - INFO - __main__ -   test_recall = 0.1621\n",
      " 60% 611/1024 [20:02<07:51,  1.14s/it]04/28/2024 17:33:26 - WARNING - __main__ - epoch 5 step 612 loss 0.00525\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:35:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:35:33 - INFO - __main__ -   eval_f1 = 0.296\n",
      "04/28/2024 17:35:33 - INFO - __main__ -   eval_precision = 0.5429\n",
      "04/28/2024 17:35:33 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:37:39 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:37:39 - INFO - __main__ -   auc_score = 0.8187\n",
      "04/28/2024 17:37:39 - INFO - __main__ -   test_f1 = 0.3231\n",
      "04/28/2024 17:37:39 - INFO - __main__ -   test_precision = 0.5236\n",
      "04/28/2024 17:37:39 - INFO - __main__ -   test_recall = 0.2337\n",
      " 80% 815/1024 [28:07<03:59,  1.14s/it]04/28/2024 17:41:31 - WARNING - __main__ - epoch 5 step 816 loss 0.00957\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:43:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:43:38 - INFO - __main__ -   eval_f1 = 0.3142\n",
      "04/28/2024 17:43:38 - INFO - __main__ -   eval_precision = 0.5333\n",
      "04/28/2024 17:43:38 - INFO - __main__ -   eval_recall = 0.2227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:45:44 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:45:44 - INFO - __main__ -   auc_score = 0.7586\n",
      "04/28/2024 17:45:44 - INFO - __main__ -   test_f1 = 0.2993\n",
      "04/28/2024 17:45:44 - INFO - __main__ -   test_precision = 0.4727\n",
      "04/28/2024 17:45:44 - INFO - __main__ -   test_recall = 0.2189\n",
      "100% 1019/1024 [36:11<00:05,  1.14s/it]04/28/2024 17:49:35 - WARNING - __main__ - epoch 5 step 1020 loss 0.01827\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:51:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:51:42 - INFO - __main__ -   eval_f1 = 0.3367\n",
      "04/28/2024 17:51:42 - INFO - __main__ -   eval_precision = 0.5043\n",
      "04/28/2024 17:51:42 - INFO - __main__ -   eval_recall = 0.2527\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 17:53:48 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 17:53:48 - INFO - __main__ -   auc_score = 0.8281\n",
      "04/28/2024 17:53:48 - INFO - __main__ -   test_f1 = 0.3174\n",
      "04/28/2024 17:53:48 - INFO - __main__ -   test_precision = 0.4531\n",
      "04/28/2024 17:53:48 - INFO - __main__ -   test_recall = 0.2442\n",
      "100% 1024/1024 [40:27<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/28/2024 17:57:44 - WARNING - __main__ - epoch 6 step 204 loss 0.00569\n",
      "04/28/2024 17:59:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 17:59:50 - INFO - __main__ -   eval_f1 = 0.3096\n",
      "04/28/2024 17:59:50 - INFO - __main__ -   eval_precision = 0.5587\n",
      "04/28/2024 17:59:50 - INFO - __main__ -   eval_recall = 0.2141\n",
      "04/28/2024 17:59:50 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 203/1024 [05:58<24:10,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 5e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqgnMZ3T9OnS",
    "outputId": "be79db42-a7f0-4b85-a039-da77b11ef9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/28/2024 18:02:42 - INFO - __main__ - Successfully load epoch 0's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:04:49 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 18:04:49 - INFO - __main__ -   auc_score = 0.861\n",
      "04/28/2024 18:04:49 - INFO - __main__ -   test_f1 = 0.3769\n",
      "04/28/2024 18:04:49 - INFO - __main__ -   test_precision = 0.482\n",
      "04/28/2024 18:04:49 - INFO - __main__ -   test_recall = 0.3095\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 5e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwFNbdpt7l39"
   },
   "source": [
    "#### LR = 1e-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmm5qkiT7zUq"
   },
   "outputs": [],
   "source": [
    "!rm -r ../results/jitfine_adapter/codet5p-770m/single/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHFlfwZc5zPe",
    "outputId": "dddf192f-3da2-4f80-ed5b-a3b4f83c2bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:38,  1.14s/it]04/28/2024 18:27:46 - WARNING - __main__ - epoch 0 step 204 loss 0.30441\n",
      "04/28/2024 18:29:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 18:29:52 - INFO - __main__ -   eval_f1 = 0.0128\n",
      "04/28/2024 18:29:52 - INFO - __main__ -   eval_precision = 1.0\n",
      "04/28/2024 18:29:52 - INFO - __main__ -   eval_recall = 0.0064\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:32:14 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 18:32:14 - INFO - __main__ -   auc_score = 0.8393\n",
      "04/28/2024 18:32:14 - INFO - __main__ -   test_f1 = 0.0042\n",
      "04/28/2024 18:32:14 - INFO - __main__ -   test_precision = 1.0\n",
      "04/28/2024 18:32:14 - INFO - __main__ -   test_recall = 0.0021\n",
      " 40% 407/1024 [12:12<11:44,  1.14s/it]04/28/2024 18:36:06 - WARNING - __main__ - epoch 0 step 408 loss 0.23984\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:38:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 18:38:12 - INFO - __main__ -   eval_f1 = 0.3785\n",
      "04/28/2024 18:38:12 - INFO - __main__ -   eval_precision = 0.5072\n",
      "04/28/2024 18:38:12 - INFO - __main__ -   eval_recall = 0.3019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:40:34 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 18:40:34 - INFO - __main__ -   auc_score = 0.8585\n",
      "04/28/2024 18:40:34 - INFO - __main__ -   test_f1 = 0.3542\n",
      "04/28/2024 18:40:34 - INFO - __main__ -   test_precision = 0.4819\n",
      "04/28/2024 18:40:34 - INFO - __main__ -   test_recall = 0.28\n",
      " 60% 611/1024 [20:32<07:51,  1.14s/it]04/28/2024 18:44:26 - WARNING - __main__ - epoch 0 step 612 loss 0.22373\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:46:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 18:46:32 - INFO - __main__ -   eval_f1 = 0.3354\n",
      "04/28/2024 18:46:32 - INFO - __main__ -   eval_precision = 0.5956\n",
      "04/28/2024 18:46:32 - INFO - __main__ -   eval_recall = 0.2334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:48:39 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 18:48:39 - INFO - __main__ -   auc_score = 0.8709\n",
      "04/28/2024 18:48:39 - INFO - __main__ -   test_f1 = 0.2951\n",
      "04/28/2024 18:48:39 - INFO - __main__ -   test_precision = 0.5802\n",
      "04/28/2024 18:48:39 - INFO - __main__ -   test_recall = 0.1979\n",
      " 80% 815/1024 [28:37<03:58,  1.14s/it]04/28/2024 18:52:31 - WARNING - __main__ - epoch 0 step 816 loss 0.21536\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:54:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 18:54:38 - INFO - __main__ -   eval_f1 = 0.31\n",
      "04/28/2024 18:54:38 - INFO - __main__ -   eval_precision = 0.6507\n",
      "04/28/2024 18:54:38 - INFO - __main__ -   eval_recall = 0.2034\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 18:56:43 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 18:56:43 - INFO - __main__ -   auc_score = 0.8687\n",
      "04/28/2024 18:56:43 - INFO - __main__ -   test_f1 = 0.2968\n",
      "04/28/2024 18:56:43 - INFO - __main__ -   test_precision = 0.6345\n",
      "04/28/2024 18:56:43 - INFO - __main__ -   test_recall = 0.1937\n",
      "100% 1019/1024 [36:42<00:05,  1.14s/it]04/28/2024 19:00:36 - WARNING - __main__ - epoch 0 step 1020 loss 0.21809\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:02:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:02:42 - INFO - __main__ -   eval_f1 = 0.3375\n",
      "04/28/2024 19:02:42 - INFO - __main__ -   eval_precision = 0.6089\n",
      "04/28/2024 19:02:42 - INFO - __main__ -   eval_recall = 0.2334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:04:48 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:04:48 - INFO - __main__ -   auc_score = 0.869\n",
      "04/28/2024 19:04:48 - INFO - __main__ -   test_f1 = 0.3242\n",
      "04/28/2024 19:04:48 - INFO - __main__ -   test_precision = 0.5922\n",
      "04/28/2024 19:04:48 - INFO - __main__ -   test_recall = 0.2232\n",
      "100% 1024/1024 [40:58<00:00,  2.40s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/28/2024 19:08:44 - WARNING - __main__ - epoch 1 step 204 loss 0.18348\n",
      "04/28/2024 19:10:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:10:50 - INFO - __main__ -   eval_f1 = 0.3859\n",
      "04/28/2024 19:10:50 - INFO - __main__ -   eval_precision = 0.6179\n",
      "04/28/2024 19:10:50 - INFO - __main__ -   eval_recall = 0.2805\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:13:14 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:13:14 - INFO - __main__ -   auc_score = 0.874\n",
      "04/28/2024 19:13:14 - INFO - __main__ -   test_f1 = 0.3314\n",
      "04/28/2024 19:13:14 - INFO - __main__ -   test_precision = 0.5251\n",
      "04/28/2024 19:13:14 - INFO - __main__ -   test_recall = 0.2421\n",
      " 40% 407/1024 [12:13<11:43,  1.14s/it]04/28/2024 19:17:05 - WARNING - __main__ - epoch 1 step 408 loss 0.17908\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:19:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:19:12 - INFO - __main__ -   eval_f1 = 0.2808\n",
      "04/28/2024 19:19:12 - INFO - __main__ -   eval_precision = 0.7009\n",
      "04/28/2024 19:19:12 - INFO - __main__ -   eval_recall = 0.1756\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:21:17 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:21:17 - INFO - __main__ -   auc_score = 0.8648\n",
      "04/28/2024 19:21:17 - INFO - __main__ -   test_f1 = 0.2304\n",
      "04/28/2024 19:21:17 - INFO - __main__ -   test_precision = 0.6735\n",
      "04/28/2024 19:21:17 - INFO - __main__ -   test_recall = 0.1389\n",
      " 60% 611/1024 [20:17<07:51,  1.14s/it]04/28/2024 19:25:09 - WARNING - __main__ - epoch 1 step 612 loss 0.17516\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:27:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:27:15 - INFO - __main__ -   eval_f1 = 0.3869\n",
      "04/28/2024 19:27:15 - INFO - __main__ -   eval_precision = 0.5763\n",
      "04/28/2024 19:27:15 - INFO - __main__ -   eval_recall = 0.2912\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:29:35 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:29:35 - INFO - __main__ -   auc_score = 0.8588\n",
      "04/28/2024 19:29:35 - INFO - __main__ -   test_f1 = 0.3268\n",
      "04/28/2024 19:29:35 - INFO - __main__ -   test_precision = 0.4936\n",
      "04/28/2024 19:29:35 - INFO - __main__ -   test_recall = 0.2442\n",
      " 80% 815/1024 [28:34<03:58,  1.14s/it]04/28/2024 19:33:27 - WARNING - __main__ - epoch 1 step 816 loss 0.18862\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:35:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:35:33 - INFO - __main__ -   eval_f1 = 0.3446\n",
      "04/28/2024 19:35:33 - INFO - __main__ -   eval_precision = 0.612\n",
      "04/28/2024 19:35:33 - INFO - __main__ -   eval_recall = 0.2398\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:37:39 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:37:39 - INFO - __main__ -   auc_score = 0.8652\n",
      "04/28/2024 19:37:39 - INFO - __main__ -   test_f1 = 0.3161\n",
      "04/28/2024 19:37:39 - INFO - __main__ -   test_precision = 0.5297\n",
      "04/28/2024 19:37:39 - INFO - __main__ -   test_recall = 0.2253\n",
      "100% 1019/1024 [36:39<00:05,  1.14s/it]04/28/2024 19:41:31 - WARNING - __main__ - epoch 1 step 1020 loss 0.17646\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:43:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:43:38 - INFO - __main__ -   eval_f1 = 0.2979\n",
      "04/28/2024 19:43:38 - INFO - __main__ -   eval_precision = 0.5732\n",
      "04/28/2024 19:43:38 - INFO - __main__ -   eval_recall = 0.2013\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:45:44 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:45:44 - INFO - __main__ -   auc_score = 0.8568\n",
      "04/28/2024 19:45:44 - INFO - __main__ -   test_f1 = 0.2938\n",
      "04/28/2024 19:45:44 - INFO - __main__ -   test_precision = 0.5697\n",
      "04/28/2024 19:45:44 - INFO - __main__ -   test_recall = 0.1979\n",
      "100% 1024/1024 [40:56<00:00,  2.40s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/28/2024 19:49:40 - WARNING - __main__ - epoch 2 step 204 loss 0.11769\n",
      "04/28/2024 19:51:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:51:46 - INFO - __main__ -   eval_f1 = 0.3409\n",
      "04/28/2024 19:51:46 - INFO - __main__ -   eval_precision = 0.4154\n",
      "04/28/2024 19:51:46 - INFO - __main__ -   eval_recall = 0.2891\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:53:52 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 19:53:52 - INFO - __main__ -   auc_score = 0.8387\n",
      "04/28/2024 19:53:52 - INFO - __main__ -   test_f1 = 0.3383\n",
      "04/28/2024 19:53:52 - INFO - __main__ -   test_precision = 0.4134\n",
      "04/28/2024 19:53:52 - INFO - __main__ -   test_recall = 0.2863\n",
      " 40% 407/1024 [11:56<11:45,  1.14s/it]04/28/2024 19:57:45 - WARNING - __main__ - epoch 2 step 408 loss 0.12122\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 19:59:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 19:59:51 - INFO - __main__ -   eval_f1 = 0.4071\n",
      "04/28/2024 19:59:51 - INFO - __main__ -   eval_precision = 0.4211\n",
      "04/28/2024 19:59:51 - INFO - __main__ -   eval_recall = 0.394\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:02:12 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:02:12 - INFO - __main__ -   auc_score = 0.8525\n",
      "04/28/2024 20:02:12 - INFO - __main__ -   test_f1 = 0.4104\n",
      "04/28/2024 20:02:12 - INFO - __main__ -   test_precision = 0.4213\n",
      "04/28/2024 20:02:12 - INFO - __main__ -   test_recall = 0.4\n",
      " 60% 611/1024 [20:15<07:50,  1.14s/it]04/28/2024 20:06:04 - WARNING - __main__ - epoch 2 step 612 loss 0.14415\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:08:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:08:10 - INFO - __main__ -   eval_f1 = 0.2388\n",
      "04/28/2024 20:08:10 - INFO - __main__ -   eval_precision = 0.5294\n",
      "04/28/2024 20:08:10 - INFO - __main__ -   eval_recall = 0.1542\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:10:16 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:10:16 - INFO - __main__ -   auc_score = 0.8446\n",
      "04/28/2024 20:10:16 - INFO - __main__ -   test_f1 = 0.199\n",
      "04/28/2024 20:10:16 - INFO - __main__ -   test_precision = 0.5\n",
      "04/28/2024 20:10:16 - INFO - __main__ -   test_recall = 0.1242\n",
      " 80% 815/1024 [28:19<03:58,  1.14s/it]04/28/2024 20:14:08 - WARNING - __main__ - epoch 2 step 816 loss 0.13099\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:16:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:16:14 - INFO - __main__ -   eval_f1 = 0.3703\n",
      "04/28/2024 20:16:14 - INFO - __main__ -   eval_precision = 0.5018\n",
      "04/28/2024 20:16:14 - INFO - __main__ -   eval_recall = 0.2934\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:18:20 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:18:20 - INFO - __main__ -   auc_score = 0.8601\n",
      "04/28/2024 20:18:20 - INFO - __main__ -   test_f1 = 0.3625\n",
      "04/28/2024 20:18:20 - INFO - __main__ -   test_precision = 0.476\n",
      "04/28/2024 20:18:20 - INFO - __main__ -   test_recall = 0.2926\n",
      "100% 1019/1024 [36:24<00:05,  1.14s/it]04/28/2024 20:22:13 - WARNING - __main__ - epoch 2 step 1020 loss 0.1139\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:24:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:24:20 - INFO - __main__ -   eval_f1 = 0.394\n",
      "04/28/2024 20:24:20 - INFO - __main__ -   eval_precision = 0.4293\n",
      "04/28/2024 20:24:20 - INFO - __main__ -   eval_recall = 0.364\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:26:26 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:26:26 - INFO - __main__ -   auc_score = 0.8561\n",
      "04/28/2024 20:26:26 - INFO - __main__ -   test_f1 = 0.3968\n",
      "04/28/2024 20:26:26 - INFO - __main__ -   test_precision = 0.4328\n",
      "04/28/2024 20:26:26 - INFO - __main__ -   test_recall = 0.3663\n",
      "100% 1024/1024 [40:41<00:00,  2.38s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/28/2024 20:30:22 - WARNING - __main__ - epoch 3 step 204 loss 0.06955\n",
      "04/28/2024 20:32:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:32:28 - INFO - __main__ -   eval_f1 = 0.3198\n",
      "04/28/2024 20:32:28 - INFO - __main__ -   eval_precision = 0.5408\n",
      "04/28/2024 20:32:28 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:34:34 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:34:34 - INFO - __main__ -   auc_score = 0.8468\n",
      "04/28/2024 20:34:34 - INFO - __main__ -   test_f1 = 0.2939\n",
      "04/28/2024 20:34:34 - INFO - __main__ -   test_precision = 0.4658\n",
      "04/28/2024 20:34:34 - INFO - __main__ -   test_recall = 0.2147\n",
      " 40% 407/1024 [11:56<11:44,  1.14s/it]04/28/2024 20:38:27 - WARNING - __main__ - epoch 3 step 408 loss 0.07353\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:40:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:40:33 - INFO - __main__ -   eval_f1 = 0.2512\n",
      "04/28/2024 20:40:33 - INFO - __main__ -   eval_precision = 0.5507\n",
      "04/28/2024 20:40:33 - INFO - __main__ -   eval_recall = 0.1627\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:42:39 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:42:39 - INFO - __main__ -   auc_score = 0.8284\n",
      "04/28/2024 20:42:39 - INFO - __main__ -   test_f1 = 0.2396\n",
      "04/28/2024 20:42:39 - INFO - __main__ -   test_precision = 0.4432\n",
      "04/28/2024 20:42:39 - INFO - __main__ -   test_recall = 0.1642\n",
      " 60% 611/1024 [20:00<07:50,  1.14s/it]04/28/2024 20:46:31 - WARNING - __main__ - epoch 3 step 612 loss 0.07611\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:48:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:48:37 - INFO - __main__ -   eval_f1 = 0.3669\n",
      "04/28/2024 20:48:37 - INFO - __main__ -   eval_precision = 0.379\n",
      "04/28/2024 20:48:37 - INFO - __main__ -   eval_recall = 0.3555\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:50:43 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:50:43 - INFO - __main__ -   auc_score = 0.8519\n",
      "04/28/2024 20:50:43 - INFO - __main__ -   test_f1 = 0.3855\n",
      "04/28/2024 20:50:43 - INFO - __main__ -   test_precision = 0.4018\n",
      "04/28/2024 20:50:43 - INFO - __main__ -   test_recall = 0.3705\n",
      " 80% 815/1024 [28:05<03:59,  1.14s/it]04/28/2024 20:54:36 - WARNING - __main__ - epoch 3 step 816 loss 0.08258\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:56:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 20:56:42 - INFO - __main__ -   eval_f1 = 0.3589\n",
      "04/28/2024 20:56:42 - INFO - __main__ -   eval_precision = 0.4\n",
      "04/28/2024 20:56:42 - INFO - __main__ -   eval_recall = 0.3255\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 20:58:48 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 20:58:48 - INFO - __main__ -   auc_score = 0.844\n",
      "04/28/2024 20:58:48 - INFO - __main__ -   test_f1 = 0.3622\n",
      "04/28/2024 20:58:48 - INFO - __main__ -   test_precision = 0.3945\n",
      "04/28/2024 20:58:48 - INFO - __main__ -   test_recall = 0.3347\n",
      "100% 1019/1024 [36:09<00:05,  1.14s/it]04/28/2024 21:02:40 - WARNING - __main__ - epoch 3 step 1020 loss 0.09373\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:04:46 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:04:46 - INFO - __main__ -   eval_f1 = 0.3324\n",
      "04/28/2024 21:04:46 - INFO - __main__ -   eval_precision = 0.4779\n",
      "04/28/2024 21:04:46 - INFO - __main__ -   eval_recall = 0.2548\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:06:52 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:06:52 - INFO - __main__ -   auc_score = 0.8386\n",
      "04/28/2024 21:06:52 - INFO - __main__ -   test_f1 = 0.3216\n",
      "04/28/2024 21:06:52 - INFO - __main__ -   test_precision = 0.4491\n",
      "04/28/2024 21:06:52 - INFO - __main__ -   test_recall = 0.2505\n",
      "100% 1024/1024 [40:26<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:36,  1.14s/it]04/28/2024 21:10:48 - WARNING - __main__ - epoch 4 step 204 loss 0.03958\n",
      "04/28/2024 21:12:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:12:55 - INFO - __main__ -   eval_f1 = 0.2451\n",
      "04/28/2024 21:12:55 - INFO - __main__ -   eval_precision = 0.5172\n",
      "04/28/2024 21:12:55 - INFO - __main__ -   eval_recall = 0.1606\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:15:01 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:15:01 - INFO - __main__ -   auc_score = 0.8309\n",
      "04/28/2024 21:15:01 - INFO - __main__ -   test_f1 = 0.2573\n",
      "04/28/2024 21:15:01 - INFO - __main__ -   test_precision = 0.4719\n",
      "04/28/2024 21:15:01 - INFO - __main__ -   test_recall = 0.1768\n",
      " 40% 407/1024 [11:56<11:43,  1.14s/it]04/28/2024 21:18:53 - WARNING - __main__ - epoch 4 step 408 loss 0.05716\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:20:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:20:59 - INFO - __main__ -   eval_f1 = 0.3592\n",
      "04/28/2024 21:20:59 - INFO - __main__ -   eval_precision = 0.4434\n",
      "04/28/2024 21:20:59 - INFO - __main__ -   eval_recall = 0.3019\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:23:05 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:23:05 - INFO - __main__ -   auc_score = 0.8421\n",
      "04/28/2024 21:23:05 - INFO - __main__ -   test_f1 = 0.359\n",
      "04/28/2024 21:23:05 - INFO - __main__ -   test_precision = 0.4197\n",
      "04/28/2024 21:23:05 - INFO - __main__ -   test_recall = 0.3137\n",
      " 60% 611/1024 [20:01<07:52,  1.14s/it]04/28/2024 21:26:58 - WARNING - __main__ - epoch 4 step 612 loss 0.04899\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:29:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:29:04 - INFO - __main__ -   eval_f1 = 0.3064\n",
      "04/28/2024 21:29:04 - INFO - __main__ -   eval_precision = 0.4242\n",
      "04/28/2024 21:29:04 - INFO - __main__ -   eval_recall = 0.2398\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:31:10 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:31:10 - INFO - __main__ -   auc_score = 0.833\n",
      "04/28/2024 21:31:10 - INFO - __main__ -   test_f1 = 0.3046\n",
      "04/28/2024 21:31:10 - INFO - __main__ -   test_precision = 0.4232\n",
      "04/28/2024 21:31:10 - INFO - __main__ -   test_recall = 0.2379\n",
      " 80% 815/1024 [28:05<03:58,  1.14s/it]04/28/2024 21:35:02 - WARNING - __main__ - epoch 4 step 816 loss 0.03749\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:37:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:37:08 - INFO - __main__ -   eval_f1 = 0.2965\n",
      "04/28/2024 21:37:08 - INFO - __main__ -   eval_precision = 0.5052\n",
      "04/28/2024 21:37:08 - INFO - __main__ -   eval_recall = 0.2099\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:39:14 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:39:14 - INFO - __main__ -   auc_score = 0.8371\n",
      "04/28/2024 21:39:14 - INFO - __main__ -   test_f1 = 0.2965\n",
      "04/28/2024 21:39:14 - INFO - __main__ -   test_precision = 0.4789\n",
      "04/28/2024 21:39:14 - INFO - __main__ -   test_recall = 0.2147\n",
      "100% 1019/1024 [36:09<00:05,  1.14s/it]04/28/2024 21:43:06 - WARNING - __main__ - epoch 4 step 1020 loss 0.04735\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:45:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:45:13 - INFO - __main__ -   eval_f1 = 0.3659\n",
      "04/28/2024 21:45:13 - INFO - __main__ -   eval_precision = 0.45\n",
      "04/28/2024 21:45:13 - INFO - __main__ -   eval_recall = 0.3084\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:47:19 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:47:19 - INFO - __main__ -   auc_score = 0.835\n",
      "04/28/2024 21:47:19 - INFO - __main__ -   test_f1 = 0.3447\n",
      "04/28/2024 21:47:19 - INFO - __main__ -   test_precision = 0.4069\n",
      "04/28/2024 21:47:19 - INFO - __main__ -   test_recall = 0.2989\n",
      "100% 1024/1024 [40:26<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]04/28/2024 21:51:16 - WARNING - __main__ - epoch 5 step 204 loss 0.02919\n",
      "04/28/2024 21:53:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 21:53:23 - INFO - __main__ -   eval_f1 = 0.3534\n",
      "04/28/2024 21:53:23 - INFO - __main__ -   eval_precision = 0.4545\n",
      "04/28/2024 21:53:23 - INFO - __main__ -   eval_recall = 0.2891\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 21:55:29 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 21:55:29 - INFO - __main__ -   auc_score = 0.8351\n",
      "04/28/2024 21:55:29 - INFO - __main__ -   test_f1 = 0.3375\n",
      "04/28/2024 21:55:29 - INFO - __main__ -   test_precision = 0.4201\n",
      "04/28/2024 21:55:29 - INFO - __main__ -   test_recall = 0.2821\n",
      " 40% 407/1024 [11:57<11:46,  1.14s/it]04/28/2024 21:59:22 - WARNING - __main__ - epoch 5 step 408 loss 0.03024\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:01:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:01:28 - INFO - __main__ -   eval_f1 = 0.3081\n",
      "04/28/2024 22:01:28 - INFO - __main__ -   eval_precision = 0.5\n",
      "04/28/2024 22:01:28 - INFO - __main__ -   eval_recall = 0.2227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:03:34 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:03:34 - INFO - __main__ -   auc_score = 0.8295\n",
      "04/28/2024 22:03:34 - INFO - __main__ -   test_f1 = 0.3046\n",
      "04/28/2024 22:03:34 - INFO - __main__ -   test_precision = 0.4796\n",
      "04/28/2024 22:03:34 - INFO - __main__ -   test_recall = 0.2232\n",
      " 60% 611/1024 [20:03<07:52,  1.14s/it]04/28/2024 22:07:27 - WARNING - __main__ - epoch 5 step 612 loss 0.02373\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:09:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:09:34 - INFO - __main__ -   eval_f1 = 0.3029\n",
      "04/28/2024 22:09:34 - INFO - __main__ -   eval_precision = 0.439\n",
      "04/28/2024 22:09:34 - INFO - __main__ -   eval_recall = 0.2313\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:11:40 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:11:40 - INFO - __main__ -   auc_score = 0.8235\n",
      "04/28/2024 22:11:40 - INFO - __main__ -   test_f1 = 0.3015\n",
      "04/28/2024 22:11:40 - INFO - __main__ -   test_precision = 0.4395\n",
      "04/28/2024 22:11:40 - INFO - __main__ -   test_recall = 0.2295\n",
      " 80% 815/1024 [28:09<03:59,  1.14s/it]04/28/2024 22:15:33 - WARNING - __main__ - epoch 5 step 816 loss 0.02458\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:17:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:17:39 - INFO - __main__ -   eval_f1 = 0.3342\n",
      "04/28/2024 22:17:39 - INFO - __main__ -   eval_precision = 0.439\n",
      "04/28/2024 22:17:39 - INFO - __main__ -   eval_recall = 0.2698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:19:45 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:19:45 - INFO - __main__ -   auc_score = 0.8249\n",
      "04/28/2024 22:19:45 - INFO - __main__ -   test_f1 = 0.3273\n",
      "04/28/2024 22:19:45 - INFO - __main__ -   test_precision = 0.4271\n",
      "04/28/2024 22:19:45 - INFO - __main__ -   test_recall = 0.2653\n",
      "100% 1019/1024 [36:14<00:05,  1.14s/it]04/28/2024 22:23:38 - WARNING - __main__ - epoch 5 step 1020 loss 0.02369\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:25:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:25:44 - INFO - __main__ -   eval_f1 = 0.3564\n",
      "04/28/2024 22:25:44 - INFO - __main__ -   eval_precision = 0.4106\n",
      "04/28/2024 22:25:44 - INFO - __main__ -   eval_recall = 0.3148\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:27:51 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:27:51 - INFO - __main__ -   auc_score = 0.8274\n",
      "04/28/2024 22:27:51 - INFO - __main__ -   test_f1 = 0.341\n",
      "04/28/2024 22:27:51 - INFO - __main__ -   test_precision = 0.4006\n",
      "04/28/2024 22:27:51 - INFO - __main__ -   test_recall = 0.2968\n",
      "100% 1024/1024 [40:31<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:37,  1.14s/it]04/28/2024 22:31:47 - WARNING - __main__ - epoch 6 step 204 loss 0.03119\n",
      "04/28/2024 22:33:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:33:54 - INFO - __main__ -   eval_f1 = 0.349\n",
      "04/28/2024 22:33:54 - INFO - __main__ -   eval_precision = 0.4941\n",
      "04/28/2024 22:33:54 - INFO - __main__ -   eval_recall = 0.2698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:36:00 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:36:00 - INFO - __main__ -   auc_score = 0.8181\n",
      "04/28/2024 22:36:00 - INFO - __main__ -   test_f1 = 0.336\n",
      "04/28/2024 22:36:00 - INFO - __main__ -   test_precision = 0.4715\n",
      "04/28/2024 22:36:00 - INFO - __main__ -   test_recall = 0.2611\n",
      " 40% 407/1024 [11:57<11:43,  1.14s/it]04/28/2024 22:39:52 - WARNING - __main__ - epoch 6 step 408 loss 0.01926\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:41:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:41:59 - INFO - __main__ -   eval_f1 = 0.41\n",
      "04/28/2024 22:41:59 - INFO - __main__ -   eval_precision = 0.438\n",
      "04/28/2024 22:41:59 - INFO - __main__ -   eval_recall = 0.3854\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:44:20 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:44:20 - INFO - __main__ -   auc_score = 0.8341\n",
      "04/28/2024 22:44:20 - INFO - __main__ -   test_f1 = 0.3735\n",
      "04/28/2024 22:44:20 - INFO - __main__ -   test_precision = 0.416\n",
      "04/28/2024 22:44:20 - INFO - __main__ -   test_recall = 0.3389\n",
      " 60% 611/1024 [20:17<07:51,  1.14s/it]04/28/2024 22:48:12 - WARNING - __main__ - epoch 6 step 612 loss 0.02855\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:50:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:50:19 - INFO - __main__ -   eval_f1 = 0.35\n",
      "04/28/2024 22:50:19 - INFO - __main__ -   eval_precision = 0.4539\n",
      "04/28/2024 22:50:19 - INFO - __main__ -   eval_recall = 0.2848\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:52:25 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 22:52:25 - INFO - __main__ -   auc_score = 0.8239\n",
      "04/28/2024 22:52:25 - INFO - __main__ -   test_f1 = 0.3386\n",
      "04/28/2024 22:52:25 - INFO - __main__ -   test_precision = 0.4495\n",
      "04/28/2024 22:52:25 - INFO - __main__ -   test_recall = 0.2716\n",
      " 80% 815/1024 [28:22<03:58,  1.14s/it]04/28/2024 22:56:17 - WARNING - __main__ - epoch 6 step 816 loss 0.01451\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 22:58:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 22:58:24 - INFO - __main__ -   eval_f1 = 0.3146\n",
      "04/28/2024 22:58:24 - INFO - __main__ -   eval_precision = 0.4823\n",
      "04/28/2024 22:58:24 - INFO - __main__ -   eval_recall = 0.2334\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:00:30 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:00:30 - INFO - __main__ -   auc_score = 0.8211\n",
      "04/28/2024 23:00:30 - INFO - __main__ -   test_f1 = 0.3217\n",
      "04/28/2024 23:00:30 - INFO - __main__ -   test_precision = 0.4792\n",
      "04/28/2024 23:00:30 - INFO - __main__ -   test_recall = 0.2421\n",
      "100% 1019/1024 [36:26<00:05,  1.14s/it]04/28/2024 23:04:22 - WARNING - __main__ - epoch 6 step 1020 loss 0.01653\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:06:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:06:28 - INFO - __main__ -   eval_f1 = 0.3508\n",
      "04/28/2024 23:06:28 - INFO - __main__ -   eval_precision = 0.4512\n",
      "04/28/2024 23:06:28 - INFO - __main__ -   eval_recall = 0.2869\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:08:35 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:08:35 - INFO - __main__ -   auc_score = 0.8297\n",
      "04/28/2024 23:08:35 - INFO - __main__ -   test_f1 = 0.3451\n",
      "04/28/2024 23:08:35 - INFO - __main__ -   test_precision = 0.4295\n",
      "04/28/2024 23:08:35 - INFO - __main__ -   test_recall = 0.2884\n",
      "100% 1024/1024 [40:43<00:00,  2.39s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:38,  1.14s/it]04/28/2024 23:12:31 - WARNING - __main__ - epoch 7 step 204 loss 0.0188\n",
      "04/28/2024 23:14:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:14:37 - INFO - __main__ -   eval_f1 = 0.3107\n",
      "04/28/2024 23:14:37 - INFO - __main__ -   eval_precision = 0.5024\n",
      "04/28/2024 23:14:37 - INFO - __main__ -   eval_recall = 0.2248\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:16:43 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:16:43 - INFO - __main__ -   auc_score = 0.8134\n",
      "04/28/2024 23:16:43 - INFO - __main__ -   test_f1 = 0.2882\n",
      "04/28/2024 23:16:43 - INFO - __main__ -   test_precision = 0.467\n",
      "04/28/2024 23:16:43 - INFO - __main__ -   test_recall = 0.2084\n",
      " 40% 407/1024 [11:57<11:46,  1.14s/it]04/28/2024 23:20:36 - WARNING - __main__ - epoch 7 step 408 loss 0.01023\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:22:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:22:42 - INFO - __main__ -   eval_f1 = 0.3766\n",
      "04/28/2024 23:22:42 - INFO - __main__ -   eval_precision = 0.4149\n",
      "04/28/2024 23:22:42 - INFO - __main__ -   eval_recall = 0.3448\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:24:48 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:24:48 - INFO - __main__ -   auc_score = 0.8235\n",
      "04/28/2024 23:24:48 - INFO - __main__ -   test_f1 = 0.3514\n",
      "04/28/2024 23:24:48 - INFO - __main__ -   test_precision = 0.3995\n",
      "04/28/2024 23:24:48 - INFO - __main__ -   test_recall = 0.3137\n",
      " 60% 611/1024 [20:01<07:51,  1.14s/it]04/28/2024 23:28:41 - WARNING - __main__ - epoch 7 step 612 loss 0.01971\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:30:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:30:47 - INFO - __main__ -   eval_f1 = 0.3567\n",
      "04/28/2024 23:30:47 - INFO - __main__ -   eval_precision = 0.4962\n",
      "04/28/2024 23:30:47 - INFO - __main__ -   eval_recall = 0.2784\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:32:53 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:32:53 - INFO - __main__ -   auc_score = 0.8174\n",
      "04/28/2024 23:32:53 - INFO - __main__ -   test_f1 = 0.3392\n",
      "04/28/2024 23:32:53 - INFO - __main__ -   test_precision = 0.4701\n",
      "04/28/2024 23:32:53 - INFO - __main__ -   test_recall = 0.2653\n",
      " 80% 815/1024 [28:06<03:58,  1.14s/it]04/28/2024 23:36:46 - WARNING - __main__ - epoch 7 step 816 loss 0.01081\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:38:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:38:52 - INFO - __main__ -   eval_f1 = 0.3904\n",
      "04/28/2024 23:38:52 - INFO - __main__ -   eval_precision = 0.4429\n",
      "04/28/2024 23:38:52 - INFO - __main__ -   eval_recall = 0.349\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:40:58 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:40:58 - INFO - __main__ -   auc_score = 0.8226\n",
      "04/28/2024 23:40:58 - INFO - __main__ -   test_f1 = 0.3556\n",
      "04/28/2024 23:40:58 - INFO - __main__ -   test_precision = 0.4105\n",
      "04/28/2024 23:40:58 - INFO - __main__ -   test_recall = 0.3137\n",
      "100% 1019/1024 [36:11<00:05,  1.14s/it]04/28/2024 23:44:50 - WARNING - __main__ - epoch 7 step 1020 loss 0.0136\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:46:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:46:57 - INFO - __main__ -   eval_f1 = 0.3503\n",
      "04/28/2024 23:46:57 - INFO - __main__ -   eval_precision = 0.4497\n",
      "04/28/2024 23:46:57 - INFO - __main__ -   eval_recall = 0.2869\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:49:03 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:49:03 - INFO - __main__ -   auc_score = 0.8207\n",
      "04/28/2024 23:49:03 - INFO - __main__ -   test_f1 = 0.332\n",
      "04/28/2024 23:49:03 - INFO - __main__ -   test_precision = 0.4324\n",
      "04/28/2024 23:49:03 - INFO - __main__ -   test_recall = 0.2695\n",
      "100% 1024/1024 [40:28<00:00,  2.37s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:51<15:35,  1.14s/it]04/28/2024 23:52:59 - WARNING - __main__ - epoch 8 step 204 loss 0.00773\n",
      "04/28/2024 23:55:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/28/2024 23:55:05 - INFO - __main__ -   eval_f1 = 0.3458\n",
      "04/28/2024 23:55:05 - INFO - __main__ -   eval_precision = 0.4624\n",
      "04/28/2024 23:55:05 - INFO - __main__ -   eval_recall = 0.2762\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/28/2024 23:57:25 - INFO - __main__ - ***** Test results *****\n",
      "04/28/2024 23:57:25 - INFO - __main__ -   auc_score = 0.8185\n",
      "04/28/2024 23:57:25 - INFO - __main__ -   test_f1 = 0.32\n",
      "04/28/2024 23:57:25 - INFO - __main__ -   test_precision = 0.4364\n",
      "04/28/2024 23:57:25 - INFO - __main__ -   test_recall = 0.2526\n",
      " 40% 407/1024 [12:09<11:43,  1.14s/it]04/29/2024 00:01:17 - WARNING - __main__ - epoch 8 step 408 loss 0.00925\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:03:23 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:03:23 - INFO - __main__ -   eval_f1 = 0.3144\n",
      "04/29/2024 00:03:23 - INFO - __main__ -   eval_precision = 0.4644\n",
      "04/29/2024 00:03:23 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:05:43 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:05:43 - INFO - __main__ -   auc_score = 0.8126\n",
      "04/29/2024 00:05:43 - INFO - __main__ -   test_f1 = 0.303\n",
      "04/29/2024 00:05:43 - INFO - __main__ -   test_precision = 0.4382\n",
      "04/29/2024 00:05:43 - INFO - __main__ -   test_recall = 0.2316\n",
      " 60% 611/1024 [20:27<07:51,  1.14s/it]04/29/2024 00:09:35 - WARNING - __main__ - epoch 8 step 612 loss 0.01065\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:11:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:11:41 - INFO - __main__ -   eval_f1 = 0.2897\n",
      "04/29/2024 00:11:41 - INFO - __main__ -   eval_precision = 0.5314\n",
      "04/29/2024 00:11:41 - INFO - __main__ -   eval_recall = 0.1991\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:14:02 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:14:02 - INFO - __main__ -   auc_score = 0.806\n",
      "04/29/2024 00:14:02 - INFO - __main__ -   test_f1 = 0.2679\n",
      "04/29/2024 00:14:02 - INFO - __main__ -   test_precision = 0.4835\n",
      "04/29/2024 00:14:02 - INFO - __main__ -   test_recall = 0.1853\n",
      " 80% 815/1024 [28:47<03:58,  1.14s/it]04/29/2024 00:17:54 - WARNING - __main__ - epoch 8 step 816 loss 0.01496\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:20:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:20:01 - INFO - __main__ -   eval_f1 = 0.328\n",
      "04/29/2024 00:20:01 - INFO - __main__ -   eval_precision = 0.509\n",
      "04/29/2024 00:20:01 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:22:28 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:22:28 - INFO - __main__ -   auc_score = 0.8139\n",
      "04/29/2024 00:22:28 - INFO - __main__ -   test_f1 = 0.3144\n",
      "04/29/2024 00:22:28 - INFO - __main__ -   test_precision = 0.4805\n",
      "04/29/2024 00:22:28 - INFO - __main__ -   test_recall = 0.2337\n",
      "100% 1019/1024 [37:13<00:05,  1.14s/it]04/29/2024 00:26:20 - WARNING - __main__ - epoch 8 step 1020 loss 0.01021\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:28:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:28:27 - INFO - __main__ -   eval_f1 = 0.3539\n",
      "04/29/2024 00:28:27 - INFO - __main__ -   eval_precision = 0.4924\n",
      "04/29/2024 00:28:27 - INFO - __main__ -   eval_recall = 0.2762\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:30:47 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:30:47 - INFO - __main__ -   auc_score = 0.8183\n",
      "04/29/2024 00:30:47 - INFO - __main__ -   test_f1 = 0.3324\n",
      "04/29/2024 00:30:47 - INFO - __main__ -   test_precision = 0.4576\n",
      "04/29/2024 00:30:47 - INFO - __main__ -   test_recall = 0.2611\n",
      "100% 1024/1024 [41:44<00:00,  2.45s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 20% 203/1024 [03:52<15:38,  1.14s/it]04/29/2024 00:34:44 - WARNING - __main__ - epoch 9 step 204 loss 0.0087\n",
      "04/29/2024 00:36:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:36:51 - INFO - __main__ -   eval_f1 = 0.3415\n",
      "04/29/2024 00:36:51 - INFO - __main__ -   eval_precision = 0.4649\n",
      "04/29/2024 00:36:51 - INFO - __main__ -   eval_recall = 0.2698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:39:17 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:39:17 - INFO - __main__ -   auc_score = 0.819\n",
      "04/29/2024 00:39:17 - INFO - __main__ -   test_f1 = 0.3293\n",
      "04/29/2024 00:39:17 - INFO - __main__ -   test_precision = 0.4522\n",
      "04/29/2024 00:39:17 - INFO - __main__ -   test_recall = 0.2589\n",
      " 40% 407/1024 [12:17<11:46,  1.14s/it]04/29/2024 00:43:09 - WARNING - __main__ - epoch 9 step 408 loss 0.00796\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:45:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:45:16 - INFO - __main__ -   eval_f1 = 0.3238\n",
      "04/29/2024 00:45:16 - INFO - __main__ -   eval_precision = 0.4892\n",
      "04/29/2024 00:45:16 - INFO - __main__ -   eval_recall = 0.242\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:47:41 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:47:41 - INFO - __main__ -   auc_score = 0.8183\n",
      "04/29/2024 00:47:41 - INFO - __main__ -   test_f1 = 0.3274\n",
      "04/29/2024 00:47:41 - INFO - __main__ -   test_precision = 0.4722\n",
      "04/29/2024 00:47:41 - INFO - __main__ -   test_recall = 0.2505\n",
      " 60% 611/1024 [20:41<07:52,  1.14s/it]04/29/2024 00:51:34 - WARNING - __main__ - epoch 9 step 612 loss 0.00791\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:53:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 00:53:40 - INFO - __main__ -   eval_f1 = 0.3362\n",
      "04/29/2024 00:53:40 - INFO - __main__ -   eval_precision = 0.4938\n",
      "04/29/2024 00:53:40 - INFO - __main__ -   eval_recall = 0.2548\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 00:56:00 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 00:56:00 - INFO - __main__ -   auc_score = 0.8201\n",
      "04/29/2024 00:56:00 - INFO - __main__ -   test_f1 = 0.3265\n",
      "04/29/2024 00:56:00 - INFO - __main__ -   test_precision = 0.4685\n",
      "04/29/2024 00:56:00 - INFO - __main__ -   test_recall = 0.2505\n",
      " 80% 815/1024 [29:01<03:59,  1.14s/it]04/29/2024 00:59:53 - WARNING - __main__ - epoch 9 step 816 loss 0.0015\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 01:01:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 01:01:59 - INFO - __main__ -   eval_f1 = 0.3127\n",
      "04/29/2024 01:01:59 - INFO - __main__ -   eval_precision = 0.5024\n",
      "04/29/2024 01:01:59 - INFO - __main__ -   eval_recall = 0.227\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 01:04:21 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 01:04:21 - INFO - __main__ -   auc_score = 0.8165\n",
      "04/29/2024 01:04:21 - INFO - __main__ -   test_f1 = 0.3234\n",
      "04/29/2024 01:04:21 - INFO - __main__ -   test_precision = 0.4957\n",
      "04/29/2024 01:04:21 - INFO - __main__ -   test_recall = 0.24\n",
      "100% 1019/1024 [37:21<00:05,  1.14s/it]04/29/2024 01:08:13 - WARNING - __main__ - epoch 9 step 1020 loss 0.00698\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 01:10:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/29/2024 01:10:20 - INFO - __main__ -   eval_f1 = 0.3213\n",
      "04/29/2024 01:10:20 - INFO - __main__ -   eval_precision = 0.4955\n",
      "04/29/2024 01:10:20 - INFO - __main__ -   eval_recall = 0.2377\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 01:12:42 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 01:12:42 - INFO - __main__ -   auc_score = 0.8178\n",
      "04/29/2024 01:12:42 - INFO - __main__ -   test_f1 = 0.3264\n",
      "04/29/2024 01:12:42 - INFO - __main__ -   test_precision = 0.4835\n",
      "04/29/2024 01:12:42 - INFO - __main__ -   test_recall = 0.2463\n",
      "100% 1024/1024 [41:54<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xq0CmLrN7vH-",
    "outputId": "b52b46da-9fc2-4fde-c485-ddaf1c911d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/29/2024 01:21:41 - INFO - __main__ - Successfully load epoch 6's model checkpoint\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "04/29/2024 01:23:48 - INFO - __main__ - ***** Test results *****\n",
      "04/29/2024 01:23:48 - INFO - __main__ -   auc_score = 0.8356\n",
      "04/29/2024 01:23:48 - INFO - __main__ -   test_f1 = 0.3861\n",
      "04/29/2024 01:23:48 - INFO - __main__ -   test_precision = 0.4282\n",
      "04/29/2024 01:23:48 - INFO - __main__ -   test_recall = 0.3516\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_adapter.py --train_data_file {path}/changes_train.pkl {path}/features_train.pkl --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl --test_data_file {path}/changes_test.pkl {path}/features_test.pkl --output_dir ../results/jitfine_adapter/codet5p-770m/single/checkpoints --pretrained_model codet5p-770m --learning_rate 1e-5 --epochs 10 --batch_size 16 --hidden_size 1024 --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hjzzdPPtfXW"
   },
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrAsoy4d-vzR"
   },
   "source": [
    "#### LR = 5e-5 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-qUEFnNth_m"
   },
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 5e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 8 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpsng2vT-0qb"
   },
   "source": [
    "04/30/2024 23:20:54 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "04/30/2024 23:20:54 - INFO - __main__ -   auc_score = 0.8735\n",
    "\n",
    "04/30/2024 23:20:54 - INFO - __main__ -   test_f1 = 0.3678\n",
    "\n",
    "04/30/2024 23:20:54 - INFO - __main__ -   test_precision = 0.4675\n",
    "\n",
    "04/30/2024 23:20:54 - INFO - __main__ -   test_recall = 0.3032\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NytUBovl_ICQ"
   },
   "source": [
    "#### LR = 5e-4 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aDuWeMzfe_J"
   },
   "source": [
    "python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file $HOME/Datasets/jitfine/changes_train.pkl $HOME/Datasets/jitfine/features_train.pkl \\\n",
    "   --eval_data_file $HOME/Datasets/jitfine/changes_valid.pkl $HOME/Datasets/jitfine/features_valid.pkl \\\n",
    "   --test_data_file $HOME/Datasets/jitfine/changes_test.pkl $HOME/Datasets/jitfine/features_test.pkl \\\n",
    "   --output_dir results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 5e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 8 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9WeRqezfjN6"
   },
   "source": [
    "05/01/2024 11:05:54 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "05/01/2024 11:05:54 - INFO - __main__ -   auc_score = 0.8401\n",
    "\n",
    "05/01/2024 11:05:54 - INFO - __main__ -   test_f1 = 0.3739\n",
    "\n",
    "05/01/2024 11:05:54 - INFO - __main__ -   test_precision = 0.3526\n",
    "\n",
    "05/01/2024 11:05:54 - INFO - __main__ -   test_recall = 0.3979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV9186WLf4U0"
   },
   "source": [
    "#### LR = 2e-5 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAJNnFB6UyLJ"
   },
   "source": [
    "python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file $HOME/Datasets/jitfine/changes_train.pkl $HOME/Datasets/jitfine/features_train.pkl \\\n",
    "   --eval_data_file $HOME/Datasets/jitfine/changes_valid.pkl $HOME/Datasets/jitfine/features_valid.pkl \\\n",
    "   --test_data_file $HOME/Datasets/jitfine/changes_test.pkl $HOME/Datasets/jitfine/features_test.pkl \\\n",
    "   --output_dir results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 2e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 8 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbCVefPYUy0i"
   },
   "source": [
    "05/01/2024 19:38:08 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "05/01/2024 19:38:08 - INFO - __main__ -   auc_score = 0.875\n",
    "\n",
    "05/01/2024 19:38:08 - INFO - __main__ -   test_f1 = 0.369\n",
    "\n",
    "05/01/2024 19:38:08 - INFO - __main__ -   test_precision = 0.4767\n",
    "\n",
    "05/01/2024 19:38:08 - INFO - __main__ -   test_recall = 0.3011\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6hfQ4XZVOJN"
   },
   "source": [
    "#### LR = 1e-5 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6pJO8qs-YVC"
   },
   "source": [
    "python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file $HOME/Datasets/jitfine/changes_train.pkl $HOME/Datasets/jitfine/features_train.pkl \\\n",
    "   --eval_data_file $HOME/Datasets/jitfine/changes_valid.pkl $HOME/Datasets/jitfine/features_valid.pkl \\\n",
    "   --test_data_file $HOME/Datasets/jitfine/changes_test.pkl $HOME/Datasets/jitfine/features_test.pkl \\\n",
    "   --output_dir results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 8 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hp3o5iuC-dDz"
   },
   "source": [
    "05/02/2024 10:38:42 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "05/02/2024 10:38:42 - INFO - __main__ -   auc_score = 0.8713\n",
    "\n",
    "05/02/2024 10:38:42 - INFO - __main__ -   test_f1 = 0.2989\n",
    "\n",
    "05/02/2024 10:38:42 - INFO - __main__ -   test_precision = 0.4706\n",
    "\n",
    "05/02/2024 10:38:42 - INFO - __main__ -   test_recall = 0.2189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5fPHwAn4KyL"
   },
   "source": [
    "## Testing inclusion of manual/expert features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgkIqgdUxYAd"
   },
   "source": [
    "### LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPDtmaI7FidP",
    "outputId": "c587f52a-feab-427a-95fc-574054e9fd1e"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oskJVB034QY1",
    "outputId": "bcf1302e-ed64-4289-92c6-cf42c1e938e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:10:06.211961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 15:10:06.230225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744211406.252296   35721 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744211406.258999   35721 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 15:10:06.281127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/09/2025 15:18:20 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:54<00:00,  1.15it/s]04/09/2025 15:35:38 - WARNING - __main__ - epoch 0 step 1024 loss 0.23937\n",
      "[[0.8709321 ]\n",
      " [0.10935685]\n",
      " [0.02549114]\n",
      " ...\n",
      " [0.2083888 ]\n",
      " [0.27290264]\n",
      " [0.21433629]]\n",
      "04/09/2025 15:37:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 15:37:48 - INFO - __main__ -   auc_score = 0.9001\n",
      "04/09/2025 15:37:48 - INFO - __main__ -   eval_f1 = 0.3522\n",
      "04/09/2025 15:37:48 - INFO - __main__ -   eval_precision = 0.7171\n",
      "04/09/2025 15:37:48 - INFO - __main__ -   eval_recall = 0.2334\n",
      "100% 1024/1024 [17:17<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 15:52:55 - WARNING - __main__ - epoch 1 step 1024 loss 0.18194\n",
      "[[0.9440537 ]\n",
      " [0.4132456 ]\n",
      " [0.06574519]\n",
      " ...\n",
      " [0.2148262 ]\n",
      " [0.59410346]\n",
      " [0.25917724]]\n",
      "04/09/2025 15:55:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 15:55:05 - INFO - __main__ -   auc_score = 0.9147\n",
      "04/09/2025 15:55:05 - INFO - __main__ -   eval_f1 = 0.5791\n",
      "04/09/2025 15:55:05 - INFO - __main__ -   eval_precision = 0.6782\n",
      "04/09/2025 15:55:05 - INFO - __main__ -   eval_recall = 0.5054\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 16:10:10 - WARNING - __main__ - epoch 2 step 1024 loss 0.16275\n",
      "[[0.95719194]\n",
      " [0.30138907]\n",
      " [0.0377227 ]\n",
      " ...\n",
      " [0.19502997]\n",
      " [0.36310336]\n",
      " [0.09815764]]\n",
      "04/09/2025 16:12:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 16:12:20 - INFO - __main__ -   auc_score = 0.9107\n",
      "04/09/2025 16:12:20 - INFO - __main__ -   eval_f1 = 0.5401\n",
      "04/09/2025 16:12:20 - INFO - __main__ -   eval_precision = 0.7189\n",
      "04/09/2025 16:12:20 - INFO - __main__ -   eval_recall = 0.4325\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 16:27:14 - WARNING - __main__ - epoch 3 step 1024 loss 0.14766\n",
      "[[0.96980613]\n",
      " [0.36205825]\n",
      " [0.06546351]\n",
      " ...\n",
      " [0.12507366]\n",
      " [0.367417  ]\n",
      " [0.07351032]]\n",
      "04/09/2025 16:29:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 16:29:24 - INFO - __main__ -   auc_score = 0.9142\n",
      "04/09/2025 16:29:24 - INFO - __main__ -   eval_f1 = 0.5529\n",
      "04/09/2025 16:29:24 - INFO - __main__ -   eval_precision = 0.7232\n",
      "04/09/2025 16:29:24 - INFO - __main__ -   eval_recall = 0.4475\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 16:44:19 - WARNING - __main__ - epoch 4 step 1024 loss 0.13447\n",
      "[[0.9959091 ]\n",
      " [0.70003396]\n",
      " [0.10821514]\n",
      " ...\n",
      " [0.2148775 ]\n",
      " [0.25861943]\n",
      " [0.05144151]]\n",
      "04/09/2025 16:46:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 16:46:29 - INFO - __main__ -   auc_score = 0.9064\n",
      "04/09/2025 16:46:29 - INFO - __main__ -   eval_f1 = 0.5639\n",
      "04/09/2025 16:46:29 - INFO - __main__ -   eval_precision = 0.5805\n",
      "04/09/2025 16:46:29 - INFO - __main__ -   eval_recall = 0.5482\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 17:01:24 - WARNING - __main__ - epoch 5 step 1024 loss 0.1222\n",
      "[[0.9927598 ]\n",
      " [0.5205698 ]\n",
      " [0.13564567]\n",
      " ...\n",
      " [0.05629974]\n",
      " [0.09058834]\n",
      " [0.0247979 ]]\n",
      "04/09/2025 17:03:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 17:03:34 - INFO - __main__ -   auc_score = 0.9026\n",
      "04/09/2025 17:03:34 - INFO - __main__ -   eval_f1 = 0.5583\n",
      "04/09/2025 17:03:34 - INFO - __main__ -   eval_precision = 0.6637\n",
      "04/09/2025 17:03:34 - INFO - __main__ -   eval_recall = 0.4818\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 17:18:28 - WARNING - __main__ - epoch 6 step 1024 loss 0.11018\n",
      "[[0.9962446 ]\n",
      " [0.6350401 ]\n",
      " [0.14180182]\n",
      " ...\n",
      " [0.06295307]\n",
      " [0.3238875 ]\n",
      " [0.04229396]]\n",
      "04/09/2025 17:20:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 17:20:39 - INFO - __main__ -   auc_score = 0.9048\n",
      "04/09/2025 17:20:39 - INFO - __main__ -   eval_f1 = 0.5704\n",
      "04/09/2025 17:20:39 - INFO - __main__ -   eval_precision = 0.625\n",
      "04/09/2025 17:20:39 - INFO - __main__ -   eval_recall = 0.5246\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 17:35:33 - WARNING - __main__ - epoch 7 step 1024 loss 0.1003\n",
      "[[0.99771154]\n",
      " [0.47172996]\n",
      " [0.15564385]\n",
      " ...\n",
      " [0.01909553]\n",
      " [0.13790624]\n",
      " [0.02012475]]\n",
      "04/09/2025 17:37:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 17:37:44 - INFO - __main__ -   auc_score = 0.9027\n",
      "04/09/2025 17:37:44 - INFO - __main__ -   eval_f1 = 0.5468\n",
      "04/09/2025 17:37:44 - INFO - __main__ -   eval_precision = 0.6213\n",
      "04/09/2025 17:37:44 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 17:52:38 - WARNING - __main__ - epoch 8 step 1024 loss 0.09085\n",
      "[[0.99811006]\n",
      " [0.2739951 ]\n",
      " [0.10874688]\n",
      " ...\n",
      " [0.01885242]\n",
      " [0.05221628]\n",
      " [0.0126944 ]]\n",
      "04/09/2025 17:54:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 17:54:48 - INFO - __main__ -   auc_score = 0.8979\n",
      "04/09/2025 17:54:48 - INFO - __main__ -   eval_f1 = 0.5305\n",
      "04/09/2025 17:54:48 - INFO - __main__ -   eval_precision = 0.6339\n",
      "04/09/2025 17:54:48 - INFO - __main__ -   eval_recall = 0.4561\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 18:09:43 - WARNING - __main__ - epoch 9 step 1024 loss 0.0864\n",
      "[[0.9990689 ]\n",
      " [0.36770743]\n",
      " [0.16640233]\n",
      " ...\n",
      " [0.02871905]\n",
      " [0.08830782]\n",
      " [0.02196151]]\n",
      "04/09/2025 18:11:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 18:11:53 - INFO - __main__ -   auc_score = 0.8992\n",
      "04/09/2025 18:11:53 - INFO - __main__ -   eval_f1 = 0.5234\n",
      "04/09/2025 18:11:53 - INFO - __main__ -   eval_precision = 0.5613\n",
      "04/09/2025 18:11:53 - INFO - __main__ -   eval_recall = 0.4904\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AH-jcR_wAxYf",
    "outputId": "067c805a-3e0f-4a6e-8466-c8cc3b8c2346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 19:35:55.103565: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 19:35:55.122370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744227355.145184  134527 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744227355.152091  134527 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 19:35:55.174961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.42947368421052634\n",
      "recall =  0.42947368421052634\n",
      "04/09/2025 19:47:14 - INFO - __main__ - ***** Test results *****\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   R0 = 0.9714\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   R1 = 0.4295\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   auc_score = 0.8986\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   g_mean = 0.6459\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   test_f1 = 0.4964\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   test_precision = 0.5879\n",
      "04/09/2025 19:47:14 - INFO - __main__ -   test_recall = 0.4295\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vh_O8y1zDzUO"
   },
   "source": [
    "#### Repeating the training with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsMfYTNVDrub"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewGyMy2sEdNv"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjpbxL28D4t8",
    "outputId": "0f5e7b33-d38b-4d15-81fa-4411bdf06a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 19:49:41.024356: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 19:49:41.042592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744228181.064630  139624 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744228181.071401  139624 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 19:49:41.093711: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/09/2025 19:58:09 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 20:15:20 - WARNING - __main__ - epoch 0 step 1024 loss 0.23342\n",
      "[[0.869385  ]\n",
      " [0.27483776]\n",
      " [0.03246695]\n",
      " ...\n",
      " [0.16586109]\n",
      " [0.3494714 ]\n",
      " [0.3026683 ]]\n",
      "04/09/2025 20:17:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 20:17:30 - INFO - __main__ -   auc_score = 0.9058\n",
      "04/09/2025 20:17:30 - INFO - __main__ -   eval_f1 = 0.4504\n",
      "04/09/2025 20:17:30 - INFO - __main__ -   eval_precision = 0.7308\n",
      "04/09/2025 20:17:30 - INFO - __main__ -   eval_recall = 0.3255\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 20:32:35 - WARNING - __main__ - epoch 1 step 1024 loss 0.18169\n",
      "[[0.9388494 ]\n",
      " [0.4207873 ]\n",
      " [0.07571434]\n",
      " ...\n",
      " [0.13604483]\n",
      " [0.5366365 ]\n",
      " [0.262886  ]]\n",
      "04/09/2025 20:34:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 20:34:45 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/09/2025 20:34:45 - INFO - __main__ -   eval_f1 = 0.5551\n",
      "04/09/2025 20:34:45 - INFO - __main__ -   eval_precision = 0.7039\n",
      "04/09/2025 20:34:45 - INFO - __main__ -   eval_recall = 0.4582\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 20:49:49 - WARNING - __main__ - epoch 2 step 1024 loss 0.1629\n",
      "[[0.9772624 ]\n",
      " [0.50950575]\n",
      " [0.17038085]\n",
      " ...\n",
      " [0.27971587]\n",
      " [0.7270982 ]\n",
      " [0.27429968]]\n",
      "04/09/2025 20:52:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 20:52:00 - INFO - __main__ -   auc_score = 0.9183\n",
      "04/09/2025 20:52:00 - INFO - __main__ -   eval_f1 = 0.6051\n",
      "04/09/2025 20:52:00 - INFO - __main__ -   eval_precision = 0.6658\n",
      "04/09/2025 20:52:00 - INFO - __main__ -   eval_recall = 0.5546\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 21:07:04 - WARNING - __main__ - epoch 3 step 1024 loss 0.14936\n",
      "[[0.9873188 ]\n",
      " [0.5474689 ]\n",
      " [0.19579332]\n",
      " ...\n",
      " [0.23512971]\n",
      " [0.50384253]\n",
      " [0.17513432]]\n",
      "04/09/2025 21:09:14 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 21:09:14 - INFO - __main__ -   auc_score = 0.9148\n",
      "04/09/2025 21:09:14 - INFO - __main__ -   eval_f1 = 0.5858\n",
      "04/09/2025 21:09:14 - INFO - __main__ -   eval_precision = 0.6436\n",
      "04/09/2025 21:09:14 - INFO - __main__ -   eval_recall = 0.5375\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 21:24:09 - WARNING - __main__ - epoch 4 step 1024 loss 0.13216\n",
      "[[0.9941461 ]\n",
      " [0.51588804]\n",
      " [0.08684953]\n",
      " ...\n",
      " [0.12632422]\n",
      " [0.42083165]\n",
      " [0.15983391]]\n",
      "04/09/2025 21:26:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 21:26:19 - INFO - __main__ -   auc_score = 0.9158\n",
      "04/09/2025 21:26:19 - INFO - __main__ -   eval_f1 = 0.6007\n",
      "04/09/2025 21:26:19 - INFO - __main__ -   eval_precision = 0.6493\n",
      "04/09/2025 21:26:19 - INFO - __main__ -   eval_recall = 0.5589\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/09/2025 21:41:13 - WARNING - __main__ - epoch 5 step 1024 loss 0.11646\n",
      "[[0.99823254]\n",
      " [0.6864056 ]\n",
      " [0.3318108 ]\n",
      " ...\n",
      " [0.06372215]\n",
      " [0.69155216]\n",
      " [0.15193485]]\n",
      "04/09/2025 21:43:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 21:43:24 - INFO - __main__ -   auc_score = 0.9169\n",
      "04/09/2025 21:43:24 - INFO - __main__ -   eval_f1 = 0.5836\n",
      "04/09/2025 21:43:24 - INFO - __main__ -   eval_precision = 0.5665\n",
      "04/09/2025 21:43:24 - INFO - __main__ -   eval_recall = 0.6017\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 21:58:18 - WARNING - __main__ - epoch 6 step 1024 loss 0.10541\n",
      "[[0.99861765]\n",
      " [0.6032857 ]\n",
      " [0.2149741 ]\n",
      " ...\n",
      " [0.1075418 ]\n",
      " [0.5139417 ]\n",
      " [0.1580489 ]]\n",
      "04/09/2025 22:00:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 22:00:28 - INFO - __main__ -   auc_score = 0.9126\n",
      "04/09/2025 22:00:28 - INFO - __main__ -   eval_f1 = 0.5622\n",
      "04/09/2025 22:00:28 - INFO - __main__ -   eval_precision = 0.5453\n",
      "04/09/2025 22:00:28 - INFO - __main__ -   eval_recall = 0.5803\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 22:15:23 - WARNING - __main__ - epoch 7 step 1024 loss 0.09616\n",
      "[[0.9990872 ]\n",
      " [0.6277938 ]\n",
      " [0.1102571 ]\n",
      " ...\n",
      " [0.03948878]\n",
      " [0.2640913 ]\n",
      " [0.0830313 ]]\n",
      "04/09/2025 22:17:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 22:17:33 - INFO - __main__ -   auc_score = 0.9103\n",
      "04/09/2025 22:17:33 - INFO - __main__ -   eval_f1 = 0.5628\n",
      "04/09/2025 22:17:33 - INFO - __main__ -   eval_precision = 0.5501\n",
      "04/09/2025 22:17:33 - INFO - __main__ -   eval_recall = 0.576\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 22:32:28 - WARNING - __main__ - epoch 8 step 1024 loss 0.08807\n",
      "[[0.9994529 ]\n",
      " [0.64698917]\n",
      " [0.07861986]\n",
      " ...\n",
      " [0.05292855]\n",
      " [0.44459483]\n",
      " [0.17275782]]\n",
      "04/09/2025 22:34:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 22:34:38 - INFO - __main__ -   auc_score = 0.9095\n",
      "04/09/2025 22:34:38 - INFO - __main__ -   eval_f1 = 0.5605\n",
      "04/09/2025 22:34:38 - INFO - __main__ -   eval_precision = 0.5558\n",
      "04/09/2025 22:34:38 - INFO - __main__ -   eval_recall = 0.5653\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/09/2025 22:49:33 - WARNING - __main__ - epoch 9 step 1024 loss 0.08241\n",
      "[[0.9995435 ]\n",
      " [0.6782457 ]\n",
      " [0.07963018]\n",
      " ...\n",
      " [0.04420991]\n",
      " [0.33131218]\n",
      " [0.14822008]]\n",
      "04/09/2025 22:51:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 22:51:43 - INFO - __main__ -   auc_score = 0.9077\n",
      "04/09/2025 22:51:43 - INFO - __main__ -   eval_f1 = 0.5499\n",
      "04/09/2025 22:51:43 - INFO - __main__ -   eval_precision = 0.5453\n",
      "04/09/2025 22:51:43 - INFO - __main__ -   eval_recall = 0.5546\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVWKyjD0ELV6",
    "outputId": "5b7ee1f4-206f-4e9e-da56-5442b15e2e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 22:57:46.927442: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 22:57:46.946343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744239466.969158  208373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744239466.975934  208373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 22:57:46.998808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.47789473684210526\n",
      "recall =  0.47789473684210526\n",
      "04/09/2025 23:09:10 - INFO - __main__ - ***** Test results *****\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   R0 = 0.9638\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   R1 = 0.4779\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   auc_score = 0.8974\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   g_mean = 0.6787\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   test_f1 = 0.5142\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   test_precision = 0.5564\n",
      "04/09/2025 23:09:10 - INFO - __main__ -   test_recall = 0.4779\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nSWQ2aWEfLd"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv9PzKsVECLX",
    "outputId": "f9427527-d95a-4c13-cad5-f76dee5b7284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 23:18:52.820761: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 23:18:52.839021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744240732.860912  216165 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744240732.867580  216165 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 23:18:52.889991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/09/2025 23:27:27 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/09/2025 23:44:38 - WARNING - __main__ - epoch 0 step 1024 loss 0.23817\n",
      "[[0.9220843 ]\n",
      " [0.26043975]\n",
      " [0.12069137]\n",
      " ...\n",
      " [0.3691169 ]\n",
      " [0.5639685 ]\n",
      " [0.36720124]]\n",
      "04/09/2025 23:46:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/09/2025 23:46:48 - INFO - __main__ -   auc_score = 0.9022\n",
      "04/09/2025 23:46:48 - INFO - __main__ -   eval_f1 = 0.5362\n",
      "04/09/2025 23:46:48 - INFO - __main__ -   eval_precision = 0.615\n",
      "04/09/2025 23:46:48 - INFO - __main__ -   eval_recall = 0.4754\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 00:01:53 - WARNING - __main__ - epoch 1 step 1024 loss 0.18226\n",
      "[[0.93771386]\n",
      " [0.37367642]\n",
      " [0.0560176 ]\n",
      " ...\n",
      " [0.16043526]\n",
      " [0.16562033]\n",
      " [0.10316156]]\n",
      "04/10/2025 00:04:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 00:04:03 - INFO - __main__ -   auc_score = 0.9099\n",
      "04/10/2025 00:04:03 - INFO - __main__ -   eval_f1 = 0.5442\n",
      "04/10/2025 00:04:03 - INFO - __main__ -   eval_precision = 0.7665\n",
      "04/10/2025 00:04:03 - INFO - __main__ -   eval_recall = 0.4218\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 00:19:07 - WARNING - __main__ - epoch 2 step 1024 loss 0.16079\n",
      "[[0.9762927 ]\n",
      " [0.65330946]\n",
      " [0.07471214]\n",
      " ...\n",
      " [0.24710023]\n",
      " [0.14456625]\n",
      " [0.13663091]]\n",
      "04/10/2025 00:21:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 00:21:17 - INFO - __main__ -   auc_score = 0.9097\n",
      "04/10/2025 00:21:17 - INFO - __main__ -   eval_f1 = 0.5791\n",
      "04/10/2025 00:21:17 - INFO - __main__ -   eval_precision = 0.6704\n",
      "04/10/2025 00:21:17 - INFO - __main__ -   eval_recall = 0.5096\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/10/2025 00:36:21 - WARNING - __main__ - epoch 3 step 1024 loss 0.14306\n",
      "[[0.9915119 ]\n",
      " [0.72166324]\n",
      " [0.0502797 ]\n",
      " ...\n",
      " [0.18061809]\n",
      " [0.08057413]\n",
      " [0.05291282]]\n",
      "04/10/2025 00:38:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 00:38:32 - INFO - __main__ -   auc_score = 0.9077\n",
      "04/10/2025 00:38:32 - INFO - __main__ -   eval_f1 = 0.5757\n",
      "04/10/2025 00:38:32 - INFO - __main__ -   eval_precision = 0.6928\n",
      "04/10/2025 00:38:32 - INFO - __main__ -   eval_recall = 0.4925\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/10/2025 00:53:26 - WARNING - __main__ - epoch 4 step 1024 loss 0.12998\n",
      "[[0.99641836]\n",
      " [0.8388824 ]\n",
      " [0.09684993]\n",
      " ...\n",
      " [0.2501564 ]\n",
      " [0.02975086]\n",
      " [0.02706203]]\n",
      "04/10/2025 00:55:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 00:55:36 - INFO - __main__ -   auc_score = 0.8996\n",
      "04/10/2025 00:55:36 - INFO - __main__ -   eval_f1 = 0.5732\n",
      "04/10/2025 00:55:36 - INFO - __main__ -   eval_precision = 0.6583\n",
      "04/10/2025 00:55:36 - INFO - __main__ -   eval_recall = 0.5075\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/10/2025 01:10:31 - WARNING - __main__ - epoch 5 step 1024 loss 0.11801\n",
      "[[0.9987627 ]\n",
      " [0.897919  ]\n",
      " [0.09910703]\n",
      " ...\n",
      " [0.34634936]\n",
      " [0.02458211]\n",
      " [0.10520723]]\n",
      "04/10/2025 01:12:41 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 01:12:41 - INFO - __main__ -   auc_score = 0.9\n",
      "04/10/2025 01:12:41 - INFO - __main__ -   eval_f1 = 0.5855\n",
      "04/10/2025 01:12:41 - INFO - __main__ -   eval_precision = 0.6\n",
      "04/10/2025 01:12:41 - INFO - __main__ -   eval_recall = 0.5717\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 01:27:45 - WARNING - __main__ - epoch 6 step 1024 loss 0.10294\n",
      "[[0.9992448 ]\n",
      " [0.9051405 ]\n",
      " [0.01975523]\n",
      " ...\n",
      " [0.2479124 ]\n",
      " [0.0175594 ]\n",
      " [0.01701581]]\n",
      "04/10/2025 01:29:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 01:29:55 - INFO - __main__ -   auc_score = 0.897\n",
      "04/10/2025 01:29:55 - INFO - __main__ -   eval_f1 = 0.5198\n",
      "04/10/2025 01:29:55 - INFO - __main__ -   eval_precision = 0.677\n",
      "04/10/2025 01:29:55 - INFO - __main__ -   eval_recall = 0.4218\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 01:44:50 - WARNING - __main__ - epoch 7 step 1024 loss 0.09429\n",
      "[[0.999642  ]\n",
      " [0.9102138 ]\n",
      " [0.04754955]\n",
      " ...\n",
      " [0.36972463]\n",
      " [0.01862269]\n",
      " [0.03380276]]\n",
      "04/10/2025 01:47:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 01:47:00 - INFO - __main__ -   auc_score = 0.8991\n",
      "04/10/2025 01:47:00 - INFO - __main__ -   eval_f1 = 0.536\n",
      "04/10/2025 01:47:00 - INFO - __main__ -   eval_precision = 0.6372\n",
      "04/10/2025 01:47:00 - INFO - __main__ -   eval_recall = 0.4625\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 02:01:55 - WARNING - __main__ - epoch 8 step 1024 loss 0.08808\n",
      "[[0.99974996]\n",
      " [0.93892455]\n",
      " [0.0365535 ]\n",
      " ...\n",
      " [0.45037147]\n",
      " [0.0174114 ]\n",
      " [0.05591668]]\n",
      "04/10/2025 02:04:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 02:04:05 - INFO - __main__ -   auc_score = 0.8963\n",
      "04/10/2025 02:04:05 - INFO - __main__ -   eval_f1 = 0.5406\n",
      "04/10/2025 02:04:05 - INFO - __main__ -   eval_precision = 0.5899\n",
      "04/10/2025 02:04:05 - INFO - __main__ -   eval_recall = 0.4989\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 02:19:00 - WARNING - __main__ - epoch 9 step 1024 loss 0.08169\n",
      "[[0.9998023 ]\n",
      " [0.93352747]\n",
      " [0.03666861]\n",
      " ...\n",
      " [0.4959511 ]\n",
      " [0.01387072]\n",
      " [0.04432082]]\n",
      "04/10/2025 02:21:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 02:21:10 - INFO - __main__ -   auc_score = 0.8952\n",
      "04/10/2025 02:21:10 - INFO - __main__ -   eval_f1 = 0.5398\n",
      "04/10/2025 02:21:10 - INFO - __main__ -   eval_precision = 0.585\n",
      "04/10/2025 02:21:10 - INFO - __main__ -   eval_recall = 0.5011\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_725A-hEQcy",
    "outputId": "6a9ec1cb-23f6-4978-d4fd-a7b97fe19db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 02:25:32.365269: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 02:25:32.385654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744251932.408350  283061 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744251932.415297  283061 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 02:25:32.438262: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.5073684210526316\n",
      "recall =  0.5073684210526316\n",
      "04/10/2025 02:37:05 - INFO - __main__ - ***** Test results *****\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   R0 = 0.9586\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   R1 = 0.5074\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   auc_score = 0.8992\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   g_mean = 0.6974\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   test_f1 = 0.5222\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   test_precision = 0.5379\n",
      "04/10/2025 02:37:05 - INFO - __main__ -   test_recall = 0.5074\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDRocYrJEgmp"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuTydgueEDsP",
    "outputId": "5753e971-ec5d-47fa-9957-6a80eb38082c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 12:56:23.155337: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 12:56:23.175696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744289783.198563    9243 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744289783.205385    9243 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 12:56:23.227896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "config.json: 100% 770/770 [00:00<00:00, 6.51MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 13.6MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 11.1MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 11.7MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 17.1kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 65.4MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:05<00:00, 260MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/10/2025 13:04:38 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/10/2025 13:21:52 - WARNING - __main__ - epoch 0 step 1024 loss 0.23486\n",
      "[[0.88838714]\n",
      " [0.2720892 ]\n",
      " [0.07212249]\n",
      " ...\n",
      " [0.22913326]\n",
      " [0.47366205]\n",
      " [0.32000217]]\n",
      "04/10/2025 13:24:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 13:24:02 - INFO - __main__ -   auc_score = 0.9083\n",
      "04/10/2025 13:24:02 - INFO - __main__ -   eval_f1 = 0.4795\n",
      "04/10/2025 13:24:02 - INFO - __main__ -   eval_precision = 0.6654\n",
      "04/10/2025 13:24:02 - INFO - __main__ -   eval_recall = 0.3747\n",
      "100% 1024/1024 [17:16<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 13:39:06 - WARNING - __main__ - epoch 1 step 1024 loss 0.18073\n",
      "[[0.94762206]\n",
      " [0.369778  ]\n",
      " [0.06097428]\n",
      " ...\n",
      " [0.13247968]\n",
      " [0.62579155]\n",
      " [0.19044048]]\n",
      "04/10/2025 13:41:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 13:41:17 - INFO - __main__ -   auc_score = 0.9095\n",
      "04/10/2025 13:41:17 - INFO - __main__ -   eval_f1 = 0.5108\n",
      "04/10/2025 13:41:17 - INFO - __main__ -   eval_precision = 0.6923\n",
      "04/10/2025 13:41:17 - INFO - __main__ -   eval_recall = 0.4047\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 13:56:22 - WARNING - __main__ - epoch 2 step 1024 loss 0.16319\n",
      "[[0.9834013 ]\n",
      " [0.73208326]\n",
      " [0.16326953]\n",
      " ...\n",
      " [0.1282501 ]\n",
      " [0.5209971 ]\n",
      " [0.16219966]]\n",
      "04/10/2025 13:58:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 13:58:32 - INFO - __main__ -   auc_score = 0.9113\n",
      "04/10/2025 13:58:32 - INFO - __main__ -   eval_f1 = 0.5836\n",
      "04/10/2025 13:58:32 - INFO - __main__ -   eval_precision = 0.679\n",
      "04/10/2025 13:58:32 - INFO - __main__ -   eval_recall = 0.5118\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/10/2025 14:13:37 - WARNING - __main__ - epoch 3 step 1024 loss 0.14885\n",
      "[[0.9906303 ]\n",
      " [0.72017616]\n",
      " [0.23150408]\n",
      " ...\n",
      " [0.17119163]\n",
      " [0.9144442 ]\n",
      " [0.37628582]]\n",
      "04/10/2025 14:15:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 14:15:47 - INFO - __main__ -   auc_score = 0.9147\n",
      "04/10/2025 14:15:47 - INFO - __main__ -   eval_f1 = 0.5889\n",
      "04/10/2025 14:15:47 - INFO - __main__ -   eval_precision = 0.6\n",
      "04/10/2025 14:15:47 - INFO - __main__ -   eval_recall = 0.5782\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 14:30:51 - WARNING - __main__ - epoch 4 step 1024 loss 0.13639\n",
      "[[0.99506915]\n",
      " [0.7601877 ]\n",
      " [0.20988485]\n",
      " ...\n",
      " [0.05253981]\n",
      " [0.8685671 ]\n",
      " [0.12516297]]\n",
      "04/10/2025 14:33:01 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 14:33:01 - INFO - __main__ -   auc_score = 0.9122\n",
      "04/10/2025 14:33:01 - INFO - __main__ -   eval_f1 = 0.5749\n",
      "04/10/2025 14:33:01 - INFO - __main__ -   eval_precision = 0.6522\n",
      "04/10/2025 14:33:01 - INFO - __main__ -   eval_recall = 0.5139\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 14:47:55 - WARNING - __main__ - epoch 5 step 1024 loss 0.12134\n",
      "[[0.99618727]\n",
      " [0.8397786 ]\n",
      " [0.27163103]\n",
      " ...\n",
      " [0.03323447]\n",
      " [0.88165563]\n",
      " [0.08579835]]\n",
      "04/10/2025 14:50:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 14:50:05 - INFO - __main__ -   auc_score = 0.911\n",
      "04/10/2025 14:50:05 - INFO - __main__ -   eval_f1 = 0.5852\n",
      "04/10/2025 14:50:05 - INFO - __main__ -   eval_precision = 0.5969\n",
      "04/10/2025 14:50:05 - INFO - __main__ -   eval_recall = 0.5739\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/10/2025 15:05:00 - WARNING - __main__ - epoch 6 step 1024 loss 0.1084\n",
      "[[0.9989404 ]\n",
      " [0.8866357 ]\n",
      " [0.23352894]\n",
      " ...\n",
      " [0.03385793]\n",
      " [0.97125894]\n",
      " [0.09653769]]\n",
      "04/10/2025 15:07:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 15:07:10 - INFO - __main__ -   auc_score = 0.9099\n",
      "04/10/2025 15:07:10 - INFO - __main__ -   eval_f1 = 0.5708\n",
      "04/10/2025 15:07:10 - INFO - __main__ -   eval_precision = 0.5637\n",
      "04/10/2025 15:07:10 - INFO - __main__ -   eval_recall = 0.5782\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 15:22:05 - WARNING - __main__ - epoch 7 step 1024 loss 0.10076\n",
      "[[0.9982863 ]\n",
      " [0.8843482 ]\n",
      " [0.09758151]\n",
      " ...\n",
      " [0.00783859]\n",
      " [0.8596929 ]\n",
      " [0.04394933]]\n",
      "04/10/2025 15:24:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 15:24:15 - INFO - __main__ -   auc_score = 0.9071\n",
      "04/10/2025 15:24:15 - INFO - __main__ -   eval_f1 = 0.5654\n",
      "04/10/2025 15:24:15 - INFO - __main__ -   eval_precision = 0.6676\n",
      "04/10/2025 15:24:15 - INFO - __main__ -   eval_recall = 0.4904\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 15:39:10 - WARNING - __main__ - epoch 8 step 1024 loss 0.09257\n",
      "[[0.99958855]\n",
      " [0.8916893 ]\n",
      " [0.20501122]\n",
      " ...\n",
      " [0.00749716]\n",
      " [0.9643811 ]\n",
      " [0.07353965]]\n",
      "04/10/2025 15:41:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 15:41:20 - INFO - __main__ -   auc_score = 0.9073\n",
      "04/10/2025 15:41:20 - INFO - __main__ -   eval_f1 = 0.5626\n",
      "04/10/2025 15:41:20 - INFO - __main__ -   eval_precision = 0.5826\n",
      "04/10/2025 15:41:20 - INFO - __main__ -   eval_recall = 0.5439\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 15:56:14 - WARNING - __main__ - epoch 9 step 1024 loss 0.08588\n",
      "[[0.9996012 ]\n",
      " [0.8997738 ]\n",
      " [0.23105559]\n",
      " ...\n",
      " [0.0051811 ]\n",
      " [0.9430076 ]\n",
      " [0.05166912]]\n",
      "04/10/2025 15:58:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 15:58:24 - INFO - __main__ -   auc_score = 0.9069\n",
      "04/10/2025 15:58:24 - INFO - __main__ -   eval_f1 = 0.564\n",
      "04/10/2025 15:58:24 - INFO - __main__ -   eval_precision = 0.5934\n",
      "04/10/2025 15:58:24 - INFO - __main__ -   eval_recall = 0.5375\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XE6DW6lEET8J",
    "outputId": "2b7a8ec2-e69f-4a84-924f-b98d63848e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 16:26:30.826973: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 16:26:30.845737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744302390.867711   88015 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744302390.874507   88015 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 16:26:30.897306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.52\n",
      "recall =  0.52\n",
      "04/10/2025 16:37:43 - INFO - __main__ - ***** Test results *****\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   R0 = 0.9582\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   R1 = 0.52\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   auc_score = 0.899\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   g_mean = 0.7059\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   test_f1 = 0.5306\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   test_precision = 0.5417\n",
      "04/10/2025 16:37:43 - INFO - __main__ -   test_recall = 0.52\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAZrJHJQEhtC"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4VkAyvaEFlL",
    "outputId": "bbc434a7-66ec-4140-81d9-287e80f6de48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:20:39.060677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 17:20:39.078752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744305639.100599  108325 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744305639.107375  108325 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 17:20:39.129615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/10/2025 17:29:03 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/10/2025 17:46:12 - WARNING - __main__ - epoch 0 step 1024 loss 0.23696\n",
      "[[0.84261864]\n",
      " [0.22902139]\n",
      " [0.03729646]\n",
      " ...\n",
      " [0.1539364 ]\n",
      " [0.26364544]\n",
      " [0.18012035]]\n",
      "04/10/2025 17:48:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 17:48:22 - INFO - __main__ -   auc_score = 0.9007\n",
      "04/10/2025 17:48:22 - INFO - __main__ -   eval_f1 = 0.3429\n",
      "04/10/2025 17:48:22 - INFO - __main__ -   eval_precision = 0.7969\n",
      "04/10/2025 17:48:22 - INFO - __main__ -   eval_recall = 0.2184\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 18:03:25 - WARNING - __main__ - epoch 1 step 1024 loss 0.17967\n",
      "[[0.94562584]\n",
      " [0.5221116 ]\n",
      " [0.06936482]\n",
      " ...\n",
      " [0.12405836]\n",
      " [0.21806595]\n",
      " [0.05586473]]\n",
      "04/10/2025 18:05:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 18:05:35 - INFO - __main__ -   auc_score = 0.9132\n",
      "04/10/2025 18:05:35 - INFO - __main__ -   eval_f1 = 0.5522\n",
      "04/10/2025 18:05:35 - INFO - __main__ -   eval_precision = 0.8319\n",
      "04/10/2025 18:05:35 - INFO - __main__ -   eval_recall = 0.4133\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 18:20:39 - WARNING - __main__ - epoch 2 step 1024 loss 0.1624\n",
      "[[0.9683147 ]\n",
      " [0.59031755]\n",
      " [0.09158333]\n",
      " ...\n",
      " [0.164632  ]\n",
      " [0.34062546]\n",
      " [0.13301772]]\n",
      "04/10/2025 18:22:49 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 18:22:49 - INFO - __main__ -   auc_score = 0.9181\n",
      "04/10/2025 18:22:49 - INFO - __main__ -   eval_f1 = 0.5995\n",
      "04/10/2025 18:22:49 - INFO - __main__ -   eval_precision = 0.6812\n",
      "04/10/2025 18:22:49 - INFO - __main__ -   eval_recall = 0.5353\n",
      "100% 1024/1024 [17:18<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 18:37:57 - WARNING - __main__ - epoch 3 step 1024 loss 0.14345\n",
      "[[0.9907046 ]\n",
      " [0.73509145]\n",
      " [0.11140081]\n",
      " ...\n",
      " [0.08951338]\n",
      " [0.39048114]\n",
      " [0.05769255]]\n",
      "04/10/2025 18:40:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 18:40:07 - INFO - __main__ -   auc_score = 0.9141\n",
      "04/10/2025 18:40:07 - INFO - __main__ -   eval_f1 = 0.5856\n",
      "04/10/2025 18:40:07 - INFO - __main__ -   eval_precision = 0.6526\n",
      "04/10/2025 18:40:07 - INFO - __main__ -   eval_recall = 0.531\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 18:55:02 - WARNING - __main__ - epoch 4 step 1024 loss 0.13077\n",
      "[[0.9939307 ]\n",
      " [0.7123751 ]\n",
      " [0.12273742]\n",
      " ...\n",
      " [0.09063667]\n",
      " [0.2700112 ]\n",
      " [0.02958185]]\n",
      "04/10/2025 18:57:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 18:57:13 - INFO - __main__ -   auc_score = 0.913\n",
      "04/10/2025 18:57:13 - INFO - __main__ -   eval_f1 = 0.5998\n",
      "04/10/2025 18:57:13 - INFO - __main__ -   eval_precision = 0.6889\n",
      "04/10/2025 18:57:13 - INFO - __main__ -   eval_recall = 0.531\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 19:12:16 - WARNING - __main__ - epoch 5 step 1024 loss 0.11745\n",
      "[[0.98588294]\n",
      " [0.654945  ]\n",
      " [0.11113918]\n",
      " ...\n",
      " [0.03566505]\n",
      " [0.10319033]\n",
      " [0.01065131]]\n",
      "04/10/2025 19:14:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 19:14:27 - INFO - __main__ -   auc_score = 0.9056\n",
      "04/10/2025 19:14:27 - INFO - __main__ -   eval_f1 = 0.559\n",
      "04/10/2025 19:14:27 - INFO - __main__ -   eval_precision = 0.6965\n",
      "04/10/2025 19:14:27 - INFO - __main__ -   eval_recall = 0.4668\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 19:29:22 - WARNING - __main__ - epoch 6 step 1024 loss 0.10453\n",
      "[[0.99304175]\n",
      " [0.6870827 ]\n",
      " [0.20650195]\n",
      " ...\n",
      " [0.01359157]\n",
      " [0.10216627]\n",
      " [0.0099863 ]]\n",
      "04/10/2025 19:31:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 19:31:32 - INFO - __main__ -   auc_score = 0.9018\n",
      "04/10/2025 19:31:32 - INFO - __main__ -   eval_f1 = 0.5481\n",
      "04/10/2025 19:31:32 - INFO - __main__ -   eval_precision = 0.6247\n",
      "04/10/2025 19:31:32 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 19:46:27 - WARNING - __main__ - epoch 7 step 1024 loss 0.09476\n",
      "[[0.9954848 ]\n",
      " [0.700631  ]\n",
      " [0.06865577]\n",
      " ...\n",
      " [0.00956175]\n",
      " [0.06676009]\n",
      " [0.00460829]]\n",
      "04/10/2025 19:48:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 19:48:37 - INFO - __main__ -   auc_score = 0.9014\n",
      "04/10/2025 19:48:37 - INFO - __main__ -   eval_f1 = 0.5328\n",
      "04/10/2025 19:48:37 - INFO - __main__ -   eval_precision = 0.6881\n",
      "04/10/2025 19:48:37 - INFO - __main__ -   eval_recall = 0.4347\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 20:03:32 - WARNING - __main__ - epoch 8 step 1024 loss 0.08717\n",
      "[[0.99678075]\n",
      " [0.7489838 ]\n",
      " [0.11722681]\n",
      " ...\n",
      " [0.01719656]\n",
      " [0.09669157]\n",
      " [0.00538753]]\n",
      "04/10/2025 20:05:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 20:05:42 - INFO - __main__ -   auc_score = 0.9014\n",
      "04/10/2025 20:05:42 - INFO - __main__ -   eval_f1 = 0.5459\n",
      "04/10/2025 20:05:42 - INFO - __main__ -   eval_precision = 0.6156\n",
      "04/10/2025 20:05:42 - INFO - __main__ -   eval_recall = 0.4904\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/10/2025 20:20:37 - WARNING - __main__ - epoch 9 step 1024 loss 0.0832\n",
      "[[0.9974209 ]\n",
      " [0.7101685 ]\n",
      " [0.1131993 ]\n",
      " ...\n",
      " [0.02341069]\n",
      " [0.09211127]\n",
      " [0.00550551]]\n",
      "04/10/2025 20:22:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/10/2025 20:22:48 - INFO - __main__ -   auc_score = 0.9021\n",
      "04/10/2025 20:22:48 - INFO - __main__ -   eval_f1 = 0.5459\n",
      "04/10/2025 20:22:48 - INFO - __main__ -   eval_precision = 0.6156\n",
      "04/10/2025 20:22:48 - INFO - __main__ -   eval_recall = 0.4904\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dU0BRwusEV-2",
    "outputId": "f75a3c4d-e46d-42cb-cc99-d5a05a9853f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 20:23:05.230446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-10 20:23:05.248445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744316585.270144  175027 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744316585.276826  175027 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 20:23:05.298911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4652631578947368\n",
      "recall =  0.4652631578947368\n",
      "04/10/2025 20:34:26 - INFO - __main__ - ***** Test results *****\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   R0 = 0.9728\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   R1 = 0.4653\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   auc_score = 0.899\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   g_mean = 0.6728\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   test_f1 = 0.5312\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   test_precision = 0.619\n",
      "04/10/2025 20:34:26 - INFO - __main__ -   test_recall = 0.4653\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOG-dZQrrW3l"
   },
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6H2rRwIriZV",
    "outputId": "d5da0583-ca23-4739-9a74-a73bee956361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:05:40.787852: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 19:05:40.805014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744657540.826444    4180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744657540.833150    4180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 19:05:40.855775: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "config.json: 100% 770/770 [00:00<00:00, 6.42MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 9.94MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 5.09MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 45.1MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 21.4kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 70.6MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:09<00:00, 160MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/14/2025 19:14:01 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "04/14/2025 19:16:19 - INFO - __main__ - class_counts: [14984  1390]\n",
      "04/14/2025 19:16:19 - INFO - __main__ - class_weights: [6.67378537e-05 7.19424460e-04]\n",
      "100% 1023/1024 [14:54<00:00,  1.15it/s]04/14/2025 19:31:14 - WARNING - __main__ - epoch 0 step 1024 loss 0.44059\n",
      "[[0.9972179 ]\n",
      " [0.89740247]\n",
      " [0.5758678 ]\n",
      " ...\n",
      " [0.86893106]\n",
      " [0.9825455 ]\n",
      " [0.90198   ]]\n",
      "04/14/2025 19:33:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 19:33:24 - INFO - __main__ -   auc_score = 0.9114\n",
      "04/14/2025 19:33:24 - INFO - __main__ -   eval_f1 = 0.3776\n",
      "04/14/2025 19:33:24 - INFO - __main__ -   eval_precision = 0.2392\n",
      "04/14/2025 19:33:24 - INFO - __main__ -   eval_recall = 0.8972\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 19:48:27 - WARNING - __main__ - epoch 1 step 1024 loss 0.30324\n",
      "[[0.9955966 ]\n",
      " [0.9389239 ]\n",
      " [0.7478298 ]\n",
      " ...\n",
      " [0.50501615]\n",
      " [0.80718285]\n",
      " [0.37523273]]\n",
      "04/14/2025 19:50:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 19:50:37 - INFO - __main__ -   auc_score = 0.9008\n",
      "04/14/2025 19:50:37 - INFO - __main__ -   eval_f1 = 0.4763\n",
      "04/14/2025 19:50:37 - INFO - __main__ -   eval_precision = 0.3534\n",
      "04/14/2025 19:50:37 - INFO - __main__ -   eval_recall = 0.7302\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 20:05:40 - WARNING - __main__ - epoch 2 step 1024 loss 0.22976\n",
      "[[0.99803895]\n",
      " [0.9730132 ]\n",
      " [0.89930093]\n",
      " ...\n",
      " [0.18490928]\n",
      " [0.4690121 ]\n",
      " [0.35928765]]\n",
      "04/14/2025 20:07:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 20:07:50 - INFO - __main__ -   auc_score = 0.8896\n",
      "04/14/2025 20:07:50 - INFO - __main__ -   eval_f1 = 0.4483\n",
      "04/14/2025 20:07:50 - INFO - __main__ -   eval_precision = 0.3247\n",
      "04/14/2025 20:07:50 - INFO - __main__ -   eval_recall = 0.7238\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 20:22:43 - WARNING - __main__ - epoch 3 step 1024 loss 0.1759\n",
      "[[0.99980825]\n",
      " [0.9545303 ]\n",
      " [0.90228903]\n",
      " ...\n",
      " [0.72595197]\n",
      " [0.35070118]\n",
      " [0.3821485 ]]\n",
      "04/14/2025 20:24:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 20:24:53 - INFO - __main__ -   auc_score = 0.894\n",
      "04/14/2025 20:24:53 - INFO - __main__ -   eval_f1 = 0.461\n",
      "04/14/2025 20:24:53 - INFO - __main__ -   eval_precision = 0.3416\n",
      "04/14/2025 20:24:53 - INFO - __main__ -   eval_recall = 0.7088\n",
      "100% 1024/1024 [17:02<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 20:39:46 - WARNING - __main__ - epoch 4 step 1024 loss 0.12724\n",
      "[[0.9999176 ]\n",
      " [0.9773885 ]\n",
      " [0.7758592 ]\n",
      " ...\n",
      " [0.71572244]\n",
      " [0.03600283]\n",
      " [0.30366343]]\n",
      "04/14/2025 20:41:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 20:41:56 - INFO - __main__ -   auc_score = 0.8833\n",
      "04/14/2025 20:41:56 - INFO - __main__ -   eval_f1 = 0.4607\n",
      "04/14/2025 20:41:56 - INFO - __main__ -   eval_precision = 0.3504\n",
      "04/14/2025 20:41:56 - INFO - __main__ -   eval_recall = 0.6724\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 20:56:50 - WARNING - __main__ - epoch 5 step 1024 loss 0.10961\n",
      "[[0.9981981 ]\n",
      " [0.7832458 ]\n",
      " [0.7805825 ]\n",
      " ...\n",
      " [0.41650835]\n",
      " [0.05329638]\n",
      " [0.12721929]]\n",
      "04/14/2025 20:59:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 20:59:00 - INFO - __main__ -   auc_score = 0.8866\n",
      "04/14/2025 20:59:00 - INFO - __main__ -   eval_f1 = 0.4846\n",
      "04/14/2025 20:59:00 - INFO - __main__ -   eval_precision = 0.4117\n",
      "04/14/2025 20:59:00 - INFO - __main__ -   eval_recall = 0.5889\n",
      "100% 1024/1024 [17:12<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 21:14:02 - WARNING - __main__ - epoch 6 step 1024 loss 0.09426\n",
      "[[0.99776316]\n",
      " [0.8386908 ]\n",
      " [0.1553212 ]\n",
      " ...\n",
      " [0.03282699]\n",
      " [0.01047049]\n",
      " [0.03173606]]\n",
      "04/14/2025 21:16:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 21:16:12 - INFO - __main__ -   auc_score = 0.8792\n",
      "04/14/2025 21:16:12 - INFO - __main__ -   eval_f1 = 0.4754\n",
      "04/14/2025 21:16:12 - INFO - __main__ -   eval_precision = 0.4331\n",
      "04/14/2025 21:16:12 - INFO - __main__ -   eval_recall = 0.5268\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 21:31:05 - WARNING - __main__ - epoch 7 step 1024 loss 0.07389\n",
      "[[0.99412537]\n",
      " [0.68522066]\n",
      " [0.03278537]\n",
      " ...\n",
      " [0.03493405]\n",
      " [0.00974186]\n",
      " [0.02058864]]\n",
      "04/14/2025 21:33:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 21:33:15 - INFO - __main__ -   auc_score = 0.8786\n",
      "04/14/2025 21:33:15 - INFO - __main__ -   eval_f1 = 0.4903\n",
      "04/14/2025 21:33:15 - INFO - __main__ -   eval_precision = 0.4671\n",
      "04/14/2025 21:33:15 - INFO - __main__ -   eval_recall = 0.5161\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 21:48:19 - WARNING - __main__ - epoch 8 step 1024 loss 0.07033\n",
      "[[0.99710137]\n",
      " [0.5304454 ]\n",
      " [0.02953481]\n",
      " ...\n",
      " [0.02415463]\n",
      " [0.00978389]\n",
      " [0.01578896]]\n",
      "04/14/2025 21:50:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 21:50:29 - INFO - __main__ -   auc_score = 0.8782\n",
      "04/14/2025 21:50:29 - INFO - __main__ -   eval_f1 = 0.4901\n",
      "04/14/2025 21:50:29 - INFO - __main__ -   eval_precision = 0.4795\n",
      "04/14/2025 21:50:29 - INFO - __main__ -   eval_recall = 0.5011\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:52<00:00,  1.15it/s]04/14/2025 22:05:22 - WARNING - __main__ - epoch 9 step 1024 loss 0.06455\n",
      "[[0.9980804 ]\n",
      " [0.6724055 ]\n",
      " [0.03515234]\n",
      " ...\n",
      " [0.02796314]\n",
      " [0.01120548]\n",
      " [0.02182802]]\n",
      "04/14/2025 22:07:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 22:07:32 - INFO - __main__ -   auc_score = 0.8783\n",
      "04/14/2025 22:07:32 - INFO - __main__ -   eval_f1 = 0.489\n",
      "04/14/2025 22:07:32 - INFO - __main__ -   eval_precision = 0.4595\n",
      "04/14/2025 22:07:32 - INFO - __main__ -   eval_recall = 0.5225\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/over/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora \\\n",
    "   --oversample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EgZ_qSYX4Ss",
    "outputId": "b1de403b-f3e2-4e64-cc6c-057cb5987e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 22:17:12.984663: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 22:17:13.002891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744669033.026182   75329 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744669033.033289   75329 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 22:17:13.055404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.49473684210526314\n",
      "recall =  0.49473684210526314\n",
      "04/14/2025 22:28:35 - INFO - __main__ - ***** Test results *****\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   R0 = 0.9425\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   R1 = 0.4947\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   auc_score = 0.8591\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   g_mean = 0.6828\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   test_f1 = 0.4709\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   test_precision = 0.4493\n",
      "04/14/2025 22:28:35 - INFO - __main__ -   test_recall = 0.4947\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/over/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2HzIrHeceY9"
   },
   "source": [
    "### Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIAcdPGtdTyb",
    "outputId": "946ca667-b332-416a-e750-2ba86b1ebfac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 22:40:38.929276: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 22:40:38.947664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744670438.969999   83964 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744670438.976765   83964 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 22:40:38.999476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/14/2025 22:49:07 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/14/2025 23:06:17 - WARNING - __main__ - epoch 0 step 1024 loss 0.08257\n",
      "[[0.783544  ]\n",
      " [0.29212224]\n",
      " [0.10593119]\n",
      " ...\n",
      " [0.22616807]\n",
      " [0.33551183]\n",
      " [0.20192416]]\n",
      "04/14/2025 23:08:27 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 23:08:27 - INFO - __main__ -   auc_score = 0.9083\n",
      "04/14/2025 23:08:27 - INFO - __main__ -   eval_f1 = 0.3475\n",
      "04/14/2025 23:08:27 - INFO - __main__ -   eval_precision = 0.7413\n",
      "04/14/2025 23:08:27 - INFO - __main__ -   eval_recall = 0.227\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/14/2025 23:23:32 - WARNING - __main__ - epoch 1 step 1024 loss 0.06311\n",
      "[[0.89258087]\n",
      " [0.48361093]\n",
      " [0.15854858]\n",
      " ...\n",
      " [0.3307767 ]\n",
      " [0.56976724]\n",
      " [0.30300725]]\n",
      "04/14/2025 23:25:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 23:25:42 - INFO - __main__ -   auc_score = 0.9139\n",
      "04/14/2025 23:25:42 - INFO - __main__ -   eval_f1 = 0.5853\n",
      "04/14/2025 23:25:42 - INFO - __main__ -   eval_precision = 0.6994\n",
      "04/14/2025 23:25:42 - INFO - __main__ -   eval_recall = 0.5032\n",
      "100% 1024/1024 [17:12<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/14/2025 23:40:45 - WARNING - __main__ - epoch 2 step 1024 loss 0.05699\n",
      "[[0.89460385]\n",
      " [0.4284198 ]\n",
      " [0.12074341]\n",
      " ...\n",
      " [0.35687804]\n",
      " [0.63646936]\n",
      " [0.24542487]]\n",
      "04/14/2025 23:42:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 23:42:55 - INFO - __main__ -   auc_score = 0.9134\n",
      "04/14/2025 23:42:55 - INFO - __main__ -   eval_f1 = 0.5524\n",
      "04/14/2025 23:42:55 - INFO - __main__ -   eval_precision = 0.7104\n",
      "04/14/2025 23:42:55 - INFO - __main__ -   eval_recall = 0.4518\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/14/2025 23:57:49 - WARNING - __main__ - epoch 3 step 1024 loss 0.05052\n",
      "[[0.92725253]\n",
      " [0.48437154]\n",
      " [0.15365815]\n",
      " ...\n",
      " [0.36087728]\n",
      " [0.66214377]\n",
      " [0.20799987]]\n",
      "04/14/2025 23:59:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/14/2025 23:59:59 - INFO - __main__ -   auc_score = 0.914\n",
      "04/14/2025 23:59:59 - INFO - __main__ -   eval_f1 = 0.5627\n",
      "04/14/2025 23:59:59 - INFO - __main__ -   eval_precision = 0.6984\n",
      "04/14/2025 23:59:59 - INFO - __main__ -   eval_recall = 0.4711\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/15/2025 00:14:53 - WARNING - __main__ - epoch 4 step 1024 loss 0.04613\n",
      "[[0.9682548 ]\n",
      " [0.71467817]\n",
      " [0.22106342]\n",
      " ...\n",
      " [0.4468382 ]\n",
      " [0.7264966 ]\n",
      " [0.27386975]]\n",
      "04/15/2025 00:17:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 00:17:03 - INFO - __main__ -   auc_score = 0.9126\n",
      "04/15/2025 00:17:03 - INFO - __main__ -   eval_f1 = 0.5901\n",
      "04/15/2025 00:17:03 - INFO - __main__ -   eval_precision = 0.5914\n",
      "04/15/2025 00:17:03 - INFO - __main__ -   eval_recall = 0.5889\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/15/2025 00:32:07 - WARNING - __main__ - epoch 5 step 1024 loss 0.04096\n",
      "[[0.9582981 ]\n",
      " [0.69626975]\n",
      " [0.265903  ]\n",
      " ...\n",
      " [0.25739077]\n",
      " [0.5089655 ]\n",
      " [0.18379354]]\n",
      "04/15/2025 00:34:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 00:34:17 - INFO - __main__ -   auc_score = 0.908\n",
      "04/15/2025 00:34:17 - INFO - __main__ -   eval_f1 = 0.5746\n",
      "04/15/2025 00:34:17 - INFO - __main__ -   eval_precision = 0.5986\n",
      "04/15/2025 00:34:17 - INFO - __main__ -   eval_recall = 0.5525\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/15/2025 00:49:11 - WARNING - __main__ - epoch 6 step 1024 loss 0.03713\n",
      "[[0.96455663]\n",
      " [0.7153913 ]\n",
      " [0.23110501]\n",
      " ...\n",
      " [0.22424972]\n",
      " [0.3916256 ]\n",
      " [0.12371384]]\n",
      "04/15/2025 00:51:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 00:51:21 - INFO - __main__ -   auc_score = 0.9051\n",
      "04/15/2025 00:51:21 - INFO - __main__ -   eval_f1 = 0.5655\n",
      "04/15/2025 00:51:21 - INFO - __main__ -   eval_precision = 0.6527\n",
      "04/15/2025 00:51:21 - INFO - __main__ -   eval_recall = 0.4989\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/15/2025 01:06:15 - WARNING - __main__ - epoch 7 step 1024 loss 0.03245\n",
      "[[0.97747374]\n",
      " [0.6800502 ]\n",
      " [0.23847532]\n",
      " ...\n",
      " [0.19429107]\n",
      " [0.3894088 ]\n",
      " [0.11060797]]\n",
      "04/15/2025 01:08:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 01:08:25 - INFO - __main__ -   auc_score = 0.9039\n",
      "04/15/2025 01:08:25 - INFO - __main__ -   eval_f1 = 0.5711\n",
      "04/15/2025 01:08:25 - INFO - __main__ -   eval_precision = 0.6393\n",
      "04/15/2025 01:08:25 - INFO - __main__ -   eval_recall = 0.5161\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.14it/s]04/15/2025 01:23:19 - WARNING - __main__ - epoch 8 step 1024 loss 0.03011\n",
      "[[0.97863585]\n",
      " [0.6551268 ]\n",
      " [0.26981878]\n",
      " ...\n",
      " [0.15994747]\n",
      " [0.3594737 ]\n",
      " [0.07982772]]\n",
      "04/15/2025 01:25:29 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 01:25:29 - INFO - __main__ -   auc_score = 0.9026\n",
      "04/15/2025 01:25:29 - INFO - __main__ -   eval_f1 = 0.5483\n",
      "04/15/2025 01:25:29 - INFO - __main__ -   eval_precision = 0.64\n",
      "04/15/2025 01:25:29 - INFO - __main__ -   eval_recall = 0.4797\n",
      "100% 1024/1024 [17:04<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:53<00:00,  1.15it/s]04/15/2025 01:40:23 - WARNING - __main__ - epoch 9 step 1024 loss 0.02843\n",
      "[[0.9835982 ]\n",
      " [0.7121266 ]\n",
      " [0.3079603 ]\n",
      " ...\n",
      " [0.1874484 ]\n",
      " [0.4242983 ]\n",
      " [0.10015481]]\n",
      "04/15/2025 01:42:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 01:42:33 - INFO - __main__ -   auc_score = 0.9018\n",
      "04/15/2025 01:42:33 - INFO - __main__ -   eval_f1 = 0.5527\n",
      "04/15/2025 01:42:33 - INFO - __main__ -   eval_precision = 0.6098\n",
      "04/15/2025 01:42:33 - INFO - __main__ -   eval_recall = 0.5054\n",
      "100% 1024/1024 [17:03<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmtD1Nh_HvoN",
    "outputId": "53f0ca25-0894-4d78-be1a-31231c2d6af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 01:57:24.836993: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 01:57:24.856219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744682244.878316  157444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744682244.885059  157444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 01:57:24.907445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.5157894736842106\n",
      "recall =  0.5157894736842106\n",
      "04/15/2025 02:08:56 - INFO - __main__ - ***** Test results *****\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   R0 = 0.9614\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   R1 = 0.5158\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   auc_score = 0.9013\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   g_mean = 0.7042\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   test_f1 = 0.5367\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   test_precision = 0.5594\n",
      "04/15/2025 02:08:56 - INFO - __main__ -   test_recall = 0.5158\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYMFDDlWD1IF"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mau7Pn4kD6E_"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uCLfc3KD_1b",
    "outputId": "fcc2d4b0-bbd5-4db3-c434-e33e4dcd41fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 15:27:53.483357: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 15:27:53.501021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744730873.522654    3136 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744730873.529483    3136 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 15:27:53.551917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "config.json: 100% 770/770 [00:00<00:00, 5.50MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 11.0MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 9.55MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 23.7MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 20.3kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 59.4MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:06<00:00, 237MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/15/2025 15:36:14 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:56<00:00,  1.14it/s]04/15/2025 15:53:28 - WARNING - __main__ - epoch 0 step 1024 loss 0.0828\n",
      "[[0.79671454]\n",
      " [0.4399229 ]\n",
      " [0.09519037]\n",
      " ...\n",
      " [0.23913448]\n",
      " [0.56474084]\n",
      " [0.35816073]]\n",
      "04/15/2025 15:55:39 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 15:55:39 - INFO - __main__ -   auc_score = 0.9061\n",
      "04/15/2025 15:55:39 - INFO - __main__ -   eval_f1 = 0.4595\n",
      "04/15/2025 15:55:39 - INFO - __main__ -   eval_precision = 0.7067\n",
      "04/15/2025 15:55:39 - INFO - __main__ -   eval_recall = 0.3405\n",
      "100% 1024/1024 [17:20<00:00,  1.02s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 16:10:47 - WARNING - __main__ - epoch 1 step 1024 loss 0.06404\n",
      "[[0.8654545 ]\n",
      " [0.41458547]\n",
      " [0.14669423]\n",
      " ...\n",
      " [0.24183781]\n",
      " [0.5110254 ]\n",
      " [0.22944826]]\n",
      "04/15/2025 16:12:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 16:12:57 - INFO - __main__ -   auc_score = 0.9156\n",
      "04/15/2025 16:12:57 - INFO - __main__ -   eval_f1 = 0.5459\n",
      "04/15/2025 16:12:57 - INFO - __main__ -   eval_precision = 0.7218\n",
      "04/15/2025 16:12:57 - INFO - __main__ -   eval_recall = 0.439\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 16:28:03 - WARNING - __main__ - epoch 2 step 1024 loss 0.05715\n",
      "[[0.89577913]\n",
      " [0.4862755 ]\n",
      " [0.2232615 ]\n",
      " ...\n",
      " [0.24999827]\n",
      " [0.6319263 ]\n",
      " [0.23008977]]\n",
      "04/15/2025 16:30:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 16:30:13 - INFO - __main__ -   auc_score = 0.9171\n",
      "04/15/2025 16:30:13 - INFO - __main__ -   eval_f1 = 0.5935\n",
      "04/15/2025 16:30:13 - INFO - __main__ -   eval_precision = 0.7617\n",
      "04/15/2025 16:30:13 - INFO - __main__ -   eval_recall = 0.4861\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 16:45:18 - WARNING - __main__ - epoch 3 step 1024 loss 0.05158\n",
      "[[0.9471776 ]\n",
      " [0.52241564]\n",
      " [0.26031426]\n",
      " ...\n",
      " [0.19482556]\n",
      " [0.45621833]\n",
      " [0.23920295]]\n",
      "04/15/2025 16:47:28 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 16:47:28 - INFO - __main__ -   auc_score = 0.9168\n",
      "04/15/2025 16:47:28 - INFO - __main__ -   eval_f1 = 0.6047\n",
      "04/15/2025 16:47:28 - INFO - __main__ -   eval_precision = 0.7057\n",
      "04/15/2025 16:47:28 - INFO - __main__ -   eval_recall = 0.5289\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 17:02:33 - WARNING - __main__ - epoch 4 step 1024 loss 0.04573\n",
      "[[0.9588129 ]\n",
      " [0.44956863]\n",
      " [0.16678618]\n",
      " ...\n",
      " [0.13341625]\n",
      " [0.6123169 ]\n",
      " [0.22509857]]\n",
      "04/15/2025 17:04:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 17:04:43 - INFO - __main__ -   auc_score = 0.916\n",
      "04/15/2025 17:04:43 - INFO - __main__ -   eval_f1 = 0.5789\n",
      "04/15/2025 17:04:43 - INFO - __main__ -   eval_precision = 0.6893\n",
      "04/15/2025 17:04:43 - INFO - __main__ -   eval_recall = 0.4989\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 17:19:38 - WARNING - __main__ - epoch 5 step 1024 loss 0.04007\n",
      "[[0.98134816]\n",
      " [0.5352922 ]\n",
      " [0.4166337 ]\n",
      " ...\n",
      " [0.11750235]\n",
      " [0.531188  ]\n",
      " [0.3127995 ]]\n",
      "04/15/2025 17:21:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 17:21:48 - INFO - __main__ -   auc_score = 0.9175\n",
      "04/15/2025 17:21:48 - INFO - __main__ -   eval_f1 = 0.5758\n",
      "04/15/2025 17:21:48 - INFO - __main__ -   eval_precision = 0.5914\n",
      "04/15/2025 17:21:48 - INFO - __main__ -   eval_recall = 0.561\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 17:36:43 - WARNING - __main__ - epoch 6 step 1024 loss 0.03554\n",
      "[[0.98691064]\n",
      " [0.5979357 ]\n",
      " [0.4064554 ]\n",
      " ...\n",
      " [0.14343508]\n",
      " [0.41127345]\n",
      " [0.27809513]]\n",
      "04/15/2025 17:38:53 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 17:38:53 - INFO - __main__ -   auc_score = 0.9131\n",
      "04/15/2025 17:38:53 - INFO - __main__ -   eval_f1 = 0.5675\n",
      "04/15/2025 17:38:53 - INFO - __main__ -   eval_precision = 0.5593\n",
      "04/15/2025 17:38:53 - INFO - __main__ -   eval_recall = 0.576\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 17:53:48 - WARNING - __main__ - epoch 7 step 1024 loss 0.03268\n",
      "[[0.99137443]\n",
      " [0.55401707]\n",
      " [0.3517525 ]\n",
      " ...\n",
      " [0.10680986]\n",
      " [0.5413667 ]\n",
      " [0.29103088]]\n",
      "04/15/2025 17:55:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 17:55:58 - INFO - __main__ -   auc_score = 0.9133\n",
      "04/15/2025 17:55:58 - INFO - __main__ -   eval_f1 = 0.5542\n",
      "04/15/2025 17:55:58 - INFO - __main__ -   eval_precision = 0.5396\n",
      "04/15/2025 17:55:58 - INFO - __main__ -   eval_recall = 0.5696\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 18:10:53 - WARNING - __main__ - epoch 8 step 1024 loss 0.03003\n",
      "[[0.99316496]\n",
      " [0.57520676]\n",
      " [0.28062478]\n",
      " ...\n",
      " [0.0867753 ]\n",
      " [0.4958935 ]\n",
      " [0.31682152]]\n",
      "04/15/2025 18:13:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 18:13:03 - INFO - __main__ -   auc_score = 0.9114\n",
      "04/15/2025 18:13:03 - INFO - __main__ -   eval_f1 = 0.5592\n",
      "04/15/2025 18:13:03 - INFO - __main__ -   eval_precision = 0.573\n",
      "04/15/2025 18:13:03 - INFO - __main__ -   eval_recall = 0.546\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/15/2025 18:27:59 - WARNING - __main__ - epoch 9 step 1024 loss 0.02811\n",
      "[[0.993975  ]\n",
      " [0.5673173 ]\n",
      " [0.27631637]\n",
      " ...\n",
      " [0.07618574]\n",
      " [0.4461983 ]\n",
      " [0.2885099 ]]\n",
      "04/15/2025 18:30:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 18:30:09 - INFO - __main__ -   auc_score = 0.9096\n",
      "04/15/2025 18:30:09 - INFO - __main__ -   eval_f1 = 0.5451\n",
      "04/15/2025 18:30:09 - INFO - __main__ -   eval_precision = 0.5671\n",
      "04/15/2025 18:30:09 - INFO - __main__ -   eval_recall = 0.5246\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwJHnrma5Gle",
    "outputId": "9b0fb487-6231-4b26-fcec-8720e496ea5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:20:03.232092: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 19:20:03.250153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744744803.271990   90203 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744744803.278650   90203 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 19:20:03.300649: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4463157894736842\n",
      "recall =  0.4463157894736842\n",
      "04/15/2025 19:31:17 - INFO - __main__ - ***** Test results *****\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   R0 = 0.9772\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   R1 = 0.4463\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   auc_score = 0.9028\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   g_mean = 0.6604\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   test_f1 = 0.5293\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   test_precision = 0.6503\n",
      "04/15/2025 19:31:17 - INFO - __main__ -   test_recall = 0.4463\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF-OXs9u8hYM"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wwSy4j38mrC",
    "outputId": "1e9ff29a-d7ef-4c36-8e11-9fc1b7676ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:35:04.138894: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 19:35:04.157350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744745704.179442   95881 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744745704.186181   95881 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 19:35:04.208769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/15/2025 19:43:29 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/15/2025 20:00:41 - WARNING - __main__ - epoch 0 step 1024 loss 0.08246\n",
      "[[0.85571927]\n",
      " [0.40906122]\n",
      " [0.19532755]\n",
      " ...\n",
      " [0.34277484]\n",
      " [0.49654773]\n",
      " [0.2888358 ]]\n",
      "04/15/2025 20:02:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 20:02:51 - INFO - __main__ -   auc_score = 0.9047\n",
      "04/15/2025 20:02:51 - INFO - __main__ -   eval_f1 = 0.5466\n",
      "04/15/2025 20:02:51 - INFO - __main__ -   eval_precision = 0.6509\n",
      "04/15/2025 20:02:51 - INFO - __main__ -   eval_recall = 0.4711\n",
      "100% 1024/1024 [17:16<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 20:17:57 - WARNING - __main__ - epoch 1 step 1024 loss 0.06352\n",
      "[[0.8659938 ]\n",
      " [0.35797113]\n",
      " [0.12218108]\n",
      " ...\n",
      " [0.1608051 ]\n",
      " [0.4164078 ]\n",
      " [0.11932456]]\n",
      "04/15/2025 20:20:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 20:20:07 - INFO - __main__ -   auc_score = 0.9096\n",
      "04/15/2025 20:20:07 - INFO - __main__ -   eval_f1 = 0.5106\n",
      "04/15/2025 20:20:07 - INFO - __main__ -   eval_precision = 0.7479\n",
      "04/15/2025 20:20:07 - INFO - __main__ -   eval_recall = 0.3876\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 20:35:02 - WARNING - __main__ - epoch 2 step 1024 loss 0.05647\n",
      "[[0.94846827]\n",
      " [0.63274837]\n",
      " [0.23005354]\n",
      " ...\n",
      " [0.24011597]\n",
      " [0.36451358]\n",
      " [0.16797034]]\n",
      "04/15/2025 20:37:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 20:37:12 - INFO - __main__ -   auc_score = 0.9081\n",
      "04/15/2025 20:37:12 - INFO - __main__ -   eval_f1 = 0.5882\n",
      "04/15/2025 20:37:12 - INFO - __main__ -   eval_precision = 0.6235\n",
      "04/15/2025 20:37:12 - INFO - __main__ -   eval_recall = 0.5567\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 20:52:16 - WARNING - __main__ - epoch 3 step 1024 loss 0.0499\n",
      "[[0.9680071 ]\n",
      " [0.571413  ]\n",
      " [0.12455675]\n",
      " ...\n",
      " [0.15583047]\n",
      " [0.24839826]\n",
      " [0.08842253]]\n",
      "04/15/2025 20:54:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 20:54:26 - INFO - __main__ -   auc_score = 0.9134\n",
      "04/15/2025 20:54:26 - INFO - __main__ -   eval_f1 = 0.5898\n",
      "04/15/2025 20:54:26 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/15/2025 20:54:26 - INFO - __main__ -   eval_recall = 0.5096\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 21:09:29 - WARNING - __main__ - epoch 4 step 1024 loss 0.04493\n",
      "[[0.97980624]\n",
      " [0.6535755 ]\n",
      " [0.15626734]\n",
      " ...\n",
      " [0.12555595]\n",
      " [0.13902129]\n",
      " [0.07786119]]\n",
      "04/15/2025 21:11:40 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 21:11:40 - INFO - __main__ -   auc_score = 0.9077\n",
      "04/15/2025 21:11:40 - INFO - __main__ -   eval_f1 = 0.5944\n",
      "04/15/2025 21:11:40 - INFO - __main__ -   eval_precision = 0.6893\n",
      "04/15/2025 21:11:40 - INFO - __main__ -   eval_recall = 0.5225\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/15/2025 21:26:43 - WARNING - __main__ - epoch 5 step 1024 loss 0.04024\n",
      "[[0.9931463 ]\n",
      " [0.71549886]\n",
      " [0.23489182]\n",
      " ...\n",
      " [0.10012871]\n",
      " [0.16685452]\n",
      " [0.13213156]]\n",
      "04/15/2025 21:28:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 21:28:54 - INFO - __main__ -   auc_score = 0.9069\n",
      "04/15/2025 21:28:54 - INFO - __main__ -   eval_f1 = 0.5746\n",
      "04/15/2025 21:28:54 - INFO - __main__ -   eval_precision = 0.6038\n",
      "04/15/2025 21:28:54 - INFO - __main__ -   eval_recall = 0.5482\n",
      "100% 1024/1024 [17:06<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 21:43:49 - WARNING - __main__ - epoch 6 step 1024 loss 0.03564\n",
      "[[0.99641305]\n",
      " [0.70923835]\n",
      " [0.13735186]\n",
      " ...\n",
      " [0.06463476]\n",
      " [0.10678042]\n",
      " [0.04011867]]\n",
      "04/15/2025 21:45:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 21:45:59 - INFO - __main__ -   auc_score = 0.9092\n",
      "04/15/2025 21:45:59 - INFO - __main__ -   eval_f1 = 0.5602\n",
      "04/15/2025 21:45:59 - INFO - __main__ -   eval_precision = 0.6571\n",
      "04/15/2025 21:45:59 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 22:00:54 - WARNING - __main__ - epoch 7 step 1024 loss 0.03196\n",
      "[[0.9963276 ]\n",
      " [0.6915784 ]\n",
      " [0.13469586]\n",
      " ...\n",
      " [0.0583944 ]\n",
      " [0.06211456]\n",
      " [0.04125429]]\n",
      "04/15/2025 22:03:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 22:03:04 - INFO - __main__ -   auc_score = 0.9054\n",
      "04/15/2025 22:03:04 - INFO - __main__ -   eval_f1 = 0.5568\n",
      "04/15/2025 22:03:04 - INFO - __main__ -   eval_precision = 0.6899\n",
      "04/15/2025 22:03:04 - INFO - __main__ -   eval_recall = 0.4668\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/15/2025 22:18:00 - WARNING - __main__ - epoch 8 step 1024 loss 0.02934\n",
      "[[0.9981146 ]\n",
      " [0.7550615 ]\n",
      " [0.12851423]\n",
      " ...\n",
      " [0.06914139]\n",
      " [0.05299324]\n",
      " [0.06391613]]\n",
      "04/15/2025 22:20:11 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 22:20:11 - INFO - __main__ -   auc_score = 0.9029\n",
      "04/15/2025 22:20:11 - INFO - __main__ -   eval_f1 = 0.5521\n",
      "04/15/2025 22:20:11 - INFO - __main__ -   eval_precision = 0.6351\n",
      "04/15/2025 22:20:11 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1024/1024 [17:06<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 22:35:06 - WARNING - __main__ - epoch 9 step 1024 loss 0.02691\n",
      "[[0.99848914]\n",
      " [0.7765093 ]\n",
      " [0.12820333]\n",
      " ...\n",
      " [0.07079827]\n",
      " [0.0547812 ]\n",
      " [0.10860695]]\n",
      "04/15/2025 22:37:16 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 22:37:16 - INFO - __main__ -   auc_score = 0.9029\n",
      "04/15/2025 22:37:16 - INFO - __main__ -   eval_f1 = 0.5541\n",
      "04/15/2025 22:37:16 - INFO - __main__ -   eval_precision = 0.6071\n",
      "04/15/2025 22:37:16 - INFO - __main__ -   eval_recall = 0.5096\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eep68KLG8u57",
    "outputId": "ea7d5ed2-e467-4d08-8833-670a3e211142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 22:56:24.157875: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 22:56:24.176334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744757784.199008  169559 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744757784.205860  169559 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 22:56:24.228740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4336842105263158\n",
      "recall =  0.4336842105263158\n",
      "04/15/2025 23:07:46 - INFO - __main__ - ***** Test results *****\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   R0 = 0.9768\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   R1 = 0.4337\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   auc_score = 0.8998\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   g_mean = 0.6509\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   test_f1 = 0.5169\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   test_precision = 0.6398\n",
      "04/15/2025 23:07:46 - INFO - __main__ -   test_recall = 0.4337\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yiz7rQJPulIC"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEUJWYh3uzIm",
    "outputId": "80b92ec2-38eb-460b-ce59-574655e09b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 23:14:22.895545: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 23:14:22.913965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744758862.938154  176178 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744758862.945436  176178 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 23:14:22.968583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/15/2025 23:22:52 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/15/2025 23:40:05 - WARNING - __main__ - epoch 0 step 1024 loss 0.08234\n",
      "[[0.8038187 ]\n",
      " [0.36466944]\n",
      " [0.1304958 ]\n",
      " ...\n",
      " [0.22652557]\n",
      " [0.4589629 ]\n",
      " [0.27888888]]\n",
      "04/15/2025 23:42:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 23:42:15 - INFO - __main__ -   auc_score = 0.9064\n",
      "04/15/2025 23:42:15 - INFO - __main__ -   eval_f1 = 0.4672\n",
      "04/15/2025 23:42:15 - INFO - __main__ -   eval_precision = 0.6979\n",
      "04/15/2025 23:42:15 - INFO - __main__ -   eval_recall = 0.3512\n",
      "100% 1024/1024 [17:17<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/15/2025 23:57:20 - WARNING - __main__ - epoch 1 step 1024 loss 0.06328\n",
      "[[0.8828848 ]\n",
      " [0.38969982]\n",
      " [0.07934522]\n",
      " ...\n",
      " [0.22439885]\n",
      " [0.5216201 ]\n",
      " [0.23964953]]\n",
      "04/15/2025 23:59:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/15/2025 23:59:31 - INFO - __main__ -   auc_score = 0.9084\n",
      "04/15/2025 23:59:31 - INFO - __main__ -   eval_f1 = 0.5109\n",
      "04/15/2025 23:59:31 - INFO - __main__ -   eval_precision = 0.6989\n",
      "04/15/2025 23:59:31 - INFO - __main__ -   eval_recall = 0.4026\n",
      "100% 1024/1024 [17:13<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 00:14:34 - WARNING - __main__ - epoch 2 step 1024 loss 0.05779\n",
      "[[0.91323763]\n",
      " [0.5519841 ]\n",
      " [0.16007082]\n",
      " ...\n",
      " [0.14662892]\n",
      " [0.35271186]\n",
      " [0.18378587]]\n",
      "04/16/2025 00:16:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 00:16:44 - INFO - __main__ -   auc_score = 0.9099\n",
      "04/16/2025 00:16:44 - INFO - __main__ -   eval_f1 = 0.5666\n",
      "04/16/2025 00:16:44 - INFO - __main__ -   eval_precision = 0.7258\n",
      "04/16/2025 00:16:44 - INFO - __main__ -   eval_recall = 0.4647\n",
      "100% 1024/1024 [17:15<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 00:31:50 - WARNING - __main__ - epoch 3 step 1024 loss 0.0518\n",
      "[[0.93176794]\n",
      " [0.5133727 ]\n",
      " [0.16772895]\n",
      " ...\n",
      " [0.13986863]\n",
      " [0.504247  ]\n",
      " [0.20804395]]\n",
      "04/16/2025 00:34:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 00:34:00 - INFO - __main__ -   auc_score = 0.9125\n",
      "04/16/2025 00:34:00 - INFO - __main__ -   eval_f1 = 0.6026\n",
      "04/16/2025 00:34:00 - INFO - __main__ -   eval_precision = 0.6858\n",
      "04/16/2025 00:34:00 - INFO - __main__ -   eval_recall = 0.5375\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 00:49:05 - WARNING - __main__ - epoch 4 step 1024 loss 0.04753\n",
      "[[0.96203715]\n",
      " [0.5505684 ]\n",
      " [0.15630236]\n",
      " ...\n",
      " [0.11663246]\n",
      " [0.43639383]\n",
      " [0.1929049 ]]\n",
      "04/16/2025 00:51:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 00:51:15 - INFO - __main__ -   auc_score = 0.9131\n",
      "04/16/2025 00:51:15 - INFO - __main__ -   eval_f1 = 0.584\n",
      "04/16/2025 00:51:15 - INFO - __main__ -   eval_precision = 0.6839\n",
      "04/16/2025 00:51:15 - INFO - __main__ -   eval_recall = 0.5096\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 01:06:11 - WARNING - __main__ - epoch 5 step 1024 loss 0.04167\n",
      "[[0.98849523]\n",
      " [0.75564516]\n",
      " [0.16277869]\n",
      " ...\n",
      " [0.06936217]\n",
      " [0.4095061 ]\n",
      " [0.1629281 ]]\n",
      "04/16/2025 01:08:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 01:08:21 - INFO - __main__ -   auc_score = 0.9105\n",
      "04/16/2025 01:08:21 - INFO - __main__ -   eval_f1 = 0.5919\n",
      "04/16/2025 01:08:21 - INFO - __main__ -   eval_precision = 0.6018\n",
      "04/16/2025 01:08:21 - INFO - __main__ -   eval_recall = 0.5824\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 01:23:16 - WARNING - __main__ - epoch 6 step 1024 loss 0.03764\n",
      "[[0.98889625]\n",
      " [0.7330981 ]\n",
      " [0.23569724]\n",
      " ...\n",
      " [0.07037078]\n",
      " [0.3458497 ]\n",
      " [0.21044785]]\n",
      "04/16/2025 01:25:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 01:25:26 - INFO - __main__ -   auc_score = 0.9115\n",
      "04/16/2025 01:25:26 - INFO - __main__ -   eval_f1 = 0.5772\n",
      "04/16/2025 01:25:26 - INFO - __main__ -   eval_precision = 0.6095\n",
      "04/16/2025 01:25:26 - INFO - __main__ -   eval_recall = 0.5482\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 01:40:22 - WARNING - __main__ - epoch 7 step 1024 loss 0.03427\n",
      "[[0.9899234 ]\n",
      " [0.8023857 ]\n",
      " [0.18436174]\n",
      " ...\n",
      " [0.04532064]\n",
      " [0.3221975 ]\n",
      " [0.15698786]]\n",
      "04/16/2025 01:42:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 01:42:32 - INFO - __main__ -   auc_score = 0.9092\n",
      "04/16/2025 01:42:32 - INFO - __main__ -   eval_f1 = 0.5878\n",
      "04/16/2025 01:42:32 - INFO - __main__ -   eval_precision = 0.6486\n",
      "04/16/2025 01:42:32 - INFO - __main__ -   eval_recall = 0.5375\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 01:57:27 - WARNING - __main__ - epoch 8 step 1024 loss 0.03125\n",
      "[[0.9927988 ]\n",
      " [0.7847696 ]\n",
      " [0.21315908]\n",
      " ...\n",
      " [0.03992902]\n",
      " [0.22223689]\n",
      " [0.1050697 ]]\n",
      "04/16/2025 01:59:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 01:59:37 - INFO - __main__ -   auc_score = 0.907\n",
      "04/16/2025 01:59:37 - INFO - __main__ -   eval_f1 = 0.5671\n",
      "04/16/2025 01:59:37 - INFO - __main__ -   eval_precision = 0.6292\n",
      "04/16/2025 01:59:37 - INFO - __main__ -   eval_recall = 0.5161\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 02:14:32 - WARNING - __main__ - epoch 9 step 1024 loss 0.02947\n",
      "[[0.9940646 ]\n",
      " [0.7929752 ]\n",
      " [0.24945794]\n",
      " ...\n",
      " [0.04557639]\n",
      " [0.23339371]\n",
      " [0.11500684]]\n",
      "04/16/2025 02:16:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 02:16:43 - INFO - __main__ -   auc_score = 0.9071\n",
      "04/16/2025 02:16:43 - INFO - __main__ -   eval_f1 = 0.5718\n",
      "04/16/2025 02:16:43 - INFO - __main__ -   eval_precision = 0.6163\n",
      "04/16/2025 02:16:43 - INFO - __main__ -   eval_recall = 0.5332\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LEWIiemocIa",
    "outputId": "20e84e55-51b8-4317-858e-61b7e4452e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:45:46.049424: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 12:45:46.066899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744807546.088769    2806 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744807546.095489    2806 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 12:45:46.118028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "config.json: 100% 770/770 [00:00<00:00, 4.86MB/s]\n",
      "tokenizer_config.json: 100% 1.48k/1.48k [00:00<00:00, 11.7MB/s]\n",
      "vocab.json: 100% 703k/703k [00:00<00:00, 2.90MB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 13.3MB/s]\n",
      "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 18.1kB/s]\n",
      "special_tokens_map.json: 100% 12.5k/12.5k [00:00<00:00, 20.6MB/s]\n",
      "pytorch_model.bin: 100% 1.48G/1.48G [00:19<00:00, 77.3MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4442105263157895\n",
      "recall =  0.4442105263157895\n",
      "04/16/2025 12:57:36 - INFO - __main__ - ***** Test results *****\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   R0 = 0.9724\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   R1 = 0.4442\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   auc_score = 0.8986\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   g_mean = 0.6572\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   test_f1 = 0.5121\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   test_precision = 0.6046\n",
      "04/16/2025 12:57:36 - INFO - __main__ -   test_recall = 0.4442\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bk_dRJ6ri-n"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd6prmb_rnOH",
    "outputId": "7a7830aa-220d-4e5e-8c66-0fc5354931e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:59:15.766265: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 12:59:15.784364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744808355.805983    7976 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744808355.812581    7976 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 12:59:15.834283: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "04/16/2025 13:07:35 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 13:24:49 - WARNING - __main__ - epoch 0 step 1024 loss 0.08253\n",
      "[[0.75077736]\n",
      " [0.33284327]\n",
      " [0.12743074]\n",
      " ...\n",
      " [0.26604947]\n",
      " [0.38263717]\n",
      " [0.33225608]]\n",
      "04/16/2025 13:26:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 13:26:59 - INFO - __main__ -   auc_score = 0.903\n",
      "04/16/2025 13:26:59 - INFO - __main__ -   eval_f1 = 0.3811\n",
      "04/16/2025 13:26:59 - INFO - __main__ -   eval_precision = 0.7959\n",
      "04/16/2025 13:26:59 - INFO - __main__ -   eval_recall = 0.2505\n",
      "100% 1024/1024 [17:16<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 13:42:05 - WARNING - __main__ - epoch 1 step 1024 loss 0.06305\n",
      "[[0.8454595 ]\n",
      " [0.5323651 ]\n",
      " [0.17348044]\n",
      " ...\n",
      " [0.20131099]\n",
      " [0.34720796]\n",
      " [0.19803753]]\n",
      "04/16/2025 13:44:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 13:44:15 - INFO - __main__ -   auc_score = 0.9139\n",
      "04/16/2025 13:44:15 - INFO - __main__ -   eval_f1 = 0.5492\n",
      "04/16/2025 13:44:15 - INFO - __main__ -   eval_precision = 0.7795\n",
      "04/16/2025 13:44:15 - INFO - __main__ -   eval_recall = 0.424\n",
      "100% 1024/1024 [17:16<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 13:59:21 - WARNING - __main__ - epoch 2 step 1024 loss 0.05685\n",
      "[[0.8770186 ]\n",
      " [0.61586225]\n",
      " [0.2196522 ]\n",
      " ...\n",
      " [0.32655457]\n",
      " [0.58477724]\n",
      " [0.35922888]]\n",
      "04/16/2025 14:01:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 14:01:31 - INFO - __main__ -   auc_score = 0.9156\n",
      "04/16/2025 14:01:31 - INFO - __main__ -   eval_f1 = 0.5934\n",
      "04/16/2025 14:01:31 - INFO - __main__ -   eval_precision = 0.6623\n",
      "04/16/2025 14:01:31 - INFO - __main__ -   eval_recall = 0.5375\n",
      "100% 1024/1024 [17:14<00:00,  1.01s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 14:16:35 - WARNING - __main__ - epoch 3 step 1024 loss 0.05114\n",
      "[[0.9321387 ]\n",
      " [0.695504  ]\n",
      " [0.22860143]\n",
      " ...\n",
      " [0.24706052]\n",
      " [0.3536466 ]\n",
      " [0.25083375]]\n",
      "04/16/2025 14:18:45 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 14:18:45 - INFO - __main__ -   auc_score = 0.9142\n",
      "04/16/2025 14:18:45 - INFO - __main__ -   eval_f1 = 0.5881\n",
      "04/16/2025 14:18:45 - INFO - __main__ -   eval_precision = 0.6462\n",
      "04/16/2025 14:18:45 - INFO - __main__ -   eval_recall = 0.5396\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 14:33:41 - WARNING - __main__ - epoch 4 step 1024 loss 0.04596\n",
      "[[0.9630674 ]\n",
      " [0.6621325 ]\n",
      " [0.21535584]\n",
      " ...\n",
      " [0.12966754]\n",
      " [0.2961773 ]\n",
      " [0.16398762]]\n",
      "04/16/2025 14:35:51 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 14:35:51 - INFO - __main__ -   auc_score = 0.911\n",
      "04/16/2025 14:35:51 - INFO - __main__ -   eval_f1 = 0.5844\n",
      "04/16/2025 14:35:51 - INFO - __main__ -   eval_precision = 0.7095\n",
      "04/16/2025 14:35:51 - INFO - __main__ -   eval_recall = 0.4968\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 14:50:46 - WARNING - __main__ - epoch 5 step 1024 loss 0.04183\n",
      "[[0.9670951 ]\n",
      " [0.76099813]\n",
      " [0.20408997]\n",
      " ...\n",
      " [0.06075713]\n",
      " [0.13304824]\n",
      " [0.12007485]]\n",
      "04/16/2025 14:52:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 14:52:57 - INFO - __main__ -   auc_score = 0.9043\n",
      "04/16/2025 14:52:57 - INFO - __main__ -   eval_f1 = 0.5468\n",
      "04/16/2025 14:52:57 - INFO - __main__ -   eval_precision = 0.6557\n",
      "04/16/2025 14:52:57 - INFO - __main__ -   eval_recall = 0.469\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 15:07:53 - WARNING - __main__ - epoch 6 step 1024 loss 0.03696\n",
      "[[0.98028606]\n",
      " [0.7685592 ]\n",
      " [0.19788255]\n",
      " ...\n",
      " [0.05501171]\n",
      " [0.20719197]\n",
      " [0.14689319]]\n",
      "04/16/2025 15:10:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 15:10:03 - INFO - __main__ -   auc_score = 0.9053\n",
      "04/16/2025 15:10:03 - INFO - __main__ -   eval_f1 = 0.5487\n",
      "04/16/2025 15:10:03 - INFO - __main__ -   eval_precision = 0.616\n",
      "04/16/2025 15:10:03 - INFO - __main__ -   eval_recall = 0.4946\n",
      "100% 1024/1024 [17:06<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 15:24:59 - WARNING - __main__ - epoch 7 step 1024 loss 0.03409\n",
      "[[0.97764313]\n",
      " [0.79374045]\n",
      " [0.1743929 ]\n",
      " ...\n",
      " [0.0215766 ]\n",
      " [0.09744998]\n",
      " [0.0908104 ]]\n",
      "04/16/2025 15:27:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 15:27:09 - INFO - __main__ -   auc_score = 0.8991\n",
      "04/16/2025 15:27:09 - INFO - __main__ -   eval_f1 = 0.5416\n",
      "04/16/2025 15:27:09 - INFO - __main__ -   eval_precision = 0.7069\n",
      "04/16/2025 15:27:09 - INFO - __main__ -   eval_recall = 0.439\n",
      "100% 1024/1024 [17:06<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:55<00:00,  1.14it/s]04/16/2025 15:42:05 - WARNING - __main__ - epoch 8 step 1024 loss 0.03116\n",
      "[[0.9834691 ]\n",
      " [0.84713405]\n",
      " [0.1991009 ]\n",
      " ...\n",
      " [0.0334037 ]\n",
      " [0.09262644]\n",
      " [0.12945676]]\n",
      "04/16/2025 15:44:15 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 15:44:15 - INFO - __main__ -   auc_score = 0.8974\n",
      "04/16/2025 15:44:15 - INFO - __main__ -   eval_f1 = 0.5314\n",
      "04/16/2025 15:44:15 - INFO - __main__ -   eval_precision = 0.6243\n",
      "04/16/2025 15:44:15 - INFO - __main__ -   eval_recall = 0.4625\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n",
      "100% 1023/1024 [14:54<00:00,  1.14it/s]04/16/2025 15:59:11 - WARNING - __main__ - epoch 9 step 1024 loss 0.02917\n",
      "[[0.986466  ]\n",
      " [0.85608995]\n",
      " [0.20412257]\n",
      " ...\n",
      " [0.03542767]\n",
      " [0.10796069]\n",
      " [0.1672295 ]]\n",
      "04/16/2025 16:01:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 16:01:21 - INFO - __main__ -   auc_score = 0.8989\n",
      "04/16/2025 16:01:21 - INFO - __main__ -   eval_f1 = 0.538\n",
      "04/16/2025 16:01:21 - INFO - __main__ -   eval_precision = 0.5928\n",
      "04/16/2025 16:01:21 - INFO - __main__ -   eval_recall = 0.4925\n",
      "100% 1024/1024 [17:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHc0JRhrVoDD",
    "outputId": "ee910ab2-7572-4224-b7d2-8493da3e0eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 16:02:49.099026: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 16:02:49.117374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744819369.139229   76734 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744819369.145890   76734 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 16:02:49.168303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4442105263157895\n",
      "recall =  0.4442105263157895\n",
      "04/16/2025 16:14:05 - INFO - __main__ - ***** Test results *****\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   R0 = 0.9658\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   R1 = 0.4442\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   auc_score = 0.8952\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   g_mean = 0.655\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   test_f1 = 0.4924\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   test_precision = 0.5524\n",
      "04/16/2025 16:14:05 - INFO - __main__ -   test_recall = 0.4442\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/focal/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YFCBiFMagBv"
   },
   "source": [
    "### Skewed oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZxdymCgasU_",
    "outputId": "0ac684ef-25a9-40fa-dc12-d475cc359b2b"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/skewed_over/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --skewed_oversample \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVLGWTQ7M_rU",
    "outputId": "386c8b33-d1c7-46a2-aa34-94f7f3c807b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 20:05:22.223629: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 20:05:22.242325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744833922.264825  166016 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744833922.271611  166016 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 20:05:22.294234: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.6968421052631579\n",
      "recall =  0.6968421052631579\n",
      "04/16/2025 20:16:44 - INFO - __main__ - ***** Test results *****\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   R0 = 0.8627\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   R1 = 0.6968\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   auc_score = 0.8727\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   g_mean = 0.7754\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   test_f1 = 0.4434\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   test_precision = 0.3251\n",
      "04/16/2025 20:16:44 - INFO - __main__ -   test_recall = 0.6968\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/concat/skewed_over/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46HcX9M8xdFx"
   },
   "source": [
    "### LR = 2e-5 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L0qsNhjxpT0"
   },
   "source": [
    "python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file $HOME/Datasets/jitfine/changes_train.pkl $HOME/Datasets/jitfine/features_train.pkl \\\n",
    "   --eval_data_file $HOME/Datasets/jitfine/changes_valid.pkl $HOME/Datasets/jitfine/features_valid.pkl \\\n",
    "   --test_data_file $HOME/Datasets/jitfine/changes_test.pkl $HOME/Datasets/jitfine/features_test.pkl \\\n",
    "   --output_dir results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 2e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pHBSr4wxtIv"
   },
   "source": [
    "05/03/2024 10:48:00 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "05/03/2024 10:48:00 - INFO - __main__ -   auc_score = 0.8975\n",
    "\n",
    "05/03/2024 10:48:00 - INFO - __main__ -   test_f1 = 0.4713\n",
    "\n",
    "05/03/2024 10:48:00 - INFO - __main__ -   test_precision = 0.578\n",
    "\n",
    "05/03/2024 10:48:00 - INFO - __main__ -   test_recall = 0.3979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeGXes6BBUAI"
   },
   "source": [
    "### LR = 5e-4 (run on Apuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0xuacSYBxoj"
   },
   "source": [
    "python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file $HOME/Datasets/jitfine/changes_train.pkl $HOME/Datasets/jitfine/features_train.pkl \\\n",
    "   --eval_data_file $HOME/Datasets/jitfine/changes_valid.pkl $HOME/Datasets/jitfine/features_valid.pkl \\\n",
    "   --test_data_file $HOME/Datasets/jitfine/changes_test.pkl $HOME/Datasets/jitfine/features_test.pkl \\\n",
    "   --output_dir results/jitfine_lora/codet5p-770m/single/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 5e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OseyuX_mB3XB"
   },
   "source": [
    "05/03/2024 14:12:49 - INFO - __main__ - ***** Test results *****\n",
    "\n",
    "05/03/2024 14:12:49 - INFO - __main__ -   auc_score = 0.8925\n",
    "\n",
    "05/03/2024 14:12:49 - INFO - __main__ -   test_f1 = 0.4824\n",
    "\n",
    "05/03/2024 14:12:49 - INFO - __main__ -   test_precision = 0.6336\n",
    "\n",
    "05/03/2024 14:12:49 - INFO - __main__ -   test_recall = 0.3895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx7um0A00IUY"
   },
   "source": [
    "### Only expert features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0sjYEwW4mqc",
    "outputId": "4cb3695f-4f3b-45e9-b0bb-cb41f50e63a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 16% 80/512 [00:00<00:03, 129.95it/s]05/09/2024 01:17:47 - WARNING - __main__ - epoch 0 step 102 loss 0.61669\n",
      "[[0.47042724]\n",
      " [0.4302513 ]\n",
      " [0.4140521 ]\n",
      " ...\n",
      " [0.45916045]\n",
      " [0.44314665]\n",
      " [0.49171445]]\n",
      "05/09/2024 01:17:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   auc_score = 0.5969\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_f1 = 0.1321\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_precision = 0.1724\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_recall = 0.1071\n",
      " 37% 187/512 [00:01<00:01, 172.33it/s]05/09/2024 01:17:48 - WARNING - __main__ - epoch 0 step 204 loss 0.60787\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.48137322]\n",
      " [0.43241215]\n",
      " [0.4089438 ]\n",
      " ...\n",
      " [0.44798586]\n",
      " [0.4418506 ]\n",
      " [0.48657447]]\n",
      "05/09/2024 01:17:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   auc_score = 0.6357\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_f1 = 0.1397\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_precision = 0.2182\n",
      "05/09/2024 01:17:48 - INFO - __main__ -   eval_recall = 0.1028\n",
      " 57% 294/512 [00:02<00:01, 182.23it/s]05/09/2024 01:17:49 - WARNING - __main__ - epoch 0 step 306 loss 0.60044\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.49165905]\n",
      " [0.43559366]\n",
      " [0.4051562 ]\n",
      " ...\n",
      " [0.43715146]\n",
      " [0.43955106]\n",
      " [0.48091722]]\n",
      "05/09/2024 01:17:49 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:49 - INFO - __main__ -   auc_score = 0.6661\n",
      "05/09/2024 01:17:49 - INFO - __main__ -   eval_f1 = 0.1576\n",
      "05/09/2024 01:17:49 - INFO - __main__ -   eval_precision = 0.2694\n",
      "05/09/2024 01:17:49 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 79% 406/512 [00:03<00:00, 196.28it/s]05/09/2024 01:17:49 - WARNING - __main__ - epoch 0 step 408 loss 0.58998\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5017442 ]\n",
      " [0.43799525]\n",
      " [0.40102217]\n",
      " ...\n",
      " [0.42695653]\n",
      " [0.43783948]\n",
      " [0.47590068]]\n",
      "05/09/2024 01:17:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   auc_score = 0.6883\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_f1 = 0.1787\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_precision = 0.3187\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_recall = 0.1242\n",
      " 93% 476/512 [00:03<00:00, 158.85it/s]05/09/2024 01:17:50 - WARNING - __main__ - epoch 0 step 510 loss 0.58275\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.510236  ]\n",
      " [0.44011903]\n",
      " [0.3972942 ]\n",
      " ...\n",
      " [0.41720676]\n",
      " [0.43537545]\n",
      " [0.4708253 ]]\n",
      "05/09/2024 01:17:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   auc_score = 0.7027\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_f1 = 0.1908\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_precision = 0.3704\n",
      "05/09/2024 01:17:50 - INFO - __main__ -   eval_recall = 0.1285\n",
      "100% 512/512 [00:04<00:00, 122.72it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 16% 84/512 [00:00<00:01, 317.16it/s]05/09/2024 01:17:51 - WARNING - __main__ - epoch 1 step 102 loss 0.58159\n",
      "[[0.5173391 ]\n",
      " [0.44208947]\n",
      " [0.39379236]\n",
      " ...\n",
      " [0.40809777]\n",
      " [0.43262985]\n",
      " [0.46561137]]\n",
      "05/09/2024 01:17:51 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:51 - INFO - __main__ -   auc_score = 0.7124\n",
      "05/09/2024 01:17:51 - INFO - __main__ -   eval_f1 = 0.2067\n",
      "05/09/2024 01:17:51 - INFO - __main__ -   eval_precision = 0.4012\n",
      "05/09/2024 01:17:51 - INFO - __main__ -   eval_recall = 0.1392\n",
      " 38% 195/512 [00:01<00:01, 216.22it/s]05/09/2024 01:17:52 - WARNING - __main__ - epoch 1 step 204 loss 0.57061\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5260686 ]\n",
      " [0.44397202]\n",
      " [0.39004412]\n",
      " ...\n",
      " [0.3995517 ]\n",
      " [0.4314436 ]\n",
      " [0.46155667]]\n",
      "05/09/2024 01:17:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:52 - INFO - __main__ -   auc_score = 0.7203\n",
      "05/09/2024 01:17:52 - INFO - __main__ -   eval_f1 = 0.2261\n",
      "05/09/2024 01:17:52 - INFO - __main__ -   eval_precision = 0.4235\n",
      "05/09/2024 01:17:52 - INFO - __main__ -   eval_recall = 0.1542\n",
      " 52% 268/512 [00:01<00:01, 167.34it/s]05/09/2024 01:17:52 - WARNING - __main__ - epoch 1 step 306 loss 0.56213\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5344295 ]\n",
      " [0.44615987]\n",
      " [0.3865696 ]\n",
      " ...\n",
      " [0.39106622]\n",
      " [0.42996797]\n",
      " [0.45722887]]\n",
      "05/09/2024 01:17:53 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   auc_score = 0.7259\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_f1 = 0.2477\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_precision = 0.4469\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_recall = 0.1713\n",
      " 75% 384/512 [00:02<00:00, 190.25it/s]05/09/2024 01:17:53 - WARNING - __main__ - epoch 1 step 408 loss 0.55789\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5420851 ]\n",
      " [0.4477837 ]\n",
      " [0.38256517]\n",
      " ...\n",
      " [0.38318354]\n",
      " [0.4289227 ]\n",
      " [0.45344803]]\n",
      "05/09/2024 01:17:53 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   auc_score = 0.7304\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_f1 = 0.258\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_precision = 0.4427\n",
      "05/09/2024 01:17:53 - INFO - __main__ -   eval_recall = 0.182\n",
      " 96% 490/512 [00:03<00:00, 191.62it/s]05/09/2024 01:17:54 - WARNING - __main__ - epoch 1 step 510 loss 0.54689\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.55030763]\n",
      " [0.44965023]\n",
      " [0.37937254]\n",
      " ...\n",
      " [0.37465084]\n",
      " [0.426963  ]\n",
      " [0.44882014]]\n",
      "05/09/2024 01:17:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:54 - INFO - __main__ -   auc_score = 0.7326\n",
      "05/09/2024 01:17:54 - INFO - __main__ -   eval_f1 = 0.2768\n",
      "05/09/2024 01:17:54 - INFO - __main__ -   eval_precision = 0.4537\n",
      "05/09/2024 01:17:54 - INFO - __main__ -   eval_recall = 0.1991\n",
      "100% 512/512 [00:03<00:00, 144.86it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 15% 78/512 [00:00<00:01, 295.18it/s]05/09/2024 01:17:54 - WARNING - __main__ - epoch 2 step 102 loss 0.55113\n",
      "[[0.5569351 ]\n",
      " [0.45182094]\n",
      " [0.3768959 ]\n",
      " ...\n",
      " [0.36693504]\n",
      " [0.42440918]\n",
      " [0.44419506]]\n",
      "05/09/2024 01:17:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:55 - INFO - __main__ -   auc_score = 0.7338\n",
      "05/09/2024 01:17:55 - INFO - __main__ -   eval_f1 = 0.2891\n",
      "05/09/2024 01:17:55 - INFO - __main__ -   eval_precision = 0.4755\n",
      "05/09/2024 01:17:55 - INFO - __main__ -   eval_recall = 0.2077\n",
      " 37% 187/512 [00:01<00:01, 207.31it/s]05/09/2024 01:17:55 - WARNING - __main__ - epoch 2 step 204 loss 0.54448\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5626255 ]\n",
      " [0.45284805]\n",
      " [0.3733391 ]\n",
      " ...\n",
      " [0.36074787]\n",
      " [0.42366874]\n",
      " [0.44128323]]\n",
      "05/09/2024 01:17:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   auc_score = 0.7356\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_f1 = 0.2937\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_precision = 0.4673\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 58% 295/512 [00:01<00:01, 192.58it/s]05/09/2024 01:17:56 - WARNING - __main__ - epoch 2 step 306 loss 0.53346\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5694893 ]\n",
      " [0.454489  ]\n",
      " [0.37040552]\n",
      " ...\n",
      " [0.35396218]\n",
      " [0.42241713]\n",
      " [0.43777922]]\n",
      "05/09/2024 01:17:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   auc_score = 0.7368\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_f1 = 0.2944\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_precision = 0.4513\n",
      "05/09/2024 01:17:56 - INFO - __main__ -   eval_recall = 0.2184\n",
      " 79% 402/512 [00:02<00:00, 188.17it/s]05/09/2024 01:17:57 - WARNING - __main__ - epoch 2 step 408 loss 0.53055\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.57506454]\n",
      " [0.45557782]\n",
      " [0.36696583]\n",
      " ...\n",
      " [0.34799907]\n",
      " [0.42160487]\n",
      " [0.4348336 ]]\n",
      "05/09/2024 01:17:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:57 - INFO - __main__ -   auc_score = 0.7379\n",
      "05/09/2024 01:17:57 - INFO - __main__ -   eval_f1 = 0.2991\n",
      "05/09/2024 01:17:57 - INFO - __main__ -   eval_precision = 0.4468\n",
      "05/09/2024 01:17:57 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 92% 473/512 [00:03<00:00, 147.90it/s]05/09/2024 01:17:57 - WARNING - __main__ - epoch 2 step 510 loss 0.52541\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5814456 ]\n",
      " [0.45705548]\n",
      " [0.36405554]\n",
      " ...\n",
      " [0.34200978]\n",
      " [0.42095733]\n",
      " [0.4318935 ]]\n",
      "05/09/2024 01:17:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:58 - INFO - __main__ -   auc_score = 0.7389\n",
      "05/09/2024 01:17:58 - INFO - __main__ -   eval_f1 = 0.3077\n",
      "05/09/2024 01:17:58 - INFO - __main__ -   eval_precision = 0.4435\n",
      "05/09/2024 01:17:58 - INFO - __main__ -   eval_recall = 0.2355\n",
      "100% 512/512 [00:03<00:00, 136.02it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 15% 78/512 [00:00<00:01, 289.43it/s]05/09/2024 01:17:58 - WARNING - __main__ - epoch 3 step 102 loss 0.52159\n",
      "[[0.5872081 ]\n",
      " [0.45796216]\n",
      " [0.36097983]\n",
      " ...\n",
      " [0.33628157]\n",
      " [0.42025802]\n",
      " [0.42902085]]\n",
      "05/09/2024 01:17:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   auc_score = 0.7394\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_f1 = 0.31\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_precision = 0.4313\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_recall = 0.242\n",
      " 36% 186/512 [00:01<00:01, 209.46it/s]05/09/2024 01:17:59 - WARNING - __main__ - epoch 3 step 204 loss 0.51659\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.591968  ]\n",
      " [0.45913583]\n",
      " [0.3585483 ]\n",
      " ...\n",
      " [0.33101085]\n",
      " [0.4189358 ]\n",
      " [0.42603973]]\n",
      "05/09/2024 01:17:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   auc_score = 0.7396\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_f1 = 0.3156\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_precision = 0.4328\n",
      "05/09/2024 01:17:59 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 57% 293/512 [00:01<00:01, 188.21it/s]05/09/2024 01:18:00 - WARNING - __main__ - epoch 3 step 306 loss 0.51596\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.5966089 ]\n",
      " [0.4605434 ]\n",
      " [0.35624275]\n",
      " ...\n",
      " [0.3258664 ]\n",
      " [0.41771102]\n",
      " [0.42313203]]\n",
      "05/09/2024 01:18:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:00 - INFO - __main__ -   auc_score = 0.7398\n",
      "05/09/2024 01:18:00 - INFO - __main__ -   eval_f1 = 0.3189\n",
      "05/09/2024 01:18:00 - INFO - __main__ -   eval_precision = 0.4322\n",
      "05/09/2024 01:18:00 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 79% 402/512 [00:02<00:00, 189.10it/s]05/09/2024 01:18:00 - WARNING - __main__ - epoch 3 step 408 loss 0.51449\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.600721  ]\n",
      " [0.46182027]\n",
      " [0.35402378]\n",
      " ...\n",
      " [0.3211682 ]\n",
      " [0.41651163]\n",
      " [0.4204525 ]]\n",
      "05/09/2024 01:18:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   auc_score = 0.74\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_f1 = 0.3244\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_precision = 0.4337\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 93% 474/512 [00:03<00:00, 156.42it/s]05/09/2024 01:18:01 - WARNING - __main__ - epoch 3 step 510 loss 0.51081\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.60496175]\n",
      " [0.46241888]\n",
      " [0.35131764]\n",
      " ...\n",
      " [0.31695378]\n",
      " [0.416153  ]\n",
      " [0.41844413]]\n",
      "05/09/2024 01:18:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   auc_score = 0.7404\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_f1 = 0.325\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_precision = 0.4241\n",
      "05/09/2024 01:18:01 - INFO - __main__ -   eval_recall = 0.2634\n",
      "100% 512/512 [00:03<00:00, 139.09it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 15% 79/512 [00:00<00:01, 297.85it/s]05/09/2024 01:18:02 - WARNING - __main__ - epoch 4 step 102 loss 0.50606\n",
      "[[0.6092807 ]\n",
      " [0.46324515]\n",
      " [0.3486752 ]\n",
      " ...\n",
      " [0.3129119 ]\n",
      " [0.4160164 ]\n",
      " [0.4166001 ]]\n",
      "05/09/2024 01:18:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:02 - INFO - __main__ -   auc_score = 0.7409\n",
      "05/09/2024 01:18:02 - INFO - __main__ -   eval_f1 = 0.3264\n",
      "05/09/2024 01:18:02 - INFO - __main__ -   eval_precision = 0.4131\n",
      "05/09/2024 01:18:02 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 37% 188/512 [00:01<00:01, 209.26it/s]05/09/2024 01:18:03 - WARNING - __main__ - epoch 4 step 204 loss 0.50113\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.61281604]\n",
      " [0.46412346]\n",
      " [0.34665814]\n",
      " ...\n",
      " [0.30888936]\n",
      " [0.41498542]\n",
      " [0.41428858]]\n",
      "05/09/2024 01:18:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:03 - INFO - __main__ -   auc_score = 0.7409\n",
      "05/09/2024 01:18:03 - INFO - __main__ -   eval_f1 = 0.3282\n",
      "05/09/2024 01:18:03 - INFO - __main__ -   eval_precision = 0.4137\n",
      "05/09/2024 01:18:03 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 58% 299/512 [00:01<00:01, 200.72it/s]05/09/2024 01:18:03 - WARNING - __main__ - epoch 4 step 306 loss 0.50183\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6159759 ]\n",
      " [0.46485353]\n",
      " [0.3444794 ]\n",
      " ...\n",
      " [0.30526   ]\n",
      " [0.41432387]\n",
      " [0.41233584]]\n",
      "05/09/2024 01:18:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   auc_score = 0.7411\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_f1 = 0.3286\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_precision = 0.4103\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 72% 370/512 [00:02<00:00, 160.22it/s]05/09/2024 01:18:04 - WARNING - __main__ - epoch 4 step 408 loss 0.49513\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.61948854]\n",
      " [0.46579996]\n",
      " [0.34272107]\n",
      " ...\n",
      " [0.3015519 ]\n",
      " [0.4134235 ]\n",
      " [0.41013438]]\n",
      "05/09/2024 01:18:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   auc_score = 0.7411\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_f1 = 0.3308\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_precision = 0.4121\n",
      "05/09/2024 01:18:04 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 95% 484/512 [00:03<00:00, 181.77it/s]05/09/2024 01:18:05 - WARNING - __main__ - epoch 4 step 510 loss 0.49637\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6229051 ]\n",
      " [0.46628723]\n",
      " [0.3405928 ]\n",
      " ...\n",
      " [0.29806498]\n",
      " [0.41297644]\n",
      " [0.40834847]]\n",
      "05/09/2024 01:18:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:05 - INFO - __main__ -   auc_score = 0.7411\n",
      "05/09/2024 01:18:05 - INFO - __main__ -   eval_f1 = 0.3312\n",
      "05/09/2024 01:18:05 - INFO - __main__ -   eval_precision = 0.4135\n",
      "05/09/2024 01:18:05 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 512/512 [00:03<00:00, 142.71it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 16% 82/512 [00:00<00:01, 310.78it/s]05/09/2024 01:18:05 - WARNING - __main__ - epoch 5 step 102 loss 0.49274\n",
      "[[0.626326  ]\n",
      " [0.46749845]\n",
      " [0.3390504 ]\n",
      " ...\n",
      " [0.29442966]\n",
      " [0.41195893]\n",
      " [0.4060698 ]]\n",
      "05/09/2024 01:18:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:06 - INFO - __main__ -   auc_score = 0.741\n",
      "05/09/2024 01:18:06 - INFO - __main__ -   eval_f1 = 0.324\n",
      "05/09/2024 01:18:06 - INFO - __main__ -   eval_precision = 0.4006\n",
      "05/09/2024 01:18:06 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 37% 189/512 [00:00<00:01, 211.68it/s]05/09/2024 01:18:06 - WARNING - __main__ - epoch 5 step 204 loss 0.48701\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.62949485]\n",
      " [0.46795484]\n",
      " [0.33705422]\n",
      " ...\n",
      " [0.29144537]\n",
      " [0.41181916]\n",
      " [0.40468818]]\n",
      "05/09/2024 01:18:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   auc_score = 0.7412\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_f1 = 0.3232\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_precision = 0.3938\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 59% 303/512 [00:01<00:01, 205.51it/s]05/09/2024 01:18:07 - WARNING - __main__ - epoch 5 step 306 loss 0.4902\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6318718 ]\n",
      " [0.46841666]\n",
      " [0.3352442 ]\n",
      " ...\n",
      " [0.28884476]\n",
      " [0.41150314]\n",
      " [0.40334865]]\n",
      "05/09/2024 01:18:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   auc_score = 0.7415\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_f1 = 0.322\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_precision = 0.3902\n",
      "05/09/2024 01:18:07 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 73% 374/512 [00:02<00:00, 160.59it/s]05/09/2024 01:18:07 - WARNING - __main__ - epoch 5 step 408 loss 0.48911\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.634013  ]\n",
      " [0.46853146]\n",
      " [0.33337227]\n",
      " ...\n",
      " [0.2864822 ]\n",
      " [0.41137138]\n",
      " [0.40221766]]\n",
      "05/09/2024 01:18:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:08 - INFO - __main__ -   auc_score = 0.7418\n",
      "05/09/2024 01:18:08 - INFO - __main__ -   eval_f1 = 0.3216\n",
      "05/09/2024 01:18:08 - INFO - __main__ -   eval_precision = 0.3891\n",
      "05/09/2024 01:18:08 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 94% 482/512 [00:03<00:00, 179.74it/s]05/09/2024 01:18:08 - WARNING - __main__ - epoch 5 step 510 loss 0.47882\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.636369  ]\n",
      " [0.46895662]\n",
      " [0.331795  ]\n",
      " ...\n",
      " [0.28384   ]\n",
      " [0.41083202]\n",
      " [0.400687  ]]\n",
      "05/09/2024 01:18:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   auc_score = 0.7418\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_f1 = 0.3213\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_precision = 0.3839\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 512/512 [00:03<00:00, 142.67it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 15% 79/512 [00:00<00:01, 294.69it/s]05/09/2024 01:18:09 - WARNING - __main__ - epoch 6 step 102 loss 0.48162\n",
      "[[0.63860524]\n",
      " [0.46931192]\n",
      " [0.33025578]\n",
      " ...\n",
      " [0.2815493 ]\n",
      " [0.41058585]\n",
      " [0.3995209 ]]\n",
      "05/09/2024 01:18:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   auc_score = 0.742\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_f1 = 0.3209\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_precision = 0.3828\n",
      "05/09/2024 01:18:09 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 36% 183/512 [00:01<00:01, 196.34it/s]05/09/2024 01:18:10 - WARNING - __main__ - epoch 6 step 204 loss 0.48063\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6404257 ]\n",
      " [0.46959424]\n",
      " [0.32881063]\n",
      " ...\n",
      " [0.27946687]\n",
      " [0.41026163]\n",
      " [0.39838332]]\n",
      "05/09/2024 01:18:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:10 - INFO - __main__ -   auc_score = 0.7421\n",
      "05/09/2024 01:18:10 - INFO - __main__ -   eval_f1 = 0.3217\n",
      "05/09/2024 01:18:10 - INFO - __main__ -   eval_precision = 0.3851\n",
      "05/09/2024 01:18:10 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 55% 283/512 [00:01<00:01, 176.02it/s]05/09/2024 01:18:11 - WARNING - __main__ - epoch 6 step 306 loss 0.48329\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.64233845]\n",
      " [0.46988863]\n",
      " [0.327523  ]\n",
      " ...\n",
      " [0.2773169 ]\n",
      " [0.40978265]\n",
      " [0.39711493]]\n",
      "05/09/2024 01:18:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:11 - INFO - __main__ -   auc_score = 0.7421\n",
      "05/09/2024 01:18:11 - INFO - __main__ -   eval_f1 = 0.3213\n",
      "05/09/2024 01:18:11 - INFO - __main__ -   eval_precision = 0.3839\n",
      "05/09/2024 01:18:11 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 76% 387/512 [00:02<00:00, 175.80it/s]05/09/2024 01:18:11 - WARNING - __main__ - epoch 6 step 408 loss 0.47304\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6441938 ]\n",
      " [0.47027144]\n",
      " [0.32626882]\n",
      " ...\n",
      " [0.27546027]\n",
      " [0.40961337]\n",
      " [0.39615932]]\n",
      "05/09/2024 01:18:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   auc_score = 0.7422\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_f1 = 0.3201\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_precision = 0.3805\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 97% 496/512 [00:03<00:00, 190.33it/s]05/09/2024 01:18:12 - WARNING - __main__ - epoch 6 step 510 loss 0.47491\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.64596814]\n",
      " [0.47066703]\n",
      " [0.32513025]\n",
      " ...\n",
      " [0.27353212]\n",
      " [0.40920207]\n",
      " [0.39505294]]\n",
      "05/09/2024 01:18:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   auc_score = 0.7423\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_f1 = 0.3193\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_precision = 0.3783\n",
      "05/09/2024 01:18:12 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 512/512 [00:03<00:00, 136.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 15% 79/512 [00:00<00:01, 303.05it/s]05/09/2024 01:18:13 - WARNING - __main__ - epoch 7 step 102 loss 0.47514\n",
      "[[0.6475868 ]\n",
      " [0.47083664]\n",
      " [0.3239086 ]\n",
      " ...\n",
      " [0.27186003]\n",
      " [0.40906212]\n",
      " [0.3941843 ]]\n",
      "05/09/2024 01:18:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:13 - INFO - __main__ -   auc_score = 0.7424\n",
      "05/09/2024 01:18:13 - INFO - __main__ -   eval_f1 = 0.3206\n",
      "05/09/2024 01:18:13 - INFO - __main__ -   eval_precision = 0.3779\n",
      "05/09/2024 01:18:13 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 36% 186/512 [00:01<00:01, 208.67it/s]05/09/2024 01:18:13 - WARNING - __main__ - epoch 7 step 204 loss 0.47756\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.64859384]\n",
      " [0.47116476]\n",
      " [0.32315233]\n",
      " ...\n",
      " [0.27037555]\n",
      " [0.40848863]\n",
      " [0.39314446]]\n",
      "05/09/2024 01:18:14 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:14 - INFO - __main__ -   auc_score = 0.7424\n",
      "05/09/2024 01:18:14 - INFO - __main__ -   eval_f1 = 0.3231\n",
      "05/09/2024 01:18:14 - INFO - __main__ -   eval_precision = 0.3808\n",
      "05/09/2024 01:18:14 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 57% 293/512 [00:01<00:01, 197.70it/s]05/09/2024 01:18:14 - WARNING - __main__ - epoch 7 step 306 loss 0.47126\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65006137]\n",
      " [0.47132137]\n",
      " [0.32203832]\n",
      " ...\n",
      " [0.26904914]\n",
      " [0.40860507]\n",
      " [0.3925882 ]]\n",
      "05/09/2024 01:18:15 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   auc_score = 0.7425\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_f1 = 0.3227\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_precision = 0.3797\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 79% 404/512 [00:02<00:00, 200.95it/s]05/09/2024 01:18:15 - WARNING - __main__ - epoch 7 step 408 loss 0.47128\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65137064]\n",
      " [0.47159004]\n",
      " [0.32119474]\n",
      " ...\n",
      " [0.26777792]\n",
      " [0.40846443]\n",
      " [0.39190874]]\n",
      "05/09/2024 01:18:15 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   auc_score = 0.7426\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_f1 = 0.3223\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_precision = 0.3786\n",
      "05/09/2024 01:18:15 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 93% 476/512 [00:02<00:00, 165.08it/s]05/09/2024 01:18:15 - WARNING - __main__ - epoch 7 step 510 loss 0.46668\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6525784 ]\n",
      " [0.47183737]\n",
      " [0.32044563]\n",
      " ...\n",
      " [0.2664935 ]\n",
      " [0.40817717]\n",
      " [0.3911581 ]]\n",
      "05/09/2024 01:18:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:16 - INFO - __main__ -   auc_score = 0.7426\n",
      "05/09/2024 01:18:16 - INFO - __main__ -   eval_f1 = 0.3227\n",
      "05/09/2024 01:18:16 - INFO - __main__ -   eval_precision = 0.3797\n",
      "05/09/2024 01:18:16 - INFO - __main__ -   eval_recall = 0.2805\n",
      "100% 512/512 [00:03<00:00, 145.54it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 17% 85/512 [00:00<00:01, 315.20it/s]05/09/2024 01:18:16 - WARNING - __main__ - epoch 8 step 102 loss 0.47334\n",
      "[[0.65348285]\n",
      " [0.4718962 ]\n",
      " [0.3196625 ]\n",
      " ...\n",
      " [0.2655578 ]\n",
      " [0.4081885 ]\n",
      " [0.39074078]]\n",
      "05/09/2024 01:18:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   auc_score = 0.7427\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_f1 = 0.3223\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_precision = 0.3786\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 39% 201/512 [00:01<00:01, 226.31it/s]05/09/2024 01:18:17 - WARNING - __main__ - epoch 8 step 204 loss 0.4638\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6545412 ]\n",
      " [0.4720137 ]\n",
      " [0.31891924]\n",
      " ...\n",
      " [0.2645788 ]\n",
      " [0.40819272]\n",
      " [0.3902658 ]]\n",
      "05/09/2024 01:18:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   auc_score = 0.7427\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_f1 = 0.3223\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_precision = 0.3786\n",
      "05/09/2024 01:18:17 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 54% 274/512 [00:01<00:01, 170.35it/s]05/09/2024 01:18:18 - WARNING - __main__ - epoch 8 step 306 loss 0.46928\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6551785 ]\n",
      " [0.47209334]\n",
      " [0.3183264 ]\n",
      " ...\n",
      " [0.26377133]\n",
      " [0.4080239 ]\n",
      " [0.3897773 ]]\n",
      "05/09/2024 01:18:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:18 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:18 - INFO - __main__ -   eval_f1 = 0.3243\n",
      "05/09/2024 01:18:18 - INFO - __main__ -   eval_precision = 0.3804\n",
      "05/09/2024 01:18:18 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 75% 383/512 [00:02<00:00, 188.31it/s]05/09/2024 01:18:18 - WARNING - __main__ - epoch 8 step 408 loss 0.46274\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65582937]\n",
      " [0.47231165]\n",
      " [0.3179484 ]\n",
      " ...\n",
      " [0.26300138]\n",
      " [0.40775895]\n",
      " [0.38927412]]\n",
      "05/09/2024 01:18:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_f1 = 0.3268\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_precision = 0.3833\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 97% 495/512 [00:02<00:00, 195.88it/s]05/09/2024 01:18:19 - WARNING - __main__ - epoch 8 step 510 loss 0.47042\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65636104]\n",
      " [0.47240844]\n",
      " [0.31754237]\n",
      " ...\n",
      " [0.26239115]\n",
      " [0.40762737]\n",
      " [0.3889015 ]]\n",
      "05/09/2024 01:18:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_f1 = 0.3272\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_precision = 0.3844\n",
      "05/09/2024 01:18:19 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [00:03<00:00, 146.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      " 16% 80/512 [00:00<00:01, 301.46it/s]05/09/2024 01:18:20 - WARNING - __main__ - epoch 9 step 102 loss 0.47035\n",
      "[[0.65680975]\n",
      " [0.47246656]\n",
      " [0.3172028 ]\n",
      " ...\n",
      " [0.261861  ]\n",
      " [0.40750054]\n",
      " [0.38856846]]\n",
      "05/09/2024 01:18:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:20 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:20 - INFO - __main__ -   eval_f1 = 0.3272\n",
      "05/09/2024 01:18:20 - INFO - __main__ -   eval_precision = 0.3844\n",
      "05/09/2024 01:18:20 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 37% 189/512 [00:01<00:01, 209.48it/s]05/09/2024 01:18:20 - WARNING - __main__ - epoch 9 step 204 loss 0.46229\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.65715873]\n",
      " [0.47253966]\n",
      " [0.31694987]\n",
      " ...\n",
      " [0.26145077]\n",
      " [0.4073899 ]\n",
      " [0.38832402]]\n",
      "05/09/2024 01:18:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:21 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:21 - INFO - __main__ -   eval_f1 = 0.3268\n",
      "05/09/2024 01:18:21 - INFO - __main__ -   eval_precision = 0.3833\n",
      "05/09/2024 01:18:21 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 58% 298/512 [00:01<00:01, 198.62it/s]05/09/2024 01:18:21 - WARNING - __main__ - epoch 9 step 306 loss 0.46234\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6574476 ]\n",
      " [0.47256196]\n",
      " [0.316724  ]\n",
      " ...\n",
      " [0.261177  ]\n",
      " [0.4073934 ]\n",
      " [0.3881941 ]]\n",
      "05/09/2024 01:18:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_f1 = 0.326\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_precision = 0.3811\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 79% 405/512 [00:02<00:00, 192.83it/s]05/09/2024 01:18:22 - WARNING - __main__ - epoch 9 step 408 loss 0.46099\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6576117 ]\n",
      " [0.47259167]\n",
      " [0.31660327]\n",
      " ...\n",
      " [0.2610093 ]\n",
      " [0.4073752 ]\n",
      " [0.38809913]]\n",
      "05/09/2024 01:18:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   auc_score = 0.7428\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_f1 = 0.326\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_precision = 0.3811\n",
      "05/09/2024 01:18:22 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 92% 473/512 [00:03<00:00, 152.52it/s]05/09/2024 01:18:23 - WARNING - __main__ - epoch 9 step 510 loss 0.47451\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[[0.6576568 ]\n",
      " [0.47259763]\n",
      " [0.31656122]\n",
      " ...\n",
      " [0.26096088]\n",
      " [0.4073749 ]\n",
      " [0.38807502]]\n",
      "05/09/2024 01:18:23 - INFO - __main__ - ***** Eval results *****\n",
      "05/09/2024 01:18:23 - INFO - __main__ -   auc_score = 0.7429\n",
      "05/09/2024 01:18:23 - INFO - __main__ -   eval_f1 = 0.326\n",
      "05/09/2024 01:18:23 - INFO - __main__ -   eval_precision = 0.3811\n",
      "05/09/2024 01:18:23 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [00:03<00:00, 140.73it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_manual.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/manual/checkpoints \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcqXJDRJ7pa7",
    "outputId": "fd9cbefc-a619-4788-f857-b07d2d76c167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "05/09/2024 01:19:23 - INFO - __main__ - ***** Test results *****\n",
      "05/09/2024 01:19:23 - INFO - __main__ -   auc_score = 0.6857\n",
      "05/09/2024 01:19:23 - INFO - __main__ -   test_f1 = 0.2107\n",
      "05/09/2024 01:19:23 - INFO - __main__ -   test_precision = 0.2479\n",
      "05/09/2024 01:19:23 - INFO - __main__ -   test_recall = 0.1832\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_manual.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/manual/checkpoints \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBhLVH9qy6Lm"
   },
   "source": [
    "### Expert features + commit message (UniXCoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ4tCrVO1f7f"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/m_ef/unixcoder/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3X9MT9rxepI",
    "outputId": "9725502c-2952-408c-9f0c-8c359f40af52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:01:43.846680: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 23:01:43.865047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744844503.887179    3638 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744844503.893859    3638 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 23:01:43.916652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 511/512 [03:39<00:00,  2.34it/s]04/16/2025 23:06:19 - WARNING - __main__ - epoch 0 step 512 loss 0.27192\n",
      "[[0.40540928]\n",
      " [0.15424888]\n",
      " [0.01681898]\n",
      " ...\n",
      " [0.03134894]\n",
      " [0.14514814]\n",
      " [0.04659314]]\n",
      "04/16/2025 23:06:52 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:06:52 - INFO - __main__ -   auc_score = 0.7756\n",
      "04/16/2025 23:06:52 - INFO - __main__ -   eval_f1 = 0.072\n",
      "04/16/2025 23:06:52 - INFO - __main__ -   eval_precision = 0.5455\n",
      "04/16/2025 23:06:52 - INFO - __main__ -   eval_recall = 0.0385\n",
      "100% 512/512 [04:14<00:00,  2.01it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:10:32 - WARNING - __main__ - epoch 1 step 512 loss 0.2481\n",
      "[[0.55666524]\n",
      " [0.2172081 ]\n",
      " [0.02767016]\n",
      " ...\n",
      " [0.05859282]\n",
      " [0.31820607]\n",
      " [0.100793  ]]\n",
      "04/16/2025 23:11:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:11:05 - INFO - __main__ -   auc_score = 0.7792\n",
      "04/16/2025 23:11:05 - INFO - __main__ -   eval_f1 = 0.1524\n",
      "04/16/2025 23:11:05 - INFO - __main__ -   eval_precision = 0.5775\n",
      "04/16/2025 23:11:05 - INFO - __main__ -   eval_recall = 0.0878\n",
      "100% 512/512 [04:13<00:00,  2.02it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:14:45 - WARNING - __main__ - epoch 2 step 512 loss 0.24145\n",
      "[[0.5985068 ]\n",
      " [0.26438797]\n",
      " [0.02527712]\n",
      " ...\n",
      " [0.05083793]\n",
      " [0.31568626]\n",
      " [0.09593736]]\n",
      "04/16/2025 23:15:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:15:18 - INFO - __main__ -   auc_score = 0.781\n",
      "04/16/2025 23:15:18 - INFO - __main__ -   eval_f1 = 0.1453\n",
      "04/16/2025 23:15:18 - INFO - __main__ -   eval_precision = 0.5571\n",
      "04/16/2025 23:15:18 - INFO - __main__ -   eval_recall = 0.0835\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:18:57 - WARNING - __main__ - epoch 3 step 512 loss 0.23455\n",
      "[[0.6422737 ]\n",
      " [0.24981067]\n",
      " [0.03166163]\n",
      " ...\n",
      " [0.05681381]\n",
      " [0.42519736]\n",
      " [0.09911323]]\n",
      "04/16/2025 23:19:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:19:30 - INFO - __main__ -   auc_score = 0.7737\n",
      "04/16/2025 23:19:30 - INFO - __main__ -   eval_f1 = 0.1473\n",
      "04/16/2025 23:19:30 - INFO - __main__ -   eval_precision = 0.5263\n",
      "04/16/2025 23:19:30 - INFO - __main__ -   eval_recall = 0.0857\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:23:09 - WARNING - __main__ - epoch 4 step 512 loss 0.23073\n",
      "[[0.6552436 ]\n",
      " [0.27104104]\n",
      " [0.02463533]\n",
      " ...\n",
      " [0.05090851]\n",
      " [0.45653838]\n",
      " [0.11588421]]\n",
      "04/16/2025 23:23:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:23:42 - INFO - __main__ -   auc_score = 0.7754\n",
      "04/16/2025 23:23:42 - INFO - __main__ -   eval_f1 = 0.1697\n",
      "04/16/2025 23:23:42 - INFO - __main__ -   eval_precision = 0.5402\n",
      "04/16/2025 23:23:42 - INFO - __main__ -   eval_recall = 0.1006\n",
      "100% 512/512 [04:13<00:00,  2.02it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:27:22 - WARNING - __main__ - epoch 5 step 512 loss 0.2255\n",
      "[[0.5590969 ]\n",
      " [0.20237811]\n",
      " [0.0252763 ]\n",
      " ...\n",
      " [0.04160872]\n",
      " [0.4555965 ]\n",
      " [0.11856627]]\n",
      "04/16/2025 23:27:55 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:27:55 - INFO - __main__ -   auc_score = 0.7724\n",
      "04/16/2025 23:27:55 - INFO - __main__ -   eval_f1 = 0.1642\n",
      "04/16/2025 23:27:55 - INFO - __main__ -   eval_precision = 0.5556\n",
      "04/16/2025 23:27:55 - INFO - __main__ -   eval_recall = 0.0964\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:31:34 - WARNING - __main__ - epoch 6 step 512 loss 0.22113\n",
      "[[0.5320713 ]\n",
      " [0.18672372]\n",
      " [0.02345998]\n",
      " ...\n",
      " [0.03627474]\n",
      " [0.4166054 ]\n",
      " [0.12989719]]\n",
      "04/16/2025 23:32:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:32:07 - INFO - __main__ -   auc_score = 0.7655\n",
      "04/16/2025 23:32:07 - INFO - __main__ -   eval_f1 = 0.1308\n",
      "04/16/2025 23:32:07 - INFO - __main__ -   eval_precision = 0.5147\n",
      "04/16/2025 23:32:07 - INFO - __main__ -   eval_recall = 0.0749\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:35:45 - WARNING - __main__ - epoch 7 step 512 loss 0.21752\n",
      "[[0.545652  ]\n",
      " [0.17965746]\n",
      " [0.02430416]\n",
      " ...\n",
      " [0.0350311 ]\n",
      " [0.44054437]\n",
      " [0.14222339]]\n",
      "04/16/2025 23:36:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:36:18 - INFO - __main__ -   auc_score = 0.767\n",
      "04/16/2025 23:36:18 - INFO - __main__ -   eval_f1 = 0.1566\n",
      "04/16/2025 23:36:18 - INFO - __main__ -   eval_precision = 0.5244\n",
      "04/16/2025 23:36:18 - INFO - __main__ -   eval_recall = 0.0921\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:39:57 - WARNING - __main__ - epoch 8 step 512 loss 0.21463\n",
      "[[0.57975465]\n",
      " [0.19788282]\n",
      " [0.02594703]\n",
      " ...\n",
      " [0.04453375]\n",
      " [0.5392508 ]\n",
      " [0.17755263]]\n",
      "04/16/2025 23:40:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:40:30 - INFO - __main__ -   auc_score = 0.7644\n",
      "04/16/2025 23:40:30 - INFO - __main__ -   eval_f1 = 0.1722\n",
      "04/16/2025 23:40:30 - INFO - __main__ -   eval_precision = 0.4804\n",
      "04/16/2025 23:40:30 - INFO - __main__ -   eval_recall = 0.1049\n",
      "100% 512/512 [04:13<00:00,  2.02it/s]\n",
      "100% 511/512 [03:38<00:00,  2.34it/s]04/16/2025 23:44:10 - WARNING - __main__ - epoch 9 step 512 loss 0.2114\n",
      "[[0.5679484 ]\n",
      " [0.18876946]\n",
      " [0.02375787]\n",
      " ...\n",
      " [0.04158554]\n",
      " [0.5784182 ]\n",
      " [0.1652471 ]]\n",
      "04/16/2025 23:44:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/16/2025 23:44:43 - INFO - __main__ -   auc_score = 0.7638\n",
      "04/16/2025 23:44:43 - INFO - __main__ -   eval_f1 = 0.1722\n",
      "04/16/2025 23:44:43 - INFO - __main__ -   eval_precision = 0.4804\n",
      "04/16/2025 23:44:43 - INFO - __main__ -   eval_recall = 0.1049\n",
      "100% 512/512 [04:11<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/m_ef/unixcoder/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLiMBhQwJ_Kf",
    "outputId": "4faa73ef-993d-4f25-8a82-feb370ce02a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 09:50:52.793417: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 09:50:52.810773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744883452.832526    2189 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744883452.839181    2189 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 09:50:52.861245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "config.json: 100% 691/691 [00:00<00:00, 4.69MB/s]\n",
      "tokenizer_config.json: 100% 1.11k/1.11k [00:00<00:00, 7.00MB/s]\n",
      "vocab.json: 100% 938k/938k [00:00<00:00, 4.12MB/s]\n",
      "merges.txt: 100% 444k/444k [00:00<00:00, 2.11MB/s]\n",
      "special_tokens_map.json: 100% 772/772 [00:00<00:00, 6.35MB/s]\n",
      "pytorch_model.bin: 100% 504M/504M [00:01<00:00, 345MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 2,359,296 || all params: 128,290,560 || trainable%: 1.8390\n",
      "model.safetensors: 100% 504M/504M [00:01<00:00, 392MB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.07578947368421053\n",
      "recall =  0.07578947368421053\n",
      "04/17/2025 09:52:02 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   R0 = 0.9902\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   R1 = 0.0758\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   auc_score = 0.7381\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   g_mean = 0.2739\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   test_f1 = 0.1286\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   test_precision = 0.4235\n",
      "04/17/2025 09:52:02 - INFO - __main__ -   test_recall = 0.0758\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/m_ef/unixcoder/checkpoints \\\n",
    "   --pretrained_model unixcoder \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgtOF9zokxVR"
   },
   "source": [
    "### Manual features in text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igtkixhJN_k2",
    "outputId": "18827e20-9563-4bae-9022-8568263cd049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:246: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:246: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      " 20% 203/1024 [02:58<11:56,  1.15it/s]09/03/2024 17:49:00 - WARNING - __main__ - epoch 0 step 204 loss 0.34134\n",
      "[[0.15853341]\n",
      " [0.05238716]\n",
      " [0.08957965]\n",
      " ...\n",
      " [0.13716704]\n",
      " [0.1350588 ]\n",
      " [0.16225149]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "09/03/2024 17:51:10 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 17:51:10 - INFO - __main__ -   auc_score = 0.7013\n",
      "09/03/2024 17:51:10 - INFO - __main__ -   eval_f1 = 0.0\n",
      "09/03/2024 17:51:10 - INFO - __main__ -   eval_precision = 0.0\n",
      "09/03/2024 17:51:10 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 407/1024 [08:06<08:58,  1.14it/s]09/03/2024 17:54:08 - WARNING - __main__ - epoch 0 step 408 loss 0.28649\n",
      "[[0.22839573]\n",
      " [0.03646409]\n",
      " [0.08441743]\n",
      " ...\n",
      " [0.19166103]\n",
      " [0.21023594]\n",
      " [0.24269767]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "09/03/2024 17:56:18 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 17:56:18 - INFO - __main__ -   auc_score = 0.7165\n",
      "09/03/2024 17:56:18 - INFO - __main__ -   eval_f1 = 0.0\n",
      "09/03/2024 17:56:18 - INFO - __main__ -   eval_precision = 0.0\n",
      "09/03/2024 17:56:18 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 611/1024 [13:14<06:00,  1.14it/s]09/03/2024 17:59:15 - WARNING - __main__ - epoch 0 step 612 loss 0.24996\n",
      "[[0.31544644]\n",
      " [0.01323466]\n",
      " [0.0452918 ]\n",
      " ...\n",
      " [0.23864077]\n",
      " [0.29425228]\n",
      " [0.32624865]]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "09/03/2024 18:01:26 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:01:26 - INFO - __main__ -   auc_score = 0.8338\n",
      "09/03/2024 18:01:26 - INFO - __main__ -   eval_f1 = 0.0\n",
      "09/03/2024 18:01:26 - INFO - __main__ -   eval_precision = 0.0\n",
      "09/03/2024 18:01:26 - INFO - __main__ -   eval_recall = 0.0\n",
      " 80% 815/1024 [18:22<03:02,  1.14it/s]09/03/2024 18:04:23 - WARNING - __main__ - epoch 0 step 816 loss 0.23028\n",
      "[[0.72287875]\n",
      " [0.18214497]\n",
      " [0.19212215]\n",
      " ...\n",
      " [0.57263213]\n",
      " [0.6817416 ]\n",
      " [0.6464304 ]]\n",
      "09/03/2024 18:06:33 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:06:33 - INFO - __main__ -   auc_score = 0.8732\n",
      "09/03/2024 18:06:33 - INFO - __main__ -   eval_f1 = 0.4013\n",
      "09/03/2024 18:06:33 - INFO - __main__ -   eval_precision = 0.4186\n",
      "09/03/2024 18:06:33 - INFO - __main__ -   eval_recall = 0.3854\n",
      "100% 1019/1024 [23:40<00:04,  1.14it/s]09/03/2024 18:09:42 - WARNING - __main__ - epoch 0 step 1020 loss 0.21984\n",
      "[[0.6241662 ]\n",
      " [0.21365835]\n",
      " [0.10965474]\n",
      " ...\n",
      " [0.2750807 ]\n",
      " [0.49233773]\n",
      " [0.4096773 ]]\n",
      "09/03/2024 18:11:52 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:11:52 - INFO - __main__ -   auc_score = 0.9027\n",
      "09/03/2024 18:11:52 - INFO - __main__ -   eval_f1 = 0.2961\n",
      "09/03/2024 18:11:52 - INFO - __main__ -   eval_precision = 0.6383\n",
      "09/03/2024 18:11:52 - INFO - __main__ -   eval_recall = 0.1927\n",
      "100% 1024/1024 [25:54<00:00,  1.52s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 18:14:53 - WARNING - __main__ - epoch 1 step 204 loss 0.19787\n",
      "[[0.8546003 ]\n",
      " [0.3328279 ]\n",
      " [0.10487438]\n",
      " ...\n",
      " [0.3565473 ]\n",
      " [0.75681674]\n",
      " [0.5353613 ]]\n",
      "09/03/2024 18:17:03 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:17:03 - INFO - __main__ -   auc_score = 0.9059\n",
      "09/03/2024 18:17:03 - INFO - __main__ -   eval_f1 = 0.5102\n",
      "09/03/2024 18:17:03 - INFO - __main__ -   eval_precision = 0.5422\n",
      "09/03/2024 18:17:03 - INFO - __main__ -   eval_recall = 0.4818\n",
      " 40% 407/1024 [08:12<08:58,  1.14it/s]09/03/2024 18:20:08 - WARNING - __main__ - epoch 1 step 408 loss 0.19129\n",
      "[[0.7832375 ]\n",
      " [0.38828   ]\n",
      " [0.05158734]\n",
      " ...\n",
      " [0.20122749]\n",
      " [0.60343635]\n",
      " [0.38058704]]\n",
      "09/03/2024 18:22:18 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:22:18 - INFO - __main__ -   auc_score = 0.9139\n",
      "09/03/2024 18:22:18 - INFO - __main__ -   eval_f1 = 0.4878\n",
      "09/03/2024 18:22:18 - INFO - __main__ -   eval_precision = 0.6642\n",
      "09/03/2024 18:22:18 - INFO - __main__ -   eval_recall = 0.3854\n",
      " 60% 611/1024 [13:20<06:00,  1.14it/s]09/03/2024 18:25:16 - WARNING - __main__ - epoch 1 step 612 loss 0.19973\n",
      "[[0.7838275 ]\n",
      " [0.5719072 ]\n",
      " [0.10196365]\n",
      " ...\n",
      " [0.39412805]\n",
      " [0.6576914 ]\n",
      " [0.4983057 ]]\n",
      "09/03/2024 18:27:26 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:27:26 - INFO - __main__ -   auc_score = 0.9187\n",
      "09/03/2024 18:27:26 - INFO - __main__ -   eval_f1 = 0.5819\n",
      "09/03/2024 18:27:26 - INFO - __main__ -   eval_precision = 0.6533\n",
      "09/03/2024 18:27:26 - INFO - __main__ -   eval_recall = 0.5246\n",
      " 80% 815/1024 [18:35<03:02,  1.14it/s]09/03/2024 18:30:31 - WARNING - __main__ - epoch 1 step 816 loss 0.18379\n",
      "[[0.8068431 ]\n",
      " [0.5263466 ]\n",
      " [0.12547964]\n",
      " ...\n",
      " [0.26666957]\n",
      " [0.52009714]\n",
      " [0.33629817]]\n",
      "09/03/2024 18:32:41 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:32:41 - INFO - __main__ -   auc_score = 0.9165\n",
      "09/03/2024 18:32:41 - INFO - __main__ -   eval_f1 = 0.57\n",
      "09/03/2024 18:32:41 - INFO - __main__ -   eval_precision = 0.6847\n",
      "09/03/2024 18:32:41 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1019/1024 [23:43<00:04,  1.14it/s]09/03/2024 18:35:39 - WARNING - __main__ - epoch 1 step 1020 loss 0.18012\n",
      "[[0.8037279 ]\n",
      " [0.43383476]\n",
      " [0.07292491]\n",
      " ...\n",
      " [0.28284785]\n",
      " [0.55152905]\n",
      " [0.48411897]]\n",
      "09/03/2024 18:37:49 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:37:49 - INFO - __main__ -   auc_score = 0.9242\n",
      "09/03/2024 18:37:49 - INFO - __main__ -   eval_f1 = 0.5859\n",
      "09/03/2024 18:37:49 - INFO - __main__ -   eval_precision = 0.7138\n",
      "09/03/2024 18:37:49 - INFO - __main__ -   eval_recall = 0.4968\n",
      "100% 1024/1024 [26:05<00:00,  1.53s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 18:40:58 - WARNING - __main__ - epoch 2 step 204 loss 0.16296\n",
      "[[0.92365754]\n",
      " [0.31403828]\n",
      " [0.05808701]\n",
      " ...\n",
      " [0.21968558]\n",
      " [0.70297426]\n",
      " [0.48295358]]\n",
      "09/03/2024 18:43:08 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:43:08 - INFO - __main__ -   auc_score = 0.9253\n",
      "09/03/2024 18:43:08 - INFO - __main__ -   eval_f1 = 0.5912\n",
      "09/03/2024 18:43:08 - INFO - __main__ -   eval_precision = 0.6667\n",
      "09/03/2024 18:43:08 - INFO - __main__ -   eval_recall = 0.531\n",
      " 40% 407/1024 [08:12<08:59,  1.14it/s]09/03/2024 18:46:13 - WARNING - __main__ - epoch 2 step 408 loss 0.17806\n",
      "[[0.8612492 ]\n",
      " [0.1979149 ]\n",
      " [0.06522047]\n",
      " ...\n",
      " [0.20636335]\n",
      " [0.68450826]\n",
      " [0.42509633]]\n",
      "09/03/2024 18:48:23 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:48:23 - INFO - __main__ -   auc_score = 0.9256\n",
      "09/03/2024 18:48:23 - INFO - __main__ -   eval_f1 = 0.6084\n",
      "09/03/2024 18:48:23 - INFO - __main__ -   eval_precision = 0.6902\n",
      "09/03/2024 18:48:23 - INFO - __main__ -   eval_recall = 0.5439\n",
      " 60% 611/1024 [13:28<06:00,  1.14it/s]09/03/2024 18:51:29 - WARNING - __main__ - epoch 2 step 612 loss 0.17573\n",
      "[[0.9229604 ]\n",
      " [0.38546026]\n",
      " [0.0570531 ]\n",
      " ...\n",
      " [0.21552077]\n",
      " [0.742645  ]\n",
      " [0.30333018]]\n",
      "09/03/2024 18:53:39 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:53:39 - INFO - __main__ -   auc_score = 0.922\n",
      "09/03/2024 18:53:39 - INFO - __main__ -   eval_f1 = 0.6075\n",
      "09/03/2024 18:53:39 - INFO - __main__ -   eval_precision = 0.7022\n",
      "09/03/2024 18:53:39 - INFO - __main__ -   eval_recall = 0.5353\n",
      " 80% 815/1024 [18:36<03:02,  1.14it/s]09/03/2024 18:56:37 - WARNING - __main__ - epoch 2 step 816 loss 0.16471\n",
      "[[0.8657394 ]\n",
      " [0.2450383 ]\n",
      " [0.05287913]\n",
      " ...\n",
      " [0.08841605]\n",
      " [0.49548638]\n",
      " [0.16244538]]\n",
      "09/03/2024 18:58:47 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 18:58:47 - INFO - __main__ -   auc_score = 0.9253\n",
      "09/03/2024 18:58:47 - INFO - __main__ -   eval_f1 = 0.6005\n",
      "09/03/2024 18:58:47 - INFO - __main__ -   eval_precision = 0.7264\n",
      "09/03/2024 18:58:47 - INFO - __main__ -   eval_recall = 0.5118\n",
      "100% 1019/1024 [23:44<00:04,  1.14it/s]09/03/2024 19:01:45 - WARNING - __main__ - epoch 2 step 1020 loss 0.16254\n",
      "[[0.9403077 ]\n",
      " [0.27684277]\n",
      " [0.08136275]\n",
      " ...\n",
      " [0.24863507]\n",
      " [0.7390452 ]\n",
      " [0.40041402]]\n",
      "09/03/2024 19:03:55 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:03:55 - INFO - __main__ -   auc_score = 0.9274\n",
      "09/03/2024 19:03:55 - INFO - __main__ -   eval_f1 = 0.6098\n",
      "09/03/2024 19:03:55 - INFO - __main__ -   eval_precision = 0.5736\n",
      "09/03/2024 19:03:55 - INFO - __main__ -   eval_recall = 0.651\n",
      "100% 1024/1024 [26:06<00:00,  1.53s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 19:07:05 - WARNING - __main__ - epoch 3 step 204 loss 0.15403\n",
      "[[0.95483106]\n",
      " [0.3971359 ]\n",
      " [0.0513472 ]\n",
      " ...\n",
      " [0.16478692]\n",
      " [0.58316416]\n",
      " [0.4087547 ]]\n",
      "09/03/2024 19:09:15 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:09:15 - INFO - __main__ -   auc_score = 0.9251\n",
      "09/03/2024 19:09:15 - INFO - __main__ -   eval_f1 = 0.6251\n",
      "09/03/2024 19:09:15 - INFO - __main__ -   eval_precision = 0.6505\n",
      "09/03/2024 19:09:15 - INFO - __main__ -   eval_recall = 0.6017\n",
      " 40% 407/1024 [08:12<08:59,  1.14it/s]09/03/2024 19:12:20 - WARNING - __main__ - epoch 3 step 408 loss 0.14862\n",
      "[[0.966065  ]\n",
      " [0.7147082 ]\n",
      " [0.09660194]\n",
      " ...\n",
      " [0.43596798]\n",
      " [0.84493273]\n",
      " [0.6598615 ]]\n",
      "09/03/2024 19:14:30 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:14:30 - INFO - __main__ -   auc_score = 0.9283\n",
      "09/03/2024 19:14:30 - INFO - __main__ -   eval_f1 = 0.6173\n",
      "09/03/2024 19:14:30 - INFO - __main__ -   eval_precision = 0.5602\n",
      "09/03/2024 19:14:30 - INFO - __main__ -   eval_recall = 0.6874\n",
      " 60% 611/1024 [13:20<06:00,  1.14it/s]09/03/2024 19:17:28 - WARNING - __main__ - epoch 3 step 612 loss 0.16222\n",
      "[[0.95511675]\n",
      " [0.6504087 ]\n",
      " [0.10559798]\n",
      " ...\n",
      " [0.32772493]\n",
      " [0.5970238 ]\n",
      " [0.4093599 ]]\n",
      "09/03/2024 19:19:38 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:19:38 - INFO - __main__ -   auc_score = 0.926\n",
      "09/03/2024 19:19:38 - INFO - __main__ -   eval_f1 = 0.6221\n",
      "09/03/2024 19:19:38 - INFO - __main__ -   eval_precision = 0.5821\n",
      "09/03/2024 19:19:38 - INFO - __main__ -   eval_recall = 0.6681\n",
      " 80% 815/1024 [18:28<03:02,  1.14it/s]09/03/2024 19:22:36 - WARNING - __main__ - epoch 3 step 816 loss 0.15251\n",
      "[[0.9621775 ]\n",
      " [0.21911208]\n",
      " [0.098272  ]\n",
      " ...\n",
      " [0.17064512]\n",
      " [0.66181636]\n",
      " [0.29311496]]\n",
      "09/03/2024 19:24:46 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:24:46 - INFO - __main__ -   auc_score = 0.9271\n",
      "09/03/2024 19:24:46 - INFO - __main__ -   eval_f1 = 0.6486\n",
      "09/03/2024 19:24:46 - INFO - __main__ -   eval_precision = 0.655\n",
      "09/03/2024 19:24:46 - INFO - __main__ -   eval_recall = 0.6424\n",
      "100% 1019/1024 [23:44<00:04,  1.14it/s]09/03/2024 19:27:52 - WARNING - __main__ - epoch 3 step 1020 loss 0.14875\n",
      "[[0.94899863]\n",
      " [0.04328379]\n",
      " [0.04402927]\n",
      " ...\n",
      " [0.24754594]\n",
      " [0.7345779 ]\n",
      " [0.3900787 ]]\n",
      "09/03/2024 19:30:02 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:30:02 - INFO - __main__ -   auc_score = 0.9287\n",
      "09/03/2024 19:30:02 - INFO - __main__ -   eval_f1 = 0.6256\n",
      "09/03/2024 19:30:02 - INFO - __main__ -   eval_precision = 0.6845\n",
      "09/03/2024 19:30:02 - INFO - __main__ -   eval_recall = 0.576\n",
      "100% 1024/1024 [25:58<00:00,  1.52s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 19:33:03 - WARNING - __main__ - epoch 4 step 204 loss 0.14607\n",
      "[[0.9582334 ]\n",
      " [0.07107877]\n",
      " [0.05935701]\n",
      " ...\n",
      " [0.17054118]\n",
      " [0.57112515]\n",
      " [0.24718988]]\n",
      "09/03/2024 19:35:13 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:35:13 - INFO - __main__ -   auc_score = 0.9293\n",
      "09/03/2024 19:35:13 - INFO - __main__ -   eval_f1 = 0.6429\n",
      "09/03/2024 19:35:13 - INFO - __main__ -   eval_precision = 0.7529\n",
      "09/03/2024 19:35:13 - INFO - __main__ -   eval_recall = 0.561\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 19:38:11 - WARNING - __main__ - epoch 4 step 408 loss 0.14306\n",
      "[[0.9660415 ]\n",
      " [0.12036806]\n",
      " [0.06341197]\n",
      " ...\n",
      " [0.30161998]\n",
      " [0.7581263 ]\n",
      " [0.43918824]]\n",
      "09/03/2024 19:40:21 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:40:21 - INFO - __main__ -   auc_score = 0.9319\n",
      "09/03/2024 19:40:21 - INFO - __main__ -   eval_f1 = 0.6497\n",
      "09/03/2024 19:40:21 - INFO - __main__ -   eval_precision = 0.6712\n",
      "09/03/2024 19:40:21 - INFO - __main__ -   eval_recall = 0.6296\n",
      " 60% 611/1024 [13:21<06:00,  1.14it/s]09/03/2024 19:43:26 - WARNING - __main__ - epoch 4 step 612 loss 0.13108\n",
      "[[0.98547375]\n",
      " [0.04695987]\n",
      " [0.11274955]\n",
      " ...\n",
      " [0.44549072]\n",
      " [0.8486784 ]\n",
      " [0.58658725]]\n",
      "09/03/2024 19:45:37 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:45:37 - INFO - __main__ -   auc_score = 0.929\n",
      "09/03/2024 19:45:37 - INFO - __main__ -   eval_f1 = 0.6318\n",
      "09/03/2024 19:45:37 - INFO - __main__ -   eval_precision = 0.6176\n",
      "09/03/2024 19:45:37 - INFO - __main__ -   eval_recall = 0.6467\n",
      " 80% 815/1024 [18:28<03:02,  1.14it/s]09/03/2024 19:48:34 - WARNING - __main__ - epoch 4 step 816 loss 0.13741\n",
      "[[0.9898033 ]\n",
      " [0.06332892]\n",
      " [0.10771863]\n",
      " ...\n",
      " [0.49393564]\n",
      " [0.92949563]\n",
      " [0.63506305]]\n",
      "09/03/2024 19:50:44 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:50:44 - INFO - __main__ -   auc_score = 0.9291\n",
      "09/03/2024 19:50:44 - INFO - __main__ -   eval_f1 = 0.6265\n",
      "09/03/2024 19:50:44 - INFO - __main__ -   eval_precision = 0.5898\n",
      "09/03/2024 19:50:44 - INFO - __main__ -   eval_recall = 0.6681\n",
      "100% 1019/1024 [23:36<00:04,  1.14it/s]09/03/2024 19:53:42 - WARNING - __main__ - epoch 4 step 1020 loss 0.14899\n",
      "[[0.88303477]\n",
      " [0.01051854]\n",
      " [0.05773979]\n",
      " ...\n",
      " [0.09573412]\n",
      " [0.3948369 ]\n",
      " [0.11583722]]\n",
      "09/03/2024 19:55:52 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 19:55:52 - INFO - __main__ -   auc_score = 0.9279\n",
      "09/03/2024 19:55:52 - INFO - __main__ -   eval_f1 = 0.5949\n",
      "09/03/2024 19:55:52 - INFO - __main__ -   eval_precision = 0.8787\n",
      "09/03/2024 19:55:52 - INFO - __main__ -   eval_recall = 0.4497\n",
      "100% 1024/1024 [25:50<00:00,  1.51s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 19:58:53 - WARNING - __main__ - epoch 5 step 204 loss 0.1359\n",
      "[[0.9741067 ]\n",
      " [0.03997533]\n",
      " [0.17949848]\n",
      " ...\n",
      " [0.20373355]\n",
      " [0.7335154 ]\n",
      " [0.19104746]]\n",
      "09/03/2024 20:01:03 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:01:03 - INFO - __main__ -   auc_score = 0.9286\n",
      "09/03/2024 20:01:03 - INFO - __main__ -   eval_f1 = 0.6484\n",
      "09/03/2024 20:01:03 - INFO - __main__ -   eval_precision = 0.6637\n",
      "09/03/2024 20:01:03 - INFO - __main__ -   eval_recall = 0.6338\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 20:04:01 - WARNING - __main__ - epoch 5 step 408 loss 0.12461\n",
      "[[0.9850072 ]\n",
      " [0.04117297]\n",
      " [0.1541869 ]\n",
      " ...\n",
      " [0.25984782]\n",
      " [0.87743914]\n",
      " [0.32083783]]\n",
      "09/03/2024 20:06:11 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:06:11 - INFO - __main__ -   auc_score = 0.9301\n",
      "09/03/2024 20:06:11 - INFO - __main__ -   eval_f1 = 0.6407\n",
      "09/03/2024 20:06:11 - INFO - __main__ -   eval_precision = 0.6307\n",
      "09/03/2024 20:06:11 - INFO - __main__ -   eval_recall = 0.651\n",
      " 60% 611/1024 [13:13<06:00,  1.14it/s]09/03/2024 20:09:09 - WARNING - __main__ - epoch 5 step 612 loss 0.12375\n",
      "[[0.99239266]\n",
      " [0.0188526 ]\n",
      " [0.1810591 ]\n",
      " ...\n",
      " [0.39098996]\n",
      " [0.8280089 ]\n",
      " [0.19293378]]\n",
      "09/03/2024 20:11:19 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:11:19 - INFO - __main__ -   auc_score = 0.9228\n",
      "09/03/2024 20:11:19 - INFO - __main__ -   eval_f1 = 0.6283\n",
      "09/03/2024 20:11:19 - INFO - __main__ -   eval_precision = 0.625\n",
      "09/03/2024 20:11:19 - INFO - __main__ -   eval_recall = 0.6317\n",
      " 80% 815/1024 [18:21<03:02,  1.14it/s]09/03/2024 20:14:17 - WARNING - __main__ - epoch 5 step 816 loss 0.11108\n",
      "[[0.99308175]\n",
      " [0.0393129 ]\n",
      " [0.162927  ]\n",
      " ...\n",
      " [0.26912132]\n",
      " [0.8907088 ]\n",
      " [0.23264724]]\n",
      "09/03/2024 20:16:27 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:16:27 - INFO - __main__ -   auc_score = 0.9251\n",
      "09/03/2024 20:16:27 - INFO - __main__ -   eval_f1 = 0.6348\n",
      "09/03/2024 20:16:27 - INFO - __main__ -   eval_precision = 0.6446\n",
      "09/03/2024 20:16:27 - INFO - __main__ -   eval_recall = 0.6253\n",
      "100% 1019/1024 [23:29<00:04,  1.14it/s]09/03/2024 20:19:25 - WARNING - __main__ - epoch 5 step 1020 loss 0.14817\n",
      "[[0.99194795]\n",
      " [0.01533255]\n",
      " [0.09289145]\n",
      " ...\n",
      " [0.2531238 ]\n",
      " [0.9365365 ]\n",
      " [0.51098764]]\n",
      "09/03/2024 20:21:35 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:21:35 - INFO - __main__ -   auc_score = 0.9261\n",
      "09/03/2024 20:21:35 - INFO - __main__ -   eval_f1 = 0.6228\n",
      "09/03/2024 20:21:35 - INFO - __main__ -   eval_precision = 0.6503\n",
      "09/03/2024 20:21:35 - INFO - __main__ -   eval_recall = 0.5974\n",
      "100% 1024/1024 [25:42<00:00,  1.51s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 20:24:36 - WARNING - __main__ - epoch 6 step 204 loss 0.11724\n",
      "[[0.99618226]\n",
      " [0.01709499]\n",
      " [0.16437024]\n",
      " ...\n",
      " [0.41198647]\n",
      " [0.9505757 ]\n",
      " [0.49822652]]\n",
      "09/03/2024 20:26:46 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:26:46 - INFO - __main__ -   auc_score = 0.9224\n",
      "09/03/2024 20:26:46 - INFO - __main__ -   eval_f1 = 0.6174\n",
      "09/03/2024 20:26:46 - INFO - __main__ -   eval_precision = 0.5722\n",
      "09/03/2024 20:26:46 - INFO - __main__ -   eval_recall = 0.6702\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 20:29:44 - WARNING - __main__ - epoch 6 step 408 loss 0.12745\n",
      "[[0.9935364 ]\n",
      " [0.02140644]\n",
      " [0.25385082]\n",
      " ...\n",
      " [0.58931524]\n",
      " [0.9316403 ]\n",
      " [0.5151001 ]]\n",
      "09/03/2024 20:31:54 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:31:54 - INFO - __main__ -   auc_score = 0.9251\n",
      "09/03/2024 20:31:54 - INFO - __main__ -   eval_f1 = 0.6019\n",
      "09/03/2024 20:31:54 - INFO - __main__ -   eval_precision = 0.5302\n",
      "09/03/2024 20:31:54 - INFO - __main__ -   eval_recall = 0.6959\n",
      " 60% 611/1024 [13:13<06:00,  1.14it/s]09/03/2024 20:34:52 - WARNING - __main__ - epoch 6 step 612 loss 0.11897\n",
      "[[0.9892163 ]\n",
      " [0.00365769]\n",
      " [0.05810521]\n",
      " ...\n",
      " [0.32015237]\n",
      " [0.82212037]\n",
      " [0.21434304]]\n",
      "09/03/2024 20:37:02 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:37:02 - INFO - __main__ -   auc_score = 0.9215\n",
      "09/03/2024 20:37:02 - INFO - __main__ -   eval_f1 = 0.6349\n",
      "09/03/2024 20:37:02 - INFO - __main__ -   eval_precision = 0.6947\n",
      "09/03/2024 20:37:02 - INFO - __main__ -   eval_recall = 0.5846\n",
      " 80% 815/1024 [18:21<03:02,  1.14it/s]09/03/2024 20:40:00 - WARNING - __main__ - epoch 6 step 816 loss 0.09602\n",
      "[[0.99532014]\n",
      " [0.00445661]\n",
      " [0.1033043 ]\n",
      " ...\n",
      " [0.65122837]\n",
      " [0.9374135 ]\n",
      " [0.42551032]]\n",
      "09/03/2024 20:42:10 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:42:10 - INFO - __main__ -   auc_score = 0.9219\n",
      "09/03/2024 20:42:10 - INFO - __main__ -   eval_f1 = 0.6131\n",
      "09/03/2024 20:42:10 - INFO - __main__ -   eval_precision = 0.565\n",
      "09/03/2024 20:42:10 - INFO - __main__ -   eval_recall = 0.6702\n",
      "100% 1019/1024 [23:29<00:04,  1.14it/s]09/03/2024 20:45:08 - WARNING - __main__ - epoch 6 step 1020 loss 0.12672\n",
      "[[0.993751  ]\n",
      " [0.00598514]\n",
      " [0.10262618]\n",
      " ...\n",
      " [0.4377127 ]\n",
      " [0.9129233 ]\n",
      " [0.21384424]]\n",
      "09/03/2024 20:47:18 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:47:18 - INFO - __main__ -   auc_score = 0.9202\n",
      "09/03/2024 20:47:18 - INFO - __main__ -   eval_f1 = 0.6334\n",
      "09/03/2024 20:47:18 - INFO - __main__ -   eval_precision = 0.6739\n",
      "09/03/2024 20:47:18 - INFO - __main__ -   eval_recall = 0.5974\n",
      "100% 1024/1024 [25:42<00:00,  1.51s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 20:50:19 - WARNING - __main__ - epoch 7 step 204 loss 0.09946\n",
      "[[0.99007446]\n",
      " [0.00439115]\n",
      " [0.09467043]\n",
      " ...\n",
      " [0.35983282]\n",
      " [0.8085738 ]\n",
      " [0.14616992]]\n",
      "09/03/2024 20:52:29 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:52:29 - INFO - __main__ -   auc_score = 0.9181\n",
      "09/03/2024 20:52:29 - INFO - __main__ -   eval_f1 = 0.636\n",
      "09/03/2024 20:52:29 - INFO - __main__ -   eval_precision = 0.669\n",
      "09/03/2024 20:52:29 - INFO - __main__ -   eval_recall = 0.606\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 20:55:27 - WARNING - __main__ - epoch 7 step 408 loss 0.10745\n",
      "[[0.997752  ]\n",
      " [0.01786606]\n",
      " [0.24158452]\n",
      " ...\n",
      " [0.64573026]\n",
      " [0.9814959 ]\n",
      " [0.52335465]]\n",
      "09/03/2024 20:57:37 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 20:57:37 - INFO - __main__ -   auc_score = 0.9219\n",
      "09/03/2024 20:57:37 - INFO - __main__ -   eval_f1 = 0.5982\n",
      "09/03/2024 20:57:37 - INFO - __main__ -   eval_precision = 0.5233\n",
      "09/03/2024 20:57:37 - INFO - __main__ -   eval_recall = 0.6981\n",
      " 60% 611/1024 [13:13<06:01,  1.14it/s]09/03/2024 21:00:35 - WARNING - __main__ - epoch 7 step 612 loss 0.10426\n",
      "[[0.9978592 ]\n",
      " [0.01017119]\n",
      " [0.2532555 ]\n",
      " ...\n",
      " [0.7024553 ]\n",
      " [0.98329157]\n",
      " [0.5016573 ]]\n",
      "09/03/2024 21:02:45 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:02:45 - INFO - __main__ -   auc_score = 0.9206\n",
      "09/03/2024 21:02:45 - INFO - __main__ -   eval_f1 = 0.5919\n",
      "09/03/2024 21:02:45 - INFO - __main__ -   eval_precision = 0.5125\n",
      "09/03/2024 21:02:45 - INFO - __main__ -   eval_recall = 0.7002\n",
      " 80% 815/1024 [18:21<03:02,  1.14it/s]09/03/2024 21:05:43 - WARNING - __main__ - epoch 7 step 816 loss 0.11026\n",
      "[[0.99735594]\n",
      " [0.00878979]\n",
      " [0.10868208]\n",
      " ...\n",
      " [0.48579764]\n",
      " [0.97947776]\n",
      " [0.5227714 ]]\n",
      "09/03/2024 21:07:53 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:07:53 - INFO - __main__ -   auc_score = 0.925\n",
      "09/03/2024 21:07:53 - INFO - __main__ -   eval_f1 = 0.6258\n",
      "09/03/2024 21:07:53 - INFO - __main__ -   eval_precision = 0.6081\n",
      "09/03/2024 21:07:53 - INFO - __main__ -   eval_recall = 0.6445\n",
      "100% 1019/1024 [23:29<00:04,  1.14it/s]09/03/2024 21:10:51 - WARNING - __main__ - epoch 7 step 1020 loss 0.12851\n",
      "[[0.99159604]\n",
      " [0.0045215 ]\n",
      " [0.12386326]\n",
      " ...\n",
      " [0.32894444]\n",
      " [0.7363915 ]\n",
      " [0.14279333]]\n",
      "09/03/2024 21:13:01 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:13:01 - INFO - __main__ -   auc_score = 0.9178\n",
      "09/03/2024 21:13:01 - INFO - __main__ -   eval_f1 = 0.6426\n",
      "09/03/2024 21:13:01 - INFO - __main__ -   eval_precision = 0.7041\n",
      "09/03/2024 21:13:01 - INFO - __main__ -   eval_recall = 0.591\n",
      "100% 1024/1024 [25:42<00:00,  1.51s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 21:16:02 - WARNING - __main__ - epoch 8 step 204 loss 0.09451\n",
      "[[0.99744034]\n",
      " [0.00285666]\n",
      " [0.0846577 ]\n",
      " ...\n",
      " [0.61858237]\n",
      " [0.9712191 ]\n",
      " [0.2929438 ]]\n",
      "09/03/2024 21:18:12 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:18:12 - INFO - __main__ -   auc_score = 0.9179\n",
      "09/03/2024 21:18:12 - INFO - __main__ -   eval_f1 = 0.6171\n",
      "09/03/2024 21:18:12 - INFO - __main__ -   eval_precision = 0.5883\n",
      "09/03/2024 21:18:12 - INFO - __main__ -   eval_recall = 0.6488\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 21:21:10 - WARNING - __main__ - epoch 8 step 408 loss 0.10828\n",
      "[[0.9973443 ]\n",
      " [0.00773943]\n",
      " [0.13500628]\n",
      " ...\n",
      " [0.52838194]\n",
      " [0.9638037 ]\n",
      " [0.3785326 ]]\n",
      "09/03/2024 21:23:20 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:23:20 - INFO - __main__ -   auc_score = 0.9216\n",
      "09/03/2024 21:23:20 - INFO - __main__ -   eval_f1 = 0.6263\n",
      "09/03/2024 21:23:20 - INFO - __main__ -   eval_precision = 0.5927\n",
      "09/03/2024 21:23:20 - INFO - __main__ -   eval_recall = 0.6638\n",
      " 60% 611/1024 [13:13<06:00,  1.14it/s]09/03/2024 21:26:18 - WARNING - __main__ - epoch 8 step 612 loss 0.10223\n",
      "[[0.99793506]\n",
      " [0.00886345]\n",
      " [0.14258054]\n",
      " ...\n",
      " [0.6628388 ]\n",
      " [0.98681426]\n",
      " [0.5041274 ]]\n",
      "09/03/2024 21:28:28 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:28:28 - INFO - __main__ -   auc_score = 0.9234\n",
      "09/03/2024 21:28:28 - INFO - __main__ -   eval_f1 = 0.6138\n",
      "09/03/2024 21:28:28 - INFO - __main__ -   eval_precision = 0.5544\n",
      "09/03/2024 21:28:28 - INFO - __main__ -   eval_recall = 0.6874\n",
      " 80% 815/1024 [18:21<03:02,  1.14it/s]09/03/2024 21:31:25 - WARNING - __main__ - epoch 8 step 816 loss 0.09685\n",
      "[[0.99722254]\n",
      " [0.0050052 ]\n",
      " [0.1086558 ]\n",
      " ...\n",
      " [0.45477763]\n",
      " [0.9377693 ]\n",
      " [0.24227133]]\n",
      "09/03/2024 21:33:36 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:33:36 - INFO - __main__ -   auc_score = 0.9185\n",
      "09/03/2024 21:33:36 - INFO - __main__ -   eval_f1 = 0.629\n",
      "09/03/2024 21:33:36 - INFO - __main__ -   eval_precision = 0.6263\n",
      "09/03/2024 21:33:36 - INFO - __main__ -   eval_recall = 0.6317\n",
      "100% 1019/1024 [23:29<00:04,  1.14it/s]09/03/2024 21:36:33 - WARNING - __main__ - epoch 8 step 1020 loss 0.11318\n",
      "[[0.9974547 ]\n",
      " [0.01047671]\n",
      " [0.23662858]\n",
      " ...\n",
      " [0.59069395]\n",
      " [0.967653  ]\n",
      " [0.37896696]]\n",
      "09/03/2024 21:38:43 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:38:43 - INFO - __main__ -   auc_score = 0.9204\n",
      "09/03/2024 21:38:43 - INFO - __main__ -   eval_f1 = 0.6106\n",
      "09/03/2024 21:38:43 - INFO - __main__ -   eval_precision = 0.5465\n",
      "09/03/2024 21:38:43 - INFO - __main__ -   eval_recall = 0.6916\n",
      "100% 1024/1024 [25:42<00:00,  1.51s/it]\n",
      " 20% 203/1024 [02:57<11:57,  1.14it/s]09/03/2024 21:41:44 - WARNING - __main__ - epoch 9 step 204 loss 0.09782\n",
      "[[0.99757713]\n",
      " [0.00825108]\n",
      " [0.18863532]\n",
      " ...\n",
      " [0.4984232 ]\n",
      " [0.9738482 ]\n",
      " [0.31159827]]\n",
      "09/03/2024 21:43:54 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:43:54 - INFO - __main__ -   auc_score = 0.9212\n",
      "09/03/2024 21:43:54 - INFO - __main__ -   eval_f1 = 0.6318\n",
      "09/03/2024 21:43:54 - INFO - __main__ -   eval_precision = 0.5861\n",
      "09/03/2024 21:43:54 - INFO - __main__ -   eval_recall = 0.6852\n",
      " 40% 407/1024 [08:05<08:59,  1.14it/s]09/03/2024 21:46:52 - WARNING - __main__ - epoch 9 step 408 loss 0.1001\n",
      "[[0.9970757 ]\n",
      " [0.00599298]\n",
      " [0.12599576]\n",
      " ...\n",
      " [0.35653263]\n",
      " [0.9539722 ]\n",
      " [0.21469538]]\n",
      "09/03/2024 21:49:02 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:49:02 - INFO - __main__ -   auc_score = 0.9195\n",
      "09/03/2024 21:49:02 - INFO - __main__ -   eval_f1 = 0.6324\n",
      "09/03/2024 21:49:02 - INFO - __main__ -   eval_precision = 0.633\n",
      "09/03/2024 21:49:02 - INFO - __main__ -   eval_recall = 0.6317\n",
      " 60% 611/1024 [13:13<06:00,  1.14it/s]09/03/2024 21:52:00 - WARNING - __main__ - epoch 9 step 612 loss 0.09656\n",
      "[[0.9979298 ]\n",
      " [0.00659186]\n",
      " [0.19394314]\n",
      " ...\n",
      " [0.57447034]\n",
      " [0.97828364]\n",
      " [0.31175086]]\n",
      "09/03/2024 21:54:10 - INFO - __main__ - ***** Eval results *****\n",
      "09/03/2024 21:54:10 - INFO - __main__ -   auc_score = 0.9194\n",
      "09/03/2024 21:54:10 - INFO - __main__ -   eval_f1 = 0.6211\n",
      "09/03/2024 21:54:10 - INFO - __main__ -   eval_precision = 0.5709\n",
      "09/03/2024 21:54:10 - INFO - __main__ -   eval_recall = 0.6809\n",
      "09/03/2024 21:54:10 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 60% 611/1024 [15:23<10:24,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/single/text_manual/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tn29p-a8ugqd",
    "outputId": "163e8cb0-2842-4176-b853-6510f5af7f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,874,368 || all params: 756,515,840 || trainable%: 2.4949\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:246: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run_lora.py:313: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "09/03/2024 22:18:56 - INFO - __main__ - ***** Test results *****\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   R0 = 0.9698\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   R1 = 0.4526\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   auc_score = 0.9058\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   g_mean = 0.6626\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   test_f1 = 0.5113\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   test_precision = 0.5874\n",
      "09/03/2024 22:18:56 - INFO - __main__ -   test_recall = 0.4526\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codet5p-770m/single/text_manual/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uDD-aJVSRUJ"
   },
   "source": [
    "### CodeReviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNcBnEpUSXoV"
   },
   "source": [
    "#### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9vqOIUOzSgNQ",
    "outputId": "fd2119d6-eea0-4e57-c00d-cbab2033015d"
   },
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVExOOKcQr45"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7ko03kRSfFr",
    "outputId": "d0fc1697-f35b-4000-820b-5aa8215f7447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 10:21:29.746355: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 10:21:29.764730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744885289.786957   13432 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744885289.793746   13432 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 10:21:29.816715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "config.json: 100% 2.13k/2.13k [00:00<00:00, 15.1MB/s]\n",
      "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 9.45MB/s]\n",
      "vocab.json: 100% 575k/575k [00:00<00:00, 912kB/s]\n",
      "merges.txt: 100% 294k/294k [00:00<00:00, 688kB/s]\n",
      "added_tokens.json: 100% 1.87k/1.87k [00:00<00:00, 11.9MB/s]\n",
      "special_tokens_map.json: 100% 913/913 [00:00<00:00, 7.64MB/s]\n",
      "pytorch_model.bin: 100% 892M/892M [00:44<00:00, 19.9MB/s]\n",
      "generation_config.json: 100% 168/168 [00:00<00:00, 1.40MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "model.safetensors:   4% 31.5M/892M [00:00<00:03, 242MB/s]trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "model.safetensors:  18% 157M/892M [00:00<00:02, 331MB/s]04/17/2025 10:22:26 - INFO - __main__ - Training for the first time...\n",
      "model.safetensors: 100% 892M/892M [00:02<00:00, 307MB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [04:53<00:00,  3.50it/s]04/17/2025 10:29:42 - WARNING - __main__ - epoch 0 step 1024 loss 0.27327\n",
      "[[0.6365398 ]\n",
      " [0.1475987 ]\n",
      " [0.03316652]\n",
      " ...\n",
      " [0.11406817]\n",
      " [0.29505348]\n",
      " [0.19600245]]\n",
      "04/17/2025 10:30:24 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:30:24 - INFO - __main__ -   auc_score = 0.8865\n",
      "04/17/2025 10:30:24 - INFO - __main__ -   eval_f1 = 0.1866\n",
      "04/17/2025 10:30:24 - INFO - __main__ -   eval_precision = 0.7246\n",
      "04/17/2025 10:30:24 - INFO - __main__ -   eval_recall = 0.1071\n",
      "100% 1024/1024 [05:37<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 10:35:18 - WARNING - __main__ - epoch 1 step 1024 loss 0.19706\n",
      "[[0.81009704]\n",
      " [0.30683067]\n",
      " [0.04615656]\n",
      " ...\n",
      " [0.1644327 ]\n",
      " [0.5739011 ]\n",
      " [0.2976041 ]]\n",
      "04/17/2025 10:36:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:36:00 - INFO - __main__ -   auc_score = 0.9037\n",
      "04/17/2025 10:36:00 - INFO - __main__ -   eval_f1 = 0.4043\n",
      "04/17/2025 10:36:00 - INFO - __main__ -   eval_precision = 0.7097\n",
      "04/17/2025 10:36:00 - INFO - __main__ -   eval_recall = 0.2827\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 10:40:55 - WARNING - __main__ - epoch 2 step 1024 loss 0.18343\n",
      "[[0.9030902 ]\n",
      " [0.29349017]\n",
      " [0.03286334]\n",
      " ...\n",
      " [0.23383552]\n",
      " [0.7399135 ]\n",
      " [0.3699489 ]]\n",
      "04/17/2025 10:41:37 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:41:37 - INFO - __main__ -   auc_score = 0.9074\n",
      "04/17/2025 10:41:37 - INFO - __main__ -   eval_f1 = 0.5035\n",
      "04/17/2025 10:41:37 - INFO - __main__ -   eval_precision = 0.7183\n",
      "04/17/2025 10:41:37 - INFO - __main__ -   eval_recall = 0.3876\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 10:46:32 - WARNING - __main__ - epoch 3 step 1024 loss 0.17312\n",
      "[[0.9115982 ]\n",
      " [0.09363761]\n",
      " [0.02139539]\n",
      " ...\n",
      " [0.15483919]\n",
      " [0.63724625]\n",
      " [0.21978809]]\n",
      "04/17/2025 10:47:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:47:13 - INFO - __main__ -   auc_score = 0.9085\n",
      "04/17/2025 10:47:13 - INFO - __main__ -   eval_f1 = 0.4602\n",
      "04/17/2025 10:47:13 - INFO - __main__ -   eval_precision = 0.7393\n",
      "04/17/2025 10:47:13 - INFO - __main__ -   eval_recall = 0.334\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 10:52:06 - WARNING - __main__ - epoch 4 step 1024 loss 0.16354\n",
      "[[0.9450201 ]\n",
      " [0.06326379]\n",
      " [0.01523257]\n",
      " ...\n",
      " [0.13286503]\n",
      " [0.5980795 ]\n",
      " [0.14108977]]\n",
      "04/17/2025 10:52:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:52:48 - INFO - __main__ -   auc_score = 0.9057\n",
      "04/17/2025 10:52:48 - INFO - __main__ -   eval_f1 = 0.4816\n",
      "04/17/2025 10:52:48 - INFO - __main__ -   eval_precision = 0.7664\n",
      "04/17/2025 10:52:48 - INFO - __main__ -   eval_recall = 0.3512\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 10:57:41 - WARNING - __main__ - epoch 5 step 1024 loss 0.15566\n",
      "[[0.9594034 ]\n",
      " [0.109773  ]\n",
      " [0.01486532]\n",
      " ...\n",
      " [0.14348535]\n",
      " [0.61962146]\n",
      " [0.13106687]]\n",
      "04/17/2025 10:58:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 10:58:22 - INFO - __main__ -   auc_score = 0.9043\n",
      "04/17/2025 10:58:22 - INFO - __main__ -   eval_f1 = 0.5064\n",
      "04/17/2025 10:58:22 - INFO - __main__ -   eval_precision = 0.7458\n",
      "04/17/2025 10:58:22 - INFO - __main__ -   eval_recall = 0.3833\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:03:17 - WARNING - __main__ - epoch 6 step 1024 loss 0.14836\n",
      "[[0.97398823]\n",
      " [0.07595921]\n",
      " [0.01543859]\n",
      " ...\n",
      " [0.12001567]\n",
      " [0.6594394 ]\n",
      " [0.12094036]]\n",
      "04/17/2025 11:03:59 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:03:59 - INFO - __main__ -   auc_score = 0.9049\n",
      "04/17/2025 11:03:59 - INFO - __main__ -   eval_f1 = 0.535\n",
      "04/17/2025 11:03:59 - INFO - __main__ -   eval_precision = 0.7443\n",
      "04/17/2025 11:03:59 - INFO - __main__ -   eval_recall = 0.4176\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:08:54 - WARNING - __main__ - epoch 7 step 1024 loss 0.14032\n",
      "[[0.97969764]\n",
      " [0.06685055]\n",
      " [0.01335639]\n",
      " ...\n",
      " [0.09284688]\n",
      " [0.5801979 ]\n",
      " [0.07386979]]\n",
      "04/17/2025 11:09:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:09:36 - INFO - __main__ -   auc_score = 0.8999\n",
      "04/17/2025 11:09:36 - INFO - __main__ -   eval_f1 = 0.5346\n",
      "04/17/2025 11:09:36 - INFO - __main__ -   eval_precision = 0.7296\n",
      "04/17/2025 11:09:36 - INFO - __main__ -   eval_recall = 0.4218\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:14:29 - WARNING - __main__ - epoch 8 step 1024 loss 0.13885\n",
      "[[0.9811652 ]\n",
      " [0.06516626]\n",
      " [0.01230601]\n",
      " ...\n",
      " [0.09146281]\n",
      " [0.57170844]\n",
      " [0.08854684]]\n",
      "04/17/2025 11:15:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:15:10 - INFO - __main__ -   auc_score = 0.9006\n",
      "04/17/2025 11:15:10 - INFO - __main__ -   eval_f1 = 0.5447\n",
      "04/17/2025 11:15:10 - INFO - __main__ -   eval_precision = 0.7234\n",
      "04/17/2025 11:15:10 - INFO - __main__ -   eval_recall = 0.4368\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.48it/s]04/17/2025 11:20:05 - WARNING - __main__ - epoch 9 step 1024 loss 0.13429\n",
      "[[0.9826424 ]\n",
      " [0.07019956]\n",
      " [0.01222666]\n",
      " ...\n",
      " [0.1082653 ]\n",
      " [0.61704123]\n",
      " [0.10101883]]\n",
      "04/17/2025 11:20:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:20:47 - INFO - __main__ -   auc_score = 0.901\n",
      "04/17/2025 11:20:47 - INFO - __main__ -   eval_f1 = 0.5462\n",
      "04/17/2025 11:20:47 - INFO - __main__ -   eval_precision = 0.7113\n",
      "04/17/2025 11:20:47 - INFO - __main__ -   eval_recall = 0.4433\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XF5r54mfFYTh",
    "outputId": "c5a600c4-e9b5-4d75-f499-db7d4c8867ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:21:58.404090: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 11:21:58.422742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744888918.445049   35784 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744888918.451813   35784 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 11:21:58.474582: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.35789473684210527\n",
      "recall =  0.35789473684210527\n",
      "04/17/2025 11:23:26 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   R0 = 0.9798\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   R1 = 0.3579\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   auc_score = 0.891\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   g_mean = 0.5922\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   test_f1 = 0.4558\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   test_precision = 0.6273\n",
      "04/17/2025 11:23:26 - INFO - __main__ -   test_recall = 0.3579\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQIpAemyfulk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0ueKi-Ifzem"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaZ93qfkf3bH",
    "outputId": "52750da7-9ee9-4288-966f-7c49f8cf4c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 11:26:47.625560: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 11:26:47.643873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744889207.665695   37641 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744889207.672418   37641 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 11:26:47.694824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "04/17/2025 11:26:53 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [04:53<00:00,  3.49it/s]04/17/2025 11:34:02 - WARNING - __main__ - epoch 0 step 1024 loss 0.27655\n",
      "[[0.63204235]\n",
      " [0.17254405]\n",
      " [0.06505818]\n",
      " ...\n",
      " [0.13935909]\n",
      " [0.4228373 ]\n",
      " [0.24895044]]\n",
      "04/17/2025 11:34:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:34:44 - INFO - __main__ -   auc_score = 0.8864\n",
      "04/17/2025 11:34:44 - INFO - __main__ -   eval_f1 = 0.2667\n",
      "04/17/2025 11:34:44 - INFO - __main__ -   eval_precision = 0.7379\n",
      "04/17/2025 11:34:44 - INFO - __main__ -   eval_recall = 0.1627\n",
      "100% 1024/1024 [05:37<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:39:39 - WARNING - __main__ - epoch 1 step 1024 loss 0.19791\n",
      "[[0.83813465]\n",
      " [0.24088311]\n",
      " [0.03018763]\n",
      " ...\n",
      " [0.15216245]\n",
      " [0.48194614]\n",
      " [0.3568038 ]]\n",
      "04/17/2025 11:40:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:40:21 - INFO - __main__ -   auc_score = 0.9037\n",
      "04/17/2025 11:40:21 - INFO - __main__ -   eval_f1 = 0.375\n",
      "04/17/2025 11:40:21 - INFO - __main__ -   eval_precision = 0.7452\n",
      "04/17/2025 11:40:21 - INFO - __main__ -   eval_recall = 0.2505\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:45:16 - WARNING - __main__ - epoch 2 step 1024 loss 0.18329\n",
      "[[0.8602247 ]\n",
      " [0.29163277]\n",
      " [0.03731764]\n",
      " ...\n",
      " [0.15506105]\n",
      " [0.51211923]\n",
      " [0.33289918]]\n",
      "04/17/2025 11:45:58 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:45:58 - INFO - __main__ -   auc_score = 0.91\n",
      "04/17/2025 11:45:58 - INFO - __main__ -   eval_f1 = 0.4533\n",
      "04/17/2025 11:45:58 - INFO - __main__ -   eval_precision = 0.7356\n",
      "04/17/2025 11:45:58 - INFO - __main__ -   eval_recall = 0.3276\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:50:53 - WARNING - __main__ - epoch 3 step 1024 loss 0.1724\n",
      "[[0.9143861 ]\n",
      " [0.2304433 ]\n",
      " [0.0121896 ]\n",
      " ...\n",
      " [0.11644781]\n",
      " [0.5589673 ]\n",
      " [0.25136617]]\n",
      "04/17/2025 11:51:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:51:35 - INFO - __main__ -   auc_score = 0.9044\n",
      "04/17/2025 11:51:35 - INFO - __main__ -   eval_f1 = 0.4525\n",
      "04/17/2025 11:51:35 - INFO - __main__ -   eval_precision = 0.7653\n",
      "04/17/2025 11:51:35 - INFO - __main__ -   eval_recall = 0.3212\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 11:56:28 - WARNING - __main__ - epoch 4 step 1024 loss 0.16276\n",
      "[[0.9610808 ]\n",
      " [0.40323752]\n",
      " [0.06614038]\n",
      " ...\n",
      " [0.26260087]\n",
      " [0.8205253 ]\n",
      " [0.49250284]]\n",
      "04/17/2025 11:57:10 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 11:57:10 - INFO - __main__ -   auc_score = 0.9109\n",
      "04/17/2025 11:57:10 - INFO - __main__ -   eval_f1 = 0.5674\n",
      "04/17/2025 11:57:10 - INFO - __main__ -   eval_precision = 0.6332\n",
      "04/17/2025 11:57:10 - INFO - __main__ -   eval_recall = 0.5139\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:02:05 - WARNING - __main__ - epoch 5 step 1024 loss 0.154\n",
      "[[0.9738322 ]\n",
      " [0.32863325]\n",
      " [0.00890088]\n",
      " ...\n",
      " [0.07859889]\n",
      " [0.5241734 ]\n",
      " [0.1253305 ]]\n",
      "04/17/2025 12:02:47 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:02:47 - INFO - __main__ -   auc_score = 0.9043\n",
      "04/17/2025 12:02:47 - INFO - __main__ -   eval_f1 = 0.5119\n",
      "04/17/2025 12:02:47 - INFO - __main__ -   eval_precision = 0.7379\n",
      "04/17/2025 12:02:47 - INFO - __main__ -   eval_recall = 0.3919\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.49it/s]04/17/2025 12:07:40 - WARNING - __main__ - epoch 6 step 1024 loss 0.1451\n",
      "[[0.98216426]\n",
      " [0.28528017]\n",
      " [0.00397786]\n",
      " ...\n",
      " [0.08821764]\n",
      " [0.5370453 ]\n",
      " [0.20623907]]\n",
      "04/17/2025 12:08:21 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:08:21 - INFO - __main__ -   auc_score = 0.9018\n",
      "04/17/2025 12:08:21 - INFO - __main__ -   eval_f1 = 0.5164\n",
      "04/17/2025 12:08:21 - INFO - __main__ -   eval_precision = 0.7132\n",
      "04/17/2025 12:08:21 - INFO - __main__ -   eval_recall = 0.4047\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.47it/s]04/17/2025 12:13:14 - WARNING - __main__ - epoch 7 step 1024 loss 0.14074\n",
      "[[0.98769474]\n",
      " [0.36012363]\n",
      " [0.00936703]\n",
      " ...\n",
      " [0.13789618]\n",
      " [0.61524624]\n",
      " [0.20188178]]\n",
      "04/17/2025 12:13:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:13:56 - INFO - __main__ -   auc_score = 0.9002\n",
      "04/17/2025 12:13:56 - INFO - __main__ -   eval_f1 = 0.5548\n",
      "04/17/2025 12:13:56 - INFO - __main__ -   eval_precision = 0.6981\n",
      "04/17/2025 12:13:56 - INFO - __main__ -   eval_recall = 0.4604\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:18:49 - WARNING - __main__ - epoch 8 step 1024 loss 0.1352\n",
      "[[0.99021506]\n",
      " [0.35120583]\n",
      " [0.00475254]\n",
      " ...\n",
      " [0.11622408]\n",
      " [0.5853209 ]\n",
      " [0.1952737 ]]\n",
      "04/17/2025 12:19:31 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:19:31 - INFO - __main__ -   auc_score = 0.8992\n",
      "04/17/2025 12:19:31 - INFO - __main__ -   eval_f1 = 0.5523\n",
      "04/17/2025 12:19:31 - INFO - __main__ -   eval_precision = 0.6948\n",
      "04/17/2025 12:19:31 - INFO - __main__ -   eval_recall = 0.4582\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:24:24 - WARNING - __main__ - epoch 9 step 1024 loss 0.13046\n",
      "[[0.991411  ]\n",
      " [0.36078662]\n",
      " [0.00560175]\n",
      " ...\n",
      " [0.14226897]\n",
      " [0.6307741 ]\n",
      " [0.23377094]]\n",
      "04/17/2025 12:25:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:25:05 - INFO - __main__ -   auc_score = 0.8994\n",
      "04/17/2025 12:25:05 - INFO - __main__ -   eval_f1 = 0.5621\n",
      "04/17/2025 12:25:05 - INFO - __main__ -   eval_precision = 0.6788\n",
      "04/17/2025 12:25:05 - INFO - __main__ -   eval_recall = 0.4797\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dY3FhxmGtq2U",
    "outputId": "75a19b30-ec39-4910-df84-b8d82ed8c57a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 12:26:37.196876: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 12:26:37.215620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744892797.238177   60087 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744892797.245824   60087 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 12:26:37.270011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4189473684210526\n",
      "recall =  0.4189473684210526\n",
      "04/17/2025 12:28:04 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   R0 = 0.9664\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   R1 = 0.4189\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   auc_score = 0.8945\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   g_mean = 0.6363\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   test_f1 = 0.4727\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   test_precision = 0.5422\n",
      "04/17/2025 12:28:04 - INFO - __main__ -   test_recall = 0.4189\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtRbeihQudLl"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "witgQ3o0uXhT",
    "outputId": "b650eb35-ac2d-464f-a44f-aebad22f19c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 12:29:45.187945: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 12:29:45.206586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744892985.228925   61311 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744892985.235918   61311 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 12:29:45.258710: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "04/17/2025 12:29:51 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:37:01 - WARNING - __main__ - epoch 0 step 1024 loss 0.26473\n",
      "[[0.742003  ]\n",
      " [0.3298656 ]\n",
      " [0.0893624 ]\n",
      " ...\n",
      " [0.18584308]\n",
      " [0.5681983 ]\n",
      " [0.36474335]]\n",
      "04/17/2025 12:37:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:37:43 - INFO - __main__ -   auc_score = 0.8892\n",
      "04/17/2025 12:37:43 - INFO - __main__ -   eval_f1 = 0.3743\n",
      "04/17/2025 12:37:43 - INFO - __main__ -   eval_precision = 0.5899\n",
      "04/17/2025 12:37:43 - INFO - __main__ -   eval_recall = 0.2741\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:42:38 - WARNING - __main__ - epoch 1 step 1024 loss 0.19737\n",
      "[[0.8200863 ]\n",
      " [0.20689052]\n",
      " [0.02981657]\n",
      " ...\n",
      " [0.15378538]\n",
      " [0.5757625 ]\n",
      " [0.33988452]]\n",
      "04/17/2025 12:43:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:43:20 - INFO - __main__ -   auc_score = 0.9038\n",
      "04/17/2025 12:43:20 - INFO - __main__ -   eval_f1 = 0.3894\n",
      "04/17/2025 12:43:20 - INFO - __main__ -   eval_precision = 0.7143\n",
      "04/17/2025 12:43:20 - INFO - __main__ -   eval_recall = 0.2677\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.51it/s]04/17/2025 12:48:15 - WARNING - __main__ - epoch 2 step 1024 loss 0.18321\n",
      "[[0.86808884]\n",
      " [0.16808021]\n",
      " [0.0289914 ]\n",
      " ...\n",
      " [0.19877076]\n",
      " [0.6222052 ]\n",
      " [0.4281505 ]]\n",
      "04/17/2025 12:48:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:48:57 - INFO - __main__ -   auc_score = 0.9047\n",
      "04/17/2025 12:48:57 - INFO - __main__ -   eval_f1 = 0.4141\n",
      "04/17/2025 12:48:57 - INFO - __main__ -   eval_precision = 0.7297\n",
      "04/17/2025 12:48:57 - INFO - __main__ -   eval_recall = 0.2891\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:53:52 - WARNING - __main__ - epoch 3 step 1024 loss 0.17541\n",
      "[[0.870464  ]\n",
      " [0.2200057 ]\n",
      " [0.02714863]\n",
      " ...\n",
      " [0.14049476]\n",
      " [0.50292087]\n",
      " [0.39315537]]\n",
      "04/17/2025 12:54:33 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 12:54:33 - INFO - __main__ -   auc_score = 0.9018\n",
      "04/17/2025 12:54:33 - INFO - __main__ -   eval_f1 = 0.427\n",
      "04/17/2025 12:54:33 - INFO - __main__ -   eval_precision = 0.7554\n",
      "04/17/2025 12:54:33 - INFO - __main__ -   eval_recall = 0.2976\n",
      "100% 1024/1024 [05:38<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 12:59:30 - WARNING - __main__ - epoch 4 step 1024 loss 0.16615\n",
      "[[0.9221503 ]\n",
      " [0.13186005]\n",
      " [0.01512792]\n",
      " ...\n",
      " [0.1488967 ]\n",
      " [0.72815233]\n",
      " [0.48309097]]\n",
      "04/17/2025 13:00:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:00:12 - INFO - __main__ -   auc_score = 0.9093\n",
      "04/17/2025 13:00:12 - INFO - __main__ -   eval_f1 = 0.4835\n",
      "04/17/2025 13:00:12 - INFO - __main__ -   eval_precision = 0.7284\n",
      "04/17/2025 13:00:12 - INFO - __main__ -   eval_recall = 0.3619\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 13:05:07 - WARNING - __main__ - epoch 5 step 1024 loss 0.15974\n",
      "[[0.94991565]\n",
      " [0.2536731 ]\n",
      " [0.02347926]\n",
      " ...\n",
      " [0.14843856]\n",
      " [0.7795545 ]\n",
      " [0.5458883 ]]\n",
      "04/17/2025 13:05:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:05:48 - INFO - __main__ -   auc_score = 0.9093\n",
      "04/17/2025 13:05:48 - INFO - __main__ -   eval_f1 = 0.5535\n",
      "04/17/2025 13:05:48 - INFO - __main__ -   eval_precision = 0.709\n",
      "04/17/2025 13:05:48 - INFO - __main__ -   eval_recall = 0.454\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 13:10:44 - WARNING - __main__ - epoch 6 step 1024 loss 0.15359\n",
      "[[0.9627219 ]\n",
      " [0.15983161]\n",
      " [0.01115546]\n",
      " ...\n",
      " [0.09592967]\n",
      " [0.8052506 ]\n",
      " [0.49830785]]\n",
      "04/17/2025 13:11:25 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:11:25 - INFO - __main__ -   auc_score = 0.908\n",
      "04/17/2025 13:11:25 - INFO - __main__ -   eval_f1 = 0.5425\n",
      "04/17/2025 13:11:25 - INFO - __main__ -   eval_precision = 0.7336\n",
      "04/17/2025 13:11:25 - INFO - __main__ -   eval_recall = 0.4304\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.49it/s]04/17/2025 13:16:18 - WARNING - __main__ - epoch 7 step 1024 loss 0.14619\n",
      "[[0.9641489 ]\n",
      " [0.11023768]\n",
      " [0.00516343]\n",
      " ...\n",
      " [0.0428586 ]\n",
      " [0.7476849 ]\n",
      " [0.3629375 ]]\n",
      "04/17/2025 13:17:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:17:00 - INFO - __main__ -   auc_score = 0.9013\n",
      "04/17/2025 13:17:00 - INFO - __main__ -   eval_f1 = 0.4819\n",
      "04/17/2025 13:17:00 - INFO - __main__ -   eval_precision = 0.7477\n",
      "04/17/2025 13:17:00 - INFO - __main__ -   eval_recall = 0.3555\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.47it/s]04/17/2025 13:21:53 - WARNING - __main__ - epoch 8 step 1024 loss 0.14236\n",
      "[[0.9743903 ]\n",
      " [0.13522844]\n",
      " [0.0050057 ]\n",
      " ...\n",
      " [0.07600159]\n",
      " [0.8445548 ]\n",
      " [0.47507918]]\n",
      "04/17/2025 13:22:34 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:22:34 - INFO - __main__ -   auc_score = 0.9034\n",
      "04/17/2025 13:22:34 - INFO - __main__ -   eval_f1 = 0.5333\n",
      "04/17/2025 13:22:34 - INFO - __main__ -   eval_precision = 0.7313\n",
      "04/17/2025 13:22:34 - INFO - __main__ -   eval_recall = 0.4197\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.51it/s]04/17/2025 13:27:27 - WARNING - __main__ - epoch 9 step 1024 loss 0.13714\n",
      "[[0.9752679 ]\n",
      " [0.12595779]\n",
      " [0.00414699]\n",
      " ...\n",
      " [0.06373704]\n",
      " [0.8361204 ]\n",
      " [0.44156155]]\n",
      "04/17/2025 13:28:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:28:09 - INFO - __main__ -   auc_score = 0.9019\n",
      "04/17/2025 13:28:09 - INFO - __main__ -   eval_f1 = 0.5201\n",
      "04/17/2025 13:28:09 - INFO - __main__ -   eval_precision = 0.7344\n",
      "04/17/2025 13:28:09 - INFO - __main__ -   eval_recall = 0.4026\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tX7sp4hl8Fk8",
    "outputId": "0887dfa3-4db1-45fa-99c2-2ccb953929c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 13:29:18.114046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 13:29:18.132331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744896558.154538   83363 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744896558.161204   83363 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 13:29:18.184031: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.35368421052631577\n",
      "recall =  0.35368421052631577\n",
      "04/17/2025 13:30:45 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   R0 = 0.9778\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   R1 = 0.3537\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   auc_score = 0.8934\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   g_mean = 0.5881\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   test_f1 = 0.4456\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   test_precision = 0.6022\n",
      "04/17/2025 13:30:45 - INFO - __main__ -   test_recall = 0.3537\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qleKUlr9AH9"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAvKcUEK9C80",
    "outputId": "deb94d38-1287-4b21-e8da-536fa5ce75e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 13:33:32.332694: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 13:33:32.350983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744896812.373020   84969 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744896812.379724   84969 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 13:33:32.402351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "04/17/2025 13:33:38 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [04:53<00:00,  3.50it/s]04/17/2025 13:40:48 - WARNING - __main__ - epoch 0 step 1024 loss 0.266\n",
      "[[0.7351749 ]\n",
      " [0.21793702]\n",
      " [0.05394339]\n",
      " ...\n",
      " [0.1686793 ]\n",
      " [0.51211107]\n",
      " [0.31440648]]\n",
      "04/17/2025 13:41:30 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:41:30 - INFO - __main__ -   auc_score = 0.8867\n",
      "04/17/2025 13:41:30 - INFO - __main__ -   eval_f1 = 0.3137\n",
      "04/17/2025 13:41:30 - INFO - __main__ -   eval_precision = 0.6621\n",
      "04/17/2025 13:41:30 - INFO - __main__ -   eval_recall = 0.2056\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 13:46:25 - WARNING - __main__ - epoch 1 step 1024 loss 0.19712\n",
      "[[0.79647315]\n",
      " [0.28511694]\n",
      " [0.03835655]\n",
      " ...\n",
      " [0.20019722]\n",
      " [0.597224  ]\n",
      " [0.38053313]]\n",
      "04/17/2025 13:47:07 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:47:07 - INFO - __main__ -   auc_score = 0.9056\n",
      "04/17/2025 13:47:07 - INFO - __main__ -   eval_f1 = 0.3754\n",
      "04/17/2025 13:47:07 - INFO - __main__ -   eval_precision = 0.7126\n",
      "04/17/2025 13:47:07 - INFO - __main__ -   eval_recall = 0.2548\n",
      "100% 1024/1024 [05:37<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 13:52:02 - WARNING - __main__ - epoch 2 step 1024 loss 0.18494\n",
      "[[0.82492584]\n",
      " [0.18920395]\n",
      " [0.01857044]\n",
      " ...\n",
      " [0.12425624]\n",
      " [0.4959277 ]\n",
      " [0.2592163 ]]\n",
      "04/17/2025 13:52:44 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:52:44 - INFO - __main__ -   auc_score = 0.9042\n",
      "04/17/2025 13:52:44 - INFO - __main__ -   eval_f1 = 0.3277\n",
      "04/17/2025 13:52:44 - INFO - __main__ -   eval_precision = 0.776\n",
      "04/17/2025 13:52:44 - INFO - __main__ -   eval_recall = 0.2077\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 13:57:37 - WARNING - __main__ - epoch 3 step 1024 loss 0.17596\n",
      "[[0.8681514 ]\n",
      " [0.234959  ]\n",
      " [0.02022084]\n",
      " ...\n",
      " [0.13213442]\n",
      " [0.364629  ]\n",
      " [0.14194383]]\n",
      "04/17/2025 13:58:18 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 13:58:18 - INFO - __main__ -   auc_score = 0.9039\n",
      "04/17/2025 13:58:18 - INFO - __main__ -   eval_f1 = 0.38\n",
      "04/17/2025 13:58:18 - INFO - __main__ -   eval_precision = 0.7662\n",
      "04/17/2025 13:58:18 - INFO - __main__ -   eval_recall = 0.2527\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:03:14 - WARNING - __main__ - epoch 4 step 1024 loss 0.167\n",
      "[[0.93811727]\n",
      " [0.3891934 ]\n",
      " [0.02853513]\n",
      " ...\n",
      " [0.24190767]\n",
      " [0.539164  ]\n",
      " [0.22093615]]\n",
      "04/17/2025 14:03:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:03:56 - INFO - __main__ -   auc_score = 0.9067\n",
      "04/17/2025 14:03:56 - INFO - __main__ -   eval_f1 = 0.4884\n",
      "04/17/2025 14:03:56 - INFO - __main__ -   eval_precision = 0.7602\n",
      "04/17/2025 14:03:56 - INFO - __main__ -   eval_recall = 0.3597\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.51it/s]04/17/2025 14:08:50 - WARNING - __main__ - epoch 5 step 1024 loss 0.15832\n",
      "[[0.9546518 ]\n",
      " [0.34014332]\n",
      " [0.02090062]\n",
      " ...\n",
      " [0.28056318]\n",
      " [0.69712865]\n",
      " [0.19208133]]\n",
      "04/17/2025 14:09:32 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:09:32 - INFO - __main__ -   auc_score = 0.907\n",
      "04/17/2025 14:09:32 - INFO - __main__ -   eval_f1 = 0.5216\n",
      "04/17/2025 14:09:32 - INFO - __main__ -   eval_precision = 0.748\n",
      "04/17/2025 14:09:32 - INFO - __main__ -   eval_recall = 0.4004\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:14:27 - WARNING - __main__ - epoch 6 step 1024 loss 0.15103\n",
      "[[0.9716    ]\n",
      " [0.3438775 ]\n",
      " [0.01673898]\n",
      " ...\n",
      " [0.26749957]\n",
      " [0.67253447]\n",
      " [0.17364347]]\n",
      "04/17/2025 14:15:09 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:15:09 - INFO - __main__ -   auc_score = 0.905\n",
      "04/17/2025 14:15:09 - INFO - __main__ -   eval_f1 = 0.5078\n",
      "04/17/2025 14:15:09 - INFO - __main__ -   eval_precision = 0.7521\n",
      "04/17/2025 14:15:09 - INFO - __main__ -   eval_recall = 0.3833\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:20:02 - WARNING - __main__ - epoch 7 step 1024 loss 0.14644\n",
      "[[0.97689044]\n",
      " [0.38498184]\n",
      " [0.0215186 ]\n",
      " ...\n",
      " [0.32605928]\n",
      " [0.7749179 ]\n",
      " [0.24424326]]\n",
      "04/17/2025 14:20:43 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:20:43 - INFO - __main__ -   auc_score = 0.9038\n",
      "04/17/2025 14:20:43 - INFO - __main__ -   eval_f1 = 0.5386\n",
      "04/17/2025 14:20:43 - INFO - __main__ -   eval_precision = 0.7316\n",
      "04/17/2025 14:20:43 - INFO - __main__ -   eval_recall = 0.4261\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:25:38 - WARNING - __main__ - epoch 8 step 1024 loss 0.14142\n",
      "[[0.98133713]\n",
      " [0.4460243 ]\n",
      " [0.02117596]\n",
      " ...\n",
      " [0.33866572]\n",
      " [0.8379193 ]\n",
      " [0.2880531 ]]\n",
      "04/17/2025 14:26:20 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:26:20 - INFO - __main__ -   auc_score = 0.9048\n",
      "04/17/2025 14:26:20 - INFO - __main__ -   eval_f1 = 0.5663\n",
      "04/17/2025 14:26:20 - INFO - __main__ -   eval_precision = 0.7097\n",
      "04/17/2025 14:26:20 - INFO - __main__ -   eval_recall = 0.4711\n",
      "100% 1024/1024 [05:36<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:31:15 - WARNING - __main__ - epoch 9 step 1024 loss 0.13832\n",
      "[[0.9815824 ]\n",
      " [0.43477193]\n",
      " [0.01878216]\n",
      " ...\n",
      " [0.2866737 ]\n",
      " [0.78814703]\n",
      " [0.16919012]]\n",
      "04/17/2025 14:31:57 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:31:57 - INFO - __main__ -   auc_score = 0.9018\n",
      "04/17/2025 14:31:57 - INFO - __main__ -   eval_f1 = 0.5374\n",
      "04/17/2025 14:31:57 - INFO - __main__ -   eval_precision = 0.7153\n",
      "04/17/2025 14:31:57 - INFO - __main__ -   eval_recall = 0.4304\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lerWruY_Km8u",
    "outputId": "fa6a2489-14fc-4e51-acc6-38be41d265b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:32:46.455432: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 14:32:46.473996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744900366.496392  107033 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744900366.503105  107033 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 14:32:46.525730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.3705263157894737\n",
      "recall =  0.3705263157894737\n",
      "04/17/2025 14:34:14 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   R0 = 0.9768\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   R1 = 0.3705\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   auc_score = 0.8918\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   g_mean = 0.6016\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   test_f1 = 0.4589\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   test_precision = 0.6027\n",
      "04/17/2025 14:34:14 - INFO - __main__ -   test_recall = 0.3705\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwRB2Z8gLef0"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpW27ibULhsB",
    "outputId": "15fa5c1e-c570-454c-f9b1-ec47b2bebacc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:36:44.884098: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 14:36:44.902934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744900604.926158  108543 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744900604.933324  108543 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 14:36:44.956111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "04/17/2025 14:36:51 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [04:53<00:00,  3.49it/s]04/17/2025 14:44:00 - WARNING - __main__ - epoch 0 step 1024 loss 0.26269\n",
      "[[0.74229944]\n",
      " [0.1767954 ]\n",
      " [0.05263456]\n",
      " ...\n",
      " [0.16284898]\n",
      " [0.49165386]\n",
      " [0.31112033]]\n",
      "04/17/2025 14:44:42 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:44:42 - INFO - __main__ -   auc_score = 0.897\n",
      "04/17/2025 14:44:42 - INFO - __main__ -   eval_f1 = 0.3049\n",
      "04/17/2025 14:44:42 - INFO - __main__ -   eval_precision = 0.7\n",
      "04/17/2025 14:44:42 - INFO - __main__ -   eval_recall = 0.1949\n",
      "100% 1024/1024 [05:37<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.49it/s]04/17/2025 14:49:37 - WARNING - __main__ - epoch 1 step 1024 loss 0.19379\n",
      "[[0.8515468 ]\n",
      " [0.3145612 ]\n",
      " [0.0881822 ]\n",
      " ...\n",
      " [0.23977286]\n",
      " [0.72241586]\n",
      " [0.4653366 ]]\n",
      "04/17/2025 14:50:19 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:50:19 - INFO - __main__ -   auc_score = 0.9069\n",
      "04/17/2025 14:50:19 - INFO - __main__ -   eval_f1 = 0.4743\n",
      "04/17/2025 14:50:19 - INFO - __main__ -   eval_precision = 0.6458\n",
      "04/17/2025 14:50:19 - INFO - __main__ -   eval_recall = 0.3747\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 14:55:15 - WARNING - __main__ - epoch 2 step 1024 loss 0.18364\n",
      "[[0.88125694]\n",
      " [0.2891704 ]\n",
      " [0.07089529]\n",
      " ...\n",
      " [0.22883621]\n",
      " [0.73464316]\n",
      " [0.5077861 ]]\n",
      "04/17/2025 14:55:56 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 14:55:56 - INFO - __main__ -   auc_score = 0.9065\n",
      "04/17/2025 14:55:56 - INFO - __main__ -   eval_f1 = 0.4937\n",
      "04/17/2025 14:55:56 - INFO - __main__ -   eval_precision = 0.708\n",
      "04/17/2025 14:55:56 - INFO - __main__ -   eval_recall = 0.379\n",
      "100% 1024/1024 [05:37<00:00,  3.04it/s]\n",
      "100% 1023/1024 [04:53<00:00,  3.48it/s]04/17/2025 15:00:53 - WARNING - __main__ - epoch 3 step 1024 loss 0.17403\n",
      "[[0.8982254 ]\n",
      " [0.32787344]\n",
      " [0.05192272]\n",
      " ...\n",
      " [0.19625393]\n",
      " [0.74392295]\n",
      " [0.44836736]]\n",
      "04/17/2025 15:01:35 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:01:35 - INFO - __main__ -   auc_score = 0.9104\n",
      "04/17/2025 15:01:35 - INFO - __main__ -   eval_f1 = 0.516\n",
      "04/17/2025 15:01:35 - INFO - __main__ -   eval_precision = 0.74\n",
      "04/17/2025 15:01:35 - INFO - __main__ -   eval_recall = 0.3961\n",
      "100% 1024/1024 [05:38<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:53<00:00,  3.48it/s]04/17/2025 15:06:31 - WARNING - __main__ - epoch 4 step 1024 loss 0.1654\n",
      "[[0.91104054]\n",
      " [0.21169616]\n",
      " [0.01907665]\n",
      " ...\n",
      " [0.17848445]\n",
      " [0.75504786]\n",
      " [0.4400328 ]]\n",
      "04/17/2025 15:07:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:07:13 - INFO - __main__ -   auc_score = 0.9118\n",
      "04/17/2025 15:07:13 - INFO - __main__ -   eval_f1 = 0.5098\n",
      "04/17/2025 15:07:13 - INFO - __main__ -   eval_precision = 0.7368\n",
      "04/17/2025 15:07:13 - INFO - __main__ -   eval_recall = 0.3897\n",
      "100% 1024/1024 [05:35<00:00,  3.05it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.49it/s]04/17/2025 15:12:06 - WARNING - __main__ - epoch 5 step 1024 loss 0.15648\n",
      "[[0.949277  ]\n",
      " [0.32107773]\n",
      " [0.02348038]\n",
      " ...\n",
      " [0.11989379]\n",
      " [0.73012984]\n",
      " [0.3860304 ]]\n",
      "04/17/2025 15:12:48 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:12:48 - INFO - __main__ -   auc_score = 0.91\n",
      "04/17/2025 15:12:48 - INFO - __main__ -   eval_f1 = 0.5504\n",
      "04/17/2025 15:12:48 - INFO - __main__ -   eval_precision = 0.7566\n",
      "04/17/2025 15:12:48 - INFO - __main__ -   eval_recall = 0.4325\n",
      "100% 1024/1024 [05:37<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:53<00:00,  3.48it/s]04/17/2025 15:17:44 - WARNING - __main__ - epoch 6 step 1024 loss 0.1483\n",
      "[[0.9819083 ]\n",
      " [0.41134742]\n",
      " [0.0337836 ]\n",
      " ...\n",
      " [0.2516699 ]\n",
      " [0.8880021 ]\n",
      " [0.59565693]]\n",
      "04/17/2025 15:18:26 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:18:26 - INFO - __main__ -   auc_score = 0.9136\n",
      "04/17/2025 15:18:26 - INFO - __main__ -   eval_f1 = 0.6007\n",
      "04/17/2025 15:18:26 - INFO - __main__ -   eval_precision = 0.6582\n",
      "04/17/2025 15:18:26 - INFO - __main__ -   eval_recall = 0.5525\n",
      "100% 1024/1024 [05:38<00:00,  3.03it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 15:23:22 - WARNING - __main__ - epoch 7 step 1024 loss 0.14217\n",
      "[[0.9784853 ]\n",
      " [0.31055838]\n",
      " [0.02053706]\n",
      " ...\n",
      " [0.152414  ]\n",
      " [0.8289953 ]\n",
      " [0.4426698 ]]\n",
      "04/17/2025 15:24:04 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:24:04 - INFO - __main__ -   auc_score = 0.9106\n",
      "04/17/2025 15:24:04 - INFO - __main__ -   eval_f1 = 0.5779\n",
      "04/17/2025 15:24:04 - INFO - __main__ -   eval_precision = 0.7081\n",
      "04/17/2025 15:24:04 - INFO - __main__ -   eval_recall = 0.4882\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 15:28:56 - WARNING - __main__ - epoch 8 step 1024 loss 0.1362\n",
      "[[0.98474276]\n",
      " [0.2557927 ]\n",
      " [0.01389875]\n",
      " ...\n",
      " [0.17684434]\n",
      " [0.8509945 ]\n",
      " [0.48995408]]\n",
      "04/17/2025 15:29:38 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:29:38 - INFO - __main__ -   auc_score = 0.9095\n",
      "04/17/2025 15:29:38 - INFO - __main__ -   eval_f1 = 0.5841\n",
      "04/17/2025 15:29:38 - INFO - __main__ -   eval_precision = 0.713\n",
      "04/17/2025 15:29:38 - INFO - __main__ -   eval_recall = 0.4946\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n",
      "100% 1023/1024 [04:52<00:00,  3.50it/s]04/17/2025 15:34:31 - WARNING - __main__ - epoch 9 step 1024 loss 0.13224\n",
      "[[0.98613054]\n",
      " [0.23846593]\n",
      " [0.01147553]\n",
      " ...\n",
      " [0.17356586]\n",
      " [0.84874105]\n",
      " [0.4875122 ]]\n",
      "04/17/2025 15:35:13 - INFO - __main__ - ***** Eval results *****\n",
      "04/17/2025 15:35:13 - INFO - __main__ -   auc_score = 0.9091\n",
      "04/17/2025 15:35:13 - INFO - __main__ -   eval_f1 = 0.5806\n",
      "04/17/2025 15:35:13 - INFO - __main__ -   eval_precision = 0.7206\n",
      "04/17/2025 15:35:13 - INFO - __main__ -   eval_recall = 0.4861\n",
      "100% 1024/1024 [05:34<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_train \\\n",
    "   --use_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XevoZMH2ZgXd",
    "outputId": "7f3bc80e-4f20-48e3-f839-d3d974283204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:37:55.083749: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 15:37:55.102210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744904275.124395  131309 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744904275.131177  131309 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 15:37:55.153956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 7,077,888 || all params: 230,050,560 || trainable%: 3.0767\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.4652631578947368\n",
      "recall =  0.4652631578947368\n",
      "04/17/2025 15:39:22 - INFO - __main__ - ***** Test results *****\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   R0 = 0.9664\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   R1 = 0.4653\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   auc_score = 0.8955\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   g_mean = 0.6706\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   test_f1 = 0.5116\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   test_precision = 0.5681\n",
      "04/17/2025 15:39:22 - INFO - __main__ -   test_recall = 0.4653\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_lora.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine_lora/codereviewer/concat/checkpoints \\\n",
    "   --pretrained_model codereviewer \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 768 \\\n",
    "   --do_test \\\n",
    "   --use_lora \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dDBTnJnPsbt"
   },
   "source": [
    "### ModernBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Cz_5qXZCHMt"
   },
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ravqy9ZWPzvR",
    "outputId": "4f0ba1b0-5609-41bf-a775-bf59411dfeb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 01:54:27.839283: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 01:54:27.856907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 01:54:27.878019: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 01:54:27.884391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 01:54:27.899728: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 01:54:29.253327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 01:54:32 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:42<02:35,  2.65it/s]01/08/2025 01:57:22 - WARNING - __main__ - epoch 0 step 102 loss 0.27434\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 01:57:44 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 01:57:44 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 01:57:44 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 01:57:44 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [01:43<02:01,  2.55it/s]01/08/2025 01:58:23 - WARNING - __main__ - epoch 0 step 204 loss 0.24463\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 01:58:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 01:58:45 - INFO - __main__ -   eval_f1 = 0.1597\n",
      "01/08/2025 01:58:45 - INFO - __main__ -   eval_precision = 0.7119\n",
      "01/08/2025 01:58:45 - INFO - __main__ -   eval_recall = 0.0899\n",
      " 60% 305/512 [02:49<01:19,  2.61it/s]01/08/2025 01:59:29 - WARNING - __main__ - epoch 0 step 306 loss 0.22377\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 01:59:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 01:59:50 - INFO - __main__ -   eval_f1 = 0.2425\n",
      "01/08/2025 01:59:50 - INFO - __main__ -   eval_precision = 0.6765\n",
      "01/08/2025 01:59:50 - INFO - __main__ -   eval_recall = 0.1478\n",
      " 79% 407/512 [03:55<00:41,  2.52it/s]01/08/2025 02:00:35 - WARNING - __main__ - epoch 0 step 408 loss 0.22404\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:00:57 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:00:57 - INFO - __main__ -   eval_f1 = 0.4141\n",
      "01/08/2025 02:00:57 - INFO - __main__ -   eval_precision = 0.6589\n",
      "01/08/2025 02:00:57 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 99% 509/512 [05:02<00:01,  2.49it/s]01/08/2025 02:01:42 - WARNING - __main__ - epoch 0 step 510 loss 0.22023\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:02:04 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:02:04 - INFO - __main__ -   eval_f1 = 0.0335\n",
      "01/08/2025 02:02:04 - INFO - __main__ -   eval_precision = 0.8\n",
      "01/08/2025 02:02:04 - INFO - __main__ -   eval_recall = 0.0171\n",
      "100% 512/512 [05:25<00:00,  1.57it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:35,  2.65it/s]01/08/2025 02:02:44 - WARNING - __main__ - epoch 1 step 102 loss 0.20964\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:03:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:03:06 - INFO - __main__ -   eval_f1 = 0.266\n",
      "01/08/2025 02:03:06 - INFO - __main__ -   eval_precision = 0.6875\n",
      "01/08/2025 02:03:06 - INFO - __main__ -   eval_recall = 0.1649\n",
      " 40% 203/512 [01:41<01:58,  2.60it/s]01/08/2025 02:03:46 - WARNING - __main__ - epoch 1 step 204 loss 0.20116\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:04:08 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:04:08 - INFO - __main__ -   eval_f1 = 0.1784\n",
      "01/08/2025 02:04:08 - INFO - __main__ -   eval_precision = 0.7833\n",
      "01/08/2025 02:04:08 - INFO - __main__ -   eval_recall = 0.1006\n",
      " 60% 305/512 [02:43<01:25,  2.43it/s]01/08/2025 02:04:48 - WARNING - __main__ - epoch 1 step 306 loss 0.21404\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:05:10 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:05:10 - INFO - __main__ -   eval_f1 = 0.3781\n",
      "01/08/2025 02:05:10 - INFO - __main__ -   eval_precision = 0.6994\n",
      "01/08/2025 02:05:10 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 79% 407/512 [03:44<00:41,  2.52it/s]01/08/2025 02:05:50 - WARNING - __main__ - epoch 1 step 408 loss 0.18789\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:06:11 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:06:11 - INFO - __main__ -   eval_f1 = 0.4624\n",
      "01/08/2025 02:06:11 - INFO - __main__ -   eval_precision = 0.6849\n",
      "01/08/2025 02:06:11 - INFO - __main__ -   eval_recall = 0.349\n",
      " 99% 509/512 [04:51<00:01,  2.56it/s]01/08/2025 02:06:56 - WARNING - __main__ - epoch 1 step 510 loss 0.18581\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:07:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:07:18 - INFO - __main__ -   eval_f1 = 0.4735\n",
      "01/08/2025 02:07:18 - INFO - __main__ -   eval_precision = 0.5581\n",
      "01/08/2025 02:07:18 - INFO - __main__ -   eval_recall = 0.4111\n",
      "100% 512/512 [05:18<00:00,  1.61it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:32,  2.69it/s]01/08/2025 02:08:04 - WARNING - __main__ - epoch 2 step 102 loss 0.16505\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:08:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:08:26 - INFO - __main__ -   eval_f1 = 0.4932\n",
      "01/08/2025 02:08:26 - INFO - __main__ -   eval_precision = 0.5228\n",
      "01/08/2025 02:08:26 - INFO - __main__ -   eval_recall = 0.4668\n",
      " 40% 203/512 [01:46<01:55,  2.68it/s]01/08/2025 02:09:10 - WARNING - __main__ - epoch 2 step 204 loss 0.18552\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:09:32 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:09:32 - INFO - __main__ -   eval_f1 = 0.4774\n",
      "01/08/2025 02:09:32 - INFO - __main__ -   eval_precision = 0.6006\n",
      "01/08/2025 02:09:32 - INFO - __main__ -   eval_recall = 0.3961\n",
      " 60% 305/512 [02:47<01:15,  2.76it/s]01/08/2025 02:10:11 - WARNING - __main__ - epoch 2 step 306 loss 0.16684\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:10:33 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:10:33 - INFO - __main__ -   eval_f1 = 0.4959\n",
      "01/08/2025 02:10:33 - INFO - __main__ -   eval_precision = 0.5404\n",
      "01/08/2025 02:10:33 - INFO - __main__ -   eval_recall = 0.4582\n",
      " 79% 407/512 [03:54<00:43,  2.43it/s]01/08/2025 02:11:18 - WARNING - __main__ - epoch 2 step 408 loss 0.15876\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:11:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:11:40 - INFO - __main__ -   eval_f1 = 0.4267\n",
      "01/08/2025 02:11:40 - INFO - __main__ -   eval_precision = 0.6622\n",
      "01/08/2025 02:11:40 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 99% 509/512 [04:56<00:01,  2.74it/s]01/08/2025 02:12:20 - WARNING - __main__ - epoch 2 step 510 loss 0.15351\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:12:42 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:12:42 - INFO - __main__ -   eval_f1 = 0.4248\n",
      "01/08/2025 02:12:42 - INFO - __main__ -   eval_precision = 0.6825\n",
      "01/08/2025 02:12:42 - INFO - __main__ -   eval_recall = 0.3084\n",
      "100% 512/512 [05:18<00:00,  1.61it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:43,  2.51it/s]01/08/2025 02:13:22 - WARNING - __main__ - epoch 3 step 102 loss 0.11896\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:13:44 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:13:44 - INFO - __main__ -   eval_f1 = 0.4411\n",
      "01/08/2025 02:13:44 - INFO - __main__ -   eval_precision = 0.5235\n",
      "01/08/2025 02:13:44 - INFO - __main__ -   eval_recall = 0.3812\n",
      " 40% 203/512 [01:41<02:03,  2.50it/s]01/08/2025 02:14:24 - WARNING - __main__ - epoch 3 step 204 loss 0.13686\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:14:46 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:14:46 - INFO - __main__ -   eval_f1 = 0.429\n",
      "01/08/2025 02:14:46 - INFO - __main__ -   eval_precision = 0.5925\n",
      "01/08/2025 02:14:46 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 60% 305/512 [02:42<01:25,  2.42it/s]01/08/2025 02:15:25 - WARNING - __main__ - epoch 3 step 306 loss 0.11588\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:15:47 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:15:47 - INFO - __main__ -   eval_f1 = 0.2726\n",
      "01/08/2025 02:15:47 - INFO - __main__ -   eval_precision = 0.6667\n",
      "01/08/2025 02:15:47 - INFO - __main__ -   eval_recall = 0.1713\n",
      " 79% 407/512 [03:45<00:39,  2.65it/s]01/08/2025 02:16:28 - WARNING - __main__ - epoch 3 step 408 loss 0.14433\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:16:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:16:50 - INFO - __main__ -   eval_f1 = 0.3975\n",
      "01/08/2025 02:16:50 - INFO - __main__ -   eval_precision = 0.4694\n",
      "01/08/2025 02:16:50 - INFO - __main__ -   eval_recall = 0.3448\n",
      " 99% 509/512 [04:46<00:01,  2.39it/s]01/08/2025 02:17:29 - WARNING - __main__ - epoch 3 step 510 loss 0.13232\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:17:51 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:17:51 - INFO - __main__ -   eval_f1 = 0.3862\n",
      "01/08/2025 02:17:51 - INFO - __main__ -   eval_precision = 0.5903\n",
      "01/08/2025 02:17:51 - INFO - __main__ -   eval_recall = 0.2869\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:41,  2.54it/s]01/08/2025 02:18:32 - WARNING - __main__ - epoch 4 step 102 loss 0.08673\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:18:54 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:18:54 - INFO - __main__ -   eval_f1 = 0.3782\n",
      "01/08/2025 02:18:54 - INFO - __main__ -   eval_precision = 0.4127\n",
      "01/08/2025 02:18:54 - INFO - __main__ -   eval_recall = 0.349\n",
      " 40% 203/512 [01:42<01:53,  2.73it/s]01/08/2025 02:19:34 - WARNING - __main__ - epoch 4 step 204 loss 0.09246\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:19:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:19:56 - INFO - __main__ -   eval_f1 = 0.376\n",
      "01/08/2025 02:19:56 - INFO - __main__ -   eval_precision = 0.3912\n",
      "01/08/2025 02:19:56 - INFO - __main__ -   eval_recall = 0.3619\n",
      " 60% 305/512 [02:44<01:26,  2.39it/s]01/08/2025 02:20:36 - WARNING - __main__ - epoch 4 step 306 loss 0.09506\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:20:58 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:20:58 - INFO - __main__ -   eval_f1 = 0.3697\n",
      "01/08/2025 02:20:58 - INFO - __main__ -   eval_precision = 0.4615\n",
      "01/08/2025 02:20:58 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 79% 407/512 [03:45<00:38,  2.75it/s]01/08/2025 02:21:37 - WARNING - __main__ - epoch 4 step 408 loss 0.09641\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:21:59 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:21:59 - INFO - __main__ -   eval_f1 = 0.3642\n",
      "01/08/2025 02:21:59 - INFO - __main__ -   eval_precision = 0.56\n",
      "01/08/2025 02:21:59 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 99% 509/512 [04:46<00:01,  2.65it/s]01/08/2025 02:22:39 - WARNING - __main__ - epoch 4 step 510 loss 0.0967\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:23:00 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:23:00 - INFO - __main__ -   eval_f1 = 0.38\n",
      "01/08/2025 02:23:00 - INFO - __main__ -   eval_precision = 0.4053\n",
      "01/08/2025 02:23:00 - INFO - __main__ -   eval_recall = 0.3576\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:45,  2.49it/s]01/08/2025 02:23:42 - WARNING - __main__ - epoch 5 step 102 loss 0.0519\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:24:04 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:24:04 - INFO - __main__ -   eval_f1 = 0.3196\n",
      "01/08/2025 02:24:04 - INFO - __main__ -   eval_precision = 0.3677\n",
      "01/08/2025 02:24:04 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 40% 203/512 [01:41<02:03,  2.51it/s]01/08/2025 02:24:43 - WARNING - __main__ - epoch 5 step 204 loss 0.059\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:25:05 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:25:05 - INFO - __main__ -   eval_f1 = 0.3338\n",
      "01/08/2025 02:25:05 - INFO - __main__ -   eval_precision = 0.4119\n",
      "01/08/2025 02:25:05 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 60% 305/512 [02:43<01:22,  2.52it/s]01/08/2025 02:25:44 - WARNING - __main__ - epoch 5 step 306 loss 0.07288\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:26:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:26:06 - INFO - __main__ -   eval_f1 = 0.3365\n",
      "01/08/2025 02:26:06 - INFO - __main__ -   eval_precision = 0.3836\n",
      "01/08/2025 02:26:06 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 79% 407/512 [03:44<00:40,  2.59it/s]01/08/2025 02:26:46 - WARNING - __main__ - epoch 5 step 408 loss 0.06004\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:27:08 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:27:08 - INFO - __main__ -   eval_f1 = 0.333\n",
      "01/08/2025 02:27:08 - INFO - __main__ -   eval_precision = 0.3589\n",
      "01/08/2025 02:27:08 - INFO - __main__ -   eval_recall = 0.3105\n",
      " 99% 509/512 [04:46<00:01,  2.37it/s]01/08/2025 02:27:48 - WARNING - __main__ - epoch 5 step 510 loss 0.05682\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:28:10 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:28:10 - INFO - __main__ -   eval_f1 = 0.3441\n",
      "01/08/2025 02:28:10 - INFO - __main__ -   eval_precision = 0.3245\n",
      "01/08/2025 02:28:10 - INFO - __main__ -   eval_recall = 0.3662\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:25,  2.83it/s]01/08/2025 02:28:51 - WARNING - __main__ - epoch 6 step 102 loss 0.02728\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:29:13 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:29:13 - INFO - __main__ -   eval_f1 = 0.2979\n",
      "01/08/2025 02:29:13 - INFO - __main__ -   eval_precision = 0.3122\n",
      "01/08/2025 02:29:13 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 40% 203/512 [01:41<01:49,  2.82it/s]01/08/2025 02:29:52 - WARNING - __main__ - epoch 6 step 204 loss 0.03385\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:30:14 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:30:14 - INFO - __main__ -   eval_f1 = 0.2798\n",
      "01/08/2025 02:30:14 - INFO - __main__ -   eval_precision = 0.304\n",
      "01/08/2025 02:30:14 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 60% 305/512 [02:42<01:22,  2.50it/s]01/08/2025 02:30:53 - WARNING - __main__ - epoch 6 step 306 loss 0.03424\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:31:15 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:31:15 - INFO - __main__ -   eval_f1 = 0.3146\n",
      "01/08/2025 02:31:15 - INFO - __main__ -   eval_precision = 0.3772\n",
      "01/08/2025 02:31:15 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 79% 407/512 [03:44<00:40,  2.60it/s]01/08/2025 02:31:55 - WARNING - __main__ - epoch 6 step 408 loss 0.02574\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:32:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:32:17 - INFO - __main__ -   eval_f1 = 0.3143\n",
      "01/08/2025 02:32:17 - INFO - __main__ -   eval_precision = 0.3851\n",
      "01/08/2025 02:32:17 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 99% 509/512 [04:46<00:01,  2.54it/s]01/08/2025 02:32:57 - WARNING - __main__ - epoch 6 step 510 loss 0.04395\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:33:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:33:19 - INFO - __main__ -   eval_f1 = 0.3306\n",
      "01/08/2025 02:33:19 - INFO - __main__ -   eval_precision = 0.3212\n",
      "01/08/2025 02:33:19 - INFO - __main__ -   eval_recall = 0.3405\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:42,  2.54it/s]01/08/2025 02:34:00 - WARNING - __main__ - epoch 7 step 102 loss 0.01035\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:34:22 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:34:22 - INFO - __main__ -   eval_f1 = 0.3139\n",
      "01/08/2025 02:34:22 - INFO - __main__ -   eval_precision = 0.3529\n",
      "01/08/2025 02:34:22 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 40% 203/512 [01:42<01:59,  2.59it/s]01/08/2025 02:35:02 - WARNING - __main__ - epoch 7 step 204 loss 0.01902\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:35:24 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:35:24 - INFO - __main__ -   eval_f1 = 0.2814\n",
      "01/08/2025 02:35:24 - INFO - __main__ -   eval_precision = 0.3447\n",
      "01/08/2025 02:35:24 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 60% 305/512 [02:43<01:19,  2.61it/s]01/08/2025 02:36:03 - WARNING - __main__ - epoch 7 step 306 loss 0.01788\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:36:25 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:36:25 - INFO - __main__ -   eval_f1 = 0.2782\n",
      "01/08/2025 02:36:25 - INFO - __main__ -   eval_precision = 0.3353\n",
      "01/08/2025 02:36:25 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 79% 407/512 [03:44<00:41,  2.51it/s]01/08/2025 02:37:05 - WARNING - __main__ - epoch 7 step 408 loss 0.02578\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:37:27 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 02:37:27 - INFO - __main__ -   eval_f1 = 0.2911\n",
      "01/08/2025 02:37:27 - INFO - __main__ -   eval_precision = 0.3865\n",
      "01/08/2025 02:37:27 - INFO - __main__ -   eval_recall = 0.2334\n",
      "01/08/2025 02:37:27 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 79% 407/512 [04:06<01:03,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQfdz-fPySHh",
    "outputId": "54c214c3-22eb-402e-bf9c-05c42b37e16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 02:40:54.328146: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 02:40:54.346448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 02:40:54.367741: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 02:40:54.374128: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 02:40:54.389574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 02:40:55.743395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 02:40:59 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:352: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 02:42:01 - INFO - __main__ - ***** Test results *****\n",
      "01/08/2025 02:42:01 - INFO - __main__ -   auc_score = 0.8663\n",
      "01/08/2025 02:42:01 - INFO - __main__ -   test_f1 = 0.4041\n",
      "01/08/2025 02:42:01 - INFO - __main__ -   test_precision = 0.4355\n",
      "01/08/2025 02:42:01 - INFO - __main__ -   test_recall = 0.3768\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xza_3qQzfAWS",
    "outputId": "eb3d8819-c762-489a-9623-b0d9d605a214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 15:29:04.352377: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 15:29:04.370208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 15:29:04.391681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 15:29:04.398144: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 15:29:04.413529: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 15:29:05.739509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 15:29:08 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:42<02:35,  2.65it/s]01/08/2025 15:31:54 - WARNING - __main__ - epoch 0 step 102 loss 0.27597\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 15:32:16 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:32:16 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 15:32:16 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 15:32:16 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [01:44<02:01,  2.55it/s]01/08/2025 15:32:56 - WARNING - __main__ - epoch 0 step 204 loss 0.25746\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:33:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:33:18 - INFO - __main__ -   eval_f1 = 0.0042\n",
      "01/08/2025 15:33:18 - INFO - __main__ -   eval_precision = 0.25\n",
      "01/08/2025 15:33:18 - INFO - __main__ -   eval_recall = 0.0021\n",
      " 60% 305/512 [02:49<01:19,  2.61it/s]01/08/2025 15:34:01 - WARNING - __main__ - epoch 0 step 306 loss 0.23724\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:34:23 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:34:23 - INFO - __main__ -   eval_f1 = 0.1949\n",
      "01/08/2025 15:34:23 - INFO - __main__ -   eval_precision = 0.6883\n",
      "01/08/2025 15:34:23 - INFO - __main__ -   eval_recall = 0.1135\n",
      " 79% 407/512 [03:55<00:41,  2.52it/s]01/08/2025 15:35:08 - WARNING - __main__ - epoch 0 step 408 loss 0.22855\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:35:30 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:35:30 - INFO - __main__ -   eval_f1 = 0.3418\n",
      "01/08/2025 15:35:30 - INFO - __main__ -   eval_precision = 0.6545\n",
      "01/08/2025 15:35:30 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 99% 509/512 [05:02<00:01,  2.48it/s]01/08/2025 15:36:14 - WARNING - __main__ - epoch 0 step 510 loss 0.22138\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:36:36 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:36:36 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "01/08/2025 15:36:36 - INFO - __main__ -   eval_precision = 1.0\n",
      "01/08/2025 15:36:36 - INFO - __main__ -   eval_recall = 0.0043\n",
      "100% 512/512 [05:25<00:00,  1.57it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:35,  2.65it/s]01/08/2025 15:37:17 - WARNING - __main__ - epoch 1 step 102 loss 0.21175\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:37:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:37:39 - INFO - __main__ -   eval_f1 = 0.2838\n",
      "01/08/2025 15:37:39 - INFO - __main__ -   eval_precision = 0.7034\n",
      "01/08/2025 15:37:39 - INFO - __main__ -   eval_recall = 0.1777\n",
      " 40% 203/512 [01:41<01:58,  2.60it/s]01/08/2025 15:38:19 - WARNING - __main__ - epoch 1 step 204 loss 0.20388\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:38:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:38:40 - INFO - __main__ -   eval_f1 = 0.1737\n",
      "01/08/2025 15:38:40 - INFO - __main__ -   eval_precision = 0.8824\n",
      "01/08/2025 15:38:40 - INFO - __main__ -   eval_recall = 0.0964\n",
      " 60% 305/512 [02:43<01:25,  2.43it/s]01/08/2025 15:39:21 - WARNING - __main__ - epoch 1 step 306 loss 0.21212\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:39:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:39:43 - INFO - __main__ -   eval_f1 = 0.3188\n",
      "01/08/2025 15:39:43 - INFO - __main__ -   eval_precision = 0.7364\n",
      "01/08/2025 15:39:43 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 79% 407/512 [03:44<00:41,  2.52it/s]01/08/2025 15:40:22 - WARNING - __main__ - epoch 1 step 408 loss 0.19035\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:40:44 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:40:44 - INFO - __main__ -   eval_f1 = 0.4529\n",
      "01/08/2025 15:40:44 - INFO - __main__ -   eval_precision = 0.6241\n",
      "01/08/2025 15:40:44 - INFO - __main__ -   eval_recall = 0.3555\n",
      " 99% 509/512 [04:50<00:01,  2.56it/s]01/08/2025 15:41:28 - WARNING - __main__ - epoch 1 step 510 loss 0.18494\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:41:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:41:50 - INFO - __main__ -   eval_f1 = 0.4123\n",
      "01/08/2025 15:41:50 - INFO - __main__ -   eval_precision = 0.7322\n",
      "01/08/2025 15:41:50 - INFO - __main__ -   eval_recall = 0.2869\n",
      "100% 512/512 [05:13<00:00,  1.63it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:32,  2.69it/s]01/08/2025 15:42:31 - WARNING - __main__ - epoch 2 step 102 loss 0.16903\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:42:53 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:42:53 - INFO - __main__ -   eval_f1 = 0.4761\n",
      "01/08/2025 15:42:53 - INFO - __main__ -   eval_precision = 0.4726\n",
      "01/08/2025 15:42:53 - INFO - __main__ -   eval_recall = 0.4797\n",
      " 40% 203/512 [01:46<01:55,  2.67it/s]01/08/2025 15:43:37 - WARNING - __main__ - epoch 2 step 204 loss 0.19073\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:43:59 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:43:59 - INFO - __main__ -   eval_f1 = 0.3843\n",
      "01/08/2025 15:43:59 - INFO - __main__ -   eval_precision = 0.6546\n",
      "01/08/2025 15:43:59 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 60% 305/512 [02:47<01:15,  2.76it/s]01/08/2025 15:44:39 - WARNING - __main__ - epoch 2 step 306 loss 0.17764\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:45:01 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:45:01 - INFO - __main__ -   eval_f1 = 0.4929\n",
      "01/08/2025 15:45:01 - INFO - __main__ -   eval_precision = 0.5517\n",
      "01/08/2025 15:45:01 - INFO - __main__ -   eval_recall = 0.4454\n",
      " 79% 407/512 [03:54<00:43,  2.43it/s]01/08/2025 15:45:46 - WARNING - __main__ - epoch 2 step 408 loss 0.16489\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:46:07 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:46:07 - INFO - __main__ -   eval_f1 = 0.3764\n",
      "01/08/2025 15:46:07 - INFO - __main__ -   eval_precision = 0.6875\n",
      "01/08/2025 15:46:07 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 99% 509/512 [04:56<00:01,  2.74it/s]01/08/2025 15:46:47 - WARNING - __main__ - epoch 2 step 510 loss 0.15894\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:47:09 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:47:09 - INFO - __main__ -   eval_f1 = 0.388\n",
      "01/08/2025 15:47:09 - INFO - __main__ -   eval_precision = 0.6515\n",
      "01/08/2025 15:47:09 - INFO - __main__ -   eval_recall = 0.2762\n",
      "100% 512/512 [05:19<00:00,  1.60it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:43,  2.51it/s]01/08/2025 15:47:50 - WARNING - __main__ - epoch 3 step 102 loss 0.12976\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:48:11 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:48:11 - INFO - __main__ -   eval_f1 = 0.377\n",
      "01/08/2025 15:48:11 - INFO - __main__ -   eval_precision = 0.4848\n",
      "01/08/2025 15:48:11 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [01:41<02:03,  2.50it/s]01/08/2025 15:48:52 - WARNING - __main__ - epoch 3 step 204 loss 0.13749\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:49:14 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:49:14 - INFO - __main__ -   eval_f1 = 0.3801\n",
      "01/08/2025 15:49:14 - INFO - __main__ -   eval_precision = 0.6429\n",
      "01/08/2025 15:49:14 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 60% 305/512 [02:42<01:25,  2.42it/s]01/08/2025 15:49:53 - WARNING - __main__ - epoch 3 step 306 loss 0.12291\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:50:15 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:50:15 - INFO - __main__ -   eval_f1 = 0.3096\n",
      "01/08/2025 15:50:15 - INFO - __main__ -   eval_precision = 0.5904\n",
      "01/08/2025 15:50:15 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 79% 407/512 [03:45<00:39,  2.65it/s]01/08/2025 15:50:55 - WARNING - __main__ - epoch 3 step 408 loss 0.14993\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:51:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:51:17 - INFO - __main__ -   eval_f1 = 0.3733\n",
      "01/08/2025 15:51:17 - INFO - __main__ -   eval_precision = 0.4947\n",
      "01/08/2025 15:51:17 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 99% 509/512 [04:46<00:01,  2.39it/s]01/08/2025 15:51:57 - WARNING - __main__ - epoch 3 step 510 loss 0.13213\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:52:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:52:19 - INFO - __main__ -   eval_f1 = 0.327\n",
      "01/08/2025 15:52:19 - INFO - __main__ -   eval_precision = 0.6319\n",
      "01/08/2025 15:52:19 - INFO - __main__ -   eval_recall = 0.2206\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:41,  2.54it/s]01/08/2025 15:53:00 - WARNING - __main__ - epoch 4 step 102 loss 0.08061\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:53:22 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:53:22 - INFO - __main__ -   eval_f1 = 0.375\n",
      "01/08/2025 15:53:22 - INFO - __main__ -   eval_precision = 0.4173\n",
      "01/08/2025 15:53:22 - INFO - __main__ -   eval_recall = 0.3405\n",
      " 40% 203/512 [01:42<01:53,  2.73it/s]01/08/2025 15:54:02 - WARNING - __main__ - epoch 4 step 204 loss 0.08314\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:54:24 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:54:24 - INFO - __main__ -   eval_f1 = 0.3528\n",
      "01/08/2025 15:54:24 - INFO - __main__ -   eval_precision = 0.3567\n",
      "01/08/2025 15:54:24 - INFO - __main__ -   eval_recall = 0.349\n",
      " 60% 305/512 [02:44<01:26,  2.39it/s]01/08/2025 15:55:04 - WARNING - __main__ - epoch 4 step 306 loss 0.09586\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:55:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:55:26 - INFO - __main__ -   eval_f1 = 0.2567\n",
      "01/08/2025 15:55:26 - INFO - __main__ -   eval_precision = 0.4767\n",
      "01/08/2025 15:55:26 - INFO - __main__ -   eval_recall = 0.1756\n",
      " 79% 407/512 [03:45<00:38,  2.75it/s]01/08/2025 15:56:05 - WARNING - __main__ - epoch 4 step 408 loss 0.11044\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:56:27 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:56:27 - INFO - __main__ -   eval_f1 = 0.3873\n",
      "01/08/2025 15:56:27 - INFO - __main__ -   eval_precision = 0.4527\n",
      "01/08/2025 15:56:27 - INFO - __main__ -   eval_recall = 0.3383\n",
      " 99% 509/512 [04:46<00:01,  2.65it/s]01/08/2025 15:57:06 - WARNING - __main__ - epoch 4 step 510 loss 0.10187\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:57:28 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:57:28 - INFO - __main__ -   eval_f1 = 0.3461\n",
      "01/08/2025 15:57:28 - INFO - __main__ -   eval_precision = 0.4094\n",
      "01/08/2025 15:57:28 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:45,  2.49it/s]01/08/2025 15:58:10 - WARNING - __main__ - epoch 5 step 102 loss 0.05668\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:58:32 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:58:32 - INFO - __main__ -   eval_f1 = 0.3141\n",
      "01/08/2025 15:58:32 - INFO - __main__ -   eval_precision = 0.3569\n",
      "01/08/2025 15:58:32 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 40% 203/512 [01:41<02:03,  2.51it/s]01/08/2025 15:59:11 - WARNING - __main__ - epoch 5 step 204 loss 0.07054\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:59:33 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:59:33 - INFO - __main__ -   eval_f1 = 0.3173\n",
      "01/08/2025 15:59:33 - INFO - __main__ -   eval_precision = 0.3728\n",
      "01/08/2025 15:59:33 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 60% 305/512 [02:43<01:22,  2.52it/s]01/08/2025 16:00:12 - WARNING - __main__ - epoch 5 step 306 loss 0.06726\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:00:34 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:00:34 - INFO - __main__ -   eval_f1 = 0.357\n",
      "01/08/2025 16:00:34 - INFO - __main__ -   eval_precision = 0.3984\n",
      "01/08/2025 16:00:34 - INFO - __main__ -   eval_recall = 0.3233\n",
      " 79% 407/512 [03:44<00:40,  2.59it/s]01/08/2025 16:01:14 - WARNING - __main__ - epoch 5 step 408 loss 0.06301\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:01:36 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:01:36 - INFO - __main__ -   eval_f1 = 0.337\n",
      "01/08/2025 16:01:36 - INFO - __main__ -   eval_precision = 0.396\n",
      "01/08/2025 16:01:36 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 99% 509/512 [04:46<00:01,  2.37it/s]01/08/2025 16:02:16 - WARNING - __main__ - epoch 5 step 510 loss 0.06007\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:02:38 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:02:38 - INFO - __main__ -   eval_f1 = 0.2991\n",
      "01/08/2025 16:02:38 - INFO - __main__ -   eval_precision = 0.3808\n",
      "01/08/2025 16:02:38 - INFO - __main__ -   eval_recall = 0.2463\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:39<02:25,  2.83it/s]01/08/2025 16:03:18 - WARNING - __main__ - epoch 6 step 102 loss 0.0227\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:03:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:03:40 - INFO - __main__ -   eval_f1 = 0.3035\n",
      "01/08/2025 16:03:40 - INFO - __main__ -   eval_precision = 0.3849\n",
      "01/08/2025 16:03:40 - INFO - __main__ -   eval_recall = 0.2505\n",
      " 40% 203/512 [01:41<01:49,  2.82it/s]01/08/2025 16:04:20 - WARNING - __main__ - epoch 6 step 204 loss 0.02597\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:04:42 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:04:42 - INFO - __main__ -   eval_f1 = 0.2902\n",
      "01/08/2025 16:04:42 - INFO - __main__ -   eval_precision = 0.3725\n",
      "01/08/2025 16:04:42 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 60% 305/512 [02:42<01:22,  2.50it/s]01/08/2025 16:05:21 - WARNING - __main__ - epoch 6 step 306 loss 0.03574\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:05:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:05:43 - INFO - __main__ -   eval_f1 = 0.2773\n",
      "01/08/2025 16:05:43 - INFO - __main__ -   eval_precision = 0.3462\n",
      "01/08/2025 16:05:43 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 79% 407/512 [03:44<00:40,  2.60it/s]01/08/2025 16:06:23 - WARNING - __main__ - epoch 6 step 408 loss 0.03316\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:06:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:06:45 - INFO - __main__ -   eval_f1 = 0.2732\n",
      "01/08/2025 16:06:45 - INFO - __main__ -   eval_precision = 0.3774\n",
      "01/08/2025 16:06:45 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 99% 509/512 [04:46<00:01,  2.54it/s]01/08/2025 16:07:25 - WARNING - __main__ - epoch 6 step 510 loss 0.05687\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:07:47 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:07:47 - INFO - __main__ -   eval_f1 = 0.3238\n",
      "01/08/2025 16:07:47 - INFO - __main__ -   eval_precision = 0.3646\n",
      "01/08/2025 16:07:47 - INFO - __main__ -   eval_recall = 0.2912\n",
      "100% 512/512 [05:09<00:00,  1.65it/s]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [00:40<02:41,  2.54it/s]01/08/2025 16:08:28 - WARNING - __main__ - epoch 7 step 102 loss 0.0109\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:08:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:08:50 - INFO - __main__ -   eval_f1 = 0.2606\n",
      "01/08/2025 16:08:50 - INFO - __main__ -   eval_precision = 0.3849\n",
      "01/08/2025 16:08:50 - INFO - __main__ -   eval_recall = 0.197\n",
      " 40% 203/512 [01:42<01:59,  2.59it/s]01/08/2025 16:09:30 - WARNING - __main__ - epoch 7 step 204 loss 0.01528\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:09:52 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:09:52 - INFO - __main__ -   eval_f1 = 0.2304\n",
      "01/08/2025 16:09:52 - INFO - __main__ -   eval_precision = 0.3714\n",
      "01/08/2025 16:09:52 - INFO - __main__ -   eval_recall = 0.167\n",
      " 60% 305/512 [02:43<01:19,  2.61it/s]01/08/2025 16:10:31 - WARNING - __main__ - epoch 7 step 306 loss 0.01897\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:10:53 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:10:53 - INFO - __main__ -   eval_f1 = 0.2475\n",
      "01/08/2025 16:10:53 - INFO - __main__ -   eval_precision = 0.3686\n",
      "01/08/2025 16:10:53 - INFO - __main__ -   eval_recall = 0.1863\n",
      " 79% 407/512 [03:44<00:41,  2.51it/s]01/08/2025 16:11:33 - WARNING - __main__ - epoch 7 step 408 loss 0.02436\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:11:55 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:11:55 - INFO - __main__ -   eval_f1 = 0.2991\n",
      "01/08/2025 16:11:55 - INFO - __main__ -   eval_precision = 0.3538\n",
      "01/08/2025 16:11:55 - INFO - __main__ -   eval_recall = 0.2591\n",
      "01/08/2025 16:11:55 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 79% 407/512 [04:06<01:03,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert_b5e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 5e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elkqtHw-sDkU",
    "outputId": "f362ce19-907b-45ba-95a6-df59de10e4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 16:12:32.571520: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 16:12:32.589399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 16:12:32.610808: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 16:12:32.617293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 16:12:32.632645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 16:12:33.993123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 16:12:37 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:13:36 - INFO - __main__ - ***** Test results *****\n",
      "01/08/2025 16:13:36 - INFO - __main__ -   auc_score = 0.8669\n",
      "01/08/2025 16:13:36 - INFO - __main__ -   test_f1 = 0.3843\n",
      "01/08/2025 16:13:36 - INFO - __main__ -   test_precision = 0.4267\n",
      "01/08/2025 16:13:36 - INFO - __main__ -   test_recall = 0.3495\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert_b5e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 5e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYUKofqD1E9r"
   },
   "source": [
    "##### Repeating the training with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1dz4FNE09zP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgQiK_Ms3e1S",
    "outputId": "89b1f6b3-8870-42c5-9949-59cfc18a3046"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDKzJN7U1I06",
    "outputId": "76d0ab41-3b41-490a-99c7-d2d38dff1555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 21:03:35.923691: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 21:03:35.941138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746306215.962820    3422 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746306215.969439    3422 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-03 21:03:35.991538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "tokenizer_config.json: 100% 20.8k/20.8k [00:00<00:00, 25.0MB/s]\n",
      "tokenizer.json: 100% 2.13M/2.13M [00:00<00:00, 28.6MB/s]\n",
      "special_tokens_map.json: 100% 694/694 [00:00<00:00, 4.95MB/s]\n",
      "05/03/2025 21:03:40 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "config.json: 100% 1.19k/1.19k [00:00<00:00, 9.72MB/s]\n",
      "model.safetensors: 100% 599M/599M [00:02<00:00, 266MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10468 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:22<05:32,  1.24it/s]05/03/2025 21:07:15 - WARNING - __main__ - epoch 0 step 102 loss 0.29561\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "05/03/2025 21:08:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:08:01 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/03/2025 21:08:01 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/03/2025 21:08:01 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [03:30<04:10,  1.23it/s]05/03/2025 21:09:23 - WARNING - __main__ - epoch 0 step 204 loss 0.28237\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:10:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:10:09 - INFO - __main__ -   eval_f1 = 0.1192\n",
      "05/03/2025 21:10:09 - INFO - __main__ -   eval_precision = 0.5849\n",
      "05/03/2025 21:10:09 - INFO - __main__ -   eval_recall = 0.0664\n",
      " 60% 305/512 [05:45<02:47,  1.24it/s]05/03/2025 21:11:38 - WARNING - __main__ - epoch 0 step 306 loss 0.22497\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:12:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:12:24 - INFO - __main__ -   eval_f1 = 0.1144\n",
      "05/03/2025 21:12:24 - INFO - __main__ -   eval_precision = 0.725\n",
      "05/03/2025 21:12:24 - INFO - __main__ -   eval_recall = 0.0621\n",
      " 79% 407/512 [07:53<01:24,  1.24it/s]05/03/2025 21:13:46 - WARNING - __main__ - epoch 0 step 408 loss 0.22107\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:14:32 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:14:32 - INFO - __main__ -   eval_f1 = 0.2157\n",
      "05/03/2025 21:14:32 - INFO - __main__ -   eval_precision = 0.7375\n",
      "05/03/2025 21:14:32 - INFO - __main__ -   eval_recall = 0.1263\n",
      " 99% 509/512 [10:09<00:02,  1.24it/s]05/03/2025 21:16:02 - WARNING - __main__ - epoch 0 step 510 loss 0.20912\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:16:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:16:48 - INFO - __main__ -   eval_f1 = 0.1082\n",
      "05/03/2025 21:16:48 - INFO - __main__ -   eval_precision = 0.8438\n",
      "05/03/2025 21:16:48 - INFO - __main__ -   eval_recall = 0.0578\n",
      "100% 512/512 [10:57<00:00,  1.28s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 21:18:11 - WARNING - __main__ - epoch 1 step 102 loss 0.20654\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:18:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:18:57 - INFO - __main__ -   eval_f1 = 0.1894\n",
      "05/03/2025 21:18:57 - INFO - __main__ -   eval_precision = 0.8197\n",
      "05/03/2025 21:18:57 - INFO - __main__ -   eval_recall = 0.1071\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 21:20:19 - WARNING - __main__ - epoch 1 step 204 loss 0.18708\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:21:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:21:05 - INFO - __main__ -   eval_f1 = 0.3226\n",
      "05/03/2025 21:21:05 - INFO - __main__ -   eval_precision = 0.7787\n",
      "05/03/2025 21:21:05 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 60% 305/512 [05:41<02:47,  1.24it/s]05/03/2025 21:22:31 - WARNING - __main__ - epoch 1 step 306 loss 0.17697\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:23:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:23:17 - INFO - __main__ -   eval_f1 = 0.2967\n",
      "05/03/2025 21:23:17 - INFO - __main__ -   eval_precision = 0.8019\n",
      "05/03/2025 21:23:17 - INFO - __main__ -   eval_recall = 0.182\n",
      " 79% 407/512 [07:49<01:24,  1.24it/s]05/03/2025 21:24:39 - WARNING - __main__ - epoch 1 step 408 loss 0.18825\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:25:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:25:25 - INFO - __main__ -   eval_f1 = 0.4663\n",
      "05/03/2025 21:25:25 - INFO - __main__ -   eval_precision = 0.6776\n",
      "05/03/2025 21:25:25 - INFO - __main__ -   eval_recall = 0.3555\n",
      " 99% 509/512 [10:04<00:02,  1.24it/s]05/03/2025 21:26:54 - WARNING - __main__ - epoch 1 step 510 loss 0.19984\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:27:40 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:27:40 - INFO - __main__ -   eval_f1 = 0.4236\n",
      "05/03/2025 21:27:40 - INFO - __main__ -   eval_precision = 0.7216\n",
      "05/03/2025 21:27:40 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 512/512 [10:51<00:00,  1.27s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 21:29:03 - WARNING - __main__ - epoch 2 step 102 loss 0.14097\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:29:49 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:29:49 - INFO - __main__ -   eval_f1 = 0.3537\n",
      "05/03/2025 21:29:49 - INFO - __main__ -   eval_precision = 0.7754\n",
      "05/03/2025 21:29:49 - INFO - __main__ -   eval_recall = 0.2291\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 21:31:11 - WARNING - __main__ - epoch 2 step 204 loss 0.13453\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:31:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:31:57 - INFO - __main__ -   eval_f1 = 0.422\n",
      "05/03/2025 21:31:57 - INFO - __main__ -   eval_precision = 0.5238\n",
      "05/03/2025 21:31:57 - INFO - __main__ -   eval_recall = 0.3533\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 21:33:19 - WARNING - __main__ - epoch 2 step 306 loss 0.13678\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:34:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:34:04 - INFO - __main__ -   eval_f1 = 0.4522\n",
      "05/03/2025 21:34:04 - INFO - __main__ -   eval_precision = 0.4962\n",
      "05/03/2025 21:34:04 - INFO - __main__ -   eval_recall = 0.4154\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/03/2025 21:35:26 - WARNING - __main__ - epoch 2 step 408 loss 0.1398\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:36:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:36:12 - INFO - __main__ -   eval_f1 = 0.3469\n",
      "05/03/2025 21:36:12 - INFO - __main__ -   eval_precision = 0.6416\n",
      "05/03/2025 21:36:12 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 21:37:34 - WARNING - __main__ - epoch 2 step 510 loss 0.14651\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:38:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:38:20 - INFO - __main__ -   eval_f1 = 0.395\n",
      "05/03/2025 21:38:20 - INFO - __main__ -   eval_precision = 0.5635\n",
      "05/03/2025 21:38:20 - INFO - __main__ -   eval_recall = 0.3041\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 21:39:43 - WARNING - __main__ - epoch 3 step 102 loss 0.08651\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:40:29 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:40:29 - INFO - __main__ -   eval_f1 = 0.3496\n",
      "05/03/2025 21:40:29 - INFO - __main__ -   eval_precision = 0.4074\n",
      "05/03/2025 21:40:29 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 21:41:51 - WARNING - __main__ - epoch 3 step 204 loss 0.08562\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:42:37 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:42:37 - INFO - __main__ -   eval_f1 = 0.3483\n",
      "05/03/2025 21:42:37 - INFO - __main__ -   eval_precision = 0.5829\n",
      "05/03/2025 21:42:37 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 21:43:59 - WARNING - __main__ - epoch 3 step 306 loss 0.08649\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:44:45 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:44:45 - INFO - __main__ -   eval_f1 = 0.3678\n",
      "05/03/2025 21:44:45 - INFO - __main__ -   eval_precision = 0.397\n",
      "05/03/2025 21:44:45 - INFO - __main__ -   eval_recall = 0.3426\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/03/2025 21:46:07 - WARNING - __main__ - epoch 3 step 408 loss 0.08661\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:46:53 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:46:53 - INFO - __main__ -   eval_f1 = 0.2135\n",
      "05/03/2025 21:46:53 - INFO - __main__ -   eval_precision = 0.6316\n",
      "05/03/2025 21:46:53 - INFO - __main__ -   eval_recall = 0.1285\n",
      " 99% 509/512 [09:52<00:02,  1.23it/s]05/03/2025 21:48:15 - WARNING - __main__ - epoch 3 step 510 loss 0.08978\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:49:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:49:00 - INFO - __main__ -   eval_f1 = 0.3047\n",
      "05/03/2025 21:49:00 - INFO - __main__ -   eval_precision = 0.4928\n",
      "05/03/2025 21:49:00 - INFO - __main__ -   eval_recall = 0.2206\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.23it/s]05/03/2025 21:50:24 - WARNING - __main__ - epoch 4 step 102 loss 0.03906\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:51:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:51:10 - INFO - __main__ -   eval_f1 = 0.3262\n",
      "05/03/2025 21:51:10 - INFO - __main__ -   eval_precision = 0.3673\n",
      "05/03/2025 21:51:10 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 21:52:32 - WARNING - __main__ - epoch 4 step 204 loss 0.04691\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:53:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:53:17 - INFO - __main__ -   eval_f1 = 0.2634\n",
      "05/03/2025 21:53:17 - INFO - __main__ -   eval_precision = 0.3664\n",
      "05/03/2025 21:53:17 - INFO - __main__ -   eval_recall = 0.2056\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 21:54:39 - WARNING - __main__ - epoch 4 step 306 loss 0.03576\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:55:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:55:25 - INFO - __main__ -   eval_f1 = 0.3126\n",
      "05/03/2025 21:55:25 - INFO - __main__ -   eval_precision = 0.3241\n",
      "05/03/2025 21:55:25 - INFO - __main__ -   eval_recall = 0.3019\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/03/2025 21:56:47 - WARNING - __main__ - epoch 4 step 408 loss 0.05567\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:57:33 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:57:33 - INFO - __main__ -   eval_f1 = 0.308\n",
      "05/03/2025 21:57:33 - INFO - __main__ -   eval_precision = 0.3167\n",
      "05/03/2025 21:57:33 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 21:58:55 - WARNING - __main__ - epoch 4 step 510 loss 0.05554\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 21:59:41 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 21:59:41 - INFO - __main__ -   eval_f1 = 0.3244\n",
      "05/03/2025 21:59:41 - INFO - __main__ -   eval_precision = 0.3768\n",
      "05/03/2025 21:59:41 - INFO - __main__ -   eval_recall = 0.2848\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 22:01:04 - WARNING - __main__ - epoch 5 step 102 loss 0.01892\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:01:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:01:50 - INFO - __main__ -   eval_f1 = 0.2984\n",
      "05/03/2025 22:01:50 - INFO - __main__ -   eval_precision = 0.3187\n",
      "05/03/2025 22:01:50 - INFO - __main__ -   eval_recall = 0.2805\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 22:03:12 - WARNING - __main__ - epoch 5 step 204 loss 0.02715\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:03:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:03:58 - INFO - __main__ -   eval_f1 = 0.2523\n",
      "05/03/2025 22:03:58 - INFO - __main__ -   eval_precision = 0.3381\n",
      "05/03/2025 22:03:58 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 22:05:20 - WARNING - __main__ - epoch 5 step 306 loss 0.01189\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:06:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:06:06 - INFO - __main__ -   eval_f1 = 0.2141\n",
      "05/03/2025 22:06:06 - INFO - __main__ -   eval_precision = 0.4214\n",
      "05/03/2025 22:06:06 - INFO - __main__ -   eval_recall = 0.1435\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/03/2025 22:07:28 - WARNING - __main__ - epoch 5 step 408 loss 0.02641\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:08:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:08:13 - INFO - __main__ -   eval_f1 = 0.2507\n",
      "05/03/2025 22:08:13 - INFO - __main__ -   eval_precision = 0.3514\n",
      "05/03/2025 22:08:13 - INFO - __main__ -   eval_recall = 0.1949\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 22:09:35 - WARNING - __main__ - epoch 5 step 510 loss 0.02424\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:10:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:10:21 - INFO - __main__ -   eval_f1 = 0.266\n",
      "05/03/2025 22:10:21 - INFO - __main__ -   eval_precision = 0.2923\n",
      "05/03/2025 22:10:21 - INFO - __main__ -   eval_recall = 0.2441\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 22:11:45 - WARNING - __main__ - epoch 6 step 102 loss 0.01369\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:12:30 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:12:30 - INFO - __main__ -   eval_f1 = 0.2729\n",
      "05/03/2025 22:12:30 - INFO - __main__ -   eval_precision = 0.2938\n",
      "05/03/2025 22:12:30 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 22:13:52 - WARNING - __main__ - epoch 6 step 204 loss 0.01323\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:14:38 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:14:38 - INFO - __main__ -   eval_f1 = 0.2605\n",
      "05/03/2025 22:14:38 - INFO - __main__ -   eval_precision = 0.3097\n",
      "05/03/2025 22:14:38 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 60% 305/512 [05:37<02:47,  1.23it/s]05/03/2025 22:16:00 - WARNING - __main__ - epoch 6 step 306 loss 0.00892\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:16:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:16:46 - INFO - __main__ -   eval_f1 = 0.2577\n",
      "05/03/2025 22:16:46 - INFO - __main__ -   eval_precision = 0.2653\n",
      "05/03/2025 22:16:46 - INFO - __main__ -   eval_recall = 0.2505\n",
      " 79% 407/512 [07:44<01:25,  1.24it/s]05/03/2025 22:18:08 - WARNING - __main__ - epoch 6 step 408 loss 0.0073\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:18:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:18:54 - INFO - __main__ -   eval_f1 = 0.2545\n",
      "05/03/2025 22:18:54 - INFO - __main__ -   eval_precision = 0.2896\n",
      "05/03/2025 22:18:54 - INFO - __main__ -   eval_recall = 0.227\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 22:20:16 - WARNING - __main__ - epoch 6 step 510 loss 0.01251\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 22:21:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 22:21:02 - INFO - __main__ -   eval_f1 = 0.2517\n",
      "05/03/2025 22:21:02 - INFO - __main__ -   eval_precision = 0.3357\n",
      "05/03/2025 22:21:02 - INFO - __main__ -   eval_recall = 0.2013\n",
      "05/03/2025 22:21:02 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 99% 509/512 [10:39<00:03,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40JeGVdYYGsS",
    "outputId": "49d25ced-7d21-497b-e8f8-2ac20ccb9fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:59:49.412283: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 22:59:49.430555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746313189.452963   46529 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746313189.459679   46529 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-03 22:59:49.482127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "05/03/2025 22:59:52 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:01:13 - INFO - __main__ - ***** Test results *****\n",
      "05/03/2025 23:01:13 - INFO - __main__ -   auc_score = 0.864\n",
      "05/03/2025 23:01:13 - INFO - __main__ -   test_f1 = 0.3552\n",
      "05/03/2025 23:01:13 - INFO - __main__ -   test_precision = 0.5292\n",
      "05/03/2025 23:01:13 - INFO - __main__ -   test_recall = 0.2674\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwGEI0dhYObh"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sF5NcjZZJWI",
    "outputId": "44fe38be-9d6b-4390-b4c5-23990ed45ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:04:25.467113: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 23:04:25.485098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746313465.506856   48371 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746313465.513550   48371 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-03 23:04:25.535681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "05/03/2025 23:04:28 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14690 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:22<05:32,  1.24it/s]05/03/2025 23:07:58 - WARNING - __main__ - epoch 0 step 102 loss 0.2841\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:08:44 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:08:44 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/03/2025 23:08:44 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/03/2025 23:08:44 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 23:10:06 - WARNING - __main__ - epoch 0 step 204 loss 0.23995\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:10:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:10:52 - INFO - __main__ -   eval_f1 = 0.2752\n",
      "05/03/2025 23:10:52 - INFO - __main__ -   eval_precision = 0.6357\n",
      "05/03/2025 23:10:52 - INFO - __main__ -   eval_recall = 0.1756\n",
      " 60% 305/512 [05:43<02:47,  1.24it/s]05/03/2025 23:12:19 - WARNING - __main__ - epoch 0 step 306 loss 0.22173\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:13:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:13:05 - INFO - __main__ -   eval_f1 = 0.3024\n",
      "05/03/2025 23:13:05 - INFO - __main__ -   eval_precision = 0.5714\n",
      "05/03/2025 23:13:05 - INFO - __main__ -   eval_recall = 0.2056\n",
      " 79% 407/512 [07:54<01:24,  1.24it/s]05/03/2025 23:14:31 - WARNING - __main__ - epoch 0 step 408 loss 0.22188\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:15:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:15:17 - INFO - __main__ -   eval_f1 = 0.3231\n",
      "05/03/2025 23:15:17 - INFO - __main__ -   eval_precision = 0.6579\n",
      "05/03/2025 23:15:17 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 99% 509/512 [10:06<00:02,  1.24it/s]05/03/2025 23:16:43 - WARNING - __main__ - epoch 0 step 510 loss 0.19516\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:17:29 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:17:29 - INFO - __main__ -   eval_f1 = 0.2383\n",
      "05/03/2025 23:17:29 - INFO - __main__ -   eval_precision = 0.7586\n",
      "05/03/2025 23:17:29 - INFO - __main__ -   eval_recall = 0.1413\n",
      "100% 512/512 [10:54<00:00,  1.28s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 23:18:52 - WARNING - __main__ - epoch 1 step 102 loss 0.19871\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:19:38 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:19:38 - INFO - __main__ -   eval_f1 = 0.2809\n",
      "05/03/2025 23:19:38 - INFO - __main__ -   eval_precision = 0.6694\n",
      "05/03/2025 23:19:38 - INFO - __main__ -   eval_recall = 0.1777\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 23:21:00 - WARNING - __main__ - epoch 1 step 204 loss 0.19797\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:21:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:21:46 - INFO - __main__ -   eval_f1 = 0.2598\n",
      "05/03/2025 23:21:46 - INFO - __main__ -   eval_precision = 0.7684\n",
      "05/03/2025 23:21:46 - INFO - __main__ -   eval_recall = 0.1563\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 23:23:08 - WARNING - __main__ - epoch 1 step 306 loss 0.18839\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:23:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:23:54 - INFO - __main__ -   eval_f1 = 0.2545\n",
      "05/03/2025 23:23:54 - INFO - __main__ -   eval_precision = 0.7802\n",
      "05/03/2025 23:23:54 - INFO - __main__ -   eval_recall = 0.152\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/03/2025 23:25:16 - WARNING - __main__ - epoch 1 step 408 loss 0.19025\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:26:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:26:02 - INFO - __main__ -   eval_f1 = 0.5078\n",
      "05/03/2025 23:26:02 - INFO - __main__ -   eval_precision = 0.5797\n",
      "05/03/2025 23:26:02 - INFO - __main__ -   eval_recall = 0.4518\n",
      " 99% 509/512 [09:57<00:02,  1.24it/s]05/03/2025 23:27:29 - WARNING - __main__ - epoch 1 step 510 loss 0.18416\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:28:14 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:28:14 - INFO - __main__ -   eval_f1 = 0.3266\n",
      "05/03/2025 23:28:14 - INFO - __main__ -   eval_precision = 0.7638\n",
      "05/03/2025 23:28:14 - INFO - __main__ -   eval_recall = 0.2077\n",
      "100% 512/512 [10:45<00:00,  1.26s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 23:29:38 - WARNING - __main__ - epoch 2 step 102 loss 0.14868\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:30:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:30:24 - INFO - __main__ -   eval_f1 = 0.3631\n",
      "05/03/2025 23:30:24 - INFO - __main__ -   eval_precision = 0.6744\n",
      "05/03/2025 23:30:24 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 23:31:46 - WARNING - __main__ - epoch 2 step 204 loss 0.14728\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:32:31 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:32:31 - INFO - __main__ -   eval_f1 = 0.362\n",
      "05/03/2025 23:32:31 - INFO - __main__ -   eval_precision = 0.5894\n",
      "05/03/2025 23:32:31 - INFO - __main__ -   eval_recall = 0.2612\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 23:33:53 - WARNING - __main__ - epoch 2 step 306 loss 0.13834\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:34:39 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:34:39 - INFO - __main__ -   eval_f1 = 0.2882\n",
      "05/03/2025 23:34:39 - INFO - __main__ -   eval_precision = 0.7615\n",
      "05/03/2025 23:34:39 - INFO - __main__ -   eval_recall = 0.1777\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/03/2025 23:36:01 - WARNING - __main__ - epoch 2 step 408 loss 0.13635\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:36:47 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:36:47 - INFO - __main__ -   eval_f1 = 0.32\n",
      "05/03/2025 23:36:47 - INFO - __main__ -   eval_precision = 0.6329\n",
      "05/03/2025 23:36:47 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 23:38:09 - WARNING - __main__ - epoch 2 step 510 loss 0.14018\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:38:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:38:55 - INFO - __main__ -   eval_f1 = 0.32\n",
      "05/03/2025 23:38:55 - INFO - __main__ -   eval_precision = 0.6329\n",
      "05/03/2025 23:38:55 - INFO - __main__ -   eval_recall = 0.2141\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 23:40:18 - WARNING - __main__ - epoch 3 step 102 loss 0.08858\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:41:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:41:04 - INFO - __main__ -   eval_f1 = 0.307\n",
      "05/03/2025 23:41:04 - INFO - __main__ -   eval_precision = 0.5288\n",
      "05/03/2025 23:41:04 - INFO - __main__ -   eval_recall = 0.2163\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 23:42:26 - WARNING - __main__ - epoch 3 step 204 loss 0.07342\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:43:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:43:12 - INFO - __main__ -   eval_f1 = 0.3399\n",
      "05/03/2025 23:43:12 - INFO - __main__ -   eval_precision = 0.4362\n",
      "05/03/2025 23:43:12 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 23:44:34 - WARNING - __main__ - epoch 3 step 306 loss 0.08902\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:45:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:45:20 - INFO - __main__ -   eval_f1 = 0.3849\n",
      "05/03/2025 23:45:20 - INFO - __main__ -   eval_precision = 0.3763\n",
      "05/03/2025 23:45:20 - INFO - __main__ -   eval_recall = 0.394\n",
      " 79% 407/512 [07:45<01:25,  1.24it/s]05/03/2025 23:46:42 - WARNING - __main__ - epoch 3 step 408 loss 0.07776\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:47:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:47:28 - INFO - __main__ -   eval_f1 = 0.4038\n",
      "05/03/2025 23:47:28 - INFO - __main__ -   eval_precision = 0.45\n",
      "05/03/2025 23:47:28 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 23:48:50 - WARNING - __main__ - epoch 3 step 510 loss 0.09215\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:49:35 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:49:35 - INFO - __main__ -   eval_f1 = 0.3101\n",
      "05/03/2025 23:49:35 - INFO - __main__ -   eval_precision = 0.5618\n",
      "05/03/2025 23:49:35 - INFO - __main__ -   eval_recall = 0.2141\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/03/2025 23:50:59 - WARNING - __main__ - epoch 4 step 102 loss 0.03522\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:51:44 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:51:45 - INFO - __main__ -   eval_f1 = 0.3071\n",
      "05/03/2025 23:51:45 - INFO - __main__ -   eval_precision = 0.4078\n",
      "05/03/2025 23:51:45 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/03/2025 23:53:07 - WARNING - __main__ - epoch 4 step 204 loss 0.05431\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:53:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:53:52 - INFO - __main__ -   eval_f1 = 0.2467\n",
      "05/03/2025 23:53:52 - INFO - __main__ -   eval_precision = 0.5319\n",
      "05/03/2025 23:53:52 - INFO - __main__ -   eval_recall = 0.1606\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/03/2025 23:55:14 - WARNING - __main__ - epoch 4 step 306 loss 0.04328\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:56:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:56:00 - INFO - __main__ -   eval_f1 = 0.3324\n",
      "05/03/2025 23:56:00 - INFO - __main__ -   eval_precision = 0.4779\n",
      "05/03/2025 23:56:00 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/03/2025 23:57:22 - WARNING - __main__ - epoch 4 step 408 loss 0.056\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/03/2025 23:58:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/03/2025 23:58:08 - INFO - __main__ -   eval_f1 = 0.2475\n",
      "05/03/2025 23:58:08 - INFO - __main__ -   eval_precision = 0.5396\n",
      "05/03/2025 23:58:08 - INFO - __main__ -   eval_recall = 0.1606\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/03/2025 23:59:30 - WARNING - __main__ - epoch 4 step 510 loss 0.04543\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:00:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:00:16 - INFO - __main__ -   eval_f1 = 0.2619\n",
      "05/04/2025 00:00:16 - INFO - __main__ -   eval_precision = 0.467\n",
      "05/04/2025 00:00:16 - INFO - __main__ -   eval_recall = 0.182\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 00:01:39 - WARNING - __main__ - epoch 5 step 102 loss 0.02275\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:02:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:02:25 - INFO - __main__ -   eval_f1 = 0.2903\n",
      "05/04/2025 00:02:25 - INFO - __main__ -   eval_precision = 0.3899\n",
      "05/04/2025 00:02:25 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 00:03:47 - WARNING - __main__ - epoch 5 step 204 loss 0.02214\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:04:33 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:04:33 - INFO - __main__ -   eval_f1 = 0.3159\n",
      "05/04/2025 00:04:33 - INFO - __main__ -   eval_precision = 0.3452\n",
      "05/04/2025 00:04:33 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 00:05:55 - WARNING - __main__ - epoch 5 step 306 loss 0.027\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:06:40 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:06:40 - INFO - __main__ -   eval_f1 = 0.2612\n",
      "05/04/2025 00:06:40 - INFO - __main__ -   eval_precision = 0.4054\n",
      "05/04/2025 00:06:40 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/04/2025 00:08:02 - WARNING - __main__ - epoch 5 step 408 loss 0.01767\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:08:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:08:48 - INFO - __main__ -   eval_f1 = 0.3401\n",
      "05/04/2025 00:08:48 - INFO - __main__ -   eval_precision = 0.3859\n",
      "05/04/2025 00:08:48 - INFO - __main__ -   eval_recall = 0.3041\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/04/2025 00:10:10 - WARNING - __main__ - epoch 5 step 510 loss 0.01823\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:10:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:10:56 - INFO - __main__ -   eval_f1 = 0.3487\n",
      "05/04/2025 00:10:56 - INFO - __main__ -   eval_precision = 0.3154\n",
      "05/04/2025 00:10:56 - INFO - __main__ -   eval_recall = 0.3897\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 00:12:19 - WARNING - __main__ - epoch 6 step 102 loss 0.01425\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:13:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:13:05 - INFO - __main__ -   eval_f1 = 0.3504\n",
      "05/04/2025 00:13:05 - INFO - __main__ -   eval_precision = 0.3198\n",
      "05/04/2025 00:13:05 - INFO - __main__ -   eval_recall = 0.3876\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 00:14:27 - WARNING - __main__ - epoch 6 step 204 loss 0.00824\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:15:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:15:13 - INFO - __main__ -   eval_f1 = 0.3479\n",
      "05/04/2025 00:15:13 - INFO - __main__ -   eval_precision = 0.3387\n",
      "05/04/2025 00:15:13 - INFO - __main__ -   eval_recall = 0.3576\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 00:16:35 - WARNING - __main__ - epoch 6 step 306 loss 0.0126\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:17:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:17:21 - INFO - __main__ -   eval_f1 = 0.2947\n",
      "05/04/2025 00:17:21 - INFO - __main__ -   eval_precision = 0.3767\n",
      "05/04/2025 00:17:21 - INFO - __main__ -   eval_recall = 0.242\n",
      " 79% 407/512 [07:44<01:24,  1.24it/s]05/04/2025 00:18:43 - WARNING - __main__ - epoch 6 step 408 loss 0.00671\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:19:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:19:28 - INFO - __main__ -   eval_f1 = 0.2346\n",
      "05/04/2025 00:19:28 - INFO - __main__ -   eval_precision = 0.4199\n",
      "05/04/2025 00:19:28 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 99% 509/512 [09:52<00:02,  1.24it/s]05/04/2025 00:20:50 - WARNING - __main__ - epoch 6 step 510 loss 0.00555\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:21:36 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:21:36 - INFO - __main__ -   eval_f1 = 0.259\n",
      "05/04/2025 00:21:36 - INFO - __main__ -   eval_precision = 0.3629\n",
      "05/04/2025 00:21:36 - INFO - __main__ -   eval_recall = 0.2013\n",
      "05/04/2025 00:21:36 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 99% 509/512 [10:39<00:03,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhD4aJaTrMrF",
    "outputId": "288aac55-510d-40d4-caf2-84cf0cdb288d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:23:15.293061: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 00:23:15.310881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746318195.332514   77900 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746318195.339135   77900 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 00:23:15.361038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "05/04/2025 00:23:18 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:24:38 - INFO - __main__ - ***** Test results *****\n",
      "05/04/2025 00:24:38 - INFO - __main__ -   auc_score = 0.8613\n",
      "05/04/2025 00:24:38 - INFO - __main__ -   test_f1 = 0.3864\n",
      "05/04/2025 00:24:38 - INFO - __main__ -   test_precision = 0.4354\n",
      "05/04/2025 00:24:38 - INFO - __main__ -   test_recall = 0.3474\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCpVvN3Lr3tr"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6ZnHttBr9BR",
    "outputId": "78a2f88a-e17b-4715-95c1-c1bc4a0128c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:26:32.204630: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 00:26:32.222592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746318392.244308   79236 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746318392.250954   79236 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 00:26:32.272891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "05/04/2025 00:26:35 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14687 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:22<05:32,  1.24it/s]05/04/2025 00:29:58 - WARNING - __main__ - epoch 0 step 102 loss 0.2902\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "05/04/2025 00:30:44 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:30:44 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/04/2025 00:30:44 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/04/2025 00:30:44 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 00:32:06 - WARNING - __main__ - epoch 0 step 204 loss 0.2938\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:32:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:32:52 - INFO - __main__ -   eval_f1 = 0.0085\n",
      "05/04/2025 00:32:52 - INFO - __main__ -   eval_precision = 0.5\n",
      "05/04/2025 00:32:52 - INFO - __main__ -   eval_recall = 0.0043\n",
      " 60% 305/512 [05:43<02:47,  1.24it/s]05/04/2025 00:34:19 - WARNING - __main__ - epoch 0 step 306 loss 0.25334\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:35:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:35:05 - INFO - __main__ -   eval_f1 = 0.194\n",
      "05/04/2025 00:35:05 - INFO - __main__ -   eval_precision = 0.7536\n",
      "05/04/2025 00:35:05 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 79% 407/512 [07:55<01:24,  1.24it/s]05/04/2025 00:36:31 - WARNING - __main__ - epoch 0 step 408 loss 0.22449\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:37:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:37:17 - INFO - __main__ -   eval_f1 = 0.242\n",
      "05/04/2025 00:37:17 - INFO - __main__ -   eval_precision = 0.7158\n",
      "05/04/2025 00:37:17 - INFO - __main__ -   eval_recall = 0.1456\n",
      " 99% 509/512 [10:07<00:02,  1.24it/s]05/04/2025 00:38:43 - WARNING - __main__ - epoch 0 step 510 loss 0.20682\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:39:29 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:39:29 - INFO - __main__ -   eval_f1 = 0.3311\n",
      "05/04/2025 00:39:29 - INFO - __main__ -   eval_precision = 0.7299\n",
      "05/04/2025 00:39:29 - INFO - __main__ -   eval_recall = 0.2141\n",
      "100% 512/512 [11:01<00:00,  1.29s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 00:40:59 - WARNING - __main__ - epoch 1 step 102 loss 0.19416\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:41:45 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:41:45 - INFO - __main__ -   eval_f1 = 0.3465\n",
      "05/04/2025 00:41:45 - INFO - __main__ -   eval_precision = 0.7554\n",
      "05/04/2025 00:41:45 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 40% 203/512 [03:33<04:10,  1.24it/s]05/04/2025 00:43:11 - WARNING - __main__ - epoch 1 step 204 loss 0.19922\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:43:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:43:57 - INFO - __main__ -   eval_f1 = 0.3438\n",
      "05/04/2025 00:43:57 - INFO - __main__ -   eval_precision = 0.7536\n",
      "05/04/2025 00:43:57 - INFO - __main__ -   eval_recall = 0.2227\n",
      " 60% 305/512 [05:41<02:47,  1.24it/s]05/04/2025 00:45:19 - WARNING - __main__ - epoch 1 step 306 loss 0.18426\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:46:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:46:05 - INFO - __main__ -   eval_f1 = 0.2409\n",
      "05/04/2025 00:46:05 - INFO - __main__ -   eval_precision = 0.8148\n",
      "05/04/2025 00:46:05 - INFO - __main__ -   eval_recall = 0.1413\n",
      " 79% 407/512 [07:49<01:24,  1.24it/s]05/04/2025 00:47:27 - WARNING - __main__ - epoch 1 step 408 loss 0.19999\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:48:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:48:13 - INFO - __main__ -   eval_f1 = 0.1034\n",
      "05/04/2025 00:48:13 - INFO - __main__ -   eval_precision = 0.7222\n",
      "05/04/2025 00:48:13 - INFO - __main__ -   eval_recall = 0.0557\n",
      " 99% 509/512 [09:57<00:02,  1.24it/s]05/04/2025 00:49:35 - WARNING - __main__ - epoch 1 step 510 loss 0.18916\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:50:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:50:21 - INFO - __main__ -   eval_f1 = 0.4967\n",
      "05/04/2025 00:50:21 - INFO - __main__ -   eval_precision = 0.5033\n",
      "05/04/2025 00:50:21 - INFO - __main__ -   eval_recall = 0.4904\n",
      "100% 512/512 [10:49<00:00,  1.27s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 00:51:48 - WARNING - __main__ - epoch 2 step 102 loss 0.14558\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:52:34 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:52:34 - INFO - __main__ -   eval_f1 = 0.4571\n",
      "05/04/2025 00:52:34 - INFO - __main__ -   eval_precision = 0.5569\n",
      "05/04/2025 00:52:34 - INFO - __main__ -   eval_recall = 0.3876\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 00:53:56 - WARNING - __main__ - epoch 2 step 204 loss 0.13695\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:54:42 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:54:42 - INFO - __main__ -   eval_f1 = 0.32\n",
      "05/04/2025 00:54:42 - INFO - __main__ -   eval_precision = 0.6329\n",
      "05/04/2025 00:54:42 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 00:56:04 - WARNING - __main__ - epoch 2 step 306 loss 0.15277\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:56:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:56:50 - INFO - __main__ -   eval_f1 = 0.4035\n",
      "05/04/2025 00:56:50 - INFO - __main__ -   eval_precision = 0.478\n",
      "05/04/2025 00:56:50 - INFO - __main__ -   eval_recall = 0.349\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/04/2025 00:58:12 - WARNING - __main__ - epoch 2 step 408 loss 0.14857\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 00:58:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 00:58:58 - INFO - __main__ -   eval_f1 = 0.2803\n",
      "05/04/2025 00:58:58 - INFO - __main__ -   eval_precision = 0.6949\n",
      "05/04/2025 00:58:58 - INFO - __main__ -   eval_recall = 0.1756\n",
      " 99% 509/512 [09:53<00:02,  1.24it/s]05/04/2025 01:00:20 - WARNING - __main__ - epoch 2 step 510 loss 0.14687\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:01:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:01:06 - INFO - __main__ -   eval_f1 = 0.3252\n",
      "05/04/2025 01:01:06 - INFO - __main__ -   eval_precision = 0.573\n",
      "05/04/2025 01:01:06 - INFO - __main__ -   eval_recall = 0.227\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 01:02:29 - WARNING - __main__ - epoch 3 step 102 loss 0.09772\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:03:15 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:03:15 - INFO - __main__ -   eval_f1 = 0.3065\n",
      "05/04/2025 01:03:15 - INFO - __main__ -   eval_precision = 0.5531\n",
      "05/04/2025 01:03:15 - INFO - __main__ -   eval_recall = 0.212\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 01:04:37 - WARNING - __main__ - epoch 3 step 204 loss 0.08905\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:05:23 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:05:23 - INFO - __main__ -   eval_f1 = 0.2357\n",
      "05/04/2025 01:05:23 - INFO - __main__ -   eval_precision = 0.427\n",
      "05/04/2025 01:05:23 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 01:06:45 - WARNING - __main__ - epoch 3 step 306 loss 0.09705\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:07:31 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:07:31 - INFO - __main__ -   eval_f1 = 0.3525\n",
      "05/04/2025 01:07:31 - INFO - __main__ -   eval_precision = 0.4367\n",
      "05/04/2025 01:07:31 - INFO - __main__ -   eval_recall = 0.2955\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/04/2025 01:08:53 - WARNING - __main__ - epoch 3 step 408 loss 0.10527\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:09:39 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:09:39 - INFO - __main__ -   eval_f1 = 0.3321\n",
      "05/04/2025 01:09:39 - INFO - __main__ -   eval_precision = 0.4024\n",
      "05/04/2025 01:09:39 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 99% 509/512 [09:53<00:02,  1.24it/s]05/04/2025 01:11:01 - WARNING - __main__ - epoch 3 step 510 loss 0.10046\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:11:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:11:46 - INFO - __main__ -   eval_f1 = 0.2541\n",
      "05/04/2025 01:11:46 - INFO - __main__ -   eval_precision = 0.554\n",
      "05/04/2025 01:11:46 - INFO - __main__ -   eval_recall = 0.1649\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 01:13:10 - WARNING - __main__ - epoch 4 step 102 loss 0.05277\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:13:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:13:56 - INFO - __main__ -   eval_f1 = 0.2049\n",
      "05/04/2025 01:13:56 - INFO - __main__ -   eval_precision = 0.3583\n",
      "05/04/2025 01:13:56 - INFO - __main__ -   eval_recall = 0.1435\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 01:15:18 - WARNING - __main__ - epoch 4 step 204 loss 0.05749\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:16:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:16:04 - INFO - __main__ -   eval_f1 = 0.2794\n",
      "05/04/2025 01:16:04 - INFO - __main__ -   eval_precision = 0.3529\n",
      "05/04/2025 01:16:04 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 01:17:26 - WARNING - __main__ - epoch 4 step 306 loss 0.06257\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:18:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:18:11 - INFO - __main__ -   eval_f1 = 0.1938\n",
      "05/04/2025 01:18:11 - INFO - __main__ -   eval_precision = 0.4155\n",
      "05/04/2025 01:18:11 - INFO - __main__ -   eval_recall = 0.1263\n",
      " 79% 407/512 [07:45<01:25,  1.24it/s]05/04/2025 01:19:34 - WARNING - __main__ - epoch 4 step 408 loss 0.06667\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:20:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:20:19 - INFO - __main__ -   eval_f1 = 0.2676\n",
      "05/04/2025 01:20:19 - INFO - __main__ -   eval_precision = 0.3909\n",
      "05/04/2025 01:20:19 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 99% 509/512 [09:53<00:02,  1.24it/s]05/04/2025 01:21:41 - WARNING - __main__ - epoch 4 step 510 loss 0.05754\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:22:27 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:22:27 - INFO - __main__ -   eval_f1 = 0.3176\n",
      "05/04/2025 01:22:27 - INFO - __main__ -   eval_precision = 0.3525\n",
      "05/04/2025 01:22:27 - INFO - __main__ -   eval_recall = 0.2891\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 01:23:51 - WARNING - __main__ - epoch 5 step 102 loss 0.02826\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:24:37 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:24:37 - INFO - __main__ -   eval_f1 = 0.2771\n",
      "05/04/2025 01:24:37 - INFO - __main__ -   eval_precision = 0.3168\n",
      "05/04/2025 01:24:37 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 40% 203/512 [03:29<04:10,  1.24it/s]05/04/2025 01:25:59 - WARNING - __main__ - epoch 5 step 204 loss 0.03836\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:26:44 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:26:44 - INFO - __main__ -   eval_f1 = 0.2875\n",
      "05/04/2025 01:26:44 - INFO - __main__ -   eval_precision = 0.3333\n",
      "05/04/2025 01:26:44 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 01:28:06 - WARNING - __main__ - epoch 5 step 306 loss 0.0354\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:28:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:28:52 - INFO - __main__ -   eval_f1 = 0.2318\n",
      "05/04/2025 01:28:52 - INFO - __main__ -   eval_precision = 0.3333\n",
      "05/04/2025 01:28:52 - INFO - __main__ -   eval_recall = 0.1777\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/04/2025 01:30:14 - WARNING - __main__ - epoch 5 step 408 loss 0.02741\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:31:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:31:00 - INFO - __main__ -   eval_f1 = 0.268\n",
      "05/04/2025 01:31:00 - INFO - __main__ -   eval_precision = 0.3186\n",
      "05/04/2025 01:31:00 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 99% 509/512 [09:53<00:02,  1.24it/s]05/04/2025 01:32:22 - WARNING - __main__ - epoch 5 step 510 loss 0.03319\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:33:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:33:08 - INFO - __main__ -   eval_f1 = 0.1983\n",
      "05/04/2025 01:33:08 - INFO - __main__ -   eval_precision = 0.3013\n",
      "05/04/2025 01:33:08 - INFO - __main__ -   eval_recall = 0.1478\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 01:34:31 - WARNING - __main__ - epoch 6 step 102 loss 0.01259\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:35:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:35:17 - INFO - __main__ -   eval_f1 = 0.1877\n",
      "05/04/2025 01:35:17 - INFO - __main__ -   eval_precision = 0.2977\n",
      "05/04/2025 01:35:17 - INFO - __main__ -   eval_recall = 0.137\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 01:36:39 - WARNING - __main__ - epoch 6 step 204 loss 0.01555\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:37:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:37:25 - INFO - __main__ -   eval_f1 = 0.2009\n",
      "05/04/2025 01:37:25 - INFO - __main__ -   eval_precision = 0.3136\n",
      "05/04/2025 01:37:25 - INFO - __main__ -   eval_recall = 0.1478\n",
      " 60% 305/512 [05:37<02:47,  1.24it/s]05/04/2025 01:38:47 - WARNING - __main__ - epoch 6 step 306 loss 0.0195\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:39:33 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:39:33 - INFO - __main__ -   eval_f1 = 0.1929\n",
      "05/04/2025 01:39:33 - INFO - __main__ -   eval_precision = 0.314\n",
      "05/04/2025 01:39:33 - INFO - __main__ -   eval_recall = 0.1392\n",
      " 79% 407/512 [07:45<01:24,  1.24it/s]05/04/2025 01:40:55 - WARNING - __main__ - epoch 6 step 408 loss 0.01263\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:41:41 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:41:41 - INFO - __main__ -   eval_f1 = 0.228\n",
      "05/04/2025 01:41:41 - INFO - __main__ -   eval_precision = 0.3111\n",
      "05/04/2025 01:41:41 - INFO - __main__ -   eval_recall = 0.1799\n",
      " 99% 509/512 [09:53<00:02,  1.24it/s]05/04/2025 01:43:03 - WARNING - __main__ - epoch 6 step 510 loss 0.01279\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:43:49 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:43:49 - INFO - __main__ -   eval_f1 = 0.2363\n",
      "05/04/2025 01:43:49 - INFO - __main__ -   eval_precision = 0.3443\n",
      "05/04/2025 01:43:49 - INFO - __main__ -   eval_recall = 0.1799\n",
      "100% 512/512 [10:40<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:32,  1.24it/s]05/04/2025 01:45:12 - WARNING - __main__ - epoch 7 step 102 loss 0.0055\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:45:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 01:45:58 - INFO - __main__ -   eval_f1 = 0.2554\n",
      "05/04/2025 01:45:58 - INFO - __main__ -   eval_precision = 0.3117\n",
      "05/04/2025 01:45:58 - INFO - __main__ -   eval_recall = 0.2163\n",
      "05/04/2025 01:45:58 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 101/512 [02:08<08:41,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ao0b0ZaxwIKr",
    "outputId": "76b3fac4-ed12-45d2-de71-bb74168c89c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 01:46:07.024189: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 01:46:07.041993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746323167.063596  109312 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746323167.070166  109312 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 01:46:07.092105: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "05/04/2025 01:46:10 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 01:47:30 - INFO - __main__ - ***** Test results *****\n",
      "05/04/2025 01:47:30 - INFO - __main__ -   auc_score = 0.8593\n",
      "05/04/2025 01:47:30 - INFO - __main__ -   test_f1 = 0.3961\n",
      "05/04/2025 01:47:30 - INFO - __main__ -   test_precision = 0.4053\n",
      "05/04/2025 01:47:30 - INFO - __main__ -   test_recall = 0.3874\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLIiOuL-B_sY"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUgjYwmR6l-W",
    "outputId": "d2bad0c6-cc96-497a-d99d-8099ee022b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 15:29:32.677237: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 15:29:32.694758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746372572.716568    2740 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746372572.723261    2740 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 15:29:32.745217: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "tokenizer_config.json: 100% 20.8k/20.8k [00:00<00:00, 77.0MB/s]\n",
      "tokenizer.json: 100% 2.13M/2.13M [00:00<00:00, 12.3MB/s]\n",
      "special_tokens_map.json: 100% 694/694 [00:00<00:00, 4.76MB/s]\n",
      "05/04/2025 15:29:37 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "config.json: 100% 1.19k/1.19k [00:00<00:00, 8.35MB/s]\n",
      "model.safetensors: 100% 599M/599M [00:02<00:00, 260MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9827 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:22<05:32,  1.23it/s]05/04/2025 15:33:18 - WARNING - __main__ - epoch 0 step 102 loss 0.27962\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "05/04/2025 15:34:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:34:04 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/04/2025 15:34:04 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/04/2025 15:34:04 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [03:30<04:10,  1.23it/s]05/04/2025 15:35:26 - WARNING - __main__ - epoch 0 step 204 loss 0.25551\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:36:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:36:12 - INFO - __main__ -   eval_f1 = 0.0334\n",
      "05/04/2025 15:36:12 - INFO - __main__ -   eval_precision = 0.6667\n",
      "05/04/2025 15:36:12 - INFO - __main__ -   eval_recall = 0.0171\n",
      " 60% 305/512 [05:42<02:47,  1.23it/s]05/04/2025 15:37:38 - WARNING - __main__ - epoch 0 step 306 loss 0.22549\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:38:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:38:24 - INFO - __main__ -   eval_f1 = 0.2157\n",
      "05/04/2025 15:38:24 - INFO - __main__ -   eval_precision = 0.7375\n",
      "05/04/2025 15:38:24 - INFO - __main__ -   eval_recall = 0.1263\n",
      " 79% 407/512 [07:54<01:25,  1.23it/s]05/04/2025 15:39:50 - WARNING - __main__ - epoch 0 step 408 loss 0.22223\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:40:36 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:40:36 - INFO - __main__ -   eval_f1 = 0.4295\n",
      "05/04/2025 15:40:36 - INFO - __main__ -   eval_precision = 0.5947\n",
      "05/04/2025 15:40:36 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 99% 509/512 [10:07<00:02,  1.23it/s]05/04/2025 15:42:02 - WARNING - __main__ - epoch 0 step 510 loss 0.20623\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:42:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:42:48 - INFO - __main__ -   eval_f1 = 0.2327\n",
      "05/04/2025 15:42:48 - INFO - __main__ -   eval_precision = 0.7711\n",
      "05/04/2025 15:42:48 - INFO - __main__ -   eval_recall = 0.137\n",
      "100% 512/512 [10:54<00:00,  1.28s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 15:44:12 - WARNING - __main__ - epoch 1 step 102 loss 0.179\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:44:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:44:58 - INFO - __main__ -   eval_f1 = 0.3769\n",
      "05/04/2025 15:44:58 - INFO - __main__ -   eval_precision = 0.6492\n",
      "05/04/2025 15:44:58 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 15:46:20 - WARNING - __main__ - epoch 1 step 204 loss 0.1811\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:47:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:47:06 - INFO - __main__ -   eval_f1 = 0.4494\n",
      "05/04/2025 15:47:06 - INFO - __main__ -   eval_precision = 0.6531\n",
      "05/04/2025 15:47:06 - INFO - __main__ -   eval_recall = 0.3426\n",
      " 60% 305/512 [05:44<02:48,  1.23it/s]05/04/2025 15:48:34 - WARNING - __main__ - epoch 1 step 306 loss 0.19903\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:49:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:49:20 - INFO - __main__ -   eval_f1 = 0.377\n",
      "05/04/2025 15:49:20 - INFO - __main__ -   eval_precision = 0.7421\n",
      "05/04/2025 15:49:20 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 79% 407/512 [07:52<01:25,  1.23it/s]05/04/2025 15:50:43 - WARNING - __main__ - epoch 1 step 408 loss 0.18759\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:51:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:51:28 - INFO - __main__ -   eval_f1 = 0.4454\n",
      "05/04/2025 15:51:28 - INFO - __main__ -   eval_precision = 0.6597\n",
      "05/04/2025 15:51:28 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 99% 509/512 [10:00<00:02,  1.23it/s]05/04/2025 15:52:51 - WARNING - __main__ - epoch 1 step 510 loss 0.17949\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:53:37 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:53:37 - INFO - __main__ -   eval_f1 = 0.417\n",
      "05/04/2025 15:53:37 - INFO - __main__ -   eval_precision = 0.6636\n",
      "05/04/2025 15:53:37 - INFO - __main__ -   eval_recall = 0.3041\n",
      "100% 512/512 [10:48<00:00,  1.27s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 15:55:00 - WARNING - __main__ - epoch 2 step 102 loss 0.13897\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:55:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:55:46 - INFO - __main__ -   eval_f1 = 0.2563\n",
      "05/04/2025 15:55:46 - INFO - __main__ -   eval_precision = 0.8161\n",
      "05/04/2025 15:55:46 - INFO - __main__ -   eval_recall = 0.152\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 15:57:08 - WARNING - __main__ - epoch 2 step 204 loss 0.13974\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 15:57:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 15:57:54 - INFO - __main__ -   eval_f1 = 0.3536\n",
      "05/04/2025 15:57:54 - INFO - __main__ -   eval_precision = 0.5777\n",
      "05/04/2025 15:57:54 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 60% 305/512 [05:38<02:48,  1.23it/s]05/04/2025 15:59:17 - WARNING - __main__ - epoch 2 step 306 loss 0.13764\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:00:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:00:03 - INFO - __main__ -   eval_f1 = 0.3984\n",
      "05/04/2025 16:00:03 - INFO - __main__ -   eval_precision = 0.5302\n",
      "05/04/2025 16:00:03 - INFO - __main__ -   eval_recall = 0.3191\n",
      " 79% 407/512 [07:46<01:25,  1.23it/s]05/04/2025 16:01:25 - WARNING - __main__ - epoch 2 step 408 loss 0.12846\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:02:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:02:11 - INFO - __main__ -   eval_f1 = 0.3471\n",
      "05/04/2025 16:02:11 - INFO - __main__ -   eval_precision = 0.3611\n",
      "05/04/2025 16:02:11 - INFO - __main__ -   eval_recall = 0.334\n",
      " 99% 509/512 [09:54<00:02,  1.23it/s]05/04/2025 16:03:33 - WARNING - __main__ - epoch 2 step 510 loss 0.15054\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:04:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:04:19 - INFO - __main__ -   eval_f1 = 0.3016\n",
      "05/04/2025 16:04:19 - INFO - __main__ -   eval_precision = 0.7909\n",
      "05/04/2025 16:04:19 - INFO - __main__ -   eval_recall = 0.1863\n",
      "100% 512/512 [10:42<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 16:05:42 - WARNING - __main__ - epoch 3 step 102 loss 0.08788\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:06:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:06:28 - INFO - __main__ -   eval_f1 = 0.2731\n",
      "05/04/2025 16:06:28 - INFO - __main__ -   eval_precision = 0.4346\n",
      "05/04/2025 16:06:28 - INFO - __main__ -   eval_recall = 0.1991\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 16:07:51 - WARNING - __main__ - epoch 3 step 204 loss 0.0871\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:08:36 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:08:36 - INFO - __main__ -   eval_f1 = 0.2362\n",
      "05/04/2025 16:08:36 - INFO - __main__ -   eval_precision = 0.4834\n",
      "05/04/2025 16:08:36 - INFO - __main__ -   eval_recall = 0.1563\n",
      " 60% 305/512 [05:37<02:47,  1.23it/s]05/04/2025 16:09:59 - WARNING - __main__ - epoch 3 step 306 loss 0.08089\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:10:44 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:10:44 - INFO - __main__ -   eval_f1 = 0.363\n",
      "05/04/2025 16:10:44 - INFO - __main__ -   eval_precision = 0.3888\n",
      "05/04/2025 16:10:44 - INFO - __main__ -   eval_recall = 0.3405\n",
      " 79% 407/512 [07:46<01:25,  1.23it/s]05/04/2025 16:12:07 - WARNING - __main__ - epoch 3 step 408 loss 0.0921\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:12:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:12:52 - INFO - __main__ -   eval_f1 = 0.3733\n",
      "05/04/2025 16:12:52 - INFO - __main__ -   eval_precision = 0.4947\n",
      "05/04/2025 16:12:52 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 99% 509/512 [09:53<00:02,  1.23it/s]05/04/2025 16:14:15 - WARNING - __main__ - epoch 3 step 510 loss 0.07923\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:15:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:15:01 - INFO - __main__ -   eval_f1 = 0.2835\n",
      "05/04/2025 16:15:01 - INFO - __main__ -   eval_precision = 0.5055\n",
      "05/04/2025 16:15:01 - INFO - __main__ -   eval_recall = 0.197\n",
      "100% 512/512 [10:41<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 16:16:24 - WARNING - __main__ - epoch 4 step 102 loss 0.03543\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:17:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:17:10 - INFO - __main__ -   eval_f1 = 0.2245\n",
      "05/04/2025 16:17:10 - INFO - __main__ -   eval_precision = 0.5154\n",
      "05/04/2025 16:17:10 - INFO - __main__ -   eval_recall = 0.1435\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 16:18:32 - WARNING - __main__ - epoch 4 step 204 loss 0.04435\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:19:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:19:18 - INFO - __main__ -   eval_f1 = 0.2095\n",
      "05/04/2025 16:19:18 - INFO - __main__ -   eval_precision = 0.496\n",
      "05/04/2025 16:19:18 - INFO - __main__ -   eval_recall = 0.1328\n",
      " 60% 305/512 [05:37<02:47,  1.23it/s]05/04/2025 16:20:40 - WARNING - __main__ - epoch 4 step 306 loss 0.05317\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:21:26 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:21:26 - INFO - __main__ -   eval_f1 = 0.2655\n",
      "05/04/2025 16:21:26 - INFO - __main__ -   eval_precision = 0.39\n",
      "05/04/2025 16:21:26 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 79% 407/512 [07:45<01:25,  1.23it/s]05/04/2025 16:22:48 - WARNING - __main__ - epoch 4 step 408 loss 0.0449\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:23:34 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:23:34 - INFO - __main__ -   eval_f1 = 0.313\n",
      "05/04/2025 16:23:34 - INFO - __main__ -   eval_precision = 0.5147\n",
      "05/04/2025 16:23:34 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 99% 509/512 [09:53<00:02,  1.23it/s]05/04/2025 16:24:56 - WARNING - __main__ - epoch 4 step 510 loss 0.04924\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:25:42 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:25:42 - INFO - __main__ -   eval_f1 = 0.2661\n",
      "05/04/2025 16:25:42 - INFO - __main__ -   eval_precision = 0.4194\n",
      "05/04/2025 16:25:42 - INFO - __main__ -   eval_recall = 0.1949\n",
      "100% 512/512 [10:41<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 16:27:06 - WARNING - __main__ - epoch 5 step 102 loss 0.01849\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:27:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:27:52 - INFO - __main__ -   eval_f1 = 0.2817\n",
      "05/04/2025 16:27:52 - INFO - __main__ -   eval_precision = 0.3148\n",
      "05/04/2025 16:27:52 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 40% 203/512 [03:29<04:11,  1.23it/s]05/04/2025 16:29:14 - WARNING - __main__ - epoch 5 step 204 loss 0.02811\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:30:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:30:00 - INFO - __main__ -   eval_f1 = 0.2556\n",
      "05/04/2025 16:30:00 - INFO - __main__ -   eval_precision = 0.3636\n",
      "05/04/2025 16:30:00 - INFO - __main__ -   eval_recall = 0.197\n",
      " 60% 305/512 [05:37<02:47,  1.23it/s]05/04/2025 16:31:22 - WARNING - __main__ - epoch 5 step 306 loss 0.01951\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:32:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:32:08 - INFO - __main__ -   eval_f1 = 0.1658\n",
      "05/04/2025 16:32:08 - INFO - __main__ -   eval_precision = 0.3676\n",
      "05/04/2025 16:32:08 - INFO - __main__ -   eval_recall = 0.1071\n",
      " 79% 407/512 [07:45<01:25,  1.23it/s]05/04/2025 16:33:30 - WARNING - __main__ - epoch 5 step 408 loss 0.02963\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:34:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:34:16 - INFO - __main__ -   eval_f1 = 0.2081\n",
      "05/04/2025 16:34:16 - INFO - __main__ -   eval_precision = 0.4806\n",
      "05/04/2025 16:34:16 - INFO - __main__ -   eval_recall = 0.1328\n",
      " 99% 509/512 [09:53<00:02,  1.23it/s]05/04/2025 16:35:38 - WARNING - __main__ - epoch 5 step 510 loss 0.02223\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:36:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:36:24 - INFO - __main__ -   eval_f1 = 0.1942\n",
      "05/04/2025 16:36:24 - INFO - __main__ -   eval_precision = 0.3974\n",
      "05/04/2025 16:36:24 - INFO - __main__ -   eval_recall = 0.1285\n",
      "100% 512/512 [10:41<00:00,  1.25s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:21<05:33,  1.23it/s]05/04/2025 16:37:48 - WARNING - __main__ - epoch 6 step 102 loss 0.00872\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:38:33 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:38:33 - INFO - __main__ -   eval_f1 = 0.2775\n",
      "05/04/2025 16:38:33 - INFO - __main__ -   eval_precision = 0.3144\n",
      "05/04/2025 16:38:33 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 40% 203/512 [03:29<04:10,  1.23it/s]05/04/2025 16:39:56 - WARNING - __main__ - epoch 6 step 204 loss 0.01794\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:40:42 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:40:42 - INFO - __main__ -   eval_f1 = 0.2794\n",
      "05/04/2025 16:40:42 - INFO - __main__ -   eval_precision = 0.3579\n",
      "05/04/2025 16:40:42 - INFO - __main__ -   eval_recall = 0.2291\n",
      " 60% 305/512 [05:37<02:47,  1.23it/s]05/04/2025 16:42:04 - WARNING - __main__ - epoch 6 step 306 loss 0.01059\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:42:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 16:42:50 - INFO - __main__ -   eval_f1 = 0.1897\n",
      "05/04/2025 16:42:50 - INFO - __main__ -   eval_precision = 0.3806\n",
      "05/04/2025 16:42:50 - INFO - __main__ -   eval_recall = 0.1263\n",
      "05/04/2025 16:42:50 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 60% 305/512 [06:24<04:21,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ca6q96br6pV9",
    "outputId": "23886ccc-0531-460a-ad36-154f1a289b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 16:50:04.722640: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 16:50:04.740394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746377404.763308    2891 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746377404.770408    2891 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 16:50:04.793543: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "tokenizer_config.json: 100% 20.8k/20.8k [00:00<00:00, 72.6MB/s]\n",
      "tokenizer.json: 100% 2.13M/2.13M [00:00<00:00, 6.42MB/s]\n",
      "special_tokens_map.json: 100% 694/694 [00:00<00:00, 4.12MB/s]\n",
      "05/04/2025 16:50:10 - INFO - util - Loading model answerdotai/ModernBERT-base\n",
      "config.json: 100% 1.19k/1.19k [00:00<00:00, 7.46MB/s]\n",
      "model.safetensors: 100% 599M/599M [00:02<00:00, 248MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 16:52:00 - INFO - __main__ - ***** Test results *****\n",
      "05/04/2025 16:52:00 - INFO - __main__ -   auc_score = 0.8596\n",
      "05/04/2025 16:52:00 - INFO - __main__ -   test_f1 = 0.3499\n",
      "05/04/2025 16:52:00 - INFO - __main__ -   test_precision = 0.506\n",
      "05/04/2025 16:52:00 - INFO - __main__ -   test_recall = 0.2674\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model modernbert \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRfT1Ac4CKxZ"
   },
   "source": [
    "#### Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STGdY9-ECtn_",
    "outputId": "26f0037b-698f-40e3-8222-e0a0ea6edfc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 13:22:45.077240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 13:22:45.095452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 13:22:45.116383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 13:22:45.122747: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 13:22:45.137900: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 13:22:46.457996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 13:22:49 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:57<07:08,  1.04s/it]01/08/2025 13:26:51 - WARNING - __main__ - epoch 0 step 102 loss 0.29859\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 13:27:53 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:27:53 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 13:27:53 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 13:27:53 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [04:56<06:07,  1.19s/it]01/08/2025 13:29:50 - WARNING - __main__ - epoch 0 step 204 loss 0.26919\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:30:52 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:30:52 - INFO - __main__ -   eval_f1 = 0.0733\n",
      "01/08/2025 13:30:52 - INFO - __main__ -   eval_precision = 0.75\n",
      "01/08/2025 13:30:52 - INFO - __main__ -   eval_recall = 0.0385\n",
      " 60% 305/512 [08:09<04:04,  1.18s/it]01/08/2025 13:33:03 - WARNING - __main__ - epoch 0 step 306 loss 0.23159\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:34:05 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:34:05 - INFO - __main__ -   eval_f1 = 0.3272\n",
      "01/08/2025 13:34:05 - INFO - __main__ -   eval_precision = 0.5856\n",
      "01/08/2025 13:34:05 - INFO - __main__ -   eval_recall = 0.227\n",
      " 79% 407/512 [11:20<02:01,  1.16s/it]01/08/2025 13:36:14 - WARNING - __main__ - epoch 0 step 408 loss 0.2208\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:37:16 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:37:16 - INFO - __main__ -   eval_f1 = 0.2779\n",
      "01/08/2025 13:37:16 - INFO - __main__ -   eval_precision = 0.6983\n",
      "01/08/2025 13:37:16 - INFO - __main__ -   eval_recall = 0.1734\n",
      " 99% 509/512 [14:16<00:03,  1.13s/it]01/08/2025 13:39:10 - WARNING - __main__ - epoch 0 step 510 loss 0.20396\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:40:13 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:40:13 - INFO - __main__ -   eval_f1 = 0.3077\n",
      "01/08/2025 13:40:13 - INFO - __main__ -   eval_precision = 0.7627\n",
      "01/08/2025 13:40:13 - INFO - __main__ -   eval_recall = 0.1927\n",
      "100% 512/512 [15:21<00:00,  1.80s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:15,  1.06s/it]01/08/2025 13:42:10 - WARNING - __main__ - epoch 1 step 102 loss 0.20314\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:43:12 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:43:12 - INFO - __main__ -   eval_f1 = 0.3736\n",
      "01/08/2025 13:43:12 - INFO - __main__ -   eval_precision = 0.7532\n",
      "01/08/2025 13:43:12 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 40% 203/512 [05:07<06:04,  1.18s/it]01/08/2025 13:45:23 - WARNING - __main__ - epoch 1 step 204 loss 0.19251\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:46:25 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:46:25 - INFO - __main__ -   eval_f1 = 0.4622\n",
      "01/08/2025 13:46:25 - INFO - __main__ -   eval_precision = 0.6264\n",
      "01/08/2025 13:46:25 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 60% 305/512 [08:21<04:09,  1.20s/it]01/08/2025 13:48:37 - WARNING - __main__ - epoch 1 step 306 loss 0.17224\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:49:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:49:39 - INFO - __main__ -   eval_f1 = 0.4111\n",
      "01/08/2025 13:49:39 - INFO - __main__ -   eval_precision = 0.7389\n",
      "01/08/2025 13:49:39 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 79% 407/512 [11:19<01:58,  1.12s/it]01/08/2025 13:51:35 - WARNING - __main__ - epoch 1 step 408 loss 0.20471\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:52:37 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:52:37 - INFO - __main__ -   eval_f1 = 0.498\n",
      "01/08/2025 13:52:37 - INFO - __main__ -   eval_precision = 0.6643\n",
      "01/08/2025 13:52:37 - INFO - __main__ -   eval_recall = 0.3983\n",
      " 99% 509/512 [14:30<00:03,  1.05s/it]01/08/2025 13:54:46 - WARNING - __main__ - epoch 1 step 510 loss 0.1753\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:55:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:55:48 - INFO - __main__ -   eval_f1 = 0.4679\n",
      "01/08/2025 13:55:48 - INFO - __main__ -   eval_precision = 0.6477\n",
      "01/08/2025 13:55:48 - INFO - __main__ -   eval_recall = 0.3662\n",
      "100% 512/512 [15:35<00:00,  1.83s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:34,  1.11s/it]01/08/2025 13:57:44 - WARNING - __main__ - epoch 2 step 102 loss 0.15872\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 13:58:47 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 13:58:47 - INFO - __main__ -   eval_f1 = 0.3682\n",
      "01/08/2025 13:58:47 - INFO - __main__ -   eval_precision = 0.8162\n",
      "01/08/2025 13:58:47 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 40% 203/512 [04:52<06:16,  1.22s/it]01/08/2025 14:00:43 - WARNING - __main__ - epoch 2 step 204 loss 0.14424\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:01:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:01:45 - INFO - __main__ -   eval_f1 = 0.4539\n",
      "01/08/2025 14:01:45 - INFO - __main__ -   eval_precision = 0.4913\n",
      "01/08/2025 14:01:45 - INFO - __main__ -   eval_recall = 0.4218\n",
      " 60% 305/512 [07:50<04:09,  1.20s/it]01/08/2025 14:03:41 - WARNING - __main__ - epoch 2 step 306 loss 0.13652\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:04:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:04:43 - INFO - __main__ -   eval_f1 = 0.4235\n",
      "01/08/2025 14:04:43 - INFO - __main__ -   eval_precision = 0.6761\n",
      "01/08/2025 14:04:43 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 79% 407/512 [10:50<02:03,  1.17s/it]01/08/2025 14:06:41 - WARNING - __main__ - epoch 2 step 408 loss 0.14074\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:07:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:07:43 - INFO - __main__ -   eval_f1 = 0.4804\n",
      "01/08/2025 14:07:43 - INFO - __main__ -   eval_precision = 0.6496\n",
      "01/08/2025 14:07:43 - INFO - __main__ -   eval_recall = 0.3812\n",
      " 99% 509/512 [13:49<00:03,  1.15s/it]01/08/2025 14:09:40 - WARNING - __main__ - epoch 2 step 510 loss 0.14251\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:10:42 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:10:42 - INFO - __main__ -   eval_f1 = 0.4521\n",
      "01/08/2025 14:10:42 - INFO - __main__ -   eval_precision = 0.5303\n",
      "01/08/2025 14:10:42 - INFO - __main__ -   eval_recall = 0.394\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:56<07:35,  1.11s/it]01/08/2025 14:12:41 - WARNING - __main__ - epoch 3 step 102 loss 0.10817\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:13:44 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:13:44 - INFO - __main__ -   eval_f1 = 0.1683\n",
      "01/08/2025 14:13:44 - INFO - __main__ -   eval_precision = 0.7857\n",
      "01/08/2025 14:13:44 - INFO - __main__ -   eval_recall = 0.0942\n",
      " 40% 203/512 [04:54<05:49,  1.13s/it]01/08/2025 14:15:39 - WARNING - __main__ - epoch 3 step 204 loss 0.09541\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:16:41 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:16:41 - INFO - __main__ -   eval_f1 = 0.3546\n",
      "01/08/2025 14:16:41 - INFO - __main__ -   eval_precision = 0.6981\n",
      "01/08/2025 14:16:41 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 60% 305/512 [07:52<04:00,  1.16s/it]01/08/2025 14:18:37 - WARNING - __main__ - epoch 3 step 306 loss 0.09244\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:19:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:19:39 - INFO - __main__ -   eval_f1 = 0.261\n",
      "01/08/2025 14:19:39 - INFO - __main__ -   eval_precision = 0.626\n",
      "01/08/2025 14:19:39 - INFO - __main__ -   eval_recall = 0.1649\n",
      " 79% 407/512 [10:51<02:01,  1.16s/it]01/08/2025 14:21:36 - WARNING - __main__ - epoch 3 step 408 loss 0.10722\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:22:38 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:22:38 - INFO - __main__ -   eval_f1 = 0.3313\n",
      "01/08/2025 14:22:38 - INFO - __main__ -   eval_precision = 0.5584\n",
      "01/08/2025 14:22:38 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 99% 509/512 [13:49<00:03,  1.10s/it]01/08/2025 14:24:34 - WARNING - __main__ - epoch 3 step 510 loss 0.0984\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:25:36 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:25:36 - INFO - __main__ -   eval_f1 = 0.2474\n",
      "01/08/2025 14:25:36 - INFO - __main__ -   eval_precision = 0.6261\n",
      "01/08/2025 14:25:36 - INFO - __main__ -   eval_recall = 0.1542\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:49,  1.14s/it]01/08/2025 14:27:33 - WARNING - __main__ - epoch 4 step 102 loss 0.05695\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:28:35 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:28:35 - INFO - __main__ -   eval_f1 = 0.2451\n",
      "01/08/2025 14:28:35 - INFO - __main__ -   eval_precision = 0.4175\n",
      "01/08/2025 14:28:35 - INFO - __main__ -   eval_recall = 0.1734\n",
      " 40% 203/512 [04:54<06:04,  1.18s/it]01/08/2025 14:30:33 - WARNING - __main__ - epoch 4 step 204 loss 0.07001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:31:35 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:31:35 - INFO - __main__ -   eval_f1 = 0.3577\n",
      "01/08/2025 14:31:35 - INFO - __main__ -   eval_precision = 0.4871\n",
      "01/08/2025 14:31:35 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 60% 305/512 [07:51<04:01,  1.17s/it]01/08/2025 14:33:30 - WARNING - __main__ - epoch 4 step 306 loss 0.05552\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:34:32 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:34:32 - INFO - __main__ -   eval_f1 = 0.3739\n",
      "01/08/2025 14:34:32 - INFO - __main__ -   eval_precision = 0.4799\n",
      "01/08/2025 14:34:32 - INFO - __main__ -   eval_recall = 0.3062\n",
      " 79% 407/512 [10:50<02:02,  1.16s/it]01/08/2025 14:36:29 - WARNING - __main__ - epoch 4 step 408 loss 0.04941\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:37:31 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:37:31 - INFO - __main__ -   eval_f1 = 0.3818\n",
      "01/08/2025 14:37:31 - INFO - __main__ -   eval_precision = 0.4068\n",
      "01/08/2025 14:37:31 - INFO - __main__ -   eval_recall = 0.3597\n",
      " 99% 509/512 [13:49<00:03,  1.09s/it]01/08/2025 14:39:28 - WARNING - __main__ - epoch 4 step 510 loss 0.06525\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:40:31 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:40:31 - INFO - __main__ -   eval_f1 = 0.374\n",
      "01/08/2025 14:40:31 - INFO - __main__ -   eval_precision = 0.4752\n",
      "01/08/2025 14:40:31 - INFO - __main__ -   eval_recall = 0.3084\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:08,  1.19s/it]01/08/2025 14:42:27 - WARNING - __main__ - epoch 5 step 102 loss 0.03395\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:43:29 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:43:29 - INFO - __main__ -   eval_f1 = 0.2878\n",
      "01/08/2025 14:43:29 - INFO - __main__ -   eval_precision = 0.4386\n",
      "01/08/2025 14:43:29 - INFO - __main__ -   eval_recall = 0.2141\n",
      " 40% 203/512 [04:53<05:38,  1.09s/it]01/08/2025 14:45:27 - WARNING - __main__ - epoch 5 step 204 loss 0.0375\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:46:29 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:46:29 - INFO - __main__ -   eval_f1 = 0.3116\n",
      "01/08/2025 14:46:29 - INFO - __main__ -   eval_precision = 0.4603\n",
      "01/08/2025 14:46:29 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 60% 305/512 [07:51<03:58,  1.15s/it]01/08/2025 14:48:25 - WARNING - __main__ - epoch 5 step 306 loss 0.03059\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:49:27 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:49:27 - INFO - __main__ -   eval_f1 = 0.2515\n",
      "01/08/2025 14:49:27 - INFO - __main__ -   eval_precision = 0.4179\n",
      "01/08/2025 14:49:27 - INFO - __main__ -   eval_recall = 0.1799\n",
      " 79% 407/512 [10:51<01:53,  1.09s/it]01/08/2025 14:51:24 - WARNING - __main__ - epoch 5 step 408 loss 0.03109\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:52:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:52:26 - INFO - __main__ -   eval_f1 = 0.2837\n",
      "01/08/2025 14:52:26 - INFO - __main__ -   eval_precision = 0.3977\n",
      "01/08/2025 14:52:26 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 99% 509/512 [13:49<00:03,  1.07s/it]01/08/2025 14:54:23 - WARNING - __main__ - epoch 5 step 510 loss 0.03136\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:55:25 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:55:25 - INFO - __main__ -   eval_f1 = 0.2254\n",
      "01/08/2025 14:55:25 - INFO - __main__ -   eval_precision = 0.4545\n",
      "01/08/2025 14:55:25 - INFO - __main__ -   eval_recall = 0.1499\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:38,  1.11s/it]01/08/2025 14:57:22 - WARNING - __main__ - epoch 6 step 102 loss 0.01686\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 14:58:24 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 14:58:24 - INFO - __main__ -   eval_f1 = 0.3044\n",
      "01/08/2025 14:58:24 - INFO - __main__ -   eval_precision = 0.3359\n",
      "01/08/2025 14:58:24 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 40% 203/512 [04:55<06:17,  1.22s/it]01/08/2025 15:00:22 - WARNING - __main__ - epoch 6 step 204 loss 0.02131\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:01:24 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:01:24 - INFO - __main__ -   eval_f1 = 0.3279\n",
      "01/08/2025 15:01:24 - INFO - __main__ -   eval_precision = 0.3143\n",
      "01/08/2025 15:01:24 - INFO - __main__ -   eval_recall = 0.3426\n",
      " 60% 305/512 [07:51<04:03,  1.18s/it]01/08/2025 15:03:19 - WARNING - __main__ - epoch 6 step 306 loss 0.01724\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:04:21 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:04:21 - INFO - __main__ -   eval_f1 = 0.3261\n",
      "01/08/2025 15:04:21 - INFO - __main__ -   eval_precision = 0.3147\n",
      "01/08/2025 15:04:21 - INFO - __main__ -   eval_recall = 0.3383\n",
      " 79% 407/512 [10:49<01:54,  1.09s/it]01/08/2025 15:06:17 - WARNING - __main__ - epoch 6 step 408 loss 0.02198\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:07:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:07:19 - INFO - __main__ -   eval_f1 = 0.2587\n",
      "01/08/2025 15:07:19 - INFO - __main__ -   eval_precision = 0.4027\n",
      "01/08/2025 15:07:19 - INFO - __main__ -   eval_recall = 0.1906\n",
      " 99% 509/512 [13:49<00:03,  1.19s/it]01/08/2025 15:09:17 - WARNING - __main__ - epoch 6 step 510 loss 0.01889\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:10:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 15:10:19 - INFO - __main__ -   eval_f1 = 0.3269\n",
      "01/08/2025 15:10:19 - INFO - __main__ -   eval_precision = 0.3726\n",
      "01/08/2025 15:10:19 - INFO - __main__ -   eval_recall = 0.2912\n",
      "01/08/2025 15:10:19 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 99% 509/512 [14:52<00:05,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCsOnkIqd7h6",
    "outputId": "9f9c4194-494a-40b4-dbff-0a4d1138abb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 15:22:42.153867: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 15:22:42.171507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 15:22:42.192538: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 15:22:42.198890: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 15:22:42.214748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 15:22:43.560492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 15:22:46 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 15:24:31 - INFO - __main__ - ***** Test results *****\n",
      "01/08/2025 15:24:31 - INFO - __main__ -   auc_score = 0.8659\n",
      "01/08/2025 15:24:31 - INFO - __main__ -   test_f1 = 0.3784\n",
      "01/08/2025 15:24:31 - INFO - __main__ -   test_precision = 0.5283\n",
      "01/08/2025 15:24:31 - INFO - __main__ -   test_recall = 0.2947\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iug3lCK7seVr",
    "outputId": "b1d66634-1c37-4e05-e39d-72888893d522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 16:15:41.420273: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 16:15:41.438265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 16:15:41.459835: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 16:15:41.466326: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 16:15:41.481879: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 16:15:42.812637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 16:15:45 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:57<07:08,  1.04s/it]01/08/2025 16:19:48 - WARNING - __main__ - epoch 0 step 102 loss 0.31386\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 16:20:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:20:50 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 16:20:50 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 16:20:50 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [04:55<06:07,  1.19s/it]01/08/2025 16:22:46 - WARNING - __main__ - epoch 0 step 204 loss 0.29404\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 16:23:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:23:48 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 16:23:48 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 16:23:48 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [07:55<04:04,  1.18s/it]01/08/2025 16:25:46 - WARNING - __main__ - epoch 0 step 306 loss 0.25174\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:26:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:26:48 - INFO - __main__ -   eval_f1 = 0.2207\n",
      "01/08/2025 16:26:48 - INFO - __main__ -   eval_precision = 0.5664\n",
      "01/08/2025 16:26:48 - INFO - __main__ -   eval_recall = 0.137\n",
      " 79% 407/512 [11:07<02:01,  1.16s/it]01/08/2025 16:28:58 - WARNING - __main__ - epoch 0 step 408 loss 0.22853\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:30:00 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:30:00 - INFO - __main__ -   eval_f1 = 0.2316\n",
      "01/08/2025 16:30:00 - INFO - __main__ -   eval_precision = 0.6408\n",
      "01/08/2025 16:30:00 - INFO - __main__ -   eval_recall = 0.1413\n",
      " 99% 509/512 [14:16<00:03,  1.13s/it]01/08/2025 16:32:07 - WARNING - __main__ - epoch 0 step 510 loss 0.20964\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:33:10 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:33:10 - INFO - __main__ -   eval_f1 = 0.2456\n",
      "01/08/2025 16:33:10 - INFO - __main__ -   eval_precision = 0.6796\n",
      "01/08/2025 16:33:10 - INFO - __main__ -   eval_recall = 0.1499\n",
      "100% 512/512 [15:34<00:00,  1.82s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:15,  1.06s/it]01/08/2025 16:35:20 - WARNING - __main__ - epoch 1 step 102 loss 0.21837\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:36:22 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:36:22 - INFO - __main__ -   eval_f1 = 0.3778\n",
      "01/08/2025 16:36:22 - INFO - __main__ -   eval_precision = 0.63\n",
      "01/08/2025 16:36:22 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 40% 203/512 [05:07<06:04,  1.18s/it]01/08/2025 16:38:32 - WARNING - __main__ - epoch 1 step 204 loss 0.20312\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:39:34 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:39:34 - INFO - __main__ -   eval_f1 = 0.3882\n",
      "01/08/2025 16:39:34 - INFO - __main__ -   eval_precision = 0.6197\n",
      "01/08/2025 16:39:34 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 60% 305/512 [08:19<04:09,  1.20s/it]01/08/2025 16:41:44 - WARNING - __main__ - epoch 1 step 306 loss 0.18802\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:42:47 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:42:47 - INFO - __main__ -   eval_f1 = 0.3833\n",
      "01/08/2025 16:42:47 - INFO - __main__ -   eval_precision = 0.6889\n",
      "01/08/2025 16:42:47 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 79% 407/512 [11:18<01:58,  1.12s/it]01/08/2025 16:44:43 - WARNING - __main__ - epoch 1 step 408 loss 0.2183\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:45:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:45:45 - INFO - __main__ -   eval_f1 = 0.4112\n",
      "01/08/2025 16:45:45 - INFO - __main__ -   eval_precision = 0.6542\n",
      "01/08/2025 16:45:45 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 99% 509/512 [14:29<00:03,  1.05s/it]01/08/2025 16:47:54 - WARNING - __main__ - epoch 1 step 510 loss 0.19799\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:48:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:48:56 - INFO - __main__ -   eval_f1 = 0.3189\n",
      "01/08/2025 16:48:56 - INFO - __main__ -   eval_precision = 0.7111\n",
      "01/08/2025 16:48:56 - INFO - __main__ -   eval_recall = 0.2056\n",
      "100% 512/512 [15:34<00:00,  1.83s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:34,  1.11s/it]01/08/2025 16:50:53 - WARNING - __main__ - epoch 2 step 102 loss 0.1952\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:51:55 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:51:55 - INFO - __main__ -   eval_f1 = 0.3424\n",
      "01/08/2025 16:51:55 - INFO - __main__ -   eval_precision = 0.6772\n",
      "01/08/2025 16:51:55 - INFO - __main__ -   eval_recall = 0.2291\n",
      " 40% 203/512 [04:53<06:16,  1.22s/it]01/08/2025 16:53:52 - WARNING - __main__ - epoch 2 step 204 loss 0.17459\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:54:54 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:54:54 - INFO - __main__ -   eval_f1 = 0.4192\n",
      "01/08/2025 16:54:54 - INFO - __main__ -   eval_precision = 0.5817\n",
      "01/08/2025 16:54:54 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 60% 305/512 [08:02<04:09,  1.20s/it]01/08/2025 16:57:02 - WARNING - __main__ - epoch 2 step 306 loss 0.16638\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 16:58:04 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 16:58:04 - INFO - __main__ -   eval_f1 = 0.3853\n",
      "01/08/2025 16:58:04 - INFO - __main__ -   eval_precision = 0.6738\n",
      "01/08/2025 16:58:04 - INFO - __main__ -   eval_recall = 0.2698\n",
      " 79% 407/512 [11:02<02:03,  1.18s/it]01/08/2025 17:00:02 - WARNING - __main__ - epoch 2 step 408 loss 0.17297\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:01:04 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:01:04 - INFO - __main__ -   eval_f1 = 0.4018\n",
      "01/08/2025 17:01:04 - INFO - __main__ -   eval_precision = 0.67\n",
      "01/08/2025 17:01:04 - INFO - __main__ -   eval_recall = 0.2869\n",
      " 99% 509/512 [14:01<00:03,  1.15s/it]01/08/2025 17:03:00 - WARNING - __main__ - epoch 2 step 510 loss 0.18115\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:04:03 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:04:03 - INFO - __main__ -   eval_f1 = 0.3261\n",
      "01/08/2025 17:04:03 - INFO - __main__ -   eval_precision = 0.7313\n",
      "01/08/2025 17:04:03 - INFO - __main__ -   eval_recall = 0.2099\n",
      "100% 512/512 [15:06<00:00,  1.77s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:56<07:35,  1.11s/it]01/08/2025 17:06:02 - WARNING - __main__ - epoch 3 step 102 loss 0.14126\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:07:05 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:07:05 - INFO - __main__ -   eval_f1 = 0.337\n",
      "01/08/2025 17:07:05 - INFO - __main__ -   eval_precision = 0.6207\n",
      "01/08/2025 17:07:05 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 40% 203/512 [04:54<05:49,  1.13s/it]01/08/2025 17:09:00 - WARNING - __main__ - epoch 3 step 204 loss 0.13027\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:10:02 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:10:02 - INFO - __main__ -   eval_f1 = 0.3529\n",
      "01/08/2025 17:10:02 - INFO - __main__ -   eval_precision = 0.5634\n",
      "01/08/2025 17:10:02 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 305/512 [07:52<04:00,  1.16s/it]01/08/2025 17:11:58 - WARNING - __main__ - epoch 3 step 306 loss 0.13946\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:13:00 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:13:00 - INFO - __main__ -   eval_f1 = 0.2929\n",
      "01/08/2025 17:13:00 - INFO - __main__ -   eval_precision = 0.685\n",
      "01/08/2025 17:13:00 - INFO - __main__ -   eval_recall = 0.1863\n",
      " 79% 407/512 [10:51<02:01,  1.16s/it]01/08/2025 17:14:57 - WARNING - __main__ - epoch 3 step 408 loss 0.14722\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:15:59 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:15:59 - INFO - __main__ -   eval_f1 = 0.3848\n",
      "01/08/2025 17:15:59 - INFO - __main__ -   eval_precision = 0.6027\n",
      "01/08/2025 17:15:59 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 99% 509/512 [13:49<00:03,  1.10s/it]01/08/2025 17:17:55 - WARNING - __main__ - epoch 3 step 510 loss 0.13761\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:18:57 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:18:57 - INFO - __main__ -   eval_f1 = 0.2646\n",
      "01/08/2025 17:18:57 - INFO - __main__ -   eval_precision = 0.6696\n",
      "01/08/2025 17:18:57 - INFO - __main__ -   eval_recall = 0.1649\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:49,  1.14s/it]01/08/2025 17:20:54 - WARNING - __main__ - epoch 4 step 102 loss 0.12068\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:21:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:21:56 - INFO - __main__ -   eval_f1 = 0.3801\n",
      "01/08/2025 17:21:56 - INFO - __main__ -   eval_precision = 0.563\n",
      "01/08/2025 17:21:56 - INFO - __main__ -   eval_recall = 0.2869\n",
      " 40% 203/512 [04:54<06:04,  1.18s/it]01/08/2025 17:23:54 - WARNING - __main__ - epoch 4 step 204 loss 0.10333\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:24:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:24:56 - INFO - __main__ -   eval_f1 = 0.338\n",
      "01/08/2025 17:24:56 - INFO - __main__ -   eval_precision = 0.4938\n",
      "01/08/2025 17:24:56 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 305/512 [07:51<04:01,  1.17s/it]01/08/2025 17:26:51 - WARNING - __main__ - epoch 4 step 306 loss 0.10399\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:27:53 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:27:53 - INFO - __main__ -   eval_f1 = 0.3753\n",
      "01/08/2025 17:27:53 - INFO - __main__ -   eval_precision = 0.4557\n",
      "01/08/2025 17:27:53 - INFO - __main__ -   eval_recall = 0.3191\n",
      " 79% 407/512 [10:50<02:02,  1.16s/it]01/08/2025 17:29:50 - WARNING - __main__ - epoch 4 step 408 loss 0.09923\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:30:52 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:30:52 - INFO - __main__ -   eval_f1 = 0.4341\n",
      "01/08/2025 17:30:52 - INFO - __main__ -   eval_precision = 0.5242\n",
      "01/08/2025 17:30:52 - INFO - __main__ -   eval_recall = 0.3704\n",
      " 99% 509/512 [14:05<00:03,  1.09s/it]01/08/2025 17:33:05 - WARNING - __main__ - epoch 4 step 510 loss 0.11944\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:34:07 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:34:07 - INFO - __main__ -   eval_f1 = 0.391\n",
      "01/08/2025 17:34:07 - INFO - __main__ -   eval_precision = 0.5103\n",
      "01/08/2025 17:34:07 - INFO - __main__ -   eval_recall = 0.3169\n",
      "100% 512/512 [15:09<00:00,  1.78s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:08,  1.19s/it]01/08/2025 17:36:04 - WARNING - __main__ - epoch 5 step 102 loss 0.07426\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:37:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:37:06 - INFO - __main__ -   eval_f1 = 0.3388\n",
      "01/08/2025 17:37:06 - INFO - __main__ -   eval_precision = 0.4679\n",
      "01/08/2025 17:37:06 - INFO - __main__ -   eval_recall = 0.2655\n",
      " 40% 203/512 [04:53<05:38,  1.09s/it]01/08/2025 17:39:03 - WARNING - __main__ - epoch 5 step 204 loss 0.08237\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:40:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:40:06 - INFO - __main__ -   eval_f1 = 0.3489\n",
      "01/08/2025 17:40:06 - INFO - __main__ -   eval_precision = 0.4866\n",
      "01/08/2025 17:40:06 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 60% 305/512 [07:51<03:58,  1.15s/it]01/08/2025 17:42:01 - WARNING - __main__ - epoch 5 step 306 loss 0.06953\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:43:03 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:43:03 - INFO - __main__ -   eval_f1 = 0.3491\n",
      "01/08/2025 17:43:03 - INFO - __main__ -   eval_precision = 0.4743\n",
      "01/08/2025 17:43:03 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 79% 407/512 [10:51<01:53,  1.09s/it]01/08/2025 17:45:01 - WARNING - __main__ - epoch 5 step 408 loss 0.0823\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:46:03 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:46:03 - INFO - __main__ -   eval_f1 = 0.3362\n",
      "01/08/2025 17:46:03 - INFO - __main__ -   eval_precision = 0.5021\n",
      "01/08/2025 17:46:03 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 99% 509/512 [13:50<00:03,  1.07s/it]01/08/2025 17:47:59 - WARNING - __main__ - epoch 5 step 510 loss 0.0695\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:49:01 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:49:01 - INFO - __main__ -   eval_f1 = 0.2888\n",
      "01/08/2025 17:49:01 - INFO - __main__ -   eval_precision = 0.4974\n",
      "01/08/2025 17:49:01 - INFO - __main__ -   eval_recall = 0.2034\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:38,  1.12s/it]01/08/2025 17:50:59 - WARNING - __main__ - epoch 6 step 102 loss 0.04657\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:52:01 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:52:01 - INFO - __main__ -   eval_f1 = 0.3104\n",
      "01/08/2025 17:52:01 - INFO - __main__ -   eval_precision = 0.433\n",
      "01/08/2025 17:52:01 - INFO - __main__ -   eval_recall = 0.242\n",
      " 40% 203/512 [04:55<06:17,  1.22s/it]01/08/2025 17:53:59 - WARNING - __main__ - epoch 6 step 204 loss 0.0678\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:55:01 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:55:01 - INFO - __main__ -   eval_f1 = 0.3325\n",
      "01/08/2025 17:55:01 - INFO - __main__ -   eval_precision = 0.4276\n",
      "01/08/2025 17:55:01 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 60% 305/512 [07:51<04:03,  1.18s/it]01/08/2025 17:56:56 - WARNING - __main__ - epoch 6 step 306 loss 0.05003\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 17:57:58 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 17:57:58 - INFO - __main__ -   eval_f1 = 0.3595\n",
      "01/08/2025 17:57:58 - INFO - __main__ -   eval_precision = 0.4048\n",
      "01/08/2025 17:57:58 - INFO - __main__ -   eval_recall = 0.3233\n",
      " 79% 407/512 [10:49<01:54,  1.09s/it]01/08/2025 17:59:54 - WARNING - __main__ - epoch 6 step 408 loss 0.05109\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:00:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:00:56 - INFO - __main__ -   eval_f1 = 0.3017\n",
      "01/08/2025 18:00:56 - INFO - __main__ -   eval_precision = 0.3841\n",
      "01/08/2025 18:00:56 - INFO - __main__ -   eval_recall = 0.2484\n",
      " 99% 509/512 [13:49<00:03,  1.19s/it]01/08/2025 18:02:54 - WARNING - __main__ - epoch 6 step 510 loss 0.06479\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:03:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:03:56 - INFO - __main__ -   eval_f1 = 0.2326\n",
      "01/08/2025 18:03:56 - INFO - __main__ -   eval_precision = 0.4213\n",
      "01/08/2025 18:03:56 - INFO - __main__ -   eval_recall = 0.1606\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:29,  1.09s/it]01/08/2025 18:05:53 - WARNING - __main__ - epoch 7 step 102 loss 0.0396\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:06:55 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:06:55 - INFO - __main__ -   eval_f1 = 0.2951\n",
      "01/08/2025 18:06:55 - INFO - __main__ -   eval_precision = 0.3589\n",
      "01/08/2025 18:06:55 - INFO - __main__ -   eval_recall = 0.2505\n",
      " 40% 203/512 [04:53<06:14,  1.21s/it]01/08/2025 18:08:52 - WARNING - __main__ - epoch 7 step 204 loss 0.04054\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:09:54 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:09:54 - INFO - __main__ -   eval_f1 = 0.2731\n",
      "01/08/2025 18:09:54 - INFO - __main__ -   eval_precision = 0.3837\n",
      "01/08/2025 18:09:54 - INFO - __main__ -   eval_recall = 0.212\n",
      " 60% 305/512 [07:50<04:03,  1.17s/it]01/08/2025 18:11:49 - WARNING - __main__ - epoch 7 step 306 loss 0.04304\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:12:51 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:12:51 - INFO - __main__ -   eval_f1 = 0.2696\n",
      "01/08/2025 18:12:51 - INFO - __main__ -   eval_precision = 0.3769\n",
      "01/08/2025 18:12:51 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 79% 407/512 [10:49<02:01,  1.16s/it]01/08/2025 18:14:48 - WARNING - __main__ - epoch 7 step 408 loss 0.04776\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:15:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:15:50 - INFO - __main__ -   eval_f1 = 0.3063\n",
      "01/08/2025 18:15:50 - INFO - __main__ -   eval_precision = 0.3839\n",
      "01/08/2025 18:15:50 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 99% 509/512 [13:49<00:03,  1.12s/it]01/08/2025 18:17:48 - WARNING - __main__ - epoch 7 step 510 loss 0.03532\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:18:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:18:50 - INFO - __main__ -   eval_f1 = 0.3045\n",
      "01/08/2025 18:18:50 - INFO - __main__ -   eval_precision = 0.3932\n",
      "01/08/2025 18:18:50 - INFO - __main__ -   eval_recall = 0.2484\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:58<07:56,  1.16s/it]01/08/2025 18:20:51 - WARNING - __main__ - epoch 8 step 102 loss 0.02835\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:21:53 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:21:53 - INFO - __main__ -   eval_f1 = 0.3052\n",
      "01/08/2025 18:21:53 - INFO - __main__ -   eval_precision = 0.3628\n",
      "01/08/2025 18:21:53 - INFO - __main__ -   eval_recall = 0.2634\n",
      " 40% 203/512 [04:55<06:05,  1.18s/it]01/08/2025 18:23:48 - WARNING - __main__ - epoch 8 step 204 loss 0.02635\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:24:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:24:50 - INFO - __main__ -   eval_f1 = 0.2876\n",
      "01/08/2025 18:24:50 - INFO - __main__ -   eval_precision = 0.3803\n",
      "01/08/2025 18:24:50 - INFO - __main__ -   eval_recall = 0.2313\n",
      " 60% 305/512 [07:54<04:15,  1.23s/it]01/08/2025 18:26:47 - WARNING - __main__ - epoch 8 step 306 loss 0.03545\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:27:49 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:27:49 - INFO - __main__ -   eval_f1 = 0.3009\n",
      "01/08/2025 18:27:49 - INFO - __main__ -   eval_precision = 0.3673\n",
      "01/08/2025 18:27:49 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 79% 407/512 [10:52<01:55,  1.10s/it]01/08/2025 18:29:45 - WARNING - __main__ - epoch 8 step 408 loss 0.03069\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:30:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:30:48 - INFO - __main__ -   eval_f1 = 0.283\n",
      "01/08/2025 18:30:48 - INFO - __main__ -   eval_precision = 0.3759\n",
      "01/08/2025 18:30:48 - INFO - __main__ -   eval_recall = 0.227\n",
      " 99% 509/512 [13:50<00:03,  1.12s/it]01/08/2025 18:32:43 - WARNING - __main__ - epoch 8 step 510 loss 0.0241\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:33:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:33:45 - INFO - __main__ -   eval_f1 = 0.2861\n",
      "01/08/2025 18:33:45 - INFO - __main__ -   eval_precision = 0.3544\n",
      "01/08/2025 18:33:45 - INFO - __main__ -   eval_recall = 0.2398\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:01,  1.17s/it]01/08/2025 18:35:41 - WARNING - __main__ - epoch 9 step 102 loss 0.02657\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:36:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:36:43 - INFO - __main__ -   eval_f1 = 0.2833\n",
      "01/08/2025 18:36:43 - INFO - __main__ -   eval_precision = 0.3333\n",
      "01/08/2025 18:36:43 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 40% 203/512 [04:53<05:16,  1.02s/it]01/08/2025 18:38:40 - WARNING - __main__ - epoch 9 step 204 loss 0.02204\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:39:42 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:39:42 - INFO - __main__ -   eval_f1 = 0.293\n",
      "01/08/2025 18:39:42 - INFO - __main__ -   eval_precision = 0.3409\n",
      "01/08/2025 18:39:42 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 305/512 [07:50<04:02,  1.17s/it]01/08/2025 18:41:37 - WARNING - __main__ - epoch 9 step 306 loss 0.01779\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:42:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:42:40 - INFO - __main__ -   eval_f1 = 0.2854\n",
      "01/08/2025 18:42:40 - INFO - __main__ -   eval_precision = 0.3477\n",
      "01/08/2025 18:42:40 - INFO - __main__ -   eval_recall = 0.242\n",
      " 79% 407/512 [10:49<02:01,  1.16s/it]01/08/2025 18:44:36 - WARNING - __main__ - epoch 9 step 408 loss 0.02176\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:45:38 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:45:38 - INFO - __main__ -   eval_f1 = 0.2864\n",
      "01/08/2025 18:45:38 - INFO - __main__ -   eval_precision = 0.3465\n",
      "01/08/2025 18:45:38 - INFO - __main__ -   eval_recall = 0.2441\n",
      " 99% 509/512 [13:50<00:03,  1.16s/it]01/08/2025 18:47:37 - WARNING - __main__ - epoch 9 step 510 loss 0.02358\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 18:48:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 18:48:39 - INFO - __main__ -   eval_f1 = 0.2883\n",
      "01/08/2025 18:48:39 - INFO - __main__ -   eval_precision = 0.3565\n",
      "01/08/2025 18:48:39 - INFO - __main__ -   eval_recall = 0.242\n",
      "01/08/2025 18:48:39 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 99% 509/512 [14:53<00:05,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l3e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 3e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyquRubffxxs",
    "outputId": "9d787e0c-289d-4cef-a4e6-e7b0fb3c6922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 19:58:33.574561: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 19:58:33.592428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 19:58:33.614029: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 19:58:33.620507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 19:58:33.636258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 19:58:34.980034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 19:58:38 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:00:22 - INFO - __main__ - ***** Test results *****\n",
      "01/08/2025 20:00:22 - INFO - __main__ -   auc_score = 0.8204\n",
      "01/08/2025 20:00:22 - INFO - __main__ -   test_f1 = 0.292\n",
      "01/08/2025 20:00:22 - INFO - __main__ -   test_precision = 0.3247\n",
      "01/08/2025 20:00:22 - INFO - __main__ -   test_recall = 0.2653\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l3e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 3e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60R08GZTgd7x",
    "outputId": "6ac30047-bb6d-4830-ccb7-32b4d642825e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:01:45.204481: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 20:01:45.222225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 20:01:45.243613: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 20:01:45.250442: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 20:01:45.266286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 20:01:46.601710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 20:01:49 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:57<07:08,  1.04s/it]01/08/2025 20:05:53 - WARNING - __main__ - epoch 0 step 102 loss 0.30393\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 20:06:55 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:06:55 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 20:06:55 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 20:06:55 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 203/512 [04:55<06:07,  1.19s/it]01/08/2025 20:08:52 - WARNING - __main__ - epoch 0 step 204 loss 0.29155\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:09:54 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:09:54 - INFO - __main__ -   eval_f1 = 0.0455\n",
      "01/08/2025 20:09:54 - INFO - __main__ -   eval_precision = 0.6471\n",
      "01/08/2025 20:09:54 - INFO - __main__ -   eval_recall = 0.0236\n",
      " 60% 305/512 [08:07<04:04,  1.18s/it]01/08/2025 20:12:04 - WARNING - __main__ - epoch 0 step 306 loss 0.24085\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:13:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:13:06 - INFO - __main__ -   eval_f1 = 0.2214\n",
      "01/08/2025 20:13:06 - INFO - __main__ -   eval_precision = 0.6176\n",
      "01/08/2025 20:13:06 - INFO - __main__ -   eval_recall = 0.1349\n",
      " 79% 407/512 [11:20<02:01,  1.16s/it]01/08/2025 20:15:17 - WARNING - __main__ - epoch 0 step 408 loss 0.22094\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:16:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:16:19 - INFO - __main__ -   eval_f1 = 0.2857\n",
      "01/08/2025 20:16:19 - INFO - __main__ -   eval_precision = 0.6641\n",
      "01/08/2025 20:16:19 - INFO - __main__ -   eval_recall = 0.182\n",
      " 99% 509/512 [14:30<00:03,  1.13s/it]01/08/2025 20:18:27 - WARNING - __main__ - epoch 0 step 510 loss 0.2044\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:19:29 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:19:29 - INFO - __main__ -   eval_f1 = 0.1989\n",
      "01/08/2025 20:19:29 - INFO - __main__ -   eval_precision = 0.7105\n",
      "01/08/2025 20:19:29 - INFO - __main__ -   eval_recall = 0.1156\n",
      "100% 512/512 [15:35<00:00,  1.83s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:15,  1.06s/it]01/08/2025 20:21:27 - WARNING - __main__ - epoch 1 step 102 loss 0.20108\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:22:29 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:22:29 - INFO - __main__ -   eval_f1 = 0.433\n",
      "01/08/2025 20:22:29 - INFO - __main__ -   eval_precision = 0.6934\n",
      "01/08/2025 20:22:29 - INFO - __main__ -   eval_recall = 0.3148\n",
      " 40% 203/512 [05:06<06:04,  1.18s/it]01/08/2025 20:24:38 - WARNING - __main__ - epoch 1 step 204 loss 0.20257\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:25:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:25:40 - INFO - __main__ -   eval_f1 = 0.4549\n",
      "01/08/2025 20:25:40 - INFO - __main__ -   eval_precision = 0.6457\n",
      "01/08/2025 20:25:40 - INFO - __main__ -   eval_recall = 0.3512\n",
      " 60% 305/512 [08:17<04:09,  1.20s/it]01/08/2025 20:27:49 - WARNING - __main__ - epoch 1 step 306 loss 0.17992\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:28:51 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:28:51 - INFO - __main__ -   eval_f1 = 0.3914\n",
      "01/08/2025 20:28:51 - INFO - __main__ -   eval_precision = 0.6845\n",
      "01/08/2025 20:28:51 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 79% 407/512 [11:15<01:58,  1.13s/it]01/08/2025 20:30:47 - WARNING - __main__ - epoch 1 step 408 loss 0.2132\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:31:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:31:50 - INFO - __main__ -   eval_f1 = 0.4429\n",
      "01/08/2025 20:31:50 - INFO - __main__ -   eval_precision = 0.6652\n",
      "01/08/2025 20:31:50 - INFO - __main__ -   eval_recall = 0.3319\n",
      " 99% 509/512 [14:14<00:03,  1.05s/it]01/08/2025 20:33:46 - WARNING - __main__ - epoch 1 step 510 loss 0.18698\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:34:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:34:48 - INFO - __main__ -   eval_f1 = 0.4577\n",
      "01/08/2025 20:34:48 - INFO - __main__ -   eval_precision = 0.6496\n",
      "01/08/2025 20:34:48 - INFO - __main__ -   eval_recall = 0.3533\n",
      "100% 512/512 [15:30<00:00,  1.82s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:35,  1.11s/it]01/08/2025 20:36:57 - WARNING - __main__ - epoch 2 step 102 loss 0.17468\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:37:59 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:37:59 - INFO - __main__ -   eval_f1 = 0.2987\n",
      "01/08/2025 20:37:59 - INFO - __main__ -   eval_precision = 0.6899\n",
      "01/08/2025 20:37:59 - INFO - __main__ -   eval_recall = 0.1906\n",
      " 40% 203/512 [04:53<06:16,  1.22s/it]01/08/2025 20:39:56 - WARNING - __main__ - epoch 2 step 204 loss 0.15944\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:40:58 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:40:58 - INFO - __main__ -   eval_f1 = 0.4447\n",
      "01/08/2025 20:40:58 - INFO - __main__ -   eval_precision = 0.5469\n",
      "01/08/2025 20:40:58 - INFO - __main__ -   eval_recall = 0.3747\n",
      " 60% 305/512 [07:51<04:09,  1.21s/it]01/08/2025 20:42:54 - WARNING - __main__ - epoch 2 step 306 loss 0.14331\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:43:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:43:56 - INFO - __main__ -   eval_f1 = 0.3848\n",
      "01/08/2025 20:43:56 - INFO - __main__ -   eval_precision = 0.658\n",
      "01/08/2025 20:43:56 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 79% 407/512 [10:50<02:03,  1.17s/it]01/08/2025 20:45:53 - WARNING - __main__ - epoch 2 step 408 loss 0.14781\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:46:56 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:46:56 - INFO - __main__ -   eval_f1 = 0.4464\n",
      "01/08/2025 20:46:56 - INFO - __main__ -   eval_precision = 0.5343\n",
      "01/08/2025 20:46:56 - INFO - __main__ -   eval_recall = 0.3833\n",
      " 99% 509/512 [13:49<00:03,  1.15s/it]01/08/2025 20:48:53 - WARNING - __main__ - epoch 2 step 510 loss 0.14667\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:49:55 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:49:55 - INFO - __main__ -   eval_f1 = 0.4336\n",
      "01/08/2025 20:49:55 - INFO - __main__ -   eval_precision = 0.5227\n",
      "01/08/2025 20:49:55 - INFO - __main__ -   eval_recall = 0.3704\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:56<07:35,  1.11s/it]01/08/2025 20:51:54 - WARNING - __main__ - epoch 3 step 102 loss 0.11296\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:52:57 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:52:57 - INFO - __main__ -   eval_f1 = 0.2625\n",
      "01/08/2025 20:52:57 - INFO - __main__ -   eval_precision = 0.6786\n",
      "01/08/2025 20:52:57 - INFO - __main__ -   eval_recall = 0.1627\n",
      " 40% 203/512 [04:54<05:49,  1.13s/it]01/08/2025 20:54:52 - WARNING - __main__ - epoch 3 step 204 loss 0.10724\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:55:54 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:55:54 - INFO - __main__ -   eval_f1 = 0.3684\n",
      "01/08/2025 20:55:54 - INFO - __main__ -   eval_precision = 0.5216\n",
      "01/08/2025 20:55:54 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 60% 305/512 [07:52<04:00,  1.16s/it]01/08/2025 20:57:50 - WARNING - __main__ - epoch 3 step 306 loss 0.10083\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 20:58:52 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 20:58:52 - INFO - __main__ -   eval_f1 = 0.2678\n",
      "01/08/2025 20:58:52 - INFO - __main__ -   eval_precision = 0.6423\n",
      "01/08/2025 20:58:52 - INFO - __main__ -   eval_recall = 0.1692\n",
      " 79% 407/512 [10:51<02:01,  1.16s/it]01/08/2025 21:00:49 - WARNING - __main__ - epoch 3 step 408 loss 0.11683\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:01:51 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:01:51 - INFO - __main__ -   eval_f1 = 0.3636\n",
      "01/08/2025 21:01:51 - INFO - __main__ -   eval_precision = 0.5401\n",
      "01/08/2025 21:01:51 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 99% 509/512 [13:50<00:03,  1.10s/it]01/08/2025 21:03:47 - WARNING - __main__ - epoch 3 step 510 loss 0.10998\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:04:50 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:04:50 - INFO - __main__ -   eval_f1 = 0.3585\n",
      "01/08/2025 21:04:50 - INFO - __main__ -   eval_precision = 0.5339\n",
      "01/08/2025 21:04:50 - INFO - __main__ -   eval_recall = 0.2698\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:50,  1.14s/it]01/08/2025 21:06:47 - WARNING - __main__ - epoch 4 step 102 loss 0.07375\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:07:49 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:07:49 - INFO - __main__ -   eval_f1 = 0.3639\n",
      "01/08/2025 21:07:49 - INFO - __main__ -   eval_precision = 0.4233\n",
      "01/08/2025 21:07:49 - INFO - __main__ -   eval_recall = 0.3191\n",
      " 40% 203/512 [04:54<06:04,  1.18s/it]01/08/2025 21:09:47 - WARNING - __main__ - epoch 4 step 204 loss 0.06585\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:10:49 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:10:49 - INFO - __main__ -   eval_f1 = 0.3501\n",
      "01/08/2025 21:10:49 - INFO - __main__ -   eval_precision = 0.4387\n",
      "01/08/2025 21:10:49 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 60% 305/512 [07:51<04:01,  1.17s/it]01/08/2025 21:12:44 - WARNING - __main__ - epoch 4 step 306 loss 0.07001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:13:46 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:13:46 - INFO - __main__ -   eval_f1 = 0.3876\n",
      "01/08/2025 21:13:46 - INFO - __main__ -   eval_precision = 0.3648\n",
      "01/08/2025 21:13:46 - INFO - __main__ -   eval_recall = 0.4133\n",
      " 79% 407/512 [10:50<02:02,  1.16s/it]01/08/2025 21:15:43 - WARNING - __main__ - epoch 4 step 408 loss 0.06048\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:16:45 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:16:45 - INFO - __main__ -   eval_f1 = 0.3498\n",
      "01/08/2025 21:16:45 - INFO - __main__ -   eval_precision = 0.4286\n",
      "01/08/2025 21:16:45 - INFO - __main__ -   eval_recall = 0.2955\n",
      " 99% 509/512 [13:50<00:03,  1.09s/it]01/08/2025 21:18:42 - WARNING - __main__ - epoch 4 step 510 loss 0.07731\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:19:44 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:19:44 - INFO - __main__ -   eval_f1 = 0.3678\n",
      "01/08/2025 21:19:44 - INFO - __main__ -   eval_precision = 0.4465\n",
      "01/08/2025 21:19:44 - INFO - __main__ -   eval_recall = 0.3126\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:08,  1.19s/it]01/08/2025 21:21:41 - WARNING - __main__ - epoch 5 step 102 loss 0.03929\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:22:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:22:43 - INFO - __main__ -   eval_f1 = 0.3103\n",
      "01/08/2025 21:22:43 - INFO - __main__ -   eval_precision = 0.3967\n",
      "01/08/2025 21:22:43 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 40% 203/512 [04:53<05:38,  1.09s/it]01/08/2025 21:24:41 - WARNING - __main__ - epoch 5 step 204 loss 0.04355\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:25:43 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:25:43 - INFO - __main__ -   eval_f1 = 0.342\n",
      "01/08/2025 21:25:43 - INFO - __main__ -   eval_precision = 0.4735\n",
      "01/08/2025 21:25:43 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 60% 305/512 [07:51<03:58,  1.15s/it]01/08/2025 21:27:39 - WARNING - __main__ - epoch 5 step 306 loss 0.04842\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:28:41 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:28:41 - INFO - __main__ -   eval_f1 = 0.3574\n",
      "01/08/2025 21:28:41 - INFO - __main__ -   eval_precision = 0.4626\n",
      "01/08/2025 21:28:41 - INFO - __main__ -   eval_recall = 0.2912\n",
      " 79% 407/512 [10:51<01:53,  1.09s/it]01/08/2025 21:30:38 - WARNING - __main__ - epoch 5 step 408 loss 0.04428\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:31:40 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:31:40 - INFO - __main__ -   eval_f1 = 0.3381\n",
      "01/08/2025 21:31:40 - INFO - __main__ -   eval_precision = 0.4358\n",
      "01/08/2025 21:31:40 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 99% 509/512 [13:50<00:03,  1.07s/it]01/08/2025 21:33:37 - WARNING - __main__ - epoch 5 step 510 loss 0.04064\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:34:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:34:39 - INFO - __main__ -   eval_f1 = 0.3508\n",
      "01/08/2025 21:34:39 - INFO - __main__ -   eval_precision = 0.4363\n",
      "01/08/2025 21:34:39 - INFO - __main__ -   eval_recall = 0.2934\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:38,  1.12s/it]01/08/2025 21:36:37 - WARNING - __main__ - epoch 6 step 102 loss 0.01768\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:37:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:37:39 - INFO - __main__ -   eval_f1 = 0.347\n",
      "01/08/2025 21:37:39 - INFO - __main__ -   eval_precision = 0.3967\n",
      "01/08/2025 21:37:39 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [04:55<06:17,  1.22s/it]01/08/2025 21:39:37 - WARNING - __main__ - epoch 6 step 204 loss 0.0345\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:40:39 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:40:39 - INFO - __main__ -   eval_f1 = 0.3433\n",
      "01/08/2025 21:40:39 - INFO - __main__ -   eval_precision = 0.33\n",
      "01/08/2025 21:40:39 - INFO - __main__ -   eval_recall = 0.3576\n",
      " 60% 305/512 [07:51<04:03,  1.18s/it]01/08/2025 21:42:33 - WARNING - __main__ - epoch 6 step 306 loss 0.02299\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:43:35 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:43:35 - INFO - __main__ -   eval_f1 = 0.303\n",
      "01/08/2025 21:43:35 - INFO - __main__ -   eval_precision = 0.4247\n",
      "01/08/2025 21:43:35 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 79% 407/512 [10:49<01:54,  1.09s/it]01/08/2025 21:45:31 - WARNING - __main__ - epoch 6 step 408 loss 0.02493\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:46:33 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:46:33 - INFO - __main__ -   eval_f1 = 0.3341\n",
      "01/08/2025 21:46:33 - INFO - __main__ -   eval_precision = 0.3774\n",
      "01/08/2025 21:46:33 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 99% 509/512 [13:49<00:03,  1.19s/it]01/08/2025 21:48:31 - WARNING - __main__ - epoch 6 step 510 loss 0.02714\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:49:33 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:49:33 - INFO - __main__ -   eval_f1 = 0.2817\n",
      "01/08/2025 21:49:33 - INFO - __main__ -   eval_precision = 0.404\n",
      "01/08/2025 21:49:33 - INFO - __main__ -   eval_recall = 0.2163\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:28,  1.09s/it]01/08/2025 21:51:30 - WARNING - __main__ - epoch 7 step 102 loss 0.00996\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:52:32 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 21:52:32 - INFO - __main__ -   eval_f1 = 0.3035\n",
      "01/08/2025 21:52:32 - INFO - __main__ -   eval_precision = 0.362\n",
      "01/08/2025 21:52:32 - INFO - __main__ -   eval_recall = 0.2612\n",
      "01/08/2025 21:52:32 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 101/512 [02:57<12:01,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l5e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 5e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MDyrRFM6C8p",
    "outputId": "a1bb6814-38c5-4072-b1ec-dfd751155e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 21:53:23.223593: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 21:53:23.241342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 21:53:23.262648: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 21:53:23.269107: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 21:53:23.284376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 21:53:24.641695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 21:53:27 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 21:55:13 - INFO - __main__ - ***** Test results *****\n",
      "01/08/2025 21:55:13 - INFO - __main__ -   auc_score = 0.8468\n",
      "01/08/2025 21:55:13 - INFO - __main__ -   test_f1 = 0.3624\n",
      "01/08/2025 21:55:13 - INFO - __main__ -   test_precision = 0.5282\n",
      "01/08/2025 21:55:13 - INFO - __main__ -   test_recall = 0.2758\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l5e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 5e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pS9UY4D_7iGq",
    "outputId": "629a5da2-fdf7-4f5b-c00a-a6c9c870b5c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 21:59:54.351439: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 21:59:54.369248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 21:59:54.390411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 21:59:54.396816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 21:59:54.412111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 21:59:55.758733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/08/2025 21:59:58 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:57<07:08,  1.04s/it]01/08/2025 22:04:04 - WARNING - __main__ - epoch 0 step 102 loss 0.32711\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:05:06 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:05:06 - INFO - __main__ -   eval_f1 = 0.0043\n",
      "01/08/2025 22:05:06 - INFO - __main__ -   eval_precision = 0.3333\n",
      "01/08/2025 22:05:06 - INFO - __main__ -   eval_recall = 0.0021\n",
      " 40% 203/512 [05:09<06:07,  1.19s/it]01/08/2025 22:07:16 - WARNING - __main__ - epoch 0 step 204 loss 0.30786\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 22:08:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:08:18 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 22:08:18 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 22:08:18 - INFO - __main__ -   eval_recall = 0.0\n",
      " 60% 305/512 [08:09<04:04,  1.18s/it]01/08/2025 22:10:16 - WARNING - __main__ - epoch 0 step 306 loss 0.27651\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 22:11:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:11:18 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 22:11:18 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 22:11:18 - INFO - __main__ -   eval_recall = 0.0\n",
      " 79% 407/512 [11:08<02:01,  1.16s/it]01/08/2025 22:13:15 - WARNING - __main__ - epoch 0 step 408 loss 0.27345\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "01/08/2025 22:14:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:14:17 - INFO - __main__ -   eval_f1 = 0.0\n",
      "01/08/2025 22:14:17 - INFO - __main__ -   eval_precision = 0.0\n",
      "01/08/2025 22:14:17 - INFO - __main__ -   eval_recall = 0.0\n",
      " 99% 509/512 [14:05<00:03,  1.13s/it]01/08/2025 22:16:12 - WARNING - __main__ - epoch 0 step 510 loss 0.25696\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:17:14 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:17:14 - INFO - __main__ -   eval_f1 = 0.0043\n",
      "01/08/2025 22:17:14 - INFO - __main__ -   eval_precision = 1.0\n",
      "01/08/2025 22:17:14 - INFO - __main__ -   eval_recall = 0.0021\n",
      "100% 512/512 [15:22<00:00,  1.80s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:15,  1.06s/it]01/08/2025 22:19:23 - WARNING - __main__ - epoch 1 step 102 loss 0.25\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:20:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:20:26 - INFO - __main__ -   eval_f1 = 0.0293\n",
      "01/08/2025 22:20:26 - INFO - __main__ -   eval_precision = 0.6364\n",
      "01/08/2025 22:20:26 - INFO - __main__ -   eval_recall = 0.015\n",
      " 40% 203/512 [05:06<06:04,  1.18s/it]01/08/2025 22:22:35 - WARNING - __main__ - epoch 1 step 204 loss 0.24112\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:23:37 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:23:37 - INFO - __main__ -   eval_f1 = 0.0574\n",
      "01/08/2025 22:23:37 - INFO - __main__ -   eval_precision = 0.6667\n",
      "01/08/2025 22:23:37 - INFO - __main__ -   eval_recall = 0.03\n",
      " 60% 305/512 [08:17<04:09,  1.20s/it]01/08/2025 22:25:46 - WARNING - __main__ - epoch 1 step 306 loss 0.21443\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:26:48 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:26:48 - INFO - __main__ -   eval_f1 = 0.1639\n",
      "01/08/2025 22:26:48 - INFO - __main__ -   eval_precision = 0.6286\n",
      "01/08/2025 22:26:48 - INFO - __main__ -   eval_recall = 0.0942\n",
      " 79% 407/512 [11:27<01:58,  1.13s/it]01/08/2025 22:28:56 - WARNING - __main__ - epoch 1 step 408 loss 0.25021\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:29:58 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:29:58 - INFO - __main__ -   eval_f1 = 0.1629\n",
      "01/08/2025 22:29:58 - INFO - __main__ -   eval_precision = 0.7049\n",
      "01/08/2025 22:29:58 - INFO - __main__ -   eval_recall = 0.0921\n",
      " 99% 509/512 [14:26<00:03,  1.05s/it]01/08/2025 22:31:55 - WARNING - __main__ - epoch 1 step 510 loss 0.21867\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:32:57 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:32:57 - INFO - __main__ -   eval_f1 = 0.2438\n",
      "01/08/2025 22:32:57 - INFO - __main__ -   eval_precision = 0.697\n",
      "01/08/2025 22:32:57 - INFO - __main__ -   eval_recall = 0.1478\n",
      "100% 512/512 [15:44<00:00,  1.85s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:34,  1.11s/it]01/08/2025 22:35:07 - WARNING - __main__ - epoch 2 step 102 loss 0.22772\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:36:10 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:36:10 - INFO - __main__ -   eval_f1 = 0.1721\n",
      "01/08/2025 22:36:10 - INFO - __main__ -   eval_precision = 0.8036\n",
      "01/08/2025 22:36:10 - INFO - __main__ -   eval_recall = 0.0964\n",
      " 40% 203/512 [04:53<06:16,  1.22s/it]01/08/2025 22:38:06 - WARNING - __main__ - epoch 2 step 204 loss 0.20515\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:39:08 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:39:08 - INFO - __main__ -   eval_f1 = 0.4178\n",
      "01/08/2025 22:39:08 - INFO - __main__ -   eval_precision = 0.5351\n",
      "01/08/2025 22:39:08 - INFO - __main__ -   eval_recall = 0.3426\n",
      " 60% 305/512 [08:03<04:09,  1.20s/it]01/08/2025 22:41:16 - WARNING - __main__ - epoch 2 step 306 loss 0.19847\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:42:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:42:19 - INFO - __main__ -   eval_f1 = 0.2788\n",
      "01/08/2025 22:42:19 - INFO - __main__ -   eval_precision = 0.7105\n",
      "01/08/2025 22:42:19 - INFO - __main__ -   eval_recall = 0.1734\n",
      " 79% 407/512 [11:03<02:03,  1.17s/it]01/08/2025 22:44:16 - WARNING - __main__ - epoch 2 step 408 loss 0.20376\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:45:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:45:18 - INFO - __main__ -   eval_f1 = 0.1629\n",
      "01/08/2025 22:45:18 - INFO - __main__ -   eval_precision = 0.7049\n",
      "01/08/2025 22:45:18 - INFO - __main__ -   eval_recall = 0.0921\n",
      " 99% 509/512 [14:01<00:03,  1.15s/it]01/08/2025 22:47:15 - WARNING - __main__ - epoch 2 step 510 loss 0.20546\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:48:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:48:17 - INFO - __main__ -   eval_f1 = 0.1903\n",
      "01/08/2025 22:48:17 - INFO - __main__ -   eval_precision = 0.7391\n",
      "01/08/2025 22:48:17 - INFO - __main__ -   eval_recall = 0.1092\n",
      "100% 512/512 [15:06<00:00,  1.77s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:56<07:35,  1.11s/it]01/08/2025 22:50:17 - WARNING - __main__ - epoch 3 step 102 loss 0.18746\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:51:19 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:51:19 - INFO - __main__ -   eval_f1 = 0.2007\n",
      "01/08/2025 22:51:19 - INFO - __main__ -   eval_precision = 0.7606\n",
      "01/08/2025 22:51:19 - INFO - __main__ -   eval_recall = 0.1156\n",
      " 40% 203/512 [04:54<05:49,  1.13s/it]01/08/2025 22:53:14 - WARNING - __main__ - epoch 3 step 204 loss 0.17525\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:54:16 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:54:16 - INFO - __main__ -   eval_f1 = 0.3137\n",
      "01/08/2025 22:54:16 - INFO - __main__ -   eval_precision = 0.7381\n",
      "01/08/2025 22:54:16 - INFO - __main__ -   eval_recall = 0.1991\n",
      " 60% 305/512 [07:52<04:00,  1.16s/it]01/08/2025 22:56:12 - WARNING - __main__ - epoch 3 step 306 loss 0.19203\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 22:57:15 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 22:57:15 - INFO - __main__ -   eval_f1 = 0.2734\n",
      "01/08/2025 22:57:15 - INFO - __main__ -   eval_precision = 0.7117\n",
      "01/08/2025 22:57:15 - INFO - __main__ -   eval_recall = 0.1692\n",
      " 79% 407/512 [10:51<02:01,  1.16s/it]01/08/2025 22:59:12 - WARNING - __main__ - epoch 3 step 408 loss 0.20232\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:00:14 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:00:14 - INFO - __main__ -   eval_f1 = 0.3119\n",
      "01/08/2025 23:00:14 - INFO - __main__ -   eval_precision = 0.748\n",
      "01/08/2025 23:00:14 - INFO - __main__ -   eval_recall = 0.197\n",
      " 99% 509/512 [13:49<00:03,  1.10s/it]01/08/2025 23:02:10 - WARNING - __main__ - epoch 3 step 510 loss 0.19204\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:03:12 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:03:12 - INFO - __main__ -   eval_f1 = 0.2576\n",
      "01/08/2025 23:03:12 - INFO - __main__ -   eval_precision = 0.7826\n",
      "01/08/2025 23:03:12 - INFO - __main__ -   eval_recall = 0.1542\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:49,  1.14s/it]01/08/2025 23:05:09 - WARNING - __main__ - epoch 4 step 102 loss 0.17999\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:06:11 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:06:11 - INFO - __main__ -   eval_f1 = 0.3706\n",
      "01/08/2025 23:06:11 - INFO - __main__ -   eval_precision = 0.6505\n",
      "01/08/2025 23:06:11 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 40% 203/512 [04:54<06:04,  1.18s/it]01/08/2025 23:08:09 - WARNING - __main__ - epoch 4 step 204 loss 0.17553\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:09:11 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:09:11 - INFO - __main__ -   eval_f1 = 0.3947\n",
      "01/08/2025 23:09:11 - INFO - __main__ -   eval_precision = 0.6221\n",
      "01/08/2025 23:09:11 - INFO - __main__ -   eval_recall = 0.2891\n",
      " 60% 305/512 [07:51<04:01,  1.17s/it]01/08/2025 23:11:06 - WARNING - __main__ - epoch 4 step 306 loss 0.17249\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:12:08 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:12:08 - INFO - __main__ -   eval_f1 = 0.4073\n",
      "01/08/2025 23:12:08 - INFO - __main__ -   eval_precision = 0.584\n",
      "01/08/2025 23:12:08 - INFO - __main__ -   eval_recall = 0.3126\n",
      " 79% 407/512 [10:50<02:02,  1.16s/it]01/08/2025 23:14:05 - WARNING - __main__ - epoch 4 step 408 loss 0.16204\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:15:07 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:15:07 - INFO - __main__ -   eval_f1 = 0.3843\n",
      "01/08/2025 23:15:07 - INFO - __main__ -   eval_precision = 0.6546\n",
      "01/08/2025 23:15:07 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 99% 509/512 [13:49<00:03,  1.09s/it]01/08/2025 23:17:04 - WARNING - __main__ - epoch 4 step 510 loss 0.18302\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:18:07 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:18:07 - INFO - __main__ -   eval_f1 = 0.3832\n",
      "01/08/2025 23:18:07 - INFO - __main__ -   eval_precision = 0.6368\n",
      "01/08/2025 23:18:07 - INFO - __main__ -   eval_recall = 0.2741\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:08,  1.19s/it]01/08/2025 23:20:03 - WARNING - __main__ - epoch 5 step 102 loss 0.15778\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:21:05 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:21:05 - INFO - __main__ -   eval_f1 = 0.2877\n",
      "01/08/2025 23:21:05 - INFO - __main__ -   eval_precision = 0.7179\n",
      "01/08/2025 23:21:05 - INFO - __main__ -   eval_recall = 0.1799\n",
      " 40% 203/512 [04:53<05:38,  1.09s/it]01/08/2025 23:23:03 - WARNING - __main__ - epoch 5 step 204 loss 0.16393\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:24:05 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:24:05 - INFO - __main__ -   eval_f1 = 0.4252\n",
      "01/08/2025 23:24:05 - INFO - __main__ -   eval_precision = 0.5492\n",
      "01/08/2025 23:24:05 - INFO - __main__ -   eval_recall = 0.3469\n",
      " 60% 305/512 [08:05<03:58,  1.15s/it]01/08/2025 23:26:15 - WARNING - __main__ - epoch 5 step 306 loss 0.14883\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:27:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:27:17 - INFO - __main__ -   eval_f1 = 0.4282\n",
      "01/08/2025 23:27:17 - INFO - __main__ -   eval_precision = 0.5073\n",
      "01/08/2025 23:27:17 - INFO - __main__ -   eval_recall = 0.3704\n",
      " 79% 407/512 [11:21<01:53,  1.09s/it]01/08/2025 23:29:31 - WARNING - __main__ - epoch 5 step 408 loss 0.16165\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:30:33 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:30:33 - INFO - __main__ -   eval_f1 = 0.3339\n",
      "01/08/2025 23:30:33 - INFO - __main__ -   eval_precision = 0.6481\n",
      "01/08/2025 23:30:33 - INFO - __main__ -   eval_recall = 0.2248\n",
      " 99% 509/512 [14:20<00:03,  1.07s/it]01/08/2025 23:32:29 - WARNING - __main__ - epoch 5 step 510 loss 0.14895\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:33:31 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:33:31 - INFO - __main__ -   eval_f1 = 0.3574\n",
      "01/08/2025 23:33:31 - INFO - __main__ -   eval_precision = 0.6667\n",
      "01/08/2025 23:33:31 - INFO - __main__ -   eval_recall = 0.2441\n",
      "100% 512/512 [15:24<00:00,  1.81s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:55<07:38,  1.11s/it]01/08/2025 23:35:29 - WARNING - __main__ - epoch 6 step 102 loss 0.14985\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:36:31 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:36:31 - INFO - __main__ -   eval_f1 = 0.3721\n",
      "01/08/2025 23:36:31 - INFO - __main__ -   eval_precision = 0.5792\n",
      "01/08/2025 23:36:31 - INFO - __main__ -   eval_recall = 0.2741\n",
      " 40% 203/512 [04:55<06:17,  1.22s/it]01/08/2025 23:38:29 - WARNING - __main__ - epoch 6 step 204 loss 0.1357\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:39:31 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:39:31 - INFO - __main__ -   eval_f1 = 0.39\n",
      "01/08/2025 23:39:31 - INFO - __main__ -   eval_precision = 0.6186\n",
      "01/08/2025 23:39:31 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 60% 305/512 [07:51<04:03,  1.18s/it]01/08/2025 23:41:26 - WARNING - __main__ - epoch 6 step 306 loss 0.13701\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:42:28 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:42:28 - INFO - __main__ -   eval_f1 = 0.4011\n",
      "01/08/2025 23:42:28 - INFO - __main__ -   eval_precision = 0.5594\n",
      "01/08/2025 23:42:28 - INFO - __main__ -   eval_recall = 0.3126\n",
      " 79% 407/512 [10:49<01:54,  1.09s/it]01/08/2025 23:44:24 - WARNING - __main__ - epoch 6 step 408 loss 0.14236\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:45:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:45:26 - INFO - __main__ -   eval_f1 = 0.383\n",
      "01/08/2025 23:45:26 - INFO - __main__ -   eval_precision = 0.5672\n",
      "01/08/2025 23:45:26 - INFO - __main__ -   eval_recall = 0.2891\n",
      " 99% 509/512 [13:49<00:03,  1.19s/it]01/08/2025 23:47:24 - WARNING - __main__ - epoch 6 step 510 loss 0.14053\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:48:26 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:48:26 - INFO - __main__ -   eval_f1 = 0.3689\n",
      "01/08/2025 23:48:26 - INFO - __main__ -   eval_precision = 0.5639\n",
      "01/08/2025 23:48:26 - INFO - __main__ -   eval_recall = 0.2741\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<07:28,  1.09s/it]01/08/2025 23:50:23 - WARNING - __main__ - epoch 7 step 102 loss 0.11837\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:51:25 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:51:25 - INFO - __main__ -   eval_f1 = 0.3192\n",
      "01/08/2025 23:51:25 - INFO - __main__ -   eval_precision = 0.593\n",
      "01/08/2025 23:51:25 - INFO - __main__ -   eval_recall = 0.2184\n",
      " 40% 203/512 [04:53<06:14,  1.21s/it]01/08/2025 23:53:21 - WARNING - __main__ - epoch 7 step 204 loss 0.1285\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:54:23 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:54:23 - INFO - __main__ -   eval_f1 = 0.3108\n",
      "01/08/2025 23:54:23 - INFO - __main__ -   eval_precision = 0.5519\n",
      "01/08/2025 23:54:23 - INFO - __main__ -   eval_recall = 0.2163\n",
      " 60% 305/512 [07:50<04:02,  1.17s/it]01/08/2025 23:56:19 - WARNING - __main__ - epoch 7 step 306 loss 0.1311\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/08/2025 23:57:21 - INFO - __main__ - ***** Eval results *****\n",
      "01/08/2025 23:57:21 - INFO - __main__ -   eval_f1 = 0.3556\n",
      "01/08/2025 23:57:21 - INFO - __main__ -   eval_precision = 0.5297\n",
      "01/08/2025 23:57:21 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 79% 407/512 [10:49<02:01,  1.16s/it]01/08/2025 23:59:17 - WARNING - __main__ - epoch 7 step 408 loss 0.12291\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:00:20 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:00:20 - INFO - __main__ -   eval_f1 = 0.3503\n",
      "01/09/2025 00:00:20 - INFO - __main__ -   eval_precision = 0.5821\n",
      "01/09/2025 00:00:20 - INFO - __main__ -   eval_recall = 0.2505\n",
      " 99% 509/512 [13:49<00:03,  1.12s/it]01/09/2025 00:02:18 - WARNING - __main__ - epoch 7 step 510 loss 0.12525\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:03:20 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:03:20 - INFO - __main__ -   eval_f1 = 0.3876\n",
      "01/09/2025 00:03:20 - INFO - __main__ -   eval_precision = 0.4886\n",
      "01/09/2025 00:03:20 - INFO - __main__ -   eval_recall = 0.3212\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:58<07:56,  1.16s/it]01/09/2025 00:05:20 - WARNING - __main__ - epoch 8 step 102 loss 0.11748\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:06:22 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:06:22 - INFO - __main__ -   eval_f1 = 0.3995\n",
      "01/09/2025 00:06:22 - INFO - __main__ -   eval_precision = 0.4396\n",
      "01/09/2025 00:06:22 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 40% 203/512 [04:55<06:05,  1.18s/it]01/09/2025 00:08:18 - WARNING - __main__ - epoch 8 step 204 loss 0.10534\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:09:20 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:09:20 - INFO - __main__ -   eval_f1 = 0.3295\n",
      "01/09/2025 00:09:20 - INFO - __main__ -   eval_precision = 0.5067\n",
      "01/09/2025 00:09:20 - INFO - __main__ -   eval_recall = 0.2441\n",
      " 60% 305/512 [07:54<04:15,  1.23s/it]01/09/2025 00:11:16 - WARNING - __main__ - epoch 8 step 306 loss 0.11059\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:12:18 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:12:18 - INFO - __main__ -   eval_f1 = 0.2989\n",
      "01/09/2025 00:12:18 - INFO - __main__ -   eval_precision = 0.533\n",
      "01/09/2025 00:12:18 - INFO - __main__ -   eval_recall = 0.2077\n",
      " 79% 407/512 [10:52<01:55,  1.10s/it]01/09/2025 00:14:15 - WARNING - __main__ - epoch 8 step 408 loss 0.10615\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:15:17 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:15:17 - INFO - __main__ -   eval_f1 = 0.3446\n",
      "01/09/2025 00:15:17 - INFO - __main__ -   eval_precision = 0.4704\n",
      "01/09/2025 00:15:17 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 99% 509/512 [13:50<00:03,  1.12s/it]01/09/2025 00:17:12 - WARNING - __main__ - epoch 8 step 510 loss 0.11537\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:18:14 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:18:14 - INFO - __main__ -   eval_f1 = 0.3437\n",
      "01/09/2025 00:18:14 - INFO - __main__ -   eval_precision = 0.4669\n",
      "01/09/2025 00:18:14 - INFO - __main__ -   eval_recall = 0.2719\n",
      "100% 512/512 [14:54<00:00,  1.75s/it]\n",
      "  0% 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 101/512 [01:54<08:01,  1.17s/it]01/09/2025 00:20:11 - WARNING - __main__ - epoch 9 step 102 loss 0.10425\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:21:13 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:21:13 - INFO - __main__ -   eval_f1 = 0.356\n",
      "01/09/2025 00:21:13 - INFO - __main__ -   eval_precision = 0.4211\n",
      "01/09/2025 00:21:13 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 40% 203/512 [04:53<05:16,  1.02s/it]01/09/2025 00:23:10 - WARNING - __main__ - epoch 9 step 204 loss 0.10189\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:24:12 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:24:12 - INFO - __main__ -   eval_f1 = 0.3646\n",
      "01/09/2025 00:24:12 - INFO - __main__ -   eval_precision = 0.4651\n",
      "01/09/2025 00:24:12 - INFO - __main__ -   eval_recall = 0.2998\n",
      " 60% 305/512 [07:50<04:02,  1.17s/it]01/09/2025 00:26:07 - WARNING - __main__ - epoch 9 step 306 loss 0.09377\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:27:09 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:27:09 - INFO - __main__ -   eval_f1 = 0.3155\n",
      "01/09/2025 00:27:09 - INFO - __main__ -   eval_precision = 0.4866\n",
      "01/09/2025 00:27:09 - INFO - __main__ -   eval_recall = 0.2334\n",
      " 79% 407/512 [10:49<02:01,  1.16s/it]01/09/2025 00:29:06 - WARNING - __main__ - epoch 9 step 408 loss 0.09694\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:30:08 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:30:08 - INFO - __main__ -   eval_f1 = 0.3279\n",
      "01/09/2025 00:30:08 - INFO - __main__ -   eval_precision = 0.4528\n",
      "01/09/2025 00:30:08 - INFO - __main__ -   eval_recall = 0.257\n",
      " 99% 509/512 [13:50<00:03,  1.16s/it]01/09/2025 00:32:07 - WARNING - __main__ - epoch 9 step 510 loss 0.10309\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:33:09 - INFO - __main__ - ***** Eval results *****\n",
      "01/09/2025 00:33:09 - INFO - __main__ -   eval_f1 = 0.3338\n",
      "01/09/2025 00:33:09 - INFO - __main__ -   eval_precision = 0.4556\n",
      "01/09/2025 00:33:09 - INFO - __main__ -   eval_recall = 0.2634\n",
      "100% 512/512 [14:55<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l1e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 1e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twEpUzfFfZmU",
    "outputId": "b73e91f8-958e-460b-c77f-75db51a91c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 00:36:27.002880: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-09 00:36:27.020508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 00:36:27.041582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 00:36:27.047970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 00:36:27.063175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 00:36:28.422632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "01/09/2025 00:36:31 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/content/PEFT4CC/just-in-time/run.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/09/2025 00:38:16 - INFO - __main__ - ***** Test results *****\n",
      "01/09/2025 00:38:16 - INFO - __main__ -   auc_score = 0.8415\n",
      "01/09/2025 00:38:16 - INFO - __main__ -   test_f1 = 0.3412\n",
      "01/09/2025 00:38:16 - INFO - __main__ -   test_precision = 0.4132\n",
      "01/09/2025 00:38:16 - INFO - __main__ -   test_recall = 0.2905\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-l1e-5/concat/checkpoints \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 1e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMueXRJ2OT6P"
   },
   "source": [
    "##### Repeating the training with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUMMKVjROmhw"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAnCSQL-OPIX",
    "outputId": "8723eba3-6f57-46c8-b62e-ad4095175857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 17:02:50.070226: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 17:02:50.087830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746378170.109893    7995 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746378170.116465    7995 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 17:02:50.137808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "05/04/2025 17:02:53 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10468 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:53<15:40,  1.15s/it]05/04/2025 17:08:57 - WARNING - __main__ - epoch 0 step 204 loss 0.3053\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:11:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:11:03 - INFO - __main__ -   eval_f1 = 0.0168\n",
      "05/04/2025 17:11:03 - INFO - __main__ -   eval_precision = 0.4\n",
      "05/04/2025 17:11:03 - INFO - __main__ -   eval_recall = 0.0086\n",
      " 40% 407/1024 [10:06<11:45,  1.14s/it]05/04/2025 17:15:10 - WARNING - __main__ - epoch 0 step 408 loss 0.26006\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:17:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:17:16 - INFO - __main__ -   eval_f1 = 0.0249\n",
      "05/04/2025 17:17:16 - INFO - __main__ -   eval_precision = 0.4\n",
      "05/04/2025 17:17:16 - INFO - __main__ -   eval_recall = 0.0128\n",
      " 60% 611/1024 [16:17<07:52,  1.14s/it]05/04/2025 17:21:21 - WARNING - __main__ - epoch 0 step 612 loss 0.2672\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:23:27 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:23:27 - INFO - __main__ -   eval_f1 = 0.0687\n",
      "05/04/2025 17:23:27 - INFO - __main__ -   eval_precision = 0.6071\n",
      "05/04/2025 17:23:27 - INFO - __main__ -   eval_recall = 0.0364\n",
      " 80% 815/1024 [22:32<03:59,  1.14s/it]05/04/2025 17:27:36 - WARNING - __main__ - epoch 0 step 816 loss 0.22513\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:29:42 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:29:42 - INFO - __main__ -   eval_f1 = 0.3328\n",
      "05/04/2025 17:29:42 - INFO - __main__ -   eval_precision = 0.7734\n",
      "05/04/2025 17:29:42 - INFO - __main__ -   eval_recall = 0.212\n",
      "100% 1019/1024 [28:44<00:05,  1.14s/it]05/04/2025 17:33:48 - WARNING - __main__ - epoch 0 step 1020 loss 0.21578\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:35:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:35:55 - INFO - __main__ -   eval_f1 = 0.4308\n",
      "05/04/2025 17:35:55 - INFO - __main__ -   eval_precision = 0.765\n",
      "05/04/2025 17:35:55 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 1024/1024 [31:09<00:00,  1.83s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]05/04/2025 17:40:05 - WARNING - __main__ - epoch 1 step 204 loss 0.17937\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:42:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:42:11 - INFO - __main__ -   eval_f1 = 0.3289\n",
      "05/04/2025 17:42:11 - INFO - __main__ -   eval_precision = 0.7597\n",
      "05/04/2025 17:42:11 - INFO - __main__ -   eval_recall = 0.2099\n",
      " 40% 407/1024 [09:50<11:46,  1.15s/it]05/04/2025 17:46:04 - WARNING - __main__ - epoch 1 step 408 loss 0.18303\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:48:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:48:10 - INFO - __main__ -   eval_f1 = 0.3441\n",
      "05/04/2025 17:48:10 - INFO - __main__ -   eval_precision = 0.8417\n",
      "05/04/2025 17:48:10 - INFO - __main__ -   eval_recall = 0.2163\n",
      " 60% 611/1024 [15:49<07:52,  1.15s/it]05/04/2025 17:52:03 - WARNING - __main__ - epoch 1 step 612 loss 0.18495\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 17:54:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 17:54:09 - INFO - __main__ -   eval_f1 = 0.4883\n",
      "05/04/2025 17:54:09 - INFO - __main__ -   eval_precision = 0.686\n",
      "05/04/2025 17:54:09 - INFO - __main__ -   eval_recall = 0.379\n",
      " 80% 815/1024 [22:00<03:59,  1.14s/it]05/04/2025 17:58:13 - WARNING - __main__ - epoch 1 step 816 loss 0.17579\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:00:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:00:19 - INFO - __main__ -   eval_f1 = 0.3488\n",
      "05/04/2025 18:00:19 - INFO - __main__ -   eval_precision = 0.7778\n",
      "05/04/2025 18:00:19 - INFO - __main__ -   eval_recall = 0.2248\n",
      "100% 1019/1024 [27:59<00:05,  1.14s/it]05/04/2025 18:04:12 - WARNING - __main__ - epoch 1 step 1020 loss 0.17578\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:06:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:06:18 - INFO - __main__ -   eval_f1 = 0.3766\n",
      "05/04/2025 18:06:18 - INFO - __main__ -   eval_precision = 0.7785\n",
      "05/04/2025 18:06:18 - INFO - __main__ -   eval_recall = 0.2484\n",
      "100% 1024/1024 [30:09<00:00,  1.77s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 18:10:15 - WARNING - __main__ - epoch 2 step 204 loss 0.11711\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:12:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:12:21 - INFO - __main__ -   eval_f1 = 0.4511\n",
      "05/04/2025 18:12:21 - INFO - __main__ -   eval_precision = 0.5094\n",
      "05/04/2025 18:12:21 - INFO - __main__ -   eval_recall = 0.4047\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/04/2025 18:16:13 - WARNING - __main__ - epoch 2 step 408 loss 0.09674\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:18:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:18:19 - INFO - __main__ -   eval_f1 = 0.3973\n",
      "05/04/2025 18:18:19 - INFO - __main__ -   eval_precision = 0.5324\n",
      "05/04/2025 18:18:19 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 18:22:12 - WARNING - __main__ - epoch 2 step 612 loss 0.09943\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:24:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:24:18 - INFO - __main__ -   eval_f1 = 0.3783\n",
      "05/04/2025 18:24:18 - INFO - __main__ -   eval_precision = 0.6\n",
      "05/04/2025 18:24:18 - INFO - __main__ -   eval_recall = 0.2762\n",
      " 80% 815/1024 [21:47<03:59,  1.14s/it]05/04/2025 18:28:11 - WARNING - __main__ - epoch 2 step 816 loss 0.10465\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:30:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:30:17 - INFO - __main__ -   eval_f1 = 0.4631\n",
      "05/04/2025 18:30:17 - INFO - __main__ -   eval_precision = 0.5572\n",
      "05/04/2025 18:30:17 - INFO - __main__ -   eval_recall = 0.3961\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/04/2025 18:34:09 - WARNING - __main__ - epoch 2 step 1020 loss 0.11153\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:36:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:36:16 - INFO - __main__ -   eval_f1 = 0.3864\n",
      "05/04/2025 18:36:16 - INFO - __main__ -   eval_precision = 0.6944\n",
      "05/04/2025 18:36:16 - INFO - __main__ -   eval_recall = 0.2677\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 18:40:12 - WARNING - __main__ - epoch 3 step 204 loss 0.04213\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:42:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:42:18 - INFO - __main__ -   eval_f1 = 0.3734\n",
      "05/04/2025 18:42:18 - INFO - __main__ -   eval_precision = 0.4015\n",
      "05/04/2025 18:42:18 - INFO - __main__ -   eval_recall = 0.349\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/04/2025 18:46:11 - WARNING - __main__ - epoch 3 step 408 loss 0.0495\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:48:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:48:17 - INFO - __main__ -   eval_f1 = 0.3689\n",
      "05/04/2025 18:48:17 - INFO - __main__ -   eval_precision = 0.5094\n",
      "05/04/2025 18:48:17 - INFO - __main__ -   eval_recall = 0.2891\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 18:52:09 - WARNING - __main__ - epoch 3 step 612 loss 0.04908\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 18:54:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 18:54:16 - INFO - __main__ -   eval_f1 = 0.3736\n",
      "05/04/2025 18:54:16 - INFO - __main__ -   eval_precision = 0.3911\n",
      "05/04/2025 18:54:16 - INFO - __main__ -   eval_recall = 0.3576\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 18:58:08 - WARNING - __main__ - epoch 3 step 816 loss 0.04326\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:00:14 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:00:14 - INFO - __main__ -   eval_f1 = 0.3352\n",
      "05/04/2025 19:00:14 - INFO - __main__ -   eval_precision = 0.5065\n",
      "05/04/2025 19:00:14 - INFO - __main__ -   eval_recall = 0.2505\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/04/2025 19:04:07 - WARNING - __main__ - epoch 3 step 1020 loss 0.04448\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:06:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:06:13 - INFO - __main__ -   eval_f1 = 0.3653\n",
      "05/04/2025 19:06:13 - INFO - __main__ -   eval_precision = 0.4525\n",
      "05/04/2025 19:06:13 - INFO - __main__ -   eval_recall = 0.3062\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 19:10:09 - WARNING - __main__ - epoch 4 step 204 loss 0.0143\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:12:16 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:12:16 - INFO - __main__ -   eval_f1 = 0.3008\n",
      "05/04/2025 19:12:16 - INFO - __main__ -   eval_precision = 0.4096\n",
      "05/04/2025 19:12:16 - INFO - __main__ -   eval_recall = 0.2377\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/04/2025 19:16:08 - WARNING - __main__ - epoch 4 step 408 loss 0.01389\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:18:14 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:18:14 - INFO - __main__ -   eval_f1 = 0.3831\n",
      "05/04/2025 19:18:14 - INFO - __main__ -   eval_precision = 0.3873\n",
      "05/04/2025 19:18:14 - INFO - __main__ -   eval_recall = 0.379\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 19:22:07 - WARNING - __main__ - epoch 4 step 612 loss 0.01043\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:24:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:24:13 - INFO - __main__ -   eval_f1 = 0.3607\n",
      "05/04/2025 19:24:13 - INFO - __main__ -   eval_precision = 0.4855\n",
      "05/04/2025 19:24:13 - INFO - __main__ -   eval_recall = 0.2869\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 19:28:06 - WARNING - __main__ - epoch 4 step 816 loss 0.00976\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:30:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:30:12 - INFO - __main__ -   eval_f1 = 0.331\n",
      "05/04/2025 19:30:12 - INFO - __main__ -   eval_precision = 0.4797\n",
      "05/04/2025 19:30:12 - INFO - __main__ -   eval_recall = 0.2527\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/04/2025 19:34:04 - WARNING - __main__ - epoch 4 step 1020 loss 0.02142\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:36:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:36:11 - INFO - __main__ -   eval_f1 = 0.324\n",
      "05/04/2025 19:36:11 - INFO - __main__ -   eval_precision = 0.4321\n",
      "05/04/2025 19:36:11 - INFO - __main__ -   eval_recall = 0.2591\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 19:40:07 - WARNING - __main__ - epoch 5 step 204 loss 0.00356\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:42:13 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:42:13 - INFO - __main__ -   eval_f1 = 0.2976\n",
      "05/04/2025 19:42:13 - INFO - __main__ -   eval_precision = 0.362\n",
      "05/04/2025 19:42:13 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 40% 407/1024 [09:50<11:46,  1.14s/it]05/04/2025 19:46:06 - WARNING - __main__ - epoch 5 step 408 loss 0.00403\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:48:12 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:48:12 - INFO - __main__ -   eval_f1 = 0.2961\n",
      "05/04/2025 19:48:12 - INFO - __main__ -   eval_precision = 0.4257\n",
      "05/04/2025 19:48:12 - INFO - __main__ -   eval_recall = 0.227\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 19:52:05 - WARNING - __main__ - epoch 5 step 612 loss 0.00201\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 19:54:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 19:54:11 - INFO - __main__ -   eval_f1 = 0.2987\n",
      "05/04/2025 19:54:11 - INFO - __main__ -   eval_precision = 0.3653\n",
      "05/04/2025 19:54:11 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 19:58:03 - WARNING - __main__ - epoch 5 step 816 loss 0.00597\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:00:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:00:10 - INFO - __main__ -   eval_f1 = 0.262\n",
      "05/04/2025 20:00:10 - INFO - __main__ -   eval_precision = 0.4091\n",
      "05/04/2025 20:00:10 - INFO - __main__ -   eval_recall = 0.1927\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/04/2025 20:04:02 - WARNING - __main__ - epoch 5 step 1020 loss 0.00174\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:06:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:06:08 - INFO - __main__ -   eval_f1 = 0.3492\n",
      "05/04/2025 20:06:08 - INFO - __main__ -   eval_precision = 0.3827\n",
      "05/04/2025 20:06:08 - INFO - __main__ -   eval_recall = 0.3212\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 20:10:05 - WARNING - __main__ - epoch 6 step 204 loss 0.00173\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:12:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:12:11 - INFO - __main__ -   eval_f1 = 0.3472\n",
      "05/04/2025 20:12:11 - INFO - __main__ -   eval_precision = 0.3904\n",
      "05/04/2025 20:12:11 - INFO - __main__ -   eval_recall = 0.3126\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/04/2025 20:16:04 - WARNING - __main__ - epoch 6 step 408 loss 6e-05\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:18:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:18:10 - INFO - __main__ -   eval_f1 = 0.2979\n",
      "05/04/2025 20:18:10 - INFO - __main__ -   eval_precision = 0.393\n",
      "05/04/2025 20:18:10 - INFO - __main__ -   eval_recall = 0.2398\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 20:22:02 - WARNING - __main__ - epoch 6 step 612 loss 0.00527\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:24:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:24:09 - INFO - __main__ -   eval_f1 = 0.3268\n",
      "05/04/2025 20:24:09 - INFO - __main__ -   eval_precision = 0.3796\n",
      "05/04/2025 20:24:09 - INFO - __main__ -   eval_recall = 0.2869\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 20:28:01 - WARNING - __main__ - epoch 6 step 816 loss 0.00253\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:30:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:30:07 - INFO - __main__ -   eval_f1 = 0.2744\n",
      "05/04/2025 20:30:07 - INFO - __main__ -   eval_precision = 0.521\n",
      "05/04/2025 20:30:07 - INFO - __main__ -   eval_recall = 0.1863\n",
      "05/04/2025 20:30:07 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 80% 815/1024 [23:55<06:08,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RogxgsXFO118",
    "outputId": "587a9717-45e3-46ba-a90f-c6e81c4e8342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:30:15.511016: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 20:30:15.528462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746390615.549776   84350 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746390615.556329   84350 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 20:30:15.577661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  23\n",
      "05/04/2025 20:30:18 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:32:58 - INFO - __main__ - ***** Test results *****\n",
      "05/04/2025 20:32:58 - INFO - __main__ -   auc_score = 0.8681\n",
      "05/04/2025 20:32:58 - INFO - __main__ -   test_f1 = 0.3229\n",
      "05/04/2025 20:32:58 - INFO - __main__ -   test_precision = 0.4935\n",
      "05/04/2025 20:32:58 - INFO - __main__ -   test_recall = 0.24\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 32 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwF872UbBu_H"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uakfbfuyBsUR",
    "outputId": "5d364b82-cc89-4851-a426-29362d6263a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 20:40:19.150731: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 20:40:19.168518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746391219.190466   88249 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746391219.199105   88249 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-04 20:40:19.222228: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "05/04/2025 20:40:22 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14690 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:53<15:40,  1.15s/it]05/04/2025 20:46:16 - WARNING - __main__ - epoch 0 step 204 loss 0.31837\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:48:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:48:22 - INFO - __main__ -   eval_f1 = 0.0043\n",
      "05/04/2025 20:48:22 - INFO - __main__ -   eval_precision = 1.0\n",
      "05/04/2025 20:48:22 - INFO - __main__ -   eval_recall = 0.0021\n",
      " 40% 407/1024 [10:06<11:45,  1.14s/it]05/04/2025 20:52:29 - WARNING - __main__ - epoch 0 step 408 loss 0.25648\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 20:54:36 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 20:54:36 - INFO - __main__ -   eval_f1 = 0.0945\n",
      "05/04/2025 20:54:36 - INFO - __main__ -   eval_precision = 0.5854\n",
      "05/04/2025 20:54:36 - INFO - __main__ -   eval_recall = 0.0514\n",
      " 60% 611/1024 [16:16<07:52,  1.14s/it]05/04/2025 20:58:40 - WARNING - __main__ - epoch 0 step 612 loss 0.26686\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:00:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:00:46 - INFO - __main__ -   eval_f1 = 0.1948\n",
      "05/04/2025 21:00:46 - INFO - __main__ -   eval_precision = 0.7761\n",
      "05/04/2025 21:00:46 - INFO - __main__ -   eval_recall = 0.1113\n",
      " 80% 815/1024 [22:28<03:59,  1.14s/it]05/04/2025 21:04:52 - WARNING - __main__ - epoch 0 step 816 loss 0.23184\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:06:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:06:58 - INFO - __main__ -   eval_f1 = 0.3032\n",
      "05/04/2025 21:06:58 - INFO - __main__ -   eval_precision = 0.7417\n",
      "05/04/2025 21:06:58 - INFO - __main__ -   eval_recall = 0.1906\n",
      "100% 1019/1024 [28:40<00:05,  1.14s/it]05/04/2025 21:11:04 - WARNING - __main__ - epoch 0 step 1020 loss 0.20629\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:13:10 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:13:10 - INFO - __main__ -   eval_f1 = 0.3713\n",
      "05/04/2025 21:13:10 - INFO - __main__ -   eval_precision = 0.6839\n",
      "05/04/2025 21:13:10 - INFO - __main__ -   eval_recall = 0.2548\n",
      "100% 1024/1024 [31:06<00:00,  1.82s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:40,  1.15s/it]05/04/2025 21:17:22 - WARNING - __main__ - epoch 1 step 204 loss 0.22184\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:19:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:19:28 - INFO - __main__ -   eval_f1 = 0.3927\n",
      "05/04/2025 21:19:28 - INFO - __main__ -   eval_precision = 0.6667\n",
      "05/04/2025 21:19:28 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 40% 407/1024 [10:02<11:45,  1.14s/it]05/04/2025 21:23:32 - WARNING - __main__ - epoch 1 step 408 loss 0.18726\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:25:39 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:25:39 - INFO - __main__ -   eval_f1 = 0.4994\n",
      "05/04/2025 21:25:39 - INFO - __main__ -   eval_precision = 0.5582\n",
      "05/04/2025 21:25:39 - INFO - __main__ -   eval_recall = 0.4518\n",
      " 60% 611/1024 [16:14<07:52,  1.14s/it]05/04/2025 21:29:45 - WARNING - __main__ - epoch 1 step 612 loss 0.18543\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:31:51 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:31:51 - INFO - __main__ -   eval_f1 = 0.4937\n",
      "05/04/2025 21:31:51 - INFO - __main__ -   eval_precision = 0.5267\n",
      "05/04/2025 21:31:51 - INFO - __main__ -   eval_recall = 0.4647\n",
      " 80% 815/1024 [22:13<03:59,  1.14s/it]05/04/2025 21:35:43 - WARNING - __main__ - epoch 1 step 816 loss 0.20663\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:37:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:37:50 - INFO - __main__ -   eval_f1 = 0.4611\n",
      "05/04/2025 21:37:50 - INFO - __main__ -   eval_precision = 0.7336\n",
      "05/04/2025 21:37:50 - INFO - __main__ -   eval_recall = 0.3362\n",
      "100% 1019/1024 [28:12<00:05,  1.14s/it]05/04/2025 21:41:42 - WARNING - __main__ - epoch 1 step 1020 loss 0.1818\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:43:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:43:48 - INFO - __main__ -   eval_f1 = 0.4987\n",
      "05/04/2025 21:43:48 - INFO - __main__ -   eval_precision = 0.6388\n",
      "05/04/2025 21:43:48 - INFO - __main__ -   eval_recall = 0.409\n",
      "100% 1024/1024 [30:23<00:00,  1.78s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 21:47:45 - WARNING - __main__ - epoch 2 step 204 loss 0.14709\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:49:51 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:49:51 - INFO - __main__ -   eval_f1 = 0.4493\n",
      "05/04/2025 21:49:51 - INFO - __main__ -   eval_precision = 0.6951\n",
      "05/04/2025 21:49:51 - INFO - __main__ -   eval_recall = 0.3319\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/04/2025 21:53:44 - WARNING - __main__ - epoch 2 step 408 loss 0.13131\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 21:55:50 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 21:55:50 - INFO - __main__ -   eval_f1 = 0.4175\n",
      "05/04/2025 21:55:50 - INFO - __main__ -   eval_precision = 0.5752\n",
      "05/04/2025 21:55:50 - INFO - __main__ -   eval_recall = 0.3276\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 21:59:43 - WARNING - __main__ - epoch 2 step 612 loss 0.14079\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:01:49 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:01:49 - INFO - __main__ -   eval_f1 = 0.2609\n",
      "05/04/2025 22:01:49 - INFO - __main__ -   eval_precision = 0.8471\n",
      "05/04/2025 22:01:49 - INFO - __main__ -   eval_recall = 0.1542\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 22:05:41 - WARNING - __main__ - epoch 2 step 816 loss 0.14778\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:07:48 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:07:48 - INFO - __main__ -   eval_f1 = 0.4833\n",
      "05/04/2025 22:07:48 - INFO - __main__ -   eval_precision = 0.6045\n",
      "05/04/2025 22:07:48 - INFO - __main__ -   eval_recall = 0.4026\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/04/2025 22:11:40 - WARNING - __main__ - epoch 2 step 1020 loss 0.13158\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:13:47 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:13:47 - INFO - __main__ -   eval_f1 = 0.5183\n",
      "05/04/2025 22:13:47 - INFO - __main__ -   eval_precision = 0.5794\n",
      "05/04/2025 22:13:47 - INFO - __main__ -   eval_recall = 0.469\n",
      "100% 1024/1024 [30:11<00:00,  1.77s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]05/04/2025 22:17:56 - WARNING - __main__ - epoch 3 step 204 loss 0.05837\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:20:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:20:03 - INFO - __main__ -   eval_f1 = 0.3155\n",
      "05/04/2025 22:20:03 - INFO - __main__ -   eval_precision = 0.5538\n",
      "05/04/2025 22:20:03 - INFO - __main__ -   eval_recall = 0.2206\n",
      " 40% 407/1024 [09:51<11:46,  1.14s/it]05/04/2025 22:23:55 - WARNING - __main__ - epoch 3 step 408 loss 0.0734\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:26:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:26:02 - INFO - __main__ -   eval_f1 = 0.335\n",
      "05/04/2025 22:26:02 - INFO - __main__ -   eval_precision = 0.4112\n",
      "05/04/2025 22:26:02 - INFO - __main__ -   eval_recall = 0.2827\n",
      " 60% 611/1024 [15:50<07:52,  1.14s/it]05/04/2025 22:29:54 - WARNING - __main__ - epoch 3 step 612 loss 0.07136\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:32:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:32:01 - INFO - __main__ -   eval_f1 = 0.3879\n",
      "05/04/2025 22:32:01 - INFO - __main__ -   eval_precision = 0.5\n",
      "05/04/2025 22:32:01 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 80% 815/1024 [21:49<03:59,  1.14s/it]05/04/2025 22:35:53 - WARNING - __main__ - epoch 3 step 816 loss 0.07719\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:38:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:38:00 - INFO - __main__ -   eval_f1 = 0.3643\n",
      "05/04/2025 22:38:00 - INFO - __main__ -   eval_precision = 0.4324\n",
      "05/04/2025 22:38:00 - INFO - __main__ -   eval_recall = 0.3148\n",
      "100% 1019/1024 [27:48<00:05,  1.14s/it]05/04/2025 22:41:52 - WARNING - __main__ - epoch 3 step 1020 loss 0.0625\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:43:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:43:59 - INFO - __main__ -   eval_f1 = 0.3996\n",
      "05/04/2025 22:43:59 - INFO - __main__ -   eval_precision = 0.3987\n",
      "05/04/2025 22:43:59 - INFO - __main__ -   eval_recall = 0.4004\n",
      "100% 1024/1024 [29:59<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]05/04/2025 22:47:55 - WARNING - __main__ - epoch 4 step 204 loss 0.01991\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:50:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:50:02 - INFO - __main__ -   eval_f1 = 0.2219\n",
      "05/04/2025 22:50:02 - INFO - __main__ -   eval_precision = 0.4452\n",
      "05/04/2025 22:50:02 - INFO - __main__ -   eval_recall = 0.1478\n",
      " 40% 407/1024 [09:51<11:46,  1.14s/it]05/04/2025 22:53:55 - WARNING - __main__ - epoch 4 step 408 loss 0.02651\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 22:56:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 22:56:01 - INFO - __main__ -   eval_f1 = 0.2941\n",
      "05/04/2025 22:56:01 - INFO - __main__ -   eval_precision = 0.5307\n",
      "05/04/2025 22:56:01 - INFO - __main__ -   eval_recall = 0.2034\n",
      " 60% 611/1024 [15:50<07:52,  1.14s/it]05/04/2025 22:59:54 - WARNING - __main__ - epoch 4 step 612 loss 0.01722\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:02:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:02:00 - INFO - __main__ -   eval_f1 = 0.2667\n",
      "05/04/2025 23:02:00 - INFO - __main__ -   eval_precision = 0.395\n",
      "05/04/2025 23:02:00 - INFO - __main__ -   eval_recall = 0.2013\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 23:05:52 - WARNING - __main__ - epoch 4 step 816 loss 0.02739\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:07:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:07:59 - INFO - __main__ -   eval_f1 = 0.2721\n",
      "05/04/2025 23:07:59 - INFO - __main__ -   eval_precision = 0.3943\n",
      "05/04/2025 23:07:59 - INFO - __main__ -   eval_recall = 0.2077\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/04/2025 23:11:51 - WARNING - __main__ - epoch 4 step 1020 loss 0.01659\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:13:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:13:57 - INFO - __main__ -   eval_f1 = 0.2588\n",
      "05/04/2025 23:13:57 - INFO - __main__ -   eval_precision = 0.4131\n",
      "05/04/2025 23:13:57 - INFO - __main__ -   eval_recall = 0.1884\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/04/2025 23:17:54 - WARNING - __main__ - epoch 5 step 204 loss 0.00878\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:20:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:20:00 - INFO - __main__ -   eval_f1 = 0.2542\n",
      "05/04/2025 23:20:00 - INFO - __main__ -   eval_precision = 0.3734\n",
      "05/04/2025 23:20:00 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 40% 407/1024 [09:50<11:46,  1.14s/it]05/04/2025 23:23:53 - WARNING - __main__ - epoch 5 step 408 loss 0.00283\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:25:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:25:59 - INFO - __main__ -   eval_f1 = 0.2627\n",
      "05/04/2025 23:25:59 - INFO - __main__ -   eval_precision = 0.3636\n",
      "05/04/2025 23:25:59 - INFO - __main__ -   eval_recall = 0.2056\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/04/2025 23:29:52 - WARNING - __main__ - epoch 5 step 612 loss 0.00883\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:31:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:31:58 - INFO - __main__ -   eval_f1 = 0.3086\n",
      "05/04/2025 23:31:58 - INFO - __main__ -   eval_precision = 0.3567\n",
      "05/04/2025 23:31:58 - INFO - __main__ -   eval_recall = 0.2719\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/04/2025 23:35:51 - WARNING - __main__ - epoch 5 step 816 loss 0.00731\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:37:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:37:57 - INFO - __main__ -   eval_f1 = 0.2622\n",
      "05/04/2025 23:37:57 - INFO - __main__ -   eval_precision = 0.4198\n",
      "05/04/2025 23:37:57 - INFO - __main__ -   eval_recall = 0.1906\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/04/2025 23:41:50 - WARNING - __main__ - epoch 5 step 1020 loss 0.00768\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:43:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:43:56 - INFO - __main__ -   eval_f1 = 0.3012\n",
      "05/04/2025 23:43:56 - INFO - __main__ -   eval_precision = 0.4111\n",
      "05/04/2025 23:43:56 - INFO - __main__ -   eval_recall = 0.2377\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:39,  1.14s/it]05/04/2025 23:47:53 - WARNING - __main__ - epoch 6 step 204 loss 0.00056\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:49:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:49:59 - INFO - __main__ -   eval_f1 = 0.2781\n",
      "05/04/2025 23:49:59 - INFO - __main__ -   eval_precision = 0.3701\n",
      "05/04/2025 23:49:59 - INFO - __main__ -   eval_recall = 0.2227\n",
      " 40% 407/1024 [09:51<11:46,  1.14s/it]05/04/2025 23:53:52 - WARNING - __main__ - epoch 6 step 408 loss 0.00424\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/04/2025 23:55:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/04/2025 23:55:58 - INFO - __main__ -   eval_f1 = 0.2482\n",
      "05/04/2025 23:55:58 - INFO - __main__ -   eval_precision = 0.3718\n",
      "05/04/2025 23:55:58 - INFO - __main__ -   eval_recall = 0.1863\n",
      " 60% 611/1024 [15:50<07:52,  1.14s/it]05/04/2025 23:59:51 - WARNING - __main__ - epoch 6 step 612 loss 0.0013\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:01:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:01:57 - INFO - __main__ -   eval_f1 = 0.2418\n",
      "05/05/2025 00:01:57 - INFO - __main__ -   eval_precision = 0.399\n",
      "05/05/2025 00:01:57 - INFO - __main__ -   eval_recall = 0.1734\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 00:05:50 - WARNING - __main__ - epoch 6 step 816 loss 0.00247\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:07:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:07:56 - INFO - __main__ -   eval_f1 = 0.3038\n",
      "05/05/2025 00:07:56 - INFO - __main__ -   eval_precision = 0.3442\n",
      "05/05/2025 00:07:56 - INFO - __main__ -   eval_recall = 0.2719\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 00:11:49 - WARNING - __main__ - epoch 6 step 1020 loss 0.0087\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:13:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:13:55 - INFO - __main__ -   eval_f1 = 0.2705\n",
      "05/05/2025 00:13:55 - INFO - __main__ -   eval_precision = 0.3736\n",
      "05/05/2025 00:13:55 - INFO - __main__ -   eval_recall = 0.212\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 00:17:52 - WARNING - __main__ - epoch 7 step 204 loss 0.00011\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:19:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:19:58 - INFO - __main__ -   eval_f1 = 0.2472\n",
      "05/05/2025 00:19:58 - INFO - __main__ -   eval_precision = 0.3671\n",
      "05/05/2025 00:19:58 - INFO - __main__ -   eval_recall = 0.1863\n",
      " 40% 407/1024 [09:50<11:46,  1.14s/it]05/05/2025 00:23:51 - WARNING - __main__ - epoch 7 step 408 loss 0.00353\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:25:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:25:57 - INFO - __main__ -   eval_f1 = 0.2667\n",
      "05/05/2025 00:25:57 - INFO - __main__ -   eval_precision = 0.3794\n",
      "05/05/2025 00:25:57 - INFO - __main__ -   eval_recall = 0.2056\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 00:29:49 - WARNING - __main__ - epoch 7 step 612 loss 0.00162\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:31:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:31:56 - INFO - __main__ -   eval_f1 = 0.2379\n",
      "05/05/2025 00:31:56 - INFO - __main__ -   eval_precision = 0.3785\n",
      "05/05/2025 00:31:56 - INFO - __main__ -   eval_recall = 0.1734\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 00:35:48 - WARNING - __main__ - epoch 7 step 816 loss 0.00438\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:37:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:37:55 - INFO - __main__ -   eval_f1 = 0.265\n",
      "05/05/2025 00:37:55 - INFO - __main__ -   eval_precision = 0.38\n",
      "05/05/2025 00:37:55 - INFO - __main__ -   eval_recall = 0.2034\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 00:41:47 - WARNING - __main__ - epoch 7 step 1020 loss 0.00017\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:43:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:43:54 - INFO - __main__ -   eval_f1 = 0.1988\n",
      "05/05/2025 00:43:54 - INFO - __main__ -   eval_precision = 0.3616\n",
      "05/05/2025 00:43:54 - INFO - __main__ -   eval_recall = 0.137\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 00:47:50 - WARNING - __main__ - epoch 8 step 204 loss 0.00042\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 00:49:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 00:49:57 - INFO - __main__ -   eval_f1 = 0.2659\n",
      "05/05/2025 00:49:57 - INFO - __main__ -   eval_precision = 0.3917\n",
      "05/05/2025 00:49:57 - INFO - __main__ -   eval_recall = 0.2013\n",
      "05/05/2025 00:49:57 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 20% 203/1024 [05:59<24:12,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilNlEiwuRheB",
    "outputId": "2cba072d-9afa-414d-8b93-168a2c47f372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 01:14:24.876483: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-05 01:14:24.894350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746407664.915970  189335 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746407664.922537  189335 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 01:14:24.944349: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  99\n",
      "05/05/2025 01:14:28 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 01:17:11 - INFO - __main__ - ***** Test results *****\n",
      "05/05/2025 01:17:11 - INFO - __main__ -   auc_score = 0.8669\n",
      "05/05/2025 01:17:11 - INFO - __main__ -   test_f1 = 0.3976\n",
      "05/05/2025 01:17:11 - INFO - __main__ -   test_precision = 0.4725\n",
      "05/05/2025 01:17:11 - INFO - __main__ -   test_recall = 0.3432\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xLgh8lzCZGt"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgQlAUakCVnQ",
    "outputId": "f19d1051-4c0d-46c7-dde1-513247fe8aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 01:22:48.103191: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-05 01:22:48.121216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746408168.143088  192575 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746408168.149804  192575 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 01:22:48.171682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "05/05/2025 01:22:51 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14687 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:40,  1.15s/it]05/05/2025 01:28:49 - WARNING - __main__ - epoch 0 step 204 loss 0.27657\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "05/05/2025 01:30:55 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 01:30:55 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/05/2025 01:30:55 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/05/2025 01:30:55 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 407/1024 [09:52<11:46,  1.15s/it]05/05/2025 01:34:48 - WARNING - __main__ - epoch 0 step 408 loss 0.28666\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 01:36:54 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 01:36:54 - INFO - __main__ -   eval_f1 = 0.2107\n",
      "05/05/2025 01:36:54 - INFO - __main__ -   eval_precision = 0.5446\n",
      "05/05/2025 01:36:54 - INFO - __main__ -   eval_recall = 0.1306\n",
      " 60% 611/1024 [16:05<07:52,  1.15s/it]05/05/2025 01:41:02 - WARNING - __main__ - epoch 0 step 612 loss 0.25019\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 01:43:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 01:43:08 - INFO - __main__ -   eval_f1 = 0.2384\n",
      "05/05/2025 01:43:08 - INFO - __main__ -   eval_precision = 0.7053\n",
      "05/05/2025 01:43:08 - INFO - __main__ -   eval_recall = 0.1435\n",
      " 80% 815/1024 [22:17<03:59,  1.14s/it]05/05/2025 01:47:14 - WARNING - __main__ - epoch 0 step 816 loss 0.22362\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 01:49:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 01:49:20 - INFO - __main__ -   eval_f1 = 0.2646\n",
      "05/05/2025 01:49:20 - INFO - __main__ -   eval_precision = 0.75\n",
      "05/05/2025 01:49:20 - INFO - __main__ -   eval_recall = 0.1606\n",
      "100% 1019/1024 [28:28<00:05,  1.14s/it]05/05/2025 01:53:25 - WARNING - __main__ - epoch 0 step 1020 loss 0.21066\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 01:55:31 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 01:55:31 - INFO - __main__ -   eval_f1 = 0.2549\n",
      "05/05/2025 01:55:31 - INFO - __main__ -   eval_precision = 0.7889\n",
      "05/05/2025 01:55:31 - INFO - __main__ -   eval_recall = 0.152\n",
      "100% 1024/1024 [30:39<00:00,  1.80s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:40,  1.15s/it]05/05/2025 01:59:28 - WARNING - __main__ - epoch 1 step 204 loss 0.19243\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:01:35 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:01:35 - INFO - __main__ -   eval_f1 = 0.4529\n",
      "05/05/2025 02:01:35 - INFO - __main__ -   eval_precision = 0.723\n",
      "05/05/2025 02:01:35 - INFO - __main__ -   eval_recall = 0.3298\n",
      " 40% 407/1024 [10:03<11:45,  1.14s/it]05/05/2025 02:05:39 - WARNING - __main__ - epoch 1 step 408 loss 0.17662\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:07:46 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:07:46 - INFO - __main__ -   eval_f1 = 0.2349\n",
      "05/05/2025 02:07:46 - INFO - __main__ -   eval_precision = 0.8205\n",
      "05/05/2025 02:07:46 - INFO - __main__ -   eval_recall = 0.137\n",
      " 60% 611/1024 [16:02<07:52,  1.14s/it]05/05/2025 02:11:38 - WARNING - __main__ - epoch 1 step 612 loss 0.18494\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:13:45 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:13:45 - INFO - __main__ -   eval_f1 = 0.4767\n",
      "05/05/2025 02:13:45 - INFO - __main__ -   eval_precision = 0.6983\n",
      "05/05/2025 02:13:45 - INFO - __main__ -   eval_recall = 0.3619\n",
      " 80% 815/1024 [22:13<03:59,  1.14s/it]05/05/2025 02:17:50 - WARNING - __main__ - epoch 1 step 816 loss 0.17265\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:19:56 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:19:56 - INFO - __main__ -   eval_f1 = 0.5047\n",
      "05/05/2025 02:19:56 - INFO - __main__ -   eval_precision = 0.6889\n",
      "05/05/2025 02:19:56 - INFO - __main__ -   eval_recall = 0.3983\n",
      "100% 1019/1024 [28:25<00:05,  1.14s/it]05/05/2025 02:24:01 - WARNING - __main__ - epoch 1 step 1020 loss 0.18212\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:26:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:26:08 - INFO - __main__ -   eval_f1 = 0.349\n",
      "05/05/2025 02:26:08 - INFO - __main__ -   eval_precision = 0.8062\n",
      "05/05/2025 02:26:08 - INFO - __main__ -   eval_recall = 0.2227\n",
      "100% 1024/1024 [30:36<00:00,  1.79s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 02:30:04 - WARNING - __main__ - epoch 2 step 204 loss 0.1105\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:32:11 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:32:11 - INFO - __main__ -   eval_f1 = 0.378\n",
      "05/05/2025 02:32:11 - INFO - __main__ -   eval_precision = 0.4548\n",
      "05/05/2025 02:32:11 - INFO - __main__ -   eval_recall = 0.3233\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 02:36:03 - WARNING - __main__ - epoch 2 step 408 loss 0.12037\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:38:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:38:09 - INFO - __main__ -   eval_f1 = 0.3661\n",
      "05/05/2025 02:38:09 - INFO - __main__ -   eval_precision = 0.6237\n",
      "05/05/2025 02:38:09 - INFO - __main__ -   eval_recall = 0.2591\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 02:42:02 - WARNING - __main__ - epoch 2 step 612 loss 0.13142\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:44:08 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:44:08 - INFO - __main__ -   eval_f1 = 0.4041\n",
      "05/05/2025 02:44:08 - INFO - __main__ -   eval_precision = 0.6389\n",
      "05/05/2025 02:44:08 - INFO - __main__ -   eval_recall = 0.2955\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 02:48:01 - WARNING - __main__ - epoch 2 step 816 loss 0.11904\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:50:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:50:07 - INFO - __main__ -   eval_f1 = 0.3082\n",
      "05/05/2025 02:50:07 - INFO - __main__ -   eval_precision = 0.7077\n",
      "05/05/2025 02:50:07 - INFO - __main__ -   eval_recall = 0.197\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 02:54:00 - WARNING - __main__ - epoch 2 step 1020 loss 0.12103\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 02:56:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 02:56:06 - INFO - __main__ -   eval_f1 = 0.429\n",
      "05/05/2025 02:56:06 - INFO - __main__ -   eval_precision = 0.6135\n",
      "05/05/2025 02:56:06 - INFO - __main__ -   eval_recall = 0.3298\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 03:00:02 - WARNING - __main__ - epoch 3 step 204 loss 0.05524\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:02:09 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:02:09 - INFO - __main__ -   eval_f1 = 0.3836\n",
      "05/05/2025 03:02:09 - INFO - __main__ -   eval_precision = 0.4762\n",
      "05/05/2025 03:02:09 - INFO - __main__ -   eval_recall = 0.3212\n",
      " 40% 407/1024 [09:50<11:46,  1.14s/it]05/05/2025 03:06:01 - WARNING - __main__ - epoch 3 step 408 loss 0.03738\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:08:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:08:07 - INFO - __main__ -   eval_f1 = 0.3343\n",
      "05/05/2025 03:08:07 - INFO - __main__ -   eval_precision = 0.4781\n",
      "05/05/2025 03:08:07 - INFO - __main__ -   eval_recall = 0.257\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 03:12:00 - WARNING - __main__ - epoch 3 step 612 loss 0.06741\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:14:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:14:06 - INFO - __main__ -   eval_f1 = 0.3806\n",
      "05/05/2025 03:14:06 - INFO - __main__ -   eval_precision = 0.4385\n",
      "05/05/2025 03:14:06 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 03:17:59 - WARNING - __main__ - epoch 3 step 816 loss 0.0388\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:20:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:20:05 - INFO - __main__ -   eval_f1 = 0.3159\n",
      "05/05/2025 03:20:05 - INFO - __main__ -   eval_precision = 0.4628\n",
      "05/05/2025 03:20:05 - INFO - __main__ -   eval_recall = 0.2398\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 03:23:58 - WARNING - __main__ - epoch 3 step 1020 loss 0.05561\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:26:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:26:04 - INFO - __main__ -   eval_f1 = 0.3537\n",
      "05/05/2025 03:26:04 - INFO - __main__ -   eval_precision = 0.4851\n",
      "05/05/2025 03:26:04 - INFO - __main__ -   eval_recall = 0.2784\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 03:30:00 - WARNING - __main__ - epoch 4 step 204 loss 0.01095\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:32:07 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:32:07 - INFO - __main__ -   eval_f1 = 0.2949\n",
      "05/05/2025 03:32:07 - INFO - __main__ -   eval_precision = 0.3943\n",
      "05/05/2025 03:32:07 - INFO - __main__ -   eval_recall = 0.2355\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 03:35:59 - WARNING - __main__ - epoch 4 step 408 loss 0.01512\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:38:05 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:38:05 - INFO - __main__ -   eval_f1 = 0.37\n",
      "05/05/2025 03:38:05 - INFO - __main__ -   eval_precision = 0.4444\n",
      "05/05/2025 03:38:05 - INFO - __main__ -   eval_recall = 0.3169\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 03:41:58 - WARNING - __main__ - epoch 4 step 612 loss 0.01898\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:44:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:44:04 - INFO - __main__ -   eval_f1 = 0.3576\n",
      "05/05/2025 03:44:04 - INFO - __main__ -   eval_precision = 0.369\n",
      "05/05/2025 03:44:04 - INFO - __main__ -   eval_recall = 0.3469\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 03:47:57 - WARNING - __main__ - epoch 4 step 816 loss 0.01985\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:50:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:50:03 - INFO - __main__ -   eval_f1 = 0.3761\n",
      "05/05/2025 03:50:03 - INFO - __main__ -   eval_precision = 0.3967\n",
      "05/05/2025 03:50:03 - INFO - __main__ -   eval_recall = 0.3576\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/05/2025 03:53:55 - WARNING - __main__ - epoch 4 step 1020 loss 0.02855\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 03:56:01 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 03:56:01 - INFO - __main__ -   eval_f1 = 0.3158\n",
      "05/05/2025 03:56:01 - INFO - __main__ -   eval_precision = 0.4703\n",
      "05/05/2025 03:56:01 - INFO - __main__ -   eval_recall = 0.2377\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 03:59:58 - WARNING - __main__ - epoch 5 step 204 loss 0.00664\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:02:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:02:04 - INFO - __main__ -   eval_f1 = 0.3308\n",
      "05/05/2025 04:02:04 - INFO - __main__ -   eval_precision = 0.3947\n",
      "05/05/2025 04:02:04 - INFO - __main__ -   eval_recall = 0.2848\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 04:05:57 - WARNING - __main__ - epoch 5 step 408 loss 0.01018\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:08:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:08:03 - INFO - __main__ -   eval_f1 = 0.2691\n",
      "05/05/2025 04:08:03 - INFO - __main__ -   eval_precision = 0.4455\n",
      "05/05/2025 04:08:03 - INFO - __main__ -   eval_recall = 0.1927\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 04:11:55 - WARNING - __main__ - epoch 5 step 612 loss 0.00685\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:14:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:14:02 - INFO - __main__ -   eval_f1 = 0.3199\n",
      "05/05/2025 04:14:02 - INFO - __main__ -   eval_precision = 0.4296\n",
      "05/05/2025 04:14:02 - INFO - __main__ -   eval_recall = 0.2548\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 04:17:54 - WARNING - __main__ - epoch 5 step 816 loss 0.00321\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:20:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:20:00 - INFO - __main__ -   eval_f1 = 0.3167\n",
      "05/05/2025 04:20:00 - INFO - __main__ -   eval_precision = 0.3791\n",
      "05/05/2025 04:20:00 - INFO - __main__ -   eval_recall = 0.2719\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/05/2025 04:23:53 - WARNING - __main__ - epoch 5 step 1020 loss 0.00744\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:25:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:25:59 - INFO - __main__ -   eval_f1 = 0.3569\n",
      "05/05/2025 04:25:59 - INFO - __main__ -   eval_precision = 0.3628\n",
      "05/05/2025 04:25:59 - INFO - __main__ -   eval_recall = 0.3512\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:39,  1.14s/it]05/05/2025 04:29:56 - WARNING - __main__ - epoch 6 step 204 loss 0.01114\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:32:02 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:32:02 - INFO - __main__ -   eval_f1 = 0.3169\n",
      "05/05/2025 04:32:02 - INFO - __main__ -   eval_precision = 0.3882\n",
      "05/05/2025 04:32:02 - INFO - __main__ -   eval_recall = 0.2677\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 04:35:54 - WARNING - __main__ - epoch 6 step 408 loss 0.00099\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:38:00 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:38:00 - INFO - __main__ -   eval_f1 = 0.3096\n",
      "05/05/2025 04:38:00 - INFO - __main__ -   eval_precision = 0.4167\n",
      "05/05/2025 04:38:00 - INFO - __main__ -   eval_recall = 0.2463\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 04:41:53 - WARNING - __main__ - epoch 6 step 612 loss 0.00908\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:43:59 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:43:59 - INFO - __main__ -   eval_f1 = 0.305\n",
      "05/05/2025 04:43:59 - INFO - __main__ -   eval_precision = 0.4124\n",
      "05/05/2025 04:43:59 - INFO - __main__ -   eval_recall = 0.242\n",
      " 80% 815/1024 [21:48<03:59,  1.14s/it]05/05/2025 04:47:52 - WARNING - __main__ - epoch 6 step 816 loss 0.00065\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:49:58 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:49:58 - INFO - __main__ -   eval_f1 = 0.2975\n",
      "05/05/2025 04:49:58 - INFO - __main__ -   eval_precision = 0.417\n",
      "05/05/2025 04:49:58 - INFO - __main__ -   eval_recall = 0.2313\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/05/2025 04:53:50 - WARNING - __main__ - epoch 6 step 1020 loss 0.00283\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:55:57 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 04:55:57 - INFO - __main__ -   eval_f1 = 0.2095\n",
      "05/05/2025 04:55:57 - INFO - __main__ -   eval_precision = 0.4444\n",
      "05/05/2025 04:55:57 - INFO - __main__ -   eval_recall = 0.137\n",
      "05/05/2025 04:55:57 - INFO - __main__ - patience greater than 5, early stop!\n",
      "100% 1019/1024 [29:53<00:08,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwCPdBIXCdno",
    "outputId": "31604b61-4883-4c00-a0ba-337d059c6863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 04:56:05.957227: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-05 04:56:05.975069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746420965.996724  271088 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746420966.003399  271088 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 04:56:06.025263: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  72\n",
      "05/05/2025 04:56:09 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 04:58:52 - INFO - __main__ - ***** Test results *****\n",
      "05/05/2025 04:58:52 - INFO - __main__ -   auc_score = 0.8718\n",
      "05/05/2025 04:58:52 - INFO - __main__ -   test_f1 = 0.387\n",
      "05/05/2025 04:58:52 - INFO - __main__ -   test_precision = 0.5417\n",
      "05/05/2025 04:58:52 - INFO - __main__ -   test_recall = 0.3011\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Blwpc7eW0T4f"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrlJOjuD0X06",
    "outputId": "11614c4c-11ba-45f6-e0bb-47a44fe13e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:32:21.361283: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-05 14:32:21.378176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746455541.399390    3423 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746455541.405839    3423 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 14:32:21.427668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "tokenizer_config.json: 100% 20.8k/20.8k [00:00<00:00, 92.2MB/s]\n",
      "tokenizer.json: 100% 2.13M/2.13M [00:00<00:00, 27.5MB/s]\n",
      "special_tokens_map.json: 100% 694/694 [00:00<00:00, 4.40MB/s]\n",
      "05/05/2025 14:32:25 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "config.json: 100% 1.19k/1.19k [00:00<00:00, 8.31MB/s]\n",
      "model.safetensors: 100% 1.58G/1.58G [00:12<00:00, 129MB/s]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9827 > 8192). Running this sequence through the model will result in indexing errors\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:52<15:38,  1.14s/it]05/05/2025 14:38:36 - WARNING - __main__ - epoch 0 step 204 loss 0.28839\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "05/05/2025 14:40:42 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 14:40:42 - INFO - __main__ -   eval_f1 = 0.0\n",
      "05/05/2025 14:40:42 - INFO - __main__ -   eval_precision = 0.0\n",
      "05/05/2025 14:40:42 - INFO - __main__ -   eval_recall = 0.0\n",
      " 40% 407/1024 [09:51<11:44,  1.14s/it]05/05/2025 14:44:34 - WARNING - __main__ - epoch 0 step 408 loss 0.26919\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 14:46:40 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 14:46:40 - INFO - __main__ -   eval_f1 = 0.1524\n",
      "05/05/2025 14:46:40 - INFO - __main__ -   eval_precision = 0.5775\n",
      "05/05/2025 14:46:40 - INFO - __main__ -   eval_recall = 0.0878\n",
      " 60% 611/1024 [16:03<07:51,  1.14s/it]05/05/2025 14:50:46 - WARNING - __main__ - epoch 0 step 612 loss 0.26342\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 14:52:52 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 14:52:52 - INFO - __main__ -   eval_f1 = 0.4201\n",
      "05/05/2025 14:52:52 - INFO - __main__ -   eval_precision = 0.4499\n",
      "05/05/2025 14:52:52 - INFO - __main__ -   eval_recall = 0.394\n",
      " 80% 815/1024 [22:15<03:58,  1.14s/it]05/05/2025 14:56:58 - WARNING - __main__ - epoch 0 step 816 loss 0.20832\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 14:59:04 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 14:59:04 - INFO - __main__ -   eval_f1 = 0.3652\n",
      "05/05/2025 14:59:04 - INFO - __main__ -   eval_precision = 0.8385\n",
      "05/05/2025 14:59:04 - INFO - __main__ -   eval_recall = 0.2334\n",
      "100% 1019/1024 [28:13<00:05,  1.14s/it]05/05/2025 15:02:57 - WARNING - __main__ - epoch 0 step 1020 loss 0.20608\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:05:03 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:05:03 - INFO - __main__ -   eval_f1 = 0.3163\n",
      "05/05/2025 15:05:03 - INFO - __main__ -   eval_precision = 0.7686\n",
      "05/05/2025 15:05:03 - INFO - __main__ -   eval_recall = 0.1991\n",
      "100% 1024/1024 [30:24<00:00,  1.78s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 15:08:59 - WARNING - __main__ - epoch 1 step 204 loss 0.19042\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:11:06 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:11:06 - INFO - __main__ -   eval_f1 = 0.5176\n",
      "05/05/2025 15:11:06 - INFO - __main__ -   eval_precision = 0.7541\n",
      "05/05/2025 15:11:06 - INFO - __main__ -   eval_recall = 0.394\n",
      " 40% 407/1024 [10:03<11:45,  1.14s/it]05/05/2025 15:15:11 - WARNING - __main__ - epoch 1 step 408 loss 0.18315\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:17:17 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:17:17 - INFO - __main__ -   eval_f1 = 0.5319\n",
      "05/05/2025 15:17:17 - INFO - __main__ -   eval_precision = 0.5937\n",
      "05/05/2025 15:17:17 - INFO - __main__ -   eval_recall = 0.4818\n",
      " 60% 611/1024 [16:15<07:52,  1.14s/it]05/05/2025 15:21:23 - WARNING - __main__ - epoch 1 step 612 loss 0.17233\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:23:29 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:23:29 - INFO - __main__ -   eval_f1 = 0.4789\n",
      "05/05/2025 15:23:29 - INFO - __main__ -   eval_precision = 0.5299\n",
      "05/05/2025 15:23:29 - INFO - __main__ -   eval_recall = 0.4368\n",
      " 80% 815/1024 [22:13<03:58,  1.14s/it]05/05/2025 15:27:22 - WARNING - __main__ - epoch 1 step 816 loss 0.17773\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:29:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:29:28 - INFO - __main__ -   eval_f1 = 0.4006\n",
      "05/05/2025 15:29:28 - INFO - __main__ -   eval_precision = 0.6034\n",
      "05/05/2025 15:29:28 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 1019/1024 [28:12<00:05,  1.14s/it]05/05/2025 15:33:20 - WARNING - __main__ - epoch 1 step 1020 loss 0.18075\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:35:27 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:35:27 - INFO - __main__ -   eval_f1 = 0.2724\n",
      "05/05/2025 15:35:27 - INFO - __main__ -   eval_precision = 0.6991\n",
      "05/05/2025 15:35:27 - INFO - __main__ -   eval_recall = 0.1692\n",
      "100% 1024/1024 [30:23<00:00,  1.78s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 15:39:23 - WARNING - __main__ - epoch 2 step 204 loss 0.12345\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:41:29 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:41:29 - INFO - __main__ -   eval_f1 = 0.4819\n",
      "05/05/2025 15:41:29 - INFO - __main__ -   eval_precision = 0.4798\n",
      "05/05/2025 15:41:29 - INFO - __main__ -   eval_recall = 0.4839\n",
      " 40% 407/1024 [09:50<11:44,  1.14s/it]05/05/2025 15:45:21 - WARNING - __main__ - epoch 2 step 408 loss 0.11215\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:47:28 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:47:28 - INFO - __main__ -   eval_f1 = 0.41\n",
      "05/05/2025 15:47:28 - INFO - __main__ -   eval_precision = 0.4351\n",
      "05/05/2025 15:47:28 - INFO - __main__ -   eval_recall = 0.3876\n",
      " 60% 611/1024 [15:48<07:51,  1.14s/it]05/05/2025 15:51:20 - WARNING - __main__ - epoch 2 step 612 loss 0.11734\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:53:26 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:53:26 - INFO - __main__ -   eval_f1 = 0.471\n",
      "05/05/2025 15:53:26 - INFO - __main__ -   eval_precision = 0.5903\n",
      "05/05/2025 15:53:26 - INFO - __main__ -   eval_recall = 0.3919\n",
      " 80% 815/1024 [21:47<03:58,  1.14s/it]05/05/2025 15:57:19 - WARNING - __main__ - epoch 2 step 816 loss 0.11753\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 15:59:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 15:59:25 - INFO - __main__ -   eval_f1 = 0.2701\n",
      "05/05/2025 15:59:25 - INFO - __main__ -   eval_precision = 0.6695\n",
      "05/05/2025 15:59:25 - INFO - __main__ -   eval_recall = 0.1692\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/05/2025 16:03:18 - WARNING - __main__ - epoch 2 step 1020 loss 0.10259\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:05:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:05:24 - INFO - __main__ -   eval_f1 = 0.4342\n",
      "05/05/2025 16:05:24 - INFO - __main__ -   eval_precision = 0.4867\n",
      "05/05/2025 16:05:24 - INFO - __main__ -   eval_recall = 0.3919\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 16:09:20 - WARNING - __main__ - epoch 3 step 204 loss 0.04949\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:11:27 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:11:27 - INFO - __main__ -   eval_f1 = 0.3783\n",
      "05/05/2025 16:11:27 - INFO - __main__ -   eval_precision = 0.3913\n",
      "05/05/2025 16:11:27 - INFO - __main__ -   eval_recall = 0.3662\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 16:15:19 - WARNING - __main__ - epoch 3 step 408 loss 0.03964\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:17:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:17:25 - INFO - __main__ -   eval_f1 = 0.3228\n",
      "05/05/2025 16:17:25 - INFO - __main__ -   eval_precision = 0.447\n",
      "05/05/2025 16:17:25 - INFO - __main__ -   eval_recall = 0.2527\n",
      " 60% 611/1024 [15:49<07:51,  1.14s/it]05/05/2025 16:21:18 - WARNING - __main__ - epoch 3 step 612 loss 0.04652\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:23:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:23:24 - INFO - __main__ -   eval_f1 = 0.4014\n",
      "05/05/2025 16:23:24 - INFO - __main__ -   eval_precision = 0.4575\n",
      "05/05/2025 16:23:24 - INFO - __main__ -   eval_recall = 0.3576\n",
      " 80% 815/1024 [21:48<03:58,  1.14s/it]05/05/2025 16:27:17 - WARNING - __main__ - epoch 3 step 816 loss 0.04203\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:29:23 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:29:23 - INFO - __main__ -   eval_f1 = 0.4371\n",
      "05/05/2025 16:29:23 - INFO - __main__ -   eval_precision = 0.4215\n",
      "05/05/2025 16:29:23 - INFO - __main__ -   eval_recall = 0.454\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 16:33:16 - WARNING - __main__ - epoch 3 step 1020 loss 0.04478\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:35:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:35:22 - INFO - __main__ -   eval_f1 = 0.3465\n",
      "05/05/2025 16:35:22 - INFO - __main__ -   eval_precision = 0.4106\n",
      "05/05/2025 16:35:22 - INFO - __main__ -   eval_recall = 0.2998\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 16:39:19 - WARNING - __main__ - epoch 4 step 204 loss 0.01171\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:41:25 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:41:25 - INFO - __main__ -   eval_f1 = 0.3213\n",
      "05/05/2025 16:41:25 - INFO - __main__ -   eval_precision = 0.4286\n",
      "05/05/2025 16:41:25 - INFO - __main__ -   eval_recall = 0.257\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 16:45:18 - WARNING - __main__ - epoch 4 step 408 loss 0.0051\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:47:24 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:47:24 - INFO - __main__ -   eval_f1 = 0.3652\n",
      "05/05/2025 16:47:24 - INFO - __main__ -   eval_precision = 0.3357\n",
      "05/05/2025 16:47:24 - INFO - __main__ -   eval_recall = 0.4004\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 16:51:17 - WARNING - __main__ - epoch 4 step 612 loss 0.01229\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:53:23 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:53:23 - INFO - __main__ -   eval_f1 = 0.3226\n",
      "05/05/2025 16:53:23 - INFO - __main__ -   eval_precision = 0.3835\n",
      "05/05/2025 16:53:23 - INFO - __main__ -   eval_recall = 0.2784\n",
      " 80% 815/1024 [21:48<03:58,  1.14s/it]05/05/2025 16:57:15 - WARNING - __main__ - epoch 4 step 816 loss 0.01254\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 16:59:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 16:59:22 - INFO - __main__ -   eval_f1 = 0.3367\n",
      "05/05/2025 16:59:22 - INFO - __main__ -   eval_precision = 0.3486\n",
      "05/05/2025 16:59:22 - INFO - __main__ -   eval_recall = 0.3255\n",
      "100% 1019/1024 [27:47<00:05,  1.14s/it]05/05/2025 17:03:14 - WARNING - __main__ - epoch 4 step 1020 loss 0.01741\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:05:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:05:21 - INFO - __main__ -   eval_f1 = 0.3645\n",
      "05/05/2025 17:05:21 - INFO - __main__ -   eval_precision = 0.395\n",
      "05/05/2025 17:05:21 - INFO - __main__ -   eval_recall = 0.3383\n",
      "100% 1024/1024 [29:58<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 17:09:17 - WARNING - __main__ - epoch 5 step 204 loss 0.00141\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:11:23 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:11:23 - INFO - __main__ -   eval_f1 = 0.3168\n",
      "05/05/2025 17:11:23 - INFO - __main__ -   eval_precision = 0.3442\n",
      "05/05/2025 17:11:23 - INFO - __main__ -   eval_recall = 0.2934\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 17:15:15 - WARNING - __main__ - epoch 5 step 408 loss 0.00227\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:17:22 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:17:22 - INFO - __main__ -   eval_f1 = 0.3386\n",
      "05/05/2025 17:17:22 - INFO - __main__ -   eval_precision = 0.358\n",
      "05/05/2025 17:17:22 - INFO - __main__ -   eval_recall = 0.3212\n",
      " 60% 611/1024 [15:49<07:51,  1.14s/it]05/05/2025 17:21:14 - WARNING - __main__ - epoch 5 step 612 loss 0.00296\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:23:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:23:21 - INFO - __main__ -   eval_f1 = 0.2899\n",
      "05/05/2025 17:23:21 - INFO - __main__ -   eval_precision = 0.3825\n",
      "05/05/2025 17:23:21 - INFO - __main__ -   eval_recall = 0.2334\n",
      " 80% 815/1024 [21:47<03:58,  1.14s/it]05/05/2025 17:27:13 - WARNING - __main__ - epoch 5 step 816 loss 0.00297\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:29:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:29:19 - INFO - __main__ -   eval_f1 = 0.3004\n",
      "05/05/2025 17:29:19 - INFO - __main__ -   eval_precision = 0.375\n",
      "05/05/2025 17:29:19 - INFO - __main__ -   eval_recall = 0.2505\n",
      "100% 1019/1024 [27:46<00:05,  1.14s/it]05/05/2025 17:33:12 - WARNING - __main__ - epoch 5 step 1020 loss 0.00593\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:35:18 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:35:18 - INFO - __main__ -   eval_f1 = 0.3077\n",
      "05/05/2025 17:35:18 - INFO - __main__ -   eval_precision = 0.358\n",
      "05/05/2025 17:35:18 - INFO - __main__ -   eval_recall = 0.2698\n",
      "100% 1024/1024 [29:57<00:00,  1.76s/it]\n",
      "  0% 0/1024 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 20% 203/1024 [03:51<15:38,  1.14s/it]05/05/2025 17:39:14 - WARNING - __main__ - epoch 6 step 204 loss 0.00279\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:41:21 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:41:21 - INFO - __main__ -   eval_f1 = 0.3351\n",
      "05/05/2025 17:41:21 - INFO - __main__ -   eval_precision = 0.334\n",
      "05/05/2025 17:41:21 - INFO - __main__ -   eval_recall = 0.3362\n",
      " 40% 407/1024 [09:50<11:45,  1.14s/it]05/05/2025 17:45:14 - WARNING - __main__ - epoch 6 step 408 loss 0.00448\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:47:20 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:47:20 - INFO - __main__ -   eval_f1 = 0.3307\n",
      "05/05/2025 17:47:20 - INFO - __main__ -   eval_precision = 0.3564\n",
      "05/05/2025 17:47:20 - INFO - __main__ -   eval_recall = 0.3084\n",
      " 60% 611/1024 [15:49<07:52,  1.14s/it]05/05/2025 17:51:13 - WARNING - __main__ - epoch 6 step 612 loss 4e-05\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:53:19 - INFO - __main__ - ***** Eval results *****\n",
      "05/05/2025 17:53:19 - INFO - __main__ -   eval_f1 = 0.3148\n",
      "05/05/2025 17:53:19 - INFO - __main__ -   eval_precision = 0.3621\n",
      "05/05/2025 17:53:19 - INFO - __main__ -   eval_recall = 0.2784\n",
      "05/05/2025 17:53:19 - INFO - __main__ - patience greater than 5, early stop!\n",
      " 60% 611/1024 [17:57<12:08,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRmEZ2s_UdIf",
    "outputId": "1afc67f3-8cbc-4f4f-b07f-2bbbf123612a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:53:30.158979: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-05 17:53:30.176466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746467610.197913   59444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746467610.204588   59444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 17:53:30.226898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  22\n",
      "05/05/2025 17:53:33 - INFO - util - Loading model answerdotai/ModernBERT-large\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8413 > 8192). Running this sequence through the model will result in indexing errors\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "05/05/2025 17:56:17 - INFO - __main__ - ***** Test results *****\n",
      "05/05/2025 17:56:17 - INFO - __main__ -   auc_score = 0.8624\n",
      "05/05/2025 17:56:17 - INFO - __main__ -   test_f1 = 0.3935\n",
      "05/05/2025 17:56:17 - INFO - __main__ -   test_precision = 0.4861\n",
      "05/05/2025 17:56:17 - INFO - __main__ -   test_recall = 0.3305\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/modernbert-large/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model modernbert-large \\\n",
    "   --learning_rate 8e-5 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWb3pxuUILn_"
   },
   "source": [
    "### (IA)3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um1hy966lIHd",
    "outputId": "2bd1d060-0f26-4ee9-de8e-543fda6330cd"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9WBpDBVIqtF",
    "outputId": "eef22ecb-f469-49aa-b1b0-8bfcbcfb8a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 18:33:38.761970: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 18:33:38.780693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744569218.803131   94301 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744569218.809920   94301 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-13 18:33:38.832326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 344,064 || all params: 737,985,536 || trainable%: 0.0466\n",
      "04/13/2025 18:42:02 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:38<00:00,  1.17it/s]04/13/2025 18:58:57 - WARNING - __main__ - epoch 0 step 1024 loss 0.2968\n",
      "[[0.37818596]\n",
      " [0.1135315 ]\n",
      " [0.04852636]\n",
      " ...\n",
      " [0.06876238]\n",
      " [0.21502437]\n",
      " [0.12026493]]\n",
      "04/13/2025 19:01:05 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 19:01:05 - INFO - __main__ -   auc_score = 0.7376\n",
      "04/13/2025 19:01:05 - INFO - __main__ -   eval_f1 = 0.1109\n",
      "04/13/2025 19:01:05 - INFO - __main__ -   eval_precision = 0.5179\n",
      "04/13/2025 19:01:05 - INFO - __main__ -   eval_recall = 0.0621\n",
      "100% 1024/1024 [16:55<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 19:15:52 - WARNING - __main__ - epoch 1 step 1024 loss 0.25966\n",
      "[[0.5694021 ]\n",
      " [0.12889491]\n",
      " [0.04218939]\n",
      " ...\n",
      " [0.08430376]\n",
      " [0.27554595]\n",
      " [0.15992282]]\n",
      "04/13/2025 19:18:00 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 19:18:00 - INFO - __main__ -   auc_score = 0.7654\n",
      "04/13/2025 19:18:00 - INFO - __main__ -   eval_f1 = 0.1812\n",
      "04/13/2025 19:18:00 - INFO - __main__ -   eval_precision = 0.486\n",
      "04/13/2025 19:18:00 - INFO - __main__ -   eval_recall = 0.1113\n",
      "100% 1024/1024 [16:54<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 19:32:46 - WARNING - __main__ - epoch 2 step 1024 loss 0.25446\n",
      "[[0.58426744]\n",
      " [0.10793564]\n",
      " [0.04294454]\n",
      " ...\n",
      " [0.0981136 ]\n",
      " [0.26228547]\n",
      " [0.17659028]]\n",
      "04/13/2025 19:34:54 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 19:34:54 - INFO - __main__ -   auc_score = 0.7781\n",
      "04/13/2025 19:34:54 - INFO - __main__ -   eval_f1 = 0.1835\n",
      "04/13/2025 19:34:54 - INFO - __main__ -   eval_precision = 0.573\n",
      "04/13/2025 19:34:54 - INFO - __main__ -   eval_recall = 0.1092\n",
      "100% 1024/1024 [16:55<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 19:49:42 - WARNING - __main__ - epoch 3 step 1024 loss 0.24943\n",
      "[[0.59749985]\n",
      " [0.09990298]\n",
      " [0.0491618 ]\n",
      " ...\n",
      " [0.10103319]\n",
      " [0.2563252 ]\n",
      " [0.18230303]]\n",
      "04/13/2025 19:51:50 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 19:51:50 - INFO - __main__ -   auc_score = 0.7951\n",
      "04/13/2025 19:51:50 - INFO - __main__ -   eval_f1 = 0.172\n",
      "04/13/2025 19:51:50 - INFO - __main__ -   eval_precision = 0.5275\n",
      "04/13/2025 19:51:50 - INFO - __main__ -   eval_recall = 0.1028\n",
      "100% 1024/1024 [16:46<00:00,  1.02it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 20:06:28 - WARNING - __main__ - epoch 4 step 1024 loss 0.24451\n",
      "[[0.6028239 ]\n",
      " [0.11869967]\n",
      " [0.04470023]\n",
      " ...\n",
      " [0.07238077]\n",
      " [0.20427734]\n",
      " [0.13579454]]\n",
      "04/13/2025 20:08:36 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 20:08:36 - INFO - __main__ -   auc_score = 0.8147\n",
      "04/13/2025 20:08:36 - INFO - __main__ -   eval_f1 = 0.153\n",
      "04/13/2025 20:08:36 - INFO - __main__ -   eval_precision = 0.5942\n",
      "04/13/2025 20:08:36 - INFO - __main__ -   eval_recall = 0.0878\n",
      "100% 1024/1024 [16:46<00:00,  1.02it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 20:23:14 - WARNING - __main__ - epoch 5 step 1024 loss 0.23714\n",
      "[[0.6938236 ]\n",
      " [0.1162423 ]\n",
      " [0.05994752]\n",
      " ...\n",
      " [0.10544864]\n",
      " [0.2781641 ]\n",
      " [0.197613  ]]\n",
      "04/13/2025 20:25:22 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 20:25:22 - INFO - __main__ -   auc_score = 0.8361\n",
      "04/13/2025 20:25:22 - INFO - __main__ -   eval_f1 = 0.2018\n",
      "04/13/2025 20:25:22 - INFO - __main__ -   eval_precision = 0.5816\n",
      "04/13/2025 20:25:22 - INFO - __main__ -   eval_recall = 0.1221\n",
      "100% 1024/1024 [16:54<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 20:40:09 - WARNING - __main__ - epoch 6 step 1024 loss 0.23212\n",
      "[[0.71821404]\n",
      " [0.11901341]\n",
      " [0.06225045]\n",
      " ...\n",
      " [0.10635908]\n",
      " [0.2784072 ]\n",
      " [0.19703747]]\n",
      "04/13/2025 20:42:17 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 20:42:17 - INFO - __main__ -   auc_score = 0.8516\n",
      "04/13/2025 20:42:17 - INFO - __main__ -   eval_f1 = 0.21\n",
      "04/13/2025 20:42:17 - INFO - __main__ -   eval_precision = 0.6211\n",
      "04/13/2025 20:42:17 - INFO - __main__ -   eval_recall = 0.1263\n",
      "100% 1024/1024 [16:54<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 20:57:04 - WARNING - __main__ - epoch 7 step 1024 loss 0.22726\n",
      "[[0.7851685 ]\n",
      " [0.12164218]\n",
      " [0.06423592]\n",
      " ...\n",
      " [0.10708859]\n",
      " [0.32162172]\n",
      " [0.2134283 ]]\n",
      "04/13/2025 20:59:12 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 20:59:12 - INFO - __main__ -   auc_score = 0.8593\n",
      "04/13/2025 20:59:12 - INFO - __main__ -   eval_f1 = 0.2551\n",
      "04/13/2025 20:59:12 - INFO - __main__ -   eval_precision = 0.6198\n",
      "04/13/2025 20:59:12 - INFO - __main__ -   eval_recall = 0.1606\n",
      "100% 1024/1024 [16:55<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 21:14:00 - WARNING - __main__ - epoch 8 step 1024 loss 0.22247\n",
      "[[0.8035345 ]\n",
      " [0.12272363]\n",
      " [0.06853588]\n",
      " ...\n",
      " [0.11705483]\n",
      " [0.34611997]\n",
      " [0.229625  ]]\n",
      "04/13/2025 21:16:08 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 21:16:08 - INFO - __main__ -   auc_score = 0.8649\n",
      "04/13/2025 21:16:08 - INFO - __main__ -   eval_f1 = 0.266\n",
      "04/13/2025 21:16:08 - INFO - __main__ -   eval_precision = 0.622\n",
      "04/13/2025 21:16:08 - INFO - __main__ -   eval_recall = 0.1692\n",
      "100% 1024/1024 [16:54<00:00,  1.01it/s]\n",
      "100% 1023/1024 [14:37<00:00,  1.17it/s]04/13/2025 21:30:54 - WARNING - __main__ - epoch 9 step 1024 loss 0.22093\n",
      "[[0.80345404]\n",
      " [0.12294067]\n",
      " [0.06919591]\n",
      " ...\n",
      " [0.1180534 ]\n",
      " [0.3438474 ]\n",
      " [0.22957948]]\n",
      "04/13/2025 21:33:02 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 21:33:02 - INFO - __main__ -   auc_score = 0.8668\n",
      "04/13/2025 21:33:02 - INFO - __main__ -   eval_f1 = 0.2678\n",
      "04/13/2025 21:33:02 - INFO - __main__ -   eval_precision = 0.6423\n",
      "04/13/2025 21:33:02 - INFO - __main__ -   eval_recall = 0.1692\n",
      "100% 1024/1024 [16:55<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99Rg1DlN0hfY",
    "outputId": "4201c551-a8ef-4f47-ddfd-ca79193e2856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 21:41:27.432695: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 21:41:27.451491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744580487.473989  164221 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744580487.480801  164221 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-13 21:41:27.503587: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 344,064 || all params: 737,985,536 || trainable%: 0.0466\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "r1 =  0.12631578947368421\n",
      "recall =  0.12631578947368421\n",
      "04/13/2025 21:52:52 - INFO - __main__ - ***** Test results *****\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   R0 = 0.9906\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   R1 = 0.1263\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   auc_score = 0.817\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   g_mean = 0.3537\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   test_f1 = 0.2062\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   test_precision = 0.5607\n",
      "04/13/2025 21:52:52 - INFO - __main__ -   test_recall = 0.1263\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d65uvdIKMOqj"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4EaQbusMZLN",
    "outputId": "d8f62a81-a6a1-4ba5-b73d-640b570904df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13 22:07:44.291189: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 22:07:44.310134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744582064.333342  173947 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744582064.340365  173947 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-13 22:07:44.363931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Seed =  33\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "trainable params: 147,456 || all params: 737,788,928 || trainable%: 0.0200\n",
      "04/13/2025 22:16:22 - INFO - __main__ - Training for the first time...\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py:277: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "100% 1023/1024 [14:17<00:00,  1.19it/s]04/13/2025 22:32:57 - WARNING - __main__ - epoch 0 step 1024 loss 0.29787\n",
      "[[0.52331614]\n",
      " [0.11410848]\n",
      " [0.03472976]\n",
      " ...\n",
      " [0.05371829]\n",
      " [0.21441811]\n",
      " [0.14510804]]\n",
      "04/13/2025 22:35:03 - INFO - __main__ - ***** Eval results *****\n",
      "04/13/2025 22:35:03 - INFO - __main__ -   auc_score = 0.751\n",
      "04/13/2025 22:35:03 - INFO - __main__ -   eval_f1 = 0.1672\n",
      "04/13/2025 22:35:03 - INFO - __main__ -   eval_precision = 0.4486\n",
      "04/13/2025 22:35:03 - INFO - __main__ -   eval_recall = 0.1028\n",
      "100% 1024/1024 [16:32<00:00,  1.03it/s]\n",
      " 33% 341/1024 [04:45<09:32,  1.19it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIKOhp3T3fz0"
   },
   "source": [
    "#### Repeating the training with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6OWoy-64b_n"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#seeds = random.sample(range(101), 4)\n",
    "seeds = [23, 99, 72, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3aKe12P5Iv2",
    "outputId": "30900989-b53a-41e7-ad52-09bcbf3d31f0"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeIe7I5m4lzK"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12z0Pg4l4vyN"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[0]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICCv3i2j5LHp"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkRjJtFR401H"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFMqiVfA42xP"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[1]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXdzKdYG5OfI"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_39In9-45CC"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Tw7VSIc48cG"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[2]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOu4bpgm5Qnf"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSTgMbts4-qg"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFkW_Tja5CFU"
   },
   "outputs": [],
   "source": [
    "!python PEFT4CC/just-in-time/run_ia3.py \\\n",
    "   --train_data_file {path}/changes_train_lst.pkl {path}/features_train.pkl \\\n",
    "   --eval_data_file {path}/changes_valid_lst.pkl {path}/features_valid.pkl \\\n",
    "   --test_data_file {path}/changes_test_lst.pkl {path}/features_test.pkl \\\n",
    "   --output_dir /content/drive/MyDrive/PEFT4CC/results/jitfine/ia3/concat/checkpoints \\\n",
    "   --seed {seeds[3]} \\\n",
    "   --pretrained_model codet5p-770m \\\n",
    "   --learning_rate 1e-4 \\\n",
    "   --epochs 10 \\\n",
    "   --batch_size 16 \\\n",
    "   --hidden_size 1024 \\\n",
    "   --do_test \\\n",
    "   --calculate_metrics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nis054awwn4G",
    "_mE13J3skSyy",
    "H7y1reehqIw0",
    "_czhedGwb-Cr",
    "msJhwt1bKOLp",
    "3sXz45ErKSnb",
    "leR4hSYoLh_r",
    "UwjTahocLnlw",
    "ZTZbnb2iNEzt",
    "KpWyaGcsMSD1",
    "gTeCY-hd38hS",
    "5BfAE9yNdkTj",
    "kTz53-EDdoPI",
    "kuj21f92Ts-D",
    "1qyWxD7em-tL",
    "mZYrMBVTnF4h",
    "33WC8ZVkVsAM",
    "6Oq-1dx8V59m",
    "3_p4mUZbXRuw",
    "iCkAoHe9wmj8",
    "skkk2YvJwucF",
    "vrAsoy4d-vzR",
    "NytUBovl_ICQ",
    "rV9186WLf4U0",
    "T6hfQ4XZVOJN",
    "QgkIqgdUxYAd",
    "AOG-dZQrrW3l",
    "a2HzIrHeceY9",
    "-YFCBiFMagBv",
    "7OUjQ0MFCRY5",
    "q3ntkgnVCOmj",
    "sPNIkzGz1js_",
    "46HcX9M8xdFx",
    "JeGXes6BBUAI",
    "Hx7um0A00IUY",
    "eBhLVH9qy6Lm",
    "nsSGBjVlF0S_",
    "J9knfzBp79BK",
    "rTolI6o2L_Ch",
    "4Q8UVhjdUMu4",
    "wiBQ7c9NzsHY",
    "bMGkS8ZhNvak",
    "wgtOF9zokxVR",
    "GNcBnEpUSXoV",
    "SPcKAYlmGPwl"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
